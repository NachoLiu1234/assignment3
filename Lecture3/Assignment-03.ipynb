{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-03 First Step of Machine Learning: Model and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同学们，今天我们的学习了基本的机器学习概念，相比你已经对机器学习的这些方法有一个基本的认识了。值得说明的是，机器学习不仅仅是一系列方法，更重要的是一种思维体系，即：依据以往的、现有的数据，构建某种方法来解决未见过的问题。而且决策树，贝叶斯只是实现这个目标的一个方法，包括之后的神经网络。很有可能有一天，神经网络也会被淘汰，但是重要的是我们要理解机器学习的目标，就是尽可能的自动化解决未知的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1571556399207&di=4a97dc15ad08dd49d3748d1edf6109b3&imgtype=0&src=http%3A%2F%2Fc.hiphotos.baidu.com%2Fzhidao%2Fwh%3D450%2C600%2Fsign%3Dae742c6aedcd7b89e93932873a146e91%2F5d6034a85edf8db1b16050c40223dd54574e74c7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1 Programming Review 编程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Re-code the Linear-Regression Model using scikit-learning(10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>： \n",
    "> + 是否完成线性回归模型 (4')\n",
    "+ 能够进行预测新数据(3')\n",
    "+ 能够进行可视化操作(3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b7decd2c18>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1,30, 100)\n",
    "y = [el * 12 + 4+ random.random() * 100 for el in x]\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.35000019])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.59878020072853"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = [el * reg.coef_ + reg.intercept_ for el in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19cf9cbf2e8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y_hat)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    return x * reg.coef_ + reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 [197.79878242]\n"
     ]
    }
   ],
   "source": [
    "print(12, predict(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Complete the unfinished KNN Model using pure python to solve the previous Line-Regression problem. (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>:\n",
    "> + 是否完成了KNN模型 (4')\n",
    "+ 是否能够预测新的数据 (4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "from scipy.spatial.distance import cosine\n",
    "def distance(x1, x2):\n",
    "    return cosine(x1, x2)\n",
    "def model(x, y):\n",
    "    return list(zip(x, y))\n",
    "def predict(x_2, k=5):\n",
    "    m = model(x, y)\n",
    "    sorted_m = sorted(m, key=lambda xi: distance(xi[0], x_2))\n",
    "    print(sorted_m[:k])\n",
    "    return sum([el[1] for el in sorted_m[:k]]) / k\n",
    "\n",
    "\n",
    "m = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.878787878787879, 30.421222513369734), (2.757575757575758, 115.71597262920216), (6.858585858585858, 109.99983156828752), (7.151515151515151, 115.83059347081625), (8.90909090909091, 164.1610730868851)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107.22573865371214"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(5.123456, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 想问一下老师, 这是上课的代码的东西, 为什么这里的distance不用欧氏距离, 而是要用from scipy.spatial.distance import cosine的 $$ 1 - {u ·v / ||u||_2 ||v||_2} $$ , 这个公式的几何意义是什么啊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Re-code the Decision Tree, which could sort the features by salience. (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否实现了信息熵 (1' )\n",
    "+ 是否实现了最优先特征点的选择(5')\n",
    "+ 是否实现了持续的特征选则(6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "mock_data = {\n",
    "    'gender':['F', 'F', 'F', 'F', 'M', 'M', 'M'],\n",
    "    'income': ['+10', '-10', '+10', '+10', '+10', '+10', '-10'],\n",
    "    'family_number': [1, 1, 2, 1, 1, 1, 2],\n",
    "    'bought': [1, 1, 1, 0, 0, 0, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>family_number</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender income  family_number  bought\n",
       "0      F    +10              1       1\n",
       "1      F    -10              1       1\n",
       "2      F    +10              2       1\n",
       "3      F    +10              1       0\n",
       "4      M    +10              1       0\n",
       "5      M    +10              1       0\n",
       "6      M    -10              2       1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame.from_dict(mock_data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def entropy(lis):\n",
    "    length = len(lis)\n",
    "    counter = Counter(lis)\n",
    "    lis  = [counter[el] / length for el in lis]\n",
    "    return -sum([el * np.log(el) for el in lis])\n",
    "entropy([1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "devide_set = set(dataset.columns)\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('family_number',), ('family_number', 'gender'), ('family_number', 'income'), ('family_number', 'income', 'bought'), ('family_number', 'income', 'bought', 'gender')]\n",
      "{'family_number': {'gender': {}, 'income': {'bought': {'gender': {}}}}}\n"
     ]
    }
   ],
   "source": [
    "def decision_tree(dataset):\n",
    "    def get_column(data, columns):\n",
    "        entropy_dic = {}\n",
    "        for column in columns:\n",
    "            status = list(set(data[column]))\n",
    "            sum_entropy = 0\n",
    "            for i in range(len(status)):\n",
    "                sum_entropy += entropy(data[data[column] == status[i]])\n",
    "            entropy_dic[column] = sum_entropy\n",
    "        entropy_dic = sorted([(k, v) for k, v in entropy_dic.items()], key=lambda x: x[1])\n",
    "        return entropy_dic[0][0]\n",
    "    \n",
    "    dataset = [([], dataset)]  # [([('family_number', 1), ('income', '+10'), ], dataset)]\n",
    "    finished_dataset = []\n",
    "    \n",
    "    while len(dataset):\n",
    "        dataset_tuple = dataset.pop(-1)  # ([('family_number', 1), ('income', '+10'), ], dataset)\n",
    "        data = dataset_tuple[1]  # dataset\n",
    "        column_path = dataset_tuple[0]  # [('family_number', '1'), ('income', '+10'), ]\n",
    "        \n",
    "        if devide_set - set([path[0] for path in column_path]) == set():\n",
    "            finished_dataset.append(dataset_tuple)\n",
    "            continue\n",
    "        column = get_column(data, devide_set - set([path[0] for path in column_path]))\n",
    "        values = set(data[column])\n",
    "        for value in values:\n",
    "            sub_data= data[data[column] == value]\n",
    "            new_column_path = column_path.copy()\n",
    "            new_column_path.append((column, value))\n",
    "            new_dataset_tuple = [new_column_path, sub_data]\n",
    "            if len(sub_data) <= 1:\n",
    "                finished_dataset.append(new_dataset_tuple)\n",
    "            else:\n",
    "                dataset.append(new_dataset_tuple)\n",
    "    \n",
    "    temp_set = set()  # [('family_number',), ('family_number', 'gender'), ('family_number', 'income'), ('family_number', 'income', 'bought'), ('family_number', 'income', 'bought', 'gender')]\n",
    "    for el in [el[0] for el in finished_dataset]:  # [('family_number', 2), ('gender', 'M')]\n",
    "        lis = [e[0] for e in el]  # ['family_number', 'income', 'bought', 'gender']\n",
    "        for i in range(len(lis)):\n",
    "            temp_set.add(tuple(lis[:i + 1]))\n",
    "            \n",
    "    return_dict = {}\n",
    "    temp_set= sorted(list(temp_set), key=lambda x: len(x))\n",
    "    for el in temp_set:\n",
    "        sub_return_dict  = return_dict\n",
    "        for sub_el in el:\n",
    "            if not sub_el in sub_return_dict:\n",
    "                sub_return_dict[sub_el] = {}\n",
    "            sub_return_dict = sub_return_dict[sub_el]\n",
    "    print(temp_set)\n",
    "    print(return_dict)\n",
    "    \n",
    "decision_tree(dataset)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Finish the K-Means using 2-D matplotlib (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否完成了KMeans模型，基于scikit-learning (3')\n",
    "+ 是否完成了可视化任务（5'）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [random.random() * 20 for _ in range(50)]\n",
    "X.extend([random.random() * 20 + 25 for _ in range(50)])\n",
    "random.shuffle(X)\n",
    "Y = [random.random() * 20 for _ in range(50)]\n",
    "Y.extend([random.random() * 20 + 25 for _ in range(50)])\n",
    "random.shuffle(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(x, y) for x, y in zip(X, Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19cf9d098d0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KMeans(n_clusters=4, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "    n_clusters=4, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36.39883433, 35.04879992],\n",
       "       [11.02747127, 33.78581585],\n",
       "       [32.68585332,  9.2211975 ],\n",
       "       [11.41340157, 10.00262044]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 2, 0, 2, 3, 0, 0, 1, 2, 2, 0, 1, 2, 3, 0, 3, 3, 0, 1,\n",
       "       1, 3, 2, 0, 0, 2, 1, 2, 2, 2, 0, 1, 2, 2, 0, 1, 1, 0, 1, 0, 3, 0,\n",
       "       1, 0, 3, 0, 2, 3, 1, 0, 3, 3, 2, 1, 2, 2, 0, 2, 1, 1, 3, 3, 3, 3,\n",
       "       0, 2, 3, 1, 0, 0, 3, 3, 3, 1, 2, 0, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3,\n",
       "       1, 1, 2, 3, 0, 2, 2, 1, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['red', 'yellow', 'blue', 'green']\n",
    "label = [0,1,2,3]\n",
    "color = {k: v for k, v in zip(label, color)}\n",
    "data_label = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_data, lable in zip(data, cluster.labels_):\n",
    "    data_label.setdefault(lable, []).append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19cf9d54278>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, dataset in data_label.items():\n",
    "    x = [el[0] for el in dataset]\n",
    "    y = [el[1] for el in dataset]\n",
    "    plt.scatter(x, y, c=color[label])\n",
    "centers_x = [el[0] for el in cluster.cluster_centers_]\n",
    "centers_y = [el[1] for el in cluster.cluster_centers_]\n",
    "plt.scatter(centers_x, centers_y, c=[v for v in color.values()], s=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2 Question and Answer 问答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What's the *model*? why  all the models are wrong, but some are useful? (5 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:模型是一个可以把输入数据转换成输出数据的东西. 因为不存在一个模型可以表示所有的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对模型的理解是否正确,对模型的抽象性是否正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the underfitting and overfitting? List the reasons that could make model overfitting or underfitting. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:过拟合是对训练集的预测准确率过于高, 预测集过于低, 欠拟合在两个数据集都较低, 过拟合原因: 模型过于复杂, 数据量少, 数据集片面, 欠拟合原因: 模型过于简单, 模型训练次数过少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对过拟合和欠拟合的理解是否正确 (3')\n",
    "+ 对欠拟合产生的原因是否理解正确(2')\n",
    "+ 对过拟合产生的原因是否理解正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What's the precision, recall, AUC, F1, F2score. What are they mainly target on? (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:precision:tp/所有的预测为t的数据, recall: tp/所有实际为p的数据, AUC: 在presision和recall曲线下面的面积, F1: 2*precision *recall / (precision+ recall), F2score 5*precision *recall / (4 * precision+ recall), F2属于Fβ, 是加权的准确率和召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 老师, precision和recall我这么理解有没有问题啊, 我看这两个的公式表达的其实是这个意思"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对precision, recall, AUC, F1, F2 理解是否正确(6‘)\n",
    "+ 对precision, recall, AUC, F1, F2的使用侧重点是否理解正确 (6’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Based on our course and yourself mind, what's the machine learning?  (8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:通过一个黑盒子, 让这个黑盒子自动学习输入的数据, 然后以后再输入没有标签的数据时, 可以自动判断标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，是否能说出来机器学习这种思维方式和传统的分析式编程的区别（8'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. \"正确定义了机器学习模型的评价标准(evaluation)， 问题基本上就已经解决一半\". 这句话是否正确？你是怎么看待的？ (8‘)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评价标准很重要, 很多二分类的结果并不是1比1的, 不能用判断对的比例来评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，主要看能理解评价指标对机器学习模型的重要性."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-03 Programming Practice 编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our course and previous practice, we complete some importance components of Decision Tree. In this problem, you need to build a **completed** Decision Tree Model. You show finish a `predicate()` function, which accepts three parameters **<gender, income, family_number>**, and outputs the predicated 'bought': 1 or 0.  (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "from collections import deque\n",
    "\n",
    "mock_data = {\n",
    "    'gender':['F', 'F', 'F', 'F', 'M', 'M', 'M'],\n",
    "    'income': ['+10', '-10', '+10', '+10', '+10', '+10', '-10'],\n",
    "    'family_number': [1, 1, 2, 1, 1, 1, 2],\n",
    "    'bought': [1, 1, 1, 0, 0, 0, 1],\n",
    "}\n",
    "\n",
    "dataset = pd.DataFrame.from_dict(mock_data)\n",
    "from collections import Counter\n",
    "\n",
    "def entropy(lis):\n",
    "    length = len(lis)\n",
    "    counter = Counter(lis)\n",
    "    lis  = [counter[el] / length for el in lis]\n",
    "    return -sum([el * np.log(el) for el in lis])\n",
    "\n",
    "\n",
    "def decision_tree_model(dataset):\n",
    "    devide_set = set(dataset.columns) - {'bought'}\n",
    "\n",
    "    def get_column(data, columns):\n",
    "        entropy_dic = {}\n",
    "        for column in columns:\n",
    "            status = list(set(data[column]))\n",
    "            sum_entropy = 0\n",
    "            for i in range(len(status)):\n",
    "                sum_entropy += entropy(data[data[column] == status[i]])\n",
    "            entropy_dic[column] = sum_entropy\n",
    "        entropy_dic = sorted([(k, v) for k, v in entropy_dic.items()], key=lambda x: x[1])\n",
    "        return entropy_dic[0][0]\n",
    "    \n",
    "    dataset = [([], dataset)]  # [([('family_number', 1), ('income', '+10'), ], dataset)]\n",
    "    finished_dataset = []\n",
    "    \n",
    "    while len(dataset):\n",
    "        dataset_tuple = dataset.pop(-1)  # ([('family_number', 1), ('income', '+10'), ], dataset)\n",
    "        data = dataset_tuple[1]  # dataset\n",
    "        column_path = dataset_tuple[0]  # [('family_number', '1'), ('income', '+10'), ]\n",
    "        \n",
    "        if devide_set - set([path[0] for path in column_path]) == set():\n",
    "            finished_dataset.append(dataset_tuple)\n",
    "            continue\n",
    "        column = get_column(data, devide_set - set([path[0] for path in column_path]))\n",
    "        values = set(data[column])\n",
    "        for value in values:\n",
    "            sub_data= data[data[column] == value]\n",
    "            new_column_path = column_path.copy()\n",
    "            new_column_path.append((column, value))\n",
    "            new_dataset_tuple = [new_column_path, sub_data]\n",
    "            if len(sub_data) <= 1:\n",
    "                finished_dataset.append(new_dataset_tuple)\n",
    "            else:\n",
    "                dataset.append(new_dataset_tuple)\n",
    "    \n",
    "    model = {}\n",
    "    for data in finished_dataset:\n",
    "        result = np.average(data[1]['bought'])\n",
    "        data =data[0]\n",
    "        sub_model = model\n",
    "        for el in data:\n",
    "            key = el[0] + '_' + str(el[1])\n",
    "            if key not in sub_model:\n",
    "                sub_model[key] = {}\n",
    "            sub_model = sub_model[key]\n",
    "        sub_model['result'] = result\n",
    "    \n",
    "    return model\n",
    "model = decision_tree_model(dataset)\n",
    "\n",
    "\n",
    "def predict(gender, income, family_number):\n",
    "    key_1 = 'gender_' + gender\n",
    "    key_2 = 'income_' + income\n",
    "    key_3 = 'family_number_' + str(family_number)\n",
    "    \n",
    "    key_set = set()\n",
    "    key_set.update([key_1, key_2, key_3])\n",
    "    sub_model = model\n",
    "    while 1:\n",
    "        in_model = False\n",
    "        for key in key_set:\n",
    "            if key in sub_model:\n",
    "                in_model = True\n",
    "                sub_model = sub_model[key]\n",
    "        if not in_model:\n",
    "            break\n",
    "    return sub_model['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family_number': {1: {'income': {'-10': 1,\n",
       "    '+10': {'gender': {'F': 0.5, 'M': 0}}}},\n",
       "  2: {'gender': {'M': 1, 'F': 1}}}}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'family_number': {\n",
    "        1: {\n",
    "            'income': {\n",
    "                '-10': 1, \n",
    "                '+10': {\n",
    "                    'gender': {\n",
    "                        'F': 0.5, \n",
    "                        'M': 0\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }, \n",
    "        2: {\n",
    "            'gender': {\n",
    "                'M': 1, \n",
    "                'F': 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family_number_1': {'income_-10': 1,\n",
       "  'income_+10': {'gender_F': 0.5, 'gender_M': 0},\n",
       "  'family_number_2': {'gender_M': 1, 'gender_F': 1}}}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'family_number_1': {\n",
    "        'income_-10': 1, \n",
    "        'income_+10': {\n",
    "            'gender_F': 0.5, \n",
    "            'gender_M': 0\n",
    "    }, \n",
    "    'family_number_2': {\n",
    "        'gender_M': 1, \n",
    "        'gender_F': 1\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family_number_2': {'gender_M': {'result': 1.0}, 'gender_F': {'result': 1.0}},\n",
       " 'family_number_1': {'income_-10': {'result': 1.0},\n",
       "  'income_+10': {'gender_F': {'result': 0.5}, 'gender_M': {'result': 0.0}}}}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('M', '-10', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('F', '+10', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('M', '+10', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否将之前的决策树模型的部分进行合并组装， predicate函数能够顺利运行(8')\n",
    "+ 是够能够输入未曾见过的X变量，例如gender, income, family_number 分别是： <M, -10, 1>, 模型能够预测出结果 (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 将上一节课(第二节课)的线性回归问题中的Loss函数改成\"绝对值\"，并且改变其偏导的求值方式，观察其结果的变化。(19 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{|y_i - \\hat{y_i}|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{\\sqrt{(y_i - kx_i - b_i)^2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{\\sqrt{y_i^2 + k^2x_i^2 + b_i^2 - 2y_ix_ik - 2y_ib_i + 2kx_ib_i}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac {\\partial{loss}} {\\partial{k}} = -\\frac{2}{n}\\sum{\\frac{y-\\hat{y}}{\\sqrt{(y-\\hat{y})^2}}x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac {\\partial{loss}} {\\partial{b}} = -\\frac{2}{n}\\sum{\\frac{y-\\hat{y}}{\\sqrt{(y-\\hat{y})^2}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dataset['data'],dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rm = x[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target function\n",
    "def price(rm, k, b):\n",
    "    return k * rm + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function \n",
    "def loss(y,y_hat):\n",
    "    return sum(np.abs(y_i - y_hat_i) for y_i, y_hat_i in zip(list(y),list(y_hat)))/len(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partial derivative \n",
    "def partial_derivative_k(x, y, y_hat):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        gradient += (y_i-y_hat_i) * x_i / np.abs(y_i - y_hat_i)\n",
    "    return -2/n * gradient\n",
    "\n",
    "def partial_derivative_b(y, y_hat):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for y_i, y_hat_i in zip(list(y),list(y_hat)):\n",
    "        gradient += (y_i-y_hat_i) / np.abs(y_i - y_hat_i)\n",
    "    return -2 / n * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, the loss is 10.234130434782614, parameters k is 10 and b is -50\n",
      "Iteration 1, the loss is 10.176391543157314, parameters k is 10.010610802371541 and b is -49.99830039525692\n",
      "Iteration 2, the loss is 10.118834688926214, parameters k is 10.021221604743083 and b is -49.99660079051384\n",
      "Iteration 3, the loss is 10.061632313752714, parameters k is 10.031782992094861 and b is -49.9949090909091\n",
      "Iteration 4, the loss is 10.004429938579207, parameters k is 10.04234437944664 and b is -49.993217391304356\n",
      "Iteration 5, the loss is 9.947227563405718, parameters k is 10.052905766798418 and b is -49.991525691699614\n",
      "Iteration 6, the loss is 9.89002518823222, parameters k is 10.063467154150196 and b is -49.98983399209487\n",
      "Iteration 7, the loss is 9.832822813058723, parameters k is 10.074028541501974 and b is -49.98814229249013\n",
      "Iteration 8, the loss is 9.775687368260263, parameters k is 10.084589928853752 and b is -49.98645059288539\n",
      "Iteration 9, the loss is 9.719575078588301, parameters k is 10.095056944664028 and b is -49.98477470355733\n",
      "Iteration 10, the loss is 9.663954219839669, parameters k is 10.105471335968376 and b is -49.983106719367605\n",
      "Iteration 11, the loss is 9.608333361091058, parameters k is 10.115885727272724 and b is -49.98143873517788\n",
      "Iteration 12, the loss is 9.552712502342445, parameters k is 10.126300118577072 and b is -49.97977075098816\n",
      "Iteration 13, the loss is 9.497091643593816, parameters k is 10.13671450988142 and b is -49.978102766798436\n",
      "Iteration 14, the loss is 9.4414707848452, parameters k is 10.147128901185768 and b is -49.97643478260871\n",
      "Iteration 15, the loss is 9.385870945947582, parameters k is 10.157543292490116 and b is -49.97476679841899\n",
      "Iteration 16, the loss is 9.330883442790332, parameters k is 10.167907501976282 and b is -49.97310671936761\n",
      "Iteration 17, the loss is 9.276434696616343, parameters k is 10.178220011857706 and b is -49.97145454545456\n",
      "Iteration 18, the loss is 9.222385015184003, parameters k is 10.188487090909089 and b is -49.96981027667986\n",
      "Iteration 19, the loss is 9.16885601985921, parameters k is 10.198703758893279 and b is -49.96817391304349\n",
      "Iteration 20, the loss is 9.115327024534407, parameters k is 10.20892042687747 and b is -49.96653754940713\n",
      "Iteration 21, the loss is 9.061798029209617, parameters k is 10.21913709486166 and b is -49.96490118577076\n",
      "Iteration 22, the loss is 9.00827325281, parameters k is 10.22935376284585 and b is -49.9632648221344\n",
      "Iteration 23, the loss is 8.955268031214409, parameters k is 10.239520304347826 and b is -49.96163636363637\n",
      "Iteration 24, the loss is 8.902262809618813, parameters k is 10.249686845849801 and b is -49.96000790513835\n",
      "Iteration 25, the loss is 8.84929132904731, parameters k is 10.259853387351777 and b is -49.95837944664032\n",
      "Iteration 26, the loss is 8.796888400900807, parameters k is 10.269972260869563 and b is -49.956758893280636\n",
      "Iteration 27, the loss is 8.744886566373973, parameters k is 10.280042422924899 and b is -49.95514624505929\n",
      "Iteration 28, the loss is 8.69364729551761, parameters k is 10.290061328063238 and b is -49.95354150197628\n",
      "Iteration 29, the loss is 8.643025392965805, parameters k is 10.300029442687745 and b is -49.951944664031615\n",
      "Iteration 30, the loss is 8.593186265362897, parameters k is 10.30989879051383 and b is -49.95036363636363\n",
      "Iteration 31, the loss is 8.543701224638621, parameters k is 10.319721996047427 and b is -49.94879051383399\n",
      "Iteration 32, the loss is 8.49421618391435, parameters k is 10.329545201581023 and b is -49.94721739130435\n",
      "Iteration 33, the loss is 8.444731143190065, parameters k is 10.33936840711462 and b is -49.94564426877471\n",
      "Iteration 34, the loss is 8.39524610246579, parameters k is 10.349191612648216 and b is -49.944071146245065\n",
      "Iteration 35, the loss is 8.345927338778965, parameters k is 10.359014818181812 and b is -49.94249802371542\n",
      "Iteration 36, the loss is 8.297421995266273, parameters k is 10.368740324110666 and b is -49.94094071146246\n",
      "Iteration 37, the loss is 8.248982063339993, parameters k is 10.37846583003952 and b is -49.9393833992095\n",
      "Iteration 38, the loss is 8.20144384824849, parameters k is 10.388096814229243 and b is -49.93784189723321\n",
      "Iteration 39, the loss is 8.154926746624286, parameters k is 10.397630786561258 and b is -49.93631620553361\n",
      "Iteration 40, the loss is 8.109305176074947, parameters k is 10.407065620553354 and b is -49.93480632411068\n",
      "Iteration 41, the loss is 8.064122664380951, parameters k is 10.416452264822128 and b is -49.933304347826095\n",
      "Iteration 42, the loss is 8.01894015268696, parameters k is 10.425838909090903 and b is -49.93180237154151\n",
      "Iteration 43, the loss is 7.973967205809346, parameters k is 10.435225553359677 and b is -49.93030039525692\n",
      "Iteration 44, the loss is 7.929773688462945, parameters k is 10.44450878260869 and b is -49.928814229249014\n",
      "Iteration 45, the loss is 7.885580171116557, parameters k is 10.453792011857702 and b is -49.927328063241106\n",
      "Iteration 46, the loss is 7.841389096842497, parameters k is 10.463075241106715 and b is -49.9258418972332\n",
      "Iteration 47, the loss is 7.797676120042159, parameters k is 10.47230783003952 and b is -49.92436363636363\n",
      "Iteration 48, the loss is 7.754021641930699, parameters k is 10.481540418972326 and b is -49.92288537549406\n",
      "Iteration 49, the loss is 7.7109082672664915, parameters k is 10.490725766798413 and b is -49.92141501976283\n",
      "Iteration 50, the loss is 7.668317383902053, parameters k is 10.499861335968372 and b is -49.91995256916995\n",
      "Iteration 51, the loss is 7.6260347176268075, parameters k is 10.508941513833985 and b is -49.91849802371541\n",
      "Iteration 52, the loss is 7.5838608496148066, parameters k is 10.518021691699598 and b is -49.917043478260865\n",
      "Iteration 53, the loss is 7.542205224723773, parameters k is 10.527059071146239 and b is -49.91559683794466\n",
      "Iteration 54, the loss is 7.5007958276070585, parameters k is 10.536045106719362 and b is -49.9141581027668\n",
      "Iteration 55, the loss is 7.459386430490321, parameters k is 10.545031142292485 and b is -49.912719367588934\n",
      "Iteration 56, the loss is 7.4179770333735915, parameters k is 10.554017177865608 and b is -49.91128063241107\n",
      "Iteration 57, the loss is 7.376705820623216, parameters k is 10.563003213438732 and b is -49.90984189723321\n",
      "Iteration 58, the loss is 7.336164305298425, parameters k is 10.571894687747033 and b is -49.90841897233202\n",
      "Iteration 59, the loss is 7.295640846175479, parameters k is 10.580786162055333 and b is -49.90699604743084\n",
      "Iteration 60, the loss is 7.255758703436488, parameters k is 10.589622490118574 and b is -49.90558102766799\n",
      "Iteration 61, the loss is 7.216201505761091, parameters k is 10.598405110671933 and b is -49.904173913043486\n",
      "Iteration 62, the loss is 7.176997350499104, parameters k is 10.607187731225293 and b is -49.90276679841898\n",
      "Iteration 63, the loss is 7.139443414138158, parameters k is 10.61577635968379 and b is -49.90139130434783\n",
      "Iteration 64, the loss is 7.102541941666835, parameters k is 10.624261873517783 and b is -49.900031620553364\n",
      "Iteration 65, the loss is 7.066072610954206, parameters k is 10.632694628458495 and b is -49.898679841897234\n",
      "Iteration 66, the loss is 7.029789006893075, parameters k is 10.641127383399207 and b is -49.897328063241105\n",
      "Iteration 67, the loss is 6.993800041495196, parameters k is 10.649513600790511 and b is -49.895984189723315\n",
      "Iteration 68, the loss is 6.95814997408841, parameters k is 10.657851185770749 and b is -49.89464822134387\n",
      "Iteration 69, the loss is 6.922499906681639, parameters k is 10.666188770750987 and b is -49.89331225296443\n",
      "Iteration 70, the loss is 6.886925843258803, parameters k is 10.674526355731224 and b is -49.891976284584985\n",
      "Iteration 71, the loss is 6.851770164182974, parameters k is 10.682816462450592 and b is -49.89064822134388\n",
      "Iteration 72, the loss is 6.816923732231012, parameters k is 10.691059644268774 and b is -49.889328063241116\n",
      "Iteration 73, the loss is 6.782313635164013, parameters k is 10.699302826086956 and b is -49.88800790513835\n",
      "Iteration 74, the loss is 6.748719298687687, parameters k is 10.707396521739131 and b is -49.886711462450606\n",
      "Iteration 75, the loss is 6.715124962211369, parameters k is 10.715490217391306 and b is -49.88541501976286\n",
      "Iteration 76, the loss is 6.681530625735054, parameters k is 10.72358391304348 and b is -49.884118577075114\n",
      "Iteration 77, the loss is 6.647945599601424, parameters k is 10.731677608695655 and b is -49.88282213438737\n",
      "Iteration 78, the loss is 6.614765551083053, parameters k is 10.739721225296446 and b is -49.88153359683796\n",
      "Iteration 79, the loss is 6.581585502564673, parameters k is 10.747764841897236 and b is -49.880245059288555\n",
      "Iteration 80, the loss is 6.548405454046307, parameters k is 10.755808458498027 and b is -49.87895652173915\n",
      "Iteration 81, the loss is 6.515362998140299, parameters k is 10.763852075098818 and b is -49.87766798418974\n",
      "Iteration 82, the loss is 6.483023716932023, parameters k is 10.771793027667988 and b is -49.876395256917014\n",
      "Iteration 83, the loss is 6.45068443572375, parameters k is 10.779733980237157 and b is -49.87512252964429\n",
      "Iteration 84, the loss is 6.41838295008494, parameters k is 10.787674932806327 and b is -49.87384980237156\n",
      "Iteration 85, the loss is 6.386420296095584, parameters k is 10.79556958498024 and b is -49.87258498023717\n",
      "Iteration 86, the loss is 6.354457642106227, parameters k is 10.803464237154154 and b is -49.87132015810278\n",
      "Iteration 87, the loss is 6.322494988116878, parameters k is 10.811358889328067 and b is -49.870055335968395\n",
      "Iteration 88, the loss is 6.290628818019503, parameters k is 10.81925354150198 and b is -49.86879051383401\n",
      "Iteration 89, the loss is 6.259148805020715, parameters k is 10.827106478260873 and b is -49.86753359683796\n",
      "Iteration 90, the loss is 6.227949930411137, parameters k is 10.834906332015814 and b is -49.86628458498025\n",
      "Iteration 91, the loss is 6.196751055801555, parameters k is 10.842706185770755 and b is -49.86503557312254\n",
      "Iteration 92, the loss is 6.165552181191971, parameters k is 10.850506039525696 and b is -49.86378656126483\n",
      "Iteration 93, the loss is 6.1343533065824, parameters k is 10.858305893280637 and b is -49.86253754940712\n",
      "Iteration 94, the loss is 6.103154431972822, parameters k is 10.866105747035578 and b is -49.86128853754941\n",
      "Iteration 95, the loss is 6.0721889462576115, parameters k is 10.873905600790518 and b is -49.860039525691704\n",
      "Iteration 96, the loss is 6.041874424419043, parameters k is 10.881608853754946 and b is -49.858806324110674\n",
      "Iteration 97, the loss is 6.01194127390389, parameters k is 10.88924854940712 and b is -49.85758102766798\n",
      "Iteration 98, the loss is 5.9821469140886805, parameters k is 10.896888245059293 and b is -49.85635573122529\n",
      "Iteration 99, the loss is 5.952816625949802, parameters k is 10.9044788339921 and b is -49.85513833992094\n",
      "Iteration 100, the loss is 5.924181861650649, parameters k is 10.911963968379451 and b is -49.853936758893276\n",
      "Iteration 101, the loss is 5.895817297656835, parameters k is 10.919400652173918 and b is -49.85274308300395\n",
      "Iteration 102, the loss is 5.867452733663012, parameters k is 10.926837335968385 and b is -49.851549407114625\n",
      "Iteration 103, the loss is 5.839216999662762, parameters k is 10.934274019762851 and b is -49.8503557312253\n",
      "Iteration 104, the loss is 5.811228278742822, parameters k is 10.94166126482214 and b is -49.84916996047431\n",
      "Iteration 105, the loss is 5.78325509121114, parameters k is 10.949048509881427 and b is -49.84798418972333\n",
      "Iteration 106, the loss is 5.755801380359472, parameters k is 10.95639059288538 and b is -49.84680632411068\n",
      "Iteration 107, the loss is 5.728697437728845, parameters k is 10.963680225296448 and b is -49.84563636363637\n",
      "Iteration 108, the loss is 5.701831448178303, parameters k is 10.97091773913044 and b is -49.844474308300406\n",
      "Iteration 109, the loss is 5.675279490666217, parameters k is 10.978155252964433 and b is -49.84331225296444\n",
      "Iteration 110, the loss is 5.650130996329094, parameters k is 10.985179873517792 and b is -49.84218181818183\n",
      "Iteration 111, the loss is 5.625289099814353, parameters k is 10.992138588932812 and b is -49.84105928853756\n",
      "Iteration 112, the loss is 5.600508510651964, parameters k is 10.999097304347833 and b is -49.83993675889329\n",
      "Iteration 113, the loss is 5.576161668924199, parameters k is 11.006007395256924 and b is -49.83882213438736\n",
      "Iteration 114, the loss is 5.552145151498205, parameters k is 11.01285889328064 and b is -49.837715415019765\n",
      "Iteration 115, the loss is 5.528969935409874, parameters k is 11.01960250988143 and b is -49.83662450592885\n",
      "Iteration 116, the loss is 5.506339946198918, parameters k is 11.02624360474309 and b is -49.83554940711463\n",
      "Iteration 117, the loss is 5.483723679856352, parameters k is 11.03288469960475 and b is -49.8344743083004\n",
      "Iteration 118, the loss is 5.461606314996717, parameters k is 11.039467873517793 and b is -49.833407114624514\n",
      "Iteration 119, the loss is 5.440074294162446, parameters k is 11.045958818181825 and b is -49.832355731225306\n",
      "Iteration 120, the loss is 5.419055836871125, parameters k is 11.05235916996048 and b is -49.83132015810278\n",
      "Iteration 121, the loss is 5.398413956966098, parameters k is 11.058759521739136 and b is -49.83028458498025\n",
      "Iteration 122, the loss is 5.378753487937923, parameters k is 11.064949272727278 and b is -49.82928063241108\n",
      "Iteration 123, the loss is 5.35937241643686, parameters k is 11.07113902371542 and b is -49.828276679841906\n",
      "Iteration 124, the loss is 5.340662522156178, parameters k is 11.077177146245063 and b is -49.827296442687754\n",
      "Iteration 125, the loss is 5.321952627875487, parameters k is 11.083215268774707 and b is -49.8263162055336\n",
      "Iteration 126, the loss is 5.303242733594801, parameters k is 11.08925339130435 and b is -49.82533596837945\n",
      "Iteration 127, the loss is 5.284608779611359, parameters k is 11.095291513833994 and b is -49.824355731225296\n",
      "Iteration 128, the loss is 5.266242933408738, parameters k is 11.10127367588933 and b is -49.82338339920948\n",
      "Iteration 129, the loss is 5.247877087206097, parameters k is 11.107255837944665 and b is -49.82241106719367\n",
      "Iteration 130, the loss is 5.229522785536354, parameters k is 11.113238 and b is -49.82143873517786\n",
      "Iteration 131, the loss is 5.211457950444087, parameters k is 11.119170920948617 and b is -49.82047430830038\n",
      "Iteration 132, the loss is 5.193589949459535, parameters k is 11.125103841897234 and b is -49.81950988142291\n",
      "Iteration 133, the loss is 5.176228023656282, parameters k is 11.130936367588934 and b is -49.81856126482212\n",
      "Iteration 134, the loss is 5.159336193929516, parameters k is 11.136673399209487 and b is -49.817628458498014\n",
      "Iteration 135, the loss is 5.142582383924056, parameters k is 11.14241043083004 and b is -49.816695652173905\n",
      "Iteration 136, the loss is 5.126098348918818, parameters k is 11.148095138339922 and b is -49.815770750988136\n",
      "Iteration 137, the loss is 5.109826794744076, parameters k is 11.153730604743084 and b is -49.81485375494071\n",
      "Iteration 138, the loss is 5.093984919932829, parameters k is 11.159316656126483 and b is -49.81394466403162\n",
      "Iteration 139, the loss is 5.078533314534462, parameters k is 11.16480348221344 and b is -49.813051383399205\n",
      "Iteration 140, the loss is 5.0630817091360845, parameters k is 11.170290308300396 and b is -49.812158102766794\n",
      "Iteration 141, the loss is 5.0476612851442315, parameters k is 11.175777134387353 and b is -49.81126482213438\n",
      "Iteration 142, the loss is 5.032489156621611, parameters k is 11.181214079051385 and b is -49.81037944664031\n",
      "Iteration 143, the loss is 5.017432202903388, parameters k is 11.186651023715417 and b is -49.80949407114624\n",
      "Iteration 144, the loss is 5.002615701606001, parameters k is 11.192037415019765 and b is -49.80861660079051\n",
      "Iteration 145, the loss is 4.988520301515176, parameters k is 11.197324754940714 and b is -49.807754940711455\n",
      "Iteration 146, the loss is 4.974867947801878, parameters k is 11.202497810276682 and b is -49.80690909090908\n",
      "Iteration 147, the loss is 4.961530577155959, parameters k is 11.207618415019766 and b is -49.806071146245046\n",
      "Iteration 148, the loss is 4.948498651834631, parameters k is 11.212687715415024 and b is -49.80524110671936\n",
      "Iteration 149, the loss is 4.936280267309639, parameters k is 11.217589181818186 and b is -49.80443478260869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 150, the loss is 4.9242830103604565, parameters k is 11.222431992094865 and b is -49.80363636363636\n",
      "Iteration 151, the loss is 4.912545321569107, parameters k is 11.227225553359688 and b is -49.80284584980237\n",
      "Iteration 152, the loss is 4.901069084853009, parameters k is 11.231967138339925 and b is -49.802063241106715\n",
      "Iteration 153, the loss is 4.889892780688015, parameters k is 11.236657260869569 and b is -49.801288537549404\n",
      "Iteration 154, the loss is 4.879178002673449, parameters k is 11.241248023715418 and b is -49.80052964426877\n",
      "Iteration 155, the loss is 4.868644331226425, parameters k is 11.245784407114627 and b is -49.79977865612648\n",
      "Iteration 156, the loss is 4.8583560616598245, parameters k is 11.25027263241107 and b is -49.799035573122524\n",
      "Iteration 157, the loss is 4.848512375371149, parameters k is 11.254667324110676 and b is -49.79830830039525\n",
      "Iteration 158, the loss is 4.838912229085209, parameters k is 11.259008411067198 and b is -49.79758893280631\n",
      "Iteration 159, the loss is 4.829578657430758, parameters k is 11.263303988142297 and b is -49.79687747035572\n",
      "Iteration 160, the loss is 4.8205886055206175, parameters k is 11.267500442687751 and b is -49.79618181818181\n",
      "Iteration 161, the loss is 4.811877434928112, parameters k is 11.27164749802372 and b is -49.79549407114624\n",
      "Iteration 162, the loss is 4.803480614526546, parameters k is 11.275690039525696 and b is -49.794822134387346\n",
      "Iteration 163, the loss is 4.795083794124964, parameters k is 11.279732581027671 and b is -49.794150197628454\n",
      "Iteration 164, the loss is 4.786835019490609, parameters k is 11.283775122529647 and b is -49.79347826086956\n",
      "Iteration 165, the loss is 4.7790554406791825, parameters k is 11.287712770750991 and b is -49.79282213438735\n",
      "Iteration 166, the loss is 4.771539213555365, parameters k is 11.291545976284588 and b is -49.79218181818182\n",
      "Iteration 167, the loss is 4.7642107237119165, parameters k is 11.29532996442688 and b is -49.79154940711462\n",
      "Iteration 168, the loss is 4.757053415649234, parameters k is 11.299061533596841 and b is -49.79092490118577\n",
      "Iteration 169, the loss is 4.749951541062852, parameters k is 11.302793102766802 and b is -49.790300395256914\n",
      "Iteration 170, the loss is 4.742979867915254, parameters k is 11.306475920948621 and b is -49.7896837944664\n",
      "Iteration 171, the loss is 4.736071024942503, parameters k is 11.31015873913044 and b is -49.78906719367588\n",
      "Iteration 172, the loss is 4.729345700893693, parameters k is 11.313794584980242 and b is -49.78845849802371\n",
      "Iteration 173, the loss is 4.722747216434558, parameters k is 11.317377324110677 and b is -49.78785770750987\n",
      "Iteration 174, the loss is 4.716148731975425, parameters k is 11.320960063241111 and b is -49.787256916996036\n",
      "Iteration 175, the loss is 4.709608694200076, parameters k is 11.324542802371546 and b is -49.7866561264822\n",
      "Iteration 176, the loss is 4.703335432998303, parameters k is 11.328075280632415 and b is -49.7860632411067\n",
      "Iteration 177, the loss is 4.697272000618101, parameters k is 11.331509498023719 and b is -49.785486166007885\n",
      "Iteration 178, the loss is 4.691278484451548, parameters k is 11.334943715415022 and b is -49.78490909090907\n",
      "Iteration 179, the loss is 4.685387732930773, parameters k is 11.338329181818183 and b is -49.7843399209486\n",
      "Iteration 180, the loss is 4.679755663420111, parameters k is 11.341663762845851 and b is -49.783778656126465\n",
      "Iteration 181, the loss is 4.674212373476745, parameters k is 11.344947110671939 and b is -49.78322529644267\n",
      "Iteration 182, the loss is 4.668749720750844, parameters k is 11.348230458498026 and b is -49.78267193675888\n",
      "Iteration 183, the loss is 4.663518035815837, parameters k is 11.351420193675892 and b is -49.78213438735177\n",
      "Iteration 184, the loss is 4.658286350880838, parameters k is 11.354609928853758 and b is -49.781596837944655\n",
      "Iteration 185, the loss is 4.653130107444999, parameters k is 11.357799664031624 and b is -49.78105928853754\n",
      "Iteration 186, the loss is 4.648353034473784, parameters k is 11.360852102766803 and b is -49.78054545454545\n",
      "Iteration 187, the loss is 4.6437994632543145, parameters k is 11.363852644268778 and b is -49.78003952569169\n",
      "Iteration 188, the loss is 4.639387791355504, parameters k is 11.366796561264826 and b is -49.779541501976276\n",
      "Iteration 189, the loss is 4.635113660871867, parameters k is 11.369700217391308 and b is -49.7790513833992\n",
      "Iteration 190, the loss is 4.631034879528294, parameters k is 11.372516703557316 and b is -49.7785770750988\n",
      "Iteration 191, the loss is 4.627005061672717, parameters k is 11.375333189723325 and b is -49.778102766798405\n",
      "Iteration 192, the loss is 4.623053679170808, parameters k is 11.378105415019768 and b is -49.77763636363635\n",
      "Iteration 193, the loss is 4.619158891515094, parameters k is 11.38087764031621 and b is -49.77716996047429\n",
      "Iteration 194, the loss is 4.615332260929641, parameters k is 11.3836058339921 and b is -49.77671146245057\n",
      "Iteration 195, the loss is 4.611540210546042, parameters k is 11.386334027667989 and b is -49.77625296442685\n",
      "Iteration 196, the loss is 4.607865378555165, parameters k is 11.389008079051388 and b is -49.775802371541474\n",
      "Iteration 197, the loss is 4.604404128613117, parameters k is 11.391632865612653 and b is -49.77535968379444\n",
      "Iteration 198, the loss is 4.601271208627734, parameters k is 11.394100719367593 and b is -49.77494071146243\n",
      "Iteration 199, the loss is 4.598162815791402, parameters k is 11.396568573122533 and b is -49.774521739130414\n",
      "Iteration 200, the loss is 4.59515514725866, parameters k is 11.398986498023719 and b is -49.77411067193674\n",
      "Iteration 201, the loss is 4.592212449842055, parameters k is 11.401404422924905 and b is -49.773699604743065\n",
      "Iteration 202, the loss is 4.58947749533252, parameters k is 11.403709565217396 and b is -49.77330434782607\n",
      "Iteration 203, the loss is 4.586742540822996, parameters k is 11.406014707509886 and b is -49.772909090909074\n",
      "Iteration 204, the loss is 4.584007586313464, parameters k is 11.408319849802377 and b is -49.77251383399208\n",
      "Iteration 205, the loss is 4.581382430170007, parameters k is 11.410624992094867 and b is -49.772118577075084\n",
      "Iteration 206, the loss is 4.578900320702709, parameters k is 11.412820901185777 and b is -49.77173913043477\n",
      "Iteration 207, the loss is 4.576528666605431, parameters k is 11.414966889328069 and b is -49.77136758893279\n",
      "Iteration 208, the loss is 4.574157012508155, parameters k is 11.41711287747036 and b is -49.77099604743081\n",
      "Iteration 209, the loss is 4.571919962242448, parameters k is 11.419258865612653 and b is -49.770624505928836\n",
      "Iteration 210, the loss is 4.569999132606986, parameters k is 11.421200624505934 and b is -49.77028458498022\n",
      "Iteration 211, the loss is 4.568155342300614, parameters k is 11.423092011857712 and b is -49.76995256916994\n",
      "Iteration 212, the loss is 4.566311551994243, parameters k is 11.42498339920949 and b is -49.76962055335966\n",
      "Iteration 213, the loss is 4.564538763498599, parameters k is 11.426874786561267 and b is -49.76928853754938\n",
      "Iteration 214, the loss is 4.562936066121599, parameters k is 11.428670181818184 and b is -49.768972332015785\n",
      "Iteration 215, the loss is 4.5615362832285635, parameters k is 11.430317608695654 and b is -49.76867984189721\n",
      "Iteration 216, the loss is 4.560136500335527, parameters k is 11.431965035573125 and b is -49.768387351778635\n",
      "Iteration 217, the loss is 4.5587609369582776, parameters k is 11.433612462450595 and b is -49.76809486166006\n",
      "Iteration 218, the loss is 4.557569880968265, parameters k is 11.435162166007908 and b is -49.767818181818164\n",
      "Iteration 219, the loss is 4.556571159578705, parameters k is 11.436552652173916 and b is -49.76756521739129\n",
      "Iteration 220, the loss is 4.555596542337871, parameters k is 11.437943138339923 and b is -49.76731225296441\n",
      "Iteration 221, the loss is 4.55466465896034, parameters k is 11.439286162055339 and b is -49.76706719367587\n",
      "Iteration 222, the loss is 4.553738383152742, parameters k is 11.440629185770755 and b is -49.76682213438733\n",
      "Iteration 223, the loss is 4.55289402921807, parameters k is 11.441906865612651 and b is -49.766584980237134\n",
      "Iteration 224, the loss is 4.552049675283392, parameters k is 11.443184545454548 and b is -49.766347826086935\n",
      "Iteration 225, the loss is 4.551205321348718, parameters k is 11.444462225296444 and b is -49.76611067193674\n",
      "Iteration 226, the loss is 4.55036096741405, parameters k is 11.44573990513834 and b is -49.76587351778654\n",
      "Iteration 227, the loss is 4.549516613479375, parameters k is 11.447017584980237 and b is -49.76563636363634\n",
      "Iteration 228, the loss is 4.548677580344156, parameters k is 11.448295264822134 and b is -49.76539920948614\n",
      "Iteration 229, the loss is 4.547898683776475, parameters k is 11.449522146245059 and b is -49.76516996047428\n",
      "Iteration 230, the loss is 4.547119787208798, parameters k is 11.450749027667984 and b is -49.76494071146242\n",
      "Iteration 231, the loss is 4.546346997093884, parameters k is 11.451975909090908 and b is -49.76471146245056\n",
      "Iteration 232, the loss is 4.545648613674481, parameters k is 11.453154355731225 and b is -49.764490118577044\n",
      "Iteration 233, the loss is 4.544992784675658, parameters k is 11.454286509881424 and b is -49.76427667984186\n",
      "Iteration 234, the loss is 4.544383530364165, parameters k is 11.455371067193678 and b is -49.76407114624502\n",
      "Iteration 235, the loss is 4.543774276052668, parameters k is 11.456455624505931 and b is -49.76386561264818\n",
      "Iteration 236, the loss is 4.54316502174117, parameters k is 11.457540181818185 and b is -49.76366007905134\n",
      "Iteration 237, the loss is 4.5425557674296755, parameters k is 11.458624739130439 and b is -49.7634545454545\n",
      "Iteration 238, the loss is 4.54194651311818, parameters k is 11.459709296442693 and b is -49.76324901185766\n",
      "Iteration 239, the loss is 4.541337258806683, parameters k is 11.460793853754947 and b is -49.76304347826082\n",
      "Iteration 240, the loss is 4.540749019732017, parameters k is 11.4618784110672 and b is -49.76283794466398\n",
      "Iteration 241, the loss is 4.540277207998208, parameters k is 11.46284507905139 and b is -49.762648221343824\n",
      "Iteration 242, the loss is 4.539838870654004, parameters k is 11.463763565217397 and b is -49.76246640316201\n",
      "Iteration 243, the loss is 4.5394005333098155, parameters k is 11.464682051383404 and b is -49.76228458498019\n",
      "Iteration 244, the loss is 4.538962195965628, parameters k is 11.465600537549411 and b is -49.76210276679838\n",
      "Iteration 245, the loss is 4.538523858621429, parameters k is 11.466519023715419 and b is -49.76192094861656\n",
      "Iteration 246, the loss is 4.5380855212772335, parameters k is 11.467437509881426 and b is -49.76173913043475\n",
      "Iteration 247, the loss is 4.537663380375372, parameters k is 11.468355996047434 and b is -49.76155731225293\n",
      "Iteration 248, the loss is 4.537269102233043, parameters k is 11.469226806324114 and b is -49.76138339920946\n",
      "Iteration 249, the loss is 4.536874824090711, parameters k is 11.470097616600794 and b is -49.76120948616598\n",
      "Iteration 250, the loss is 4.536500285901132, parameters k is 11.470968426877475 and b is -49.761035573122506\n",
      "Iteration 251, the loss is 4.5361833542172265, parameters k is 11.471793363636369 and b is -49.76086956521737\n",
      "Iteration 252, the loss is 4.53595876311596, parameters k is 11.47246822134388 and b is -49.76072727272725\n",
      "Iteration 253, the loss is 4.535753302439114, parameters k is 11.473095007905144 and b is -49.76059288537547\n",
      "Iteration 254, the loss is 4.535547841762263, parameters k is 11.473721794466408 and b is -49.760458498023695\n",
      "Iteration 255, the loss is 4.53534238108541, parameters k is 11.474348581027673 and b is -49.76032411067192\n",
      "Iteration 256, the loss is 4.535136920408558, parameters k is 11.474975367588938 and b is -49.76018972332014\n",
      "Iteration 257, the loss is 4.534931459731712, parameters k is 11.475602154150202 and b is -49.76005533596836\n",
      "Iteration 258, the loss is 4.534725999054862, parameters k is 11.476228940711467 and b is -49.75992094861658\n",
      "Iteration 259, the loss is 4.5345205383780165, parameters k is 11.476855727272731 and b is -49.759786561264804\n",
      "Iteration 260, the loss is 4.534315077701168, parameters k is 11.477482513833996 and b is -49.759652173913025\n",
      "Iteration 261, the loss is 4.534109617024313, parameters k is 11.47810930039526 and b is -49.75951778656125\n",
      "Iteration 262, the loss is 4.5339041563474645, parameters k is 11.478736086956525 and b is -49.75938339920947\n",
      "Iteration 263, the loss is 4.533698695670614, parameters k is 11.47936287351779 and b is -49.75924901185769\n",
      "Iteration 264, the loss is 4.533493234993764, parameters k is 11.479989660079054 and b is -49.75911462450591\n",
      "Iteration 265, the loss is 4.53328777431692, parameters k is 11.480616446640319 and b is -49.758980237154134\n",
      "Iteration 266, the loss is 4.533090076630649, parameters k is 11.481243233201583 and b is -49.758845849802356\n",
      "Iteration 267, the loss is 4.5329139213099765, parameters k is 11.481823158102769 and b is -49.75871936758892\n",
      "Iteration 268, the loss is 4.532750942226713, parameters k is 11.482403083003954 and b is -49.75859288537548\n",
      "Iteration 269, the loss is 4.5326170163931065, parameters k is 11.482931537549408 and b is -49.75847430830038\n",
      "Iteration 270, the loss is 4.532495287789247, parameters k is 11.48341237944664 and b is -49.75836363636362\n",
      "Iteration 271, the loss is 4.532373559185386, parameters k is 11.483893221343873 and b is -49.75825296442686\n",
      "Iteration 272, the loss is 4.532251830581527, parameters k is 11.484374063241106 and b is -49.7581422924901\n",
      "Iteration 273, the loss is 4.532132423425541, parameters k is 11.484854905138338 and b is -49.75803162055334\n",
      "Iteration 274, the loss is 4.532035694656145, parameters k is 11.485282569169959 and b is -49.75792885375492\n",
      "Iteration 275, the loss is 4.531938965886737, parameters k is 11.48571023320158 and b is -49.7578260869565\n",
      "Iteration 276, the loss is 4.531842237117341, parameters k is 11.486137897233201 and b is -49.75772332015808\n",
      "Iteration 277, the loss is 4.531745508347944, parameters k is 11.486565561264822 and b is -49.75762055335966\n",
      "Iteration 278, the loss is 4.5316487795785445, parameters k is 11.486993225296443 and b is -49.75751778656124\n",
      "Iteration 279, the loss is 4.531552050809142, parameters k is 11.487420889328064 and b is -49.75741501976282\n",
      "Iteration 280, the loss is 4.531455322039746, parameters k is 11.487848553359685 and b is -49.7573122529644\n",
      "Iteration 281, the loss is 4.531359082104023, parameters k is 11.488276217391306 and b is -49.757209486165976\n",
      "Iteration 282, the loss is 4.531282248998983, parameters k is 11.488656569169962 and b is -49.757114624505896\n",
      "Iteration 283, the loss is 4.531205415893942, parameters k is 11.489036920948617 and b is -49.757019762845815\n",
      "Iteration 284, the loss is 4.531138772103998, parameters k is 11.489417272727273 and b is -49.756924901185734\n",
      "Iteration 285, the loss is 4.531095549333691, parameters k is 11.489700462450593 and b is -49.75684584980233\n",
      "Iteration 286, the loss is 4.531052326563387, parameters k is 11.489983652173912 and b is -49.75676679841893\n",
      "Iteration 287, the loss is 4.531011428588394, parameters k is 11.490266841897231 and b is -49.75668774703553\n",
      "Iteration 288, the loss is 4.530981834177285, parameters k is 11.490499494071145 and b is -49.756616600790466\n",
      "Iteration 289, the loss is 4.530952239766176, parameters k is 11.490732146245058 and b is -49.7565454545454\n",
      "Iteration 290, the loss is 4.530922645355069, parameters k is 11.490964798418972 and b is -49.75647430830034\n",
      "Iteration 291, the loss is 4.5308930509439636, parameters k is 11.491197450592885 and b is -49.75640316205528\n",
      "Iteration 292, the loss is 4.530867602047398, parameters k is 11.491430102766799 and b is -49.756332015810216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 293, the loss is 4.530848653231126, parameters k is 11.491614217391305 and b is -49.7562687747035\n",
      "Iteration 294, the loss is 4.530829704414864, parameters k is 11.491798332015811 and b is -49.756205533596784\n",
      "Iteration 295, the loss is 4.530810755598599, parameters k is 11.491982446640318 and b is -49.75614229249007\n",
      "Iteration 296, the loss is 4.530791806782327, parameters k is 11.492166561264824 and b is -49.75607905138335\n",
      "Iteration 297, the loss is 4.530772857966055, parameters k is 11.49235067588933 and b is -49.75601581027664\n",
      "Iteration 298, the loss is 4.530753909149789, parameters k is 11.492534790513837 and b is -49.75595256916992\n",
      "Iteration 299, the loss is 4.5307349603335245, parameters k is 11.492718905138343 and b is -49.755889328063205\n",
      "Iteration 300, the loss is 4.530716011517258, parameters k is 11.49290301976285 and b is -49.75582608695649\n",
      "Iteration 301, the loss is 4.530697062700984, parameters k is 11.493087134387356 and b is -49.75576284584977\n",
      "Iteration 302, the loss is 4.530678113884724, parameters k is 11.493271249011862 and b is -49.75569960474306\n",
      "Iteration 303, the loss is 4.530659165068452, parameters k is 11.493455363636368 and b is -49.75563636363634\n",
      "Iteration 304, the loss is 4.530640216252178, parameters k is 11.493639478260874 and b is -49.755573122529626\n",
      "Iteration 305, the loss is 4.530621267435912, parameters k is 11.49382359288538 and b is -49.75550988142291\n",
      "Iteration 306, the loss is 4.5306023186196525, parameters k is 11.494007707509887 and b is -49.755446640316194\n",
      "Iteration 307, the loss is 4.530583369803376, parameters k is 11.494191822134393 and b is -49.75538339920948\n",
      "Iteration 308, the loss is 4.530564420987108, parameters k is 11.4943759367589 and b is -49.75532015810276\n",
      "Iteration 309, the loss is 4.530545472170846, parameters k is 11.494560051383406 and b is -49.755256916996046\n",
      "Iteration 310, the loss is 4.530526523354577, parameters k is 11.494744166007912 and b is -49.75519367588933\n",
      "Iteration 311, the loss is 4.530507574538305, parameters k is 11.494928280632418 and b is -49.755130434782615\n",
      "Iteration 312, the loss is 4.530488625722038, parameters k is 11.495112395256925 and b is -49.7550671936759\n",
      "Iteration 313, the loss is 4.530469676905771, parameters k is 11.495296509881431 and b is -49.75500395256918\n",
      "Iteration 314, the loss is 4.530450728089504, parameters k is 11.495480624505937 and b is -49.75494071146247\n",
      "Iteration 315, the loss is 4.530431779273236, parameters k is 11.495664739130444 and b is -49.75487747035575\n",
      "Iteration 316, the loss is 4.530412830456966, parameters k is 11.49584885375495 and b is -49.754814229249035\n",
      "Iteration 317, the loss is 4.530397718709235, parameters k is 11.496032968379456 and b is -49.75475098814232\n",
      "Iteration 318, the loss is 4.530386975655291, parameters k is 11.496168703557322 and b is -49.75469565217394\n",
      "Iteration 319, the loss is 4.530376232601327, parameters k is 11.496304438735187 and b is -49.75464031620557\n",
      "Iteration 320, the loss is 4.530365489547376, parameters k is 11.496440173913053 and b is -49.75458498023719\n",
      "Iteration 321, the loss is 4.530354746493424, parameters k is 11.496575909090918 and b is -49.754529644268814\n",
      "Iteration 322, the loss is 4.530344003439468, parameters k is 11.496711644268784 and b is -49.75447430830044\n",
      "Iteration 323, the loss is 4.530333260385514, parameters k is 11.496847379446649 and b is -49.75441897233206\n",
      "Iteration 324, the loss is 4.53032251733156, parameters k is 11.496983114624514 and b is -49.754363636363685\n",
      "Iteration 325, the loss is 4.5303117742776084, parameters k is 11.49711884980238 and b is -49.75430830039531\n",
      "Iteration 326, the loss is 4.53030103122366, parameters k is 11.497254584980245 and b is -49.75425296442693\n",
      "Iteration 327, the loss is 4.530290288169703, parameters k is 11.497390320158111 and b is -49.754197628458556\n",
      "Iteration 328, the loss is 4.530279545115753, parameters k is 11.497526055335976 and b is -49.75414229249018\n",
      "Iteration 329, the loss is 4.530268802061796, parameters k is 11.497661790513842 and b is -49.7540869565218\n",
      "Iteration 330, the loss is 4.530258059007848, parameters k is 11.497797525691707 and b is -49.75403162055343\n",
      "Iteration 331, the loss is 4.530247315953892, parameters k is 11.497933260869573 and b is -49.75397628458505\n",
      "Iteration 332, the loss is 4.530236572899936, parameters k is 11.498068996047438 and b is -49.753920948616674\n",
      "Iteration 333, the loss is 4.530225829845982, parameters k is 11.498204731225304 and b is -49.7538656126483\n",
      "Iteration 334, the loss is 4.530215086792032, parameters k is 11.49834046640317 and b is -49.75381027667992\n",
      "Iteration 335, the loss is 4.530204343738078, parameters k is 11.498476201581035 and b is -49.753754940711545\n",
      "Iteration 336, the loss is 4.530193600684124, parameters k is 11.4986119367589 and b is -49.75369960474317\n",
      "Iteration 337, the loss is 4.530182857630171, parameters k is 11.498747671936766 and b is -49.75364426877479\n",
      "Iteration 338, the loss is 4.530172114576222, parameters k is 11.498883407114631 and b is -49.753588932806416\n",
      "Iteration 339, the loss is 4.530161371522263, parameters k is 11.499019142292497 and b is -49.75353359683804\n",
      "Iteration 340, the loss is 4.530150628468311, parameters k is 11.499154877470362 and b is -49.75347826086966\n",
      "Iteration 341, the loss is 4.530139885414358, parameters k is 11.499290612648227 and b is -49.75342292490129\n",
      "Iteration 342, the loss is 4.530129142360402, parameters k is 11.499426347826093 and b is -49.75336758893291\n",
      "Iteration 343, the loss is 4.530118399306455, parameters k is 11.499562083003958 and b is -49.753312252964534\n",
      "Iteration 344, the loss is 4.530107656252496, parameters k is 11.499697818181824 and b is -49.75325691699616\n",
      "Iteration 345, the loss is 4.530096913198546, parameters k is 11.49983355335969 and b is -49.75320158102778\n",
      "Iteration 346, the loss is 4.530086170144586, parameters k is 11.499969288537555 and b is -49.753146245059405\n",
      "Iteration 347, the loss is 4.5300754270906385, parameters k is 11.50010502371542 and b is -49.75309090909103\n",
      "Iteration 348, the loss is 4.53006468403669, parameters k is 11.500240758893286 and b is -49.75303557312265\n",
      "Iteration 349, the loss is 4.530053940982731, parameters k is 11.500376494071151 and b is -49.752980237154276\n",
      "Iteration 350, the loss is 4.530043197928779, parameters k is 11.500512229249017 and b is -49.7529249011859\n",
      "Iteration 351, the loss is 4.530032454874824, parameters k is 11.500647964426882 and b is -49.75286956521752\n",
      "Iteration 352, the loss is 4.530021711820867, parameters k is 11.500783699604748 and b is -49.75281422924915\n",
      "Iteration 353, the loss is 4.5300109687669226, parameters k is 11.500919434782613 and b is -49.75275889328077\n",
      "Iteration 354, the loss is 4.530000225712964, parameters k is 11.501055169960479 and b is -49.752703557312394\n",
      "Iteration 355, the loss is 4.529989482659016, parameters k is 11.501190905138344 and b is -49.75264822134402\n",
      "Iteration 356, the loss is 4.529978739605058, parameters k is 11.50132664031621 and b is -49.75259288537564\n",
      "Iteration 357, the loss is 4.529967996551103, parameters k is 11.501462375494075 and b is -49.752537549407265\n",
      "Iteration 358, the loss is 4.529957253497153, parameters k is 11.50159811067194 and b is -49.75248221343889\n",
      "Iteration 359, the loss is 4.529946510443201, parameters k is 11.501733845849806 and b is -49.75242687747051\n",
      "Iteration 360, the loss is 4.52993576738925, parameters k is 11.501869581027671 and b is -49.752371541502136\n",
      "Iteration 361, the loss is 4.529925024335299, parameters k is 11.502005316205537 and b is -49.75231620553376\n",
      "Iteration 362, the loss is 4.529914281281345, parameters k is 11.502141051383402 and b is -49.75226086956538\n",
      "Iteration 363, the loss is 4.52990353822739, parameters k is 11.502276786561268 and b is -49.75220553359701\n",
      "Iteration 364, the loss is 4.529892795173433, parameters k is 11.502412521739133 and b is -49.75215019762863\n",
      "Iteration 365, the loss is 4.529882052119481, parameters k is 11.502548256916999 and b is -49.752094861660254\n",
      "Iteration 366, the loss is 4.529871309065528, parameters k is 11.502683992094864 and b is -49.75203952569188\n",
      "Iteration 367, the loss is 4.52986056601157, parameters k is 11.50281972727273 and b is -49.7519841897235\n",
      "Iteration 368, the loss is 4.529849822957624, parameters k is 11.502955462450595 and b is -49.751928853755125\n",
      "Iteration 369, the loss is 4.529839079903667, parameters k is 11.50309119762846 and b is -49.75187351778675\n",
      "Iteration 370, the loss is 4.529828336849715, parameters k is 11.503226932806326 and b is -49.75181818181837\n",
      "Iteration 371, the loss is 4.529817593795758, parameters k is 11.503362667984192 and b is -49.751762845849996\n",
      "Iteration 372, the loss is 4.529806850741808, parameters k is 11.503498403162057 and b is -49.75170750988162\n",
      "Iteration 373, the loss is 4.529796107687855, parameters k is 11.503634138339923 and b is -49.75165217391324\n",
      "Iteration 374, the loss is 4.5297853646339, parameters k is 11.503769873517788 and b is -49.75159683794487\n",
      "Iteration 375, the loss is 4.529774621579944, parameters k is 11.503905608695653 and b is -49.75154150197649\n",
      "Iteration 376, the loss is 4.529763878525997, parameters k is 11.504041343873519 and b is -49.751486166008114\n",
      "Iteration 377, the loss is 4.529753135472038, parameters k is 11.504177079051384 and b is -49.75143083003974\n",
      "Iteration 378, the loss is 4.529742392418087, parameters k is 11.50431281422925 and b is -49.75137549407136\n",
      "Iteration 379, the loss is 4.529731649364132, parameters k is 11.504448549407115 and b is -49.751320158102985\n",
      "Iteration 380, the loss is 4.52972090631018, parameters k is 11.50458428458498 and b is -49.75126482213461\n",
      "Iteration 381, the loss is 4.529710163256225, parameters k is 11.504720019762846 and b is -49.75120948616623\n",
      "Iteration 382, the loss is 4.529699420202277, parameters k is 11.504855754940712 and b is -49.751154150197856\n",
      "Iteration 383, the loss is 4.5296886771483225, parameters k is 11.504991490118577 and b is -49.75109881422948\n",
      "Iteration 384, the loss is 4.529677934094372, parameters k is 11.505127225296443 and b is -49.7510434782611\n",
      "Iteration 385, the loss is 4.529667191040418, parameters k is 11.505262960474308 and b is -49.75098814229273\n",
      "Iteration 386, the loss is 4.529656447986465, parameters k is 11.505398695652174 and b is -49.75093280632435\n",
      "Iteration 387, the loss is 4.529645704932509, parameters k is 11.50553443083004 and b is -49.750877470355974\n",
      "Iteration 388, the loss is 4.529634961878558, parameters k is 11.505670166007905 and b is -49.7508221343876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 389, the loss is 4.529624218824604, parameters k is 11.50580590118577 and b is -49.75076679841922\n",
      "Iteration 390, the loss is 4.529613475770646, parameters k is 11.505941636363636 and b is -49.750711462450845\n",
      "Iteration 391, the loss is 4.5296027327166986, parameters k is 11.506077371541501 and b is -49.75065612648247\n",
      "Iteration 392, the loss is 4.52959198966274, parameters k is 11.506213106719366 and b is -49.75060079051409\n",
      "Iteration 393, the loss is 4.52958124660879, parameters k is 11.506348841897232 and b is -49.750545454545716\n",
      "Iteration 394, the loss is 4.5295705035548375, parameters k is 11.506484577075097 and b is -49.75049011857734\n",
      "Iteration 395, the loss is 4.529559760500882, parameters k is 11.506620312252963 and b is -49.75043478260896\n",
      "Iteration 396, the loss is 4.52954901744693, parameters k is 11.506756047430828 and b is -49.750379446640586\n",
      "Iteration 397, the loss is 4.529538274392978, parameters k is 11.506891782608694 and b is -49.75032411067221\n",
      "Iteration 398, the loss is 4.529527531339023, parameters k is 11.50702751778656 and b is -49.750268774703834\n",
      "Iteration 399, the loss is 4.529516788285077, parameters k is 11.507163252964425 and b is -49.75021343873546\n",
      "Iteration 400, the loss is 4.52950604523112, parameters k is 11.50729898814229 and b is -49.75015810276708\n",
      "Iteration 401, the loss is 4.529495302177163, parameters k is 11.507434723320156 and b is -49.750102766798705\n",
      "Iteration 402, the loss is 4.529484559123212, parameters k is 11.507570458498021 and b is -49.75004743083033\n",
      "Iteration 403, the loss is 4.529473816069258, parameters k is 11.507706193675887 and b is -49.74999209486195\n",
      "Iteration 404, the loss is 4.529463073015307, parameters k is 11.507841928853752 and b is -49.749936758893575\n",
      "Iteration 405, the loss is 4.529452329961347, parameters k is 11.507977664031618 and b is -49.7498814229252\n",
      "Iteration 406, the loss is 4.5294415869073985, parameters k is 11.508113399209483 and b is -49.74982608695682\n",
      "Iteration 407, the loss is 4.529430843853444, parameters k is 11.508249134387349 and b is -49.749770750988446\n",
      "Iteration 408, the loss is 4.529420100799488, parameters k is 11.508384869565214 and b is -49.74971541502007\n",
      "Iteration 409, the loss is 4.5294093577455365, parameters k is 11.50852060474308 and b is -49.749660079051694\n",
      "Iteration 410, the loss is 4.529398614691583, parameters k is 11.508656339920945 and b is -49.74960474308332\n",
      "Iteration 411, the loss is 4.52938787163763, parameters k is 11.50879207509881 and b is -49.74954940711494\n",
      "Iteration 412, the loss is 4.529377128583676, parameters k is 11.508927810276676 and b is -49.749494071146565\n",
      "Iteration 413, the loss is 4.529366385529723, parameters k is 11.509063545454541 and b is -49.74943873517819\n",
      "Iteration 414, the loss is 4.529355642475771, parameters k is 11.509199280632407 and b is -49.74938339920981\n",
      "Iteration 415, the loss is 4.529344899421812, parameters k is 11.509335015810272 and b is -49.749328063241435\n",
      "Iteration 416, the loss is 4.529334156367863, parameters k is 11.509470750988138 and b is -49.74927272727306\n",
      "Iteration 417, the loss is 4.529323413313913, parameters k is 11.509606486166003 and b is -49.74921739130468\n",
      "Iteration 418, the loss is 4.529312670259953, parameters k is 11.509742221343869 and b is -49.749162055336306\n",
      "Iteration 419, the loss is 4.529301927206004, parameters k is 11.509877956521734 and b is -49.74910671936793\n",
      "Iteration 420, the loss is 4.529291184152047, parameters k is 11.5100136916996 and b is -49.749051383399554\n",
      "Iteration 421, the loss is 4.529280441098094, parameters k is 11.510149426877465 and b is -49.74899604743118\n",
      "Iteration 422, the loss is 4.529269698044146, parameters k is 11.51028516205533 and b is -49.7489407114628\n",
      "Iteration 423, the loss is 4.529258954990189, parameters k is 11.510420897233196 and b is -49.748885375494424\n",
      "Iteration 424, the loss is 4.529248211936236, parameters k is 11.510556632411062 and b is -49.74883003952605\n",
      "Iteration 425, the loss is 4.529237468882283, parameters k is 11.510692367588927 and b is -49.74877470355767\n",
      "Iteration 426, the loss is 4.529226725828331, parameters k is 11.510828102766792 and b is -49.748719367589295\n",
      "Iteration 427, the loss is 4.529215982774377, parameters k is 11.510963837944658 and b is -49.74866403162092\n",
      "Iteration 428, the loss is 4.529205239720424, parameters k is 11.511099573122523 and b is -49.74860869565254\n",
      "Iteration 429, the loss is 4.529194496666474, parameters k is 11.511235308300389 and b is -49.748553359684166\n",
      "Iteration 430, the loss is 4.529183753612521, parameters k is 11.511371043478254 and b is -49.74849802371579\n",
      "Iteration 431, the loss is 4.529173010558562, parameters k is 11.51150677865612 and b is -49.74844268774741\n",
      "Iteration 432, the loss is 4.529162267504606, parameters k is 11.511642513833985 and b is -49.74838735177904\n",
      "Iteration 433, the loss is 4.529151524450659, parameters k is 11.51177824901185 and b is -49.74833201581066\n",
      "Iteration 434, the loss is 4.529140781396706, parameters k is 11.511913984189716 and b is -49.748276679842284\n",
      "Iteration 435, the loss is 4.52913003834275, parameters k is 11.512049719367582 and b is -49.74822134387391\n",
      "Iteration 436, the loss is 4.5291192952887975, parameters k is 11.512185454545447 and b is -49.74816600790553\n",
      "Iteration 437, the loss is 4.529108552234844, parameters k is 11.512321189723313 and b is -49.748110671937155\n",
      "Iteration 438, the loss is 4.529097809180893, parameters k is 11.512456924901178 and b is -49.74805533596878\n",
      "Iteration 439, the loss is 4.529087066126937, parameters k is 11.512592660079044 and b is -49.7480000000004\n",
      "Iteration 440, the loss is 4.529076323072987, parameters k is 11.512728395256909 and b is -49.747944664032026\n",
      "Iteration 441, the loss is 4.529065580019035, parameters k is 11.512864130434775 and b is -49.74788932806365\n",
      "Iteration 442, the loss is 4.529054836965079, parameters k is 11.51299986561264 and b is -49.74783399209527\n",
      "Iteration 443, the loss is 4.529044093911127, parameters k is 11.513135600790505 and b is -49.7477786561269\n",
      "Iteration 444, the loss is 4.529033350857177, parameters k is 11.513271335968371 and b is -49.74772332015852\n",
      "Iteration 445, the loss is 4.529022607803219, parameters k is 11.513407071146236 and b is -49.747667984190144\n",
      "Iteration 446, the loss is 4.529011864749267, parameters k is 11.513542806324102 and b is -49.74761264822177\n",
      "Iteration 447, the loss is 4.529001121695311, parameters k is 11.513678541501967 and b is -49.74755731225339\n",
      "Iteration 448, the loss is 4.528990378641361, parameters k is 11.513814276679833 and b is -49.747501976285015\n",
      "Iteration 449, the loss is 4.528979635587409, parameters k is 11.513950011857698 and b is -49.74744664031664\n",
      "Iteration 450, the loss is 4.528968892533454, parameters k is 11.514085747035564 and b is -49.74739130434826\n",
      "Iteration 451, the loss is 4.528958149479499, parameters k is 11.51422148221343 and b is -49.747335968379886\n",
      "Iteration 452, the loss is 4.528947406425549, parameters k is 11.514357217391295 and b is -49.74728063241151\n",
      "Iteration 453, the loss is 4.528936663371591, parameters k is 11.51449295256916 and b is -49.74722529644313\n",
      "Iteration 454, the loss is 4.528925920317641, parameters k is 11.514628687747026 and b is -49.74716996047476\n",
      "Iteration 455, the loss is 4.528915177263688, parameters k is 11.514764422924891 and b is -49.74711462450638\n",
      "Iteration 456, the loss is 4.528904434209731, parameters k is 11.514900158102757 and b is -49.747059288538004\n",
      "Iteration 457, the loss is 4.5288936911557816, parameters k is 11.515035893280622 and b is -49.74700395256963\n",
      "Iteration 458, the loss is 4.528882948101828, parameters k is 11.515171628458488 and b is -49.74694861660125\n",
      "Iteration 459, the loss is 4.5288722050478745, parameters k is 11.515307363636353 and b is -49.746893280632875\n",
      "Iteration 460, the loss is 4.528863635118323, parameters k is 11.515443098814218 and b is -49.7468379446645\n",
      "Iteration 461, the loss is 4.528859038822795, parameters k is 11.515526422924891 and b is -49.74679051383446\n",
      "Iteration 462, the loss is 4.528854442527266, parameters k is 11.515609747035564 and b is -49.746743083004425\n",
      "Iteration 463, the loss is 4.528849846231734, parameters k is 11.515693071146236 and b is -49.74669565217439\n",
      "Iteration 464, the loss is 4.528845249936209, parameters k is 11.515776395256909 and b is -49.74664822134435\n",
      "Iteration 465, the loss is 4.528840653640677, parameters k is 11.515859719367581 and b is -49.746600790514314\n",
      "Iteration 466, the loss is 4.528836057345157, parameters k is 11.515943043478254 and b is -49.74655335968428\n",
      "Iteration 467, the loss is 4.528831461049621, parameters k is 11.516026367588927 and b is -49.74650592885424\n",
      "Iteration 468, the loss is 4.528826864754092, parameters k is 11.516109691699599 and b is -49.746458498024204\n",
      "Iteration 469, the loss is 4.528822268458562, parameters k is 11.516193015810272 and b is -49.74641106719417\n",
      "Iteration 470, the loss is 4.528817672163035, parameters k is 11.516276339920944 and b is -49.74636363636413\n",
      "Iteration 471, the loss is 4.528813075867508, parameters k is 11.516359664031617 and b is -49.74631620553409\n",
      "Iteration 472, the loss is 4.528808479571978, parameters k is 11.51644298814229 and b is -49.746268774704056\n",
      "Iteration 473, the loss is 4.52880388327645, parameters k is 11.516526312252962 and b is -49.74622134387402\n",
      "Iteration 474, the loss is 4.528799286980921, parameters k is 11.516609636363635 and b is -49.74617391304398\n",
      "Iteration 475, the loss is 4.528794690685392, parameters k is 11.516692960474307 and b is -49.746126482213946\n",
      "Iteration 476, the loss is 4.52879009438986, parameters k is 11.51677628458498 and b is -49.74607905138391\n",
      "Iteration 477, the loss is 4.528785498094336, parameters k is 11.516859608695652 and b is -49.74603162055387\n",
      "Iteration 478, the loss is 4.528780901798803, parameters k is 11.516942932806325 and b is -49.745984189723835\n",
      "Iteration 479, the loss is 4.528776305503274, parameters k is 11.517026256916997 and b is -49.7459367588938\n",
      "Iteration 480, the loss is 4.528771709207748, parameters k is 11.51710958102767 and b is -49.74588932806376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 481, the loss is 4.528767112912219, parameters k is 11.517192905138343 and b is -49.745841897233724\n",
      "Iteration 482, the loss is 4.528762516616692, parameters k is 11.517276229249015 and b is -49.74579446640369\n",
      "Iteration 483, the loss is 4.528757920321163, parameters k is 11.517359553359688 and b is -49.74574703557365\n",
      "Iteration 484, the loss is 4.528753324025633, parameters k is 11.51744287747036 and b is -49.74569960474361\n",
      "Iteration 485, the loss is 4.528748727730105, parameters k is 11.517526201581033 and b is -49.74565217391358\n",
      "Iteration 486, the loss is 4.5287441314345775, parameters k is 11.517609525691705 and b is -49.74560474308354\n",
      "Iteration 487, the loss is 4.528739535139047, parameters k is 11.517692849802378 and b is -49.7455573122535\n",
      "Iteration 488, the loss is 4.528734938843517, parameters k is 11.51777617391305 and b is -49.745509881423466\n",
      "Iteration 489, the loss is 4.528730342547988, parameters k is 11.517859498023723 and b is -49.74546245059343\n",
      "Iteration 490, the loss is 4.5287257462524595, parameters k is 11.517942822134396 and b is -49.74541501976339\n",
      "Iteration 491, the loss is 4.528721149956936, parameters k is 11.518026146245068 and b is -49.745367588933355\n",
      "Iteration 492, the loss is 4.528716553661404, parameters k is 11.518109470355741 and b is -49.74532015810332\n",
      "Iteration 493, the loss is 4.528711957365875, parameters k is 11.518192794466414 and b is -49.74527272727328\n",
      "Iteration 494, the loss is 4.528707361070347, parameters k is 11.518276118577086 and b is -49.745225296443245\n",
      "Iteration 495, the loss is 4.52870276477482, parameters k is 11.518359442687759 and b is -49.74517786561321\n",
      "Iteration 496, the loss is 4.528698168479286, parameters k is 11.518442766798431 and b is -49.74513043478317\n",
      "Iteration 497, the loss is 4.528693572183758, parameters k is 11.518526090909104 and b is -49.745083003953134\n",
      "Iteration 498, the loss is 4.52868897588823, parameters k is 11.518609415019776 and b is -49.7450355731231\n",
      "Iteration 499, the loss is 4.528684379592695, parameters k is 11.518692739130449 and b is -49.74498814229306\n",
      "Iteration 500, the loss is 4.528679783297173, parameters k is 11.518776063241122 and b is -49.74494071146302\n",
      "Iteration 501, the loss is 4.528675187001645, parameters k is 11.518859387351794 and b is -49.744893280632986\n",
      "Iteration 502, the loss is 4.528670590706117, parameters k is 11.518942711462467 and b is -49.74484584980295\n",
      "Iteration 503, the loss is 4.528665994410591, parameters k is 11.51902603557314 and b is -49.74479841897291\n",
      "Iteration 504, the loss is 4.52866139811506, parameters k is 11.519109359683812 and b is -49.744750988142876\n",
      "Iteration 505, the loss is 4.528656801819531, parameters k is 11.519192683794484 and b is -49.74470355731284\n",
      "Iteration 506, the loss is 4.528652205523999, parameters k is 11.519276007905157 and b is -49.7446561264828\n",
      "Iteration 507, the loss is 4.528647609228475, parameters k is 11.51935933201583 and b is -49.744608695652765\n",
      "Iteration 508, the loss is 4.528643012932946, parameters k is 11.519442656126502 and b is -49.74456126482273\n",
      "Iteration 509, the loss is 4.528638416637418, parameters k is 11.519525980237175 and b is -49.74451383399269\n",
      "Iteration 510, the loss is 4.528633820341888, parameters k is 11.519609304347847 and b is -49.744466403162654\n",
      "Iteration 511, the loss is 4.528629224046358, parameters k is 11.51969262845852 and b is -49.74441897233262\n",
      "Iteration 512, the loss is 4.528624627750826, parameters k is 11.519775952569193 and b is -49.74437154150258\n",
      "Iteration 513, the loss is 4.528620031455298, parameters k is 11.519859276679865 and b is -49.744324110672544\n",
      "Iteration 514, the loss is 4.528615435159771, parameters k is 11.519942600790538 and b is -49.74427667984251\n",
      "Iteration 515, the loss is 4.528610838864243, parameters k is 11.52002592490121 and b is -49.74422924901247\n",
      "Iteration 516, the loss is 4.528606242568718, parameters k is 11.520109249011883 and b is -49.74418181818243\n",
      "Iteration 517, the loss is 4.528601646273186, parameters k is 11.520192573122555 and b is -49.744134387352396\n",
      "Iteration 518, the loss is 4.528597049977656, parameters k is 11.520275897233228 and b is -49.74408695652236\n",
      "Iteration 519, the loss is 4.528592453682128, parameters k is 11.5203592213439 and b is -49.74403952569232\n",
      "Iteration 520, the loss is 4.528587857386598, parameters k is 11.520442545454573 and b is -49.743992094862286\n",
      "Iteration 521, the loss is 4.528583261091076, parameters k is 11.520525869565246 and b is -49.74394466403225\n",
      "Iteration 522, the loss is 4.528578664795544, parameters k is 11.520609193675918 and b is -49.74389723320221\n",
      "Iteration 523, the loss is 4.528574068500015, parameters k is 11.52069251778659 and b is -49.743849802372175\n",
      "Iteration 524, the loss is 4.528569472204483, parameters k is 11.520775841897263 and b is -49.74380237154214\n",
      "Iteration 525, the loss is 4.528564875908956, parameters k is 11.520859166007936 and b is -49.7437549407121\n",
      "Iteration 526, the loss is 4.528560279613428, parameters k is 11.520942490118609 and b is -49.743707509882064\n",
      "Iteration 527, the loss is 4.528555683317901, parameters k is 11.521025814229281 and b is -49.74366007905203\n",
      "Iteration 528, the loss is 4.528551087022369, parameters k is 11.521109138339954 and b is -49.74361264822199\n",
      "Iteration 529, the loss is 4.528546490726844, parameters k is 11.521192462450626 and b is -49.743565217391954\n",
      "Iteration 530, the loss is 4.528541894431317, parameters k is 11.521275786561299 and b is -49.74351778656192\n",
      "Iteration 531, the loss is 4.5285372981357845, parameters k is 11.521359110671971 and b is -49.74347035573188\n",
      "Iteration 532, the loss is 4.528532701840258, parameters k is 11.521442434782644 and b is -49.74342292490184\n",
      "Iteration 533, the loss is 4.528528105544725, parameters k is 11.521525758893317 and b is -49.743375494071806\n",
      "Iteration 534, the loss is 4.528523509249198, parameters k is 11.52160908300399 and b is -49.74332806324177\n",
      "Iteration 535, the loss is 4.528518912953671, parameters k is 11.521692407114662 and b is -49.74328063241173\n",
      "Iteration 536, the loss is 4.528514316658141, parameters k is 11.521775731225334 and b is -49.743233201581695\n",
      "Iteration 537, the loss is 4.528509720362608, parameters k is 11.521859055336007 and b is -49.74318577075166\n",
      "Iteration 538, the loss is 4.528505124067084, parameters k is 11.52194237944668 and b is -49.74313833992162\n",
      "Iteration 539, the loss is 4.528500527771552, parameters k is 11.522025703557352 and b is -49.743090909091585\n",
      "Iteration 540, the loss is 4.528495931476029, parameters k is 11.522109027668025 and b is -49.74304347826155\n",
      "Iteration 541, the loss is 4.5284913351804965, parameters k is 11.522192351778697 and b is -49.74299604743151\n",
      "Iteration 542, the loss is 4.528486738884966, parameters k is 11.52227567588937 and b is -49.742948616601474\n",
      "Iteration 543, the loss is 4.528482142589439, parameters k is 11.522359000000042 and b is -49.74290118577144\n",
      "Iteration 544, the loss is 4.5284775462939075, parameters k is 11.522442324110715 and b is -49.7428537549414\n",
      "Iteration 545, the loss is 4.528472949998385, parameters k is 11.522525648221388 and b is -49.74280632411136\n",
      "Iteration 546, the loss is 4.528468353702849, parameters k is 11.52260897233206 and b is -49.74275889328133\n",
      "Iteration 547, the loss is 4.528463757407325, parameters k is 11.522692296442733 and b is -49.74271146245129\n",
      "Iteration 548, the loss is 4.52845916111179, parameters k is 11.522775620553405 and b is -49.74266403162125\n",
      "Iteration 549, the loss is 4.528454564816267, parameters k is 11.522858944664078 and b is -49.742616600791216\n",
      "Iteration 550, the loss is 4.528450566816256, parameters k is 11.52294226877475 and b is -49.74256916996118\n",
      "Iteration 551, the loss is 4.528449254399184, parameters k is 11.522974865612696 and b is -49.74252964426948\n",
      "Iteration 552, the loss is 4.528447941982113, parameters k is 11.523007462450641 and b is -49.742490118577784\n",
      "Iteration 553, the loss is 4.528446629565036, parameters k is 11.523040059288586 and b is -49.74245059288609\n",
      "Iteration 554, the loss is 4.528445317147962, parameters k is 11.523072656126532 and b is -49.74241106719439\n",
      "Iteration 555, the loss is 4.528444004730888, parameters k is 11.523105252964477 and b is -49.74237154150269\n",
      "Iteration 556, the loss is 4.5284426923138135, parameters k is 11.523137849802422 and b is -49.742332015810995\n",
      "Iteration 557, the loss is 4.528441379896737, parameters k is 11.523170446640368 and b is -49.7422924901193\n",
      "Iteration 558, the loss is 4.52844006747967, parameters k is 11.523203043478313 and b is -49.7422529644276\n",
      "Iteration 559, the loss is 4.5284387550625915, parameters k is 11.523235640316258 and b is -49.7422134387359\n",
      "Iteration 560, the loss is 4.528437442645517, parameters k is 11.523268237154204 and b is -49.742173913044205\n",
      "Iteration 561, the loss is 4.5284361302284415, parameters k is 11.523300833992149 and b is -49.74213438735251\n",
      "Iteration 562, the loss is 4.528434817811371, parameters k is 11.523333430830094 and b is -49.74209486166081\n",
      "Iteration 563, the loss is 4.5284335053942915, parameters k is 11.52336602766804 and b is -49.74205533596911\n",
      "Iteration 564, the loss is 4.528432192977222, parameters k is 11.523398624505985 and b is -49.742015810277415\n",
      "Iteration 565, the loss is 4.528430880560143, parameters k is 11.52343122134393 and b is -49.74197628458572\n",
      "Iteration 566, the loss is 4.528429568143071, parameters k is 11.523463818181876 and b is -49.74193675889402\n",
      "Iteration 567, the loss is 4.528428255726, parameters k is 11.523496415019821 and b is -49.74189723320232\n",
      "Iteration 568, the loss is 4.528426943308924, parameters k is 11.523529011857766 and b is -49.741857707510626\n",
      "Iteration 569, the loss is 4.528425630891852, parameters k is 11.523561608695712 and b is -49.74181818181893\n",
      "Iteration 570, the loss is 4.528424318474775, parameters k is 11.523594205533657 and b is -49.74177865612723\n",
      "Iteration 571, the loss is 4.528423006057701, parameters k is 11.523626802371602 and b is -49.74173913043553\n",
      "Iteration 572, the loss is 4.528421693640624, parameters k is 11.523659399209548 and b is -49.741699604743836\n",
      "Iteration 573, the loss is 4.528420381223554, parameters k is 11.523691996047493 and b is -49.74166007905214\n",
      "Iteration 574, the loss is 4.528419068806476, parameters k is 11.523724592885438 and b is -49.74162055336044\n",
      "Iteration 575, the loss is 4.5284177563894055, parameters k is 11.523757189723383 and b is -49.741581027668744\n",
      "Iteration 576, the loss is 4.528416443972331, parameters k is 11.523789786561329 and b is -49.741541501977046\n",
      "Iteration 577, the loss is 4.528415131555255, parameters k is 11.523822383399274 and b is -49.74150197628535\n",
      "Iteration 578, the loss is 4.528413819138186, parameters k is 11.52385498023722 and b is -49.74146245059365\n",
      "Iteration 579, the loss is 4.528412506721105, parameters k is 11.523887577075165 and b is -49.741422924901954\n",
      "Iteration 580, the loss is 4.528411194304031, parameters k is 11.52392017391311 and b is -49.74138339921026\n",
      "Iteration 581, the loss is 4.528409881886963, parameters k is 11.523952770751055 and b is -49.74134387351856\n",
      "Iteration 582, the loss is 4.528408569469885, parameters k is 11.523985367589 and b is -49.74130434782686\n",
      "Iteration 583, the loss is 4.5284072570528116, parameters k is 11.524017964426946 and b is -49.741264822135165\n",
      "Iteration 584, the loss is 4.52840594463574, parameters k is 11.524050561264891 and b is -49.74122529644347\n",
      "Iteration 585, the loss is 4.5284046322186615, parameters k is 11.524083158102837 and b is -49.74118577075177\n",
      "Iteration 586, the loss is 4.528403319801588, parameters k is 11.524115754940782 and b is -49.74114624506007\n",
      "Iteration 587, the loss is 4.528402007384515, parameters k is 11.524148351778727 and b is -49.741106719368375\n",
      "Iteration 588, the loss is 4.528400694967443, parameters k is 11.524180948616673 and b is -49.74106719367668\n",
      "Iteration 589, the loss is 4.528399382550364, parameters k is 11.524213545454618 and b is -49.74102766798498\n",
      "Iteration 590, the loss is 4.528398281626796, parameters k is 11.524246142292563 and b is -49.74098814229328\n",
      "Iteration 591, the loss is 4.528397727190262, parameters k is 11.524228841897306 and b is -49.740956521739925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 592, the loss is 4.528397289102232, parameters k is 11.524261438735252 and b is -49.74091699604823\n",
      "Iteration 593, the loss is 4.528396639520695, parameters k is 11.524244138339995 and b is -49.74088537549487\n",
      "Iteration 594, the loss is 4.528395989939164, parameters k is 11.524226837944738 and b is -49.74085375494151\n",
      "Iteration 595, the loss is 4.528395385944092, parameters k is 11.524209537549481 and b is -49.740822134388154\n",
      "Iteration 596, the loss is 4.528394997414596, parameters k is 11.524242134387427 and b is -49.740782608696456\n",
      "Iteration 597, the loss is 4.528394347833058, parameters k is 11.52422483399217 and b is -49.7407509881431\n",
      "Iteration 598, the loss is 4.528393698251529, parameters k is 11.524207533596913 and b is -49.74071936758974\n",
      "Iteration 599, the loss is 4.528393048669988, parameters k is 11.524190233201656 and b is -49.74068774703638\n",
      "Iteration 600, the loss is 4.528392701754894, parameters k is 11.5241729328064 and b is -49.740656126483024\n",
      "Iteration 601, the loss is 4.52839205614542, parameters k is 11.524205529644345 and b is -49.74061660079133\n",
      "Iteration 602, the loss is 4.528391406563889, parameters k is 11.524188229249088 and b is -49.74058498023797\n",
      "Iteration 603, the loss is 4.52839075698235, parameters k is 11.524170928853831 and b is -49.74055335968461\n",
      "Iteration 604, the loss is 4.528390360508727, parameters k is 11.524153628458574 and b is -49.74052173913125\n",
      "Iteration 605, the loss is 4.528389764457785, parameters k is 11.52418622529652 and b is -49.740482213439556\n",
      "Iteration 606, the loss is 4.5283891148762505, parameters k is 11.524168924901263 and b is -49.7404505928862\n",
      "Iteration 607, the loss is 4.528388465294709, parameters k is 11.524151624506006 and b is -49.74041897233284\n",
      "Iteration 608, the loss is 4.528388019262558, parameters k is 11.524134324110749 and b is -49.74038735177948\n",
      "Iteration 609, the loss is 4.528387472770146, parameters k is 11.524166920948694 and b is -49.740347826087785\n",
      "Iteration 610, the loss is 4.528386823188614, parameters k is 11.524149620553438 and b is -49.74031620553443\n",
      "Iteration 611, the loss is 4.528386173607079, parameters k is 11.52413232015818 and b is -49.74028458498107\n",
      "Iteration 612, the loss is 4.528385678016386, parameters k is 11.524115019762924 and b is -49.74025296442771\n",
      "Iteration 613, the loss is 4.528385181082509, parameters k is 11.52414761660087 and b is -49.74021343873601\n",
      "Iteration 614, the loss is 4.528384531500977, parameters k is 11.524130316205612 and b is -49.740181818182656\n",
      "Iteration 615, the loss is 4.528383881919441, parameters k is 11.524113015810356 and b is -49.7401501976293\n",
      "Iteration 616, the loss is 4.52838333677022, parameters k is 11.524095715415099 and b is -49.74011857707594\n",
      "Iteration 617, the loss is 4.52838288939487, parameters k is 11.524128312253044 and b is -49.74007905138424\n",
      "Iteration 618, the loss is 4.528382239813337, parameters k is 11.524111011857787 and b is -49.740047430830884\n",
      "Iteration 619, the loss is 4.528381590231802, parameters k is 11.52409371146253 and b is -49.74001581027753\n",
      "Iteration 620, the loss is 4.528380995524052, parameters k is 11.524076411067274 and b is -49.73998418972417\n",
      "Iteration 621, the loss is 4.528380597707237, parameters k is 11.524109007905219 and b is -49.73994466403247\n",
      "Iteration 622, the loss is 4.528379948125699, parameters k is 11.524091707509962 and b is -49.73991304347911\n",
      "Iteration 623, the loss is 4.528379298544165, parameters k is 11.524074407114705 and b is -49.739881422925755\n",
      "Iteration 624, the loss is 4.528378654277884, parameters k is 11.524057106719448 and b is -49.7398498023724\n",
      "Iteration 625, the loss is 4.528378306019602, parameters k is 11.524089703557394 and b is -49.7398102766807\n",
      "Iteration 626, the loss is 4.528377656438063, parameters k is 11.524072403162137 and b is -49.73977865612734\n",
      "Iteration 627, the loss is 4.528377006856528, parameters k is 11.52405510276688 and b is -49.739747035573984\n",
      "Iteration 628, the loss is 4.528376357274994, parameters k is 11.524037802371623 and b is -49.739715415020626\n",
      "Iteration 629, the loss is 4.5283759700886845, parameters k is 11.524020501976366 and b is -49.73968379446727\n",
      "Iteration 630, the loss is 4.528375364750425, parameters k is 11.524053098814312 and b is -49.73964426877557\n",
      "Iteration 631, the loss is 4.528374715168886, parameters k is 11.524035798419055 and b is -49.73961264822221\n",
      "Iteration 632, the loss is 4.528374065587353, parameters k is 11.524018498023798 and b is -49.739581027668855\n",
      "Iteration 633, the loss is 4.528373628842513, parameters k is 11.524001197628541 and b is -49.7395494071155\n",
      "Iteration 634, the loss is 4.528373073062783, parameters k is 11.524033794466487 and b is -49.7395098814238\n",
      "Iteration 635, the loss is 4.528372423481256, parameters k is 11.52401649407123 and b is -49.73947826087044\n",
      "Iteration 636, the loss is 4.528371773899716, parameters k is 11.523999193675973 and b is -49.739446640317084\n",
      "Iteration 637, the loss is 4.528371287596346, parameters k is 11.523981893280716 and b is -49.739415019763726\n",
      "Iteration 638, the loss is 4.528370781375148, parameters k is 11.524014490118661 and b is -49.73937549407203\n",
      "Iteration 639, the loss is 4.5283701317936105, parameters k is 11.523997189723405 and b is -49.73934387351867\n",
      "Iteration 640, the loss is 4.52836948221208, parameters k is 11.523979889328148 and b is -49.73931225296531\n",
      "Iteration 641, the loss is 4.528368946350178, parameters k is 11.523962588932891 and b is -49.739280632411955\n",
      "Iteration 642, the loss is 4.528368489687513, parameters k is 11.523995185770836 and b is -49.73924110672026\n",
      "Iteration 643, the loss is 4.5283678401059735, parameters k is 11.52397788537558 and b is -49.7392094861669\n",
      "Iteration 644, the loss is 4.528367190524445, parameters k is 11.523960584980323 and b is -49.73917786561354\n",
      "Iteration 645, the loss is 4.528366605104009, parameters k is 11.523943284585066 and b is -49.739146245060184\n",
      "Iteration 646, the loss is 4.528366197999877, parameters k is 11.523975881423011 and b is -49.739106719368486\n",
      "Iteration 647, the loss is 4.528365548418343, parameters k is 11.523958581027754 and b is -49.73907509881513\n",
      "Iteration 648, the loss is 4.528364898836804, parameters k is 11.523941280632497 and b is -49.73904347826177\n",
      "Iteration 649, the loss is 4.52836426385784, parameters k is 11.52392398023724 and b is -49.73901185770841\n",
      "Iteration 650, the loss is 4.528363906312238, parameters k is 11.523956577075186 and b is -49.738972332016715\n",
      "Iteration 651, the loss is 4.528363256730702, parameters k is 11.52393927667993 and b is -49.73894071146336\n",
      "Iteration 652, the loss is 4.528362607149168, parameters k is 11.523921976284672 and b is -49.73890909091\n",
      "Iteration 653, the loss is 4.528361957567629, parameters k is 11.523904675889415 and b is -49.73887747035664\n",
      "Iteration 654, the loss is 4.52836157966864, parameters k is 11.523887375494159 and b is -49.73884584980328\n",
      "Iteration 655, the loss is 4.5283609650430625, parameters k is 11.523919972332104 and b is -49.738806324111586\n",
      "Iteration 656, the loss is 4.528360315461528, parameters k is 11.523902671936847 and b is -49.73877470355823\n",
      "Iteration 657, the loss is 4.528359665879994, parameters k is 11.52388537154159 and b is -49.73874308300487\n",
      "Iteration 658, the loss is 4.528359238422469, parameters k is 11.523868071146333 and b is -49.73871146245151\n",
      "Iteration 659, the loss is 4.5283586733554255, parameters k is 11.523900667984279 and b is -49.738671936759815\n",
      "Iteration 660, the loss is 4.528358023773896, parameters k is 11.523883367589022 and b is -49.73864031620646\n",
      "Iteration 661, the loss is 4.52835737419236, parameters k is 11.523866067193765 and b is -49.7386086956531\n",
      "Iteration 662, the loss is 4.5283568971763035, parameters k is 11.523848766798508 and b is -49.73857707509974\n",
      "Iteration 663, the loss is 4.528356381667787, parameters k is 11.523881363636454 and b is -49.73853754940804\n",
      "Iteration 664, the loss is 4.52835573208625, parameters k is 11.523864063241197 and b is -49.738505928854686\n",
      "Iteration 665, the loss is 4.528355082504716, parameters k is 11.52384676284594 and b is -49.73847430830133\n",
      "Iteration 666, the loss is 4.5283545559301315, parameters k is 11.523829462450683 and b is -49.73844268774797\n",
      "Iteration 667, the loss is 4.528354089980155, parameters k is 11.523862059288629 and b is -49.73840316205627\n",
      "Iteration 668, the loss is 4.528353440398616, parameters k is 11.523844758893372 and b is -49.738371541502914\n",
      "Iteration 669, the loss is 4.528352790817081, parameters k is 11.523827458498115 and b is -49.73833992094956\n",
      "Iteration 670, the loss is 4.528352214683966, parameters k is 11.523810158102858 and b is -49.7383083003962\n",
      "Iteration 671, the loss is 4.528351798292512, parameters k is 11.523842754940803 and b is -49.7382687747045\n",
      "Iteration 672, the loss is 4.52835114871098, parameters k is 11.523825454545547 and b is -49.73823715415114\n",
      "Iteration 673, the loss is 4.528350499129443, parameters k is 11.52380815415029 and b is -49.738205533597785\n",
      "Iteration 674, the loss is 4.528349873437798, parameters k is 11.523790853755033 and b is -49.73817391304443\n",
      "Iteration 675, the loss is 4.528349506604876, parameters k is 11.523823450592978 and b is -49.73813438735273\n",
      "Iteration 676, the loss is 4.528348857023341, parameters k is 11.523806150197721 and b is -49.73810276679937\n",
      "Iteration 677, the loss is 4.5283482074418036, parameters k is 11.523788849802465 and b is -49.738071146246014\n",
      "Iteration 678, the loss is 4.528347557860271, parameters k is 11.523771549407208 and b is -49.738039525692656\n",
      "Iteration 679, the loss is 4.528347189248603, parameters k is 11.523754249011951 and b is -49.7380079051393\n",
      "Iteration 680, the loss is 4.528346565335702, parameters k is 11.523786845849896 and b is -49.7379683794476\n",
      "Iteration 681, the loss is 4.528345915754167, parameters k is 11.52376954545464 and b is -49.73793675889424\n",
      "Iteration 682, the loss is 4.528345266172628, parameters k is 11.523752245059383 and b is -49.737905138340885\n",
      "Iteration 683, the loss is 4.52834484800243, parameters k is 11.523734944664126 and b is -49.73787351778753\n",
      "Iteration 684, the loss is 4.5283442736480675, parameters k is 11.523767541502071 and b is -49.73783399209583\n",
      "Iteration 685, the loss is 4.528343624066533, parameters k is 11.523750241106814 and b is -49.73780237154247\n",
      "Iteration 686, the loss is 4.52834297448499, parameters k is 11.523732940711557 and b is -49.737770750989114\n",
      "Iteration 687, the loss is 4.528342506756261, parameters k is 11.5237156403163 and b is -49.737739130435756\n",
      "Iteration 688, the loss is 4.528341981960427, parameters k is 11.523748237154246 and b is -49.73769960474406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 689, the loss is 4.528341332378893, parameters k is 11.523730936758989 and b is -49.7376679841907\n",
      "Iteration 690, the loss is 4.528340682797355, parameters k is 11.523713636363732 and b is -49.73763636363734\n",
      "Iteration 691, the loss is 4.528340165510098, parameters k is 11.523696335968475 and b is -49.737604743083985\n",
      "Iteration 692, the loss is 4.528339690272791, parameters k is 11.52372893280642 and b is -49.73756521739229\n",
      "Iteration 693, the loss is 4.528339040691257, parameters k is 11.523711632411164 and b is -49.73753359683893\n",
      "Iteration 694, the loss is 4.52833839110972, parameters k is 11.523694332015907 and b is -49.73750197628557\n",
      "Iteration 695, the loss is 4.528337824263926, parameters k is 11.52367703162065 and b is -49.73747035573221\n",
      "Iteration 696, the loss is 4.528337398585155, parameters k is 11.523709628458596 and b is -49.737430830040516\n",
      "Iteration 697, the loss is 4.528336749003619, parameters k is 11.523692328063339 and b is -49.73739920948716\n",
      "Iteration 698, the loss is 4.52833609942209, parameters k is 11.523675027668082 and b is -49.7373675889338\n",
      "Iteration 699, the loss is 4.528335483017761, parameters k is 11.523657727272825 and b is -49.73733596838044\n",
      "Iteration 700, the loss is 4.528335106897517, parameters k is 11.52369032411077 and b is -49.737296442688745\n",
      "Iteration 701, the loss is 4.528334457315978, parameters k is 11.523673023715514 and b is -49.73726482213539\n",
      "Iteration 702, the loss is 4.528333807734445, parameters k is 11.523655723320257 and b is -49.73723320158203\n",
      "Iteration 703, the loss is 4.528333158152913, parameters k is 11.523638422925 and b is -49.73720158102867\n",
      "Iteration 704, the loss is 4.528332798828555, parameters k is 11.523621122529743 and b is -49.73716996047531\n",
      "Iteration 705, the loss is 4.528332165628339, parameters k is 11.523653719367688 and b is -49.737130434783616\n",
      "Iteration 706, the loss is 4.5283315160468085, parameters k is 11.523636418972432 and b is -49.73709881423026\n",
      "Iteration 707, the loss is 4.528330866465272, parameters k is 11.523619118577175 and b is -49.7370671936769\n",
      "Iteration 708, the loss is 4.528330457582389, parameters k is 11.523601818181918 and b is -49.73703557312354\n",
      "Iteration 709, the loss is 4.528329873940713, parameters k is 11.523634415019863 and b is -49.736996047431845\n",
      "Iteration 710, the loss is 4.528329224359168, parameters k is 11.523617114624606 and b is -49.73696442687849\n",
      "Iteration 711, the loss is 4.5283285747776345, parameters k is 11.52359981422935 and b is -49.73693280632513\n",
      "Iteration 712, the loss is 4.528328116336221, parameters k is 11.523582513834093 and b is -49.73690118577177\n",
      "Iteration 713, the loss is 4.528327582253068, parameters k is 11.523615110672038 and b is -49.73686166008007\n",
      "Iteration 714, the loss is 4.528326932671534, parameters k is 11.523597810276781 and b is -49.736830039526716\n",
      "Iteration 715, the loss is 4.528326283089999, parameters k is 11.523580509881524 and b is -49.73679841897336\n",
      "Iteration 716, the loss is 4.5283257750900505, parameters k is 11.523563209486268 and b is -49.73676679842\n",
      "Iteration 717, the loss is 4.528325290565436, parameters k is 11.523595806324213 and b is -49.7367272727283\n",
      "Iteration 718, the loss is 4.528324640983892, parameters k is 11.523578505928956 and b is -49.736695652174944\n",
      "Iteration 719, the loss is 4.528323991402357, parameters k is 11.5235612055337 and b is -49.736664031621586\n",
      "Iteration 720, the loss is 4.528323433843881, parameters k is 11.523543905138443 and b is -49.73663241106823\n",
      "Iteration 721, the loss is 4.528322998877791, parameters k is 11.523576501976388 and b is -49.73659288537653\n",
      "Iteration 722, the loss is 4.5283223492962525, parameters k is 11.523559201581131 and b is -49.73656126482317\n",
      "Iteration 723, the loss is 4.528321699714717, parameters k is 11.523541901185874 and b is -49.736529644269815\n",
      "Iteration 724, the loss is 4.528321092597713, parameters k is 11.523524600790617 and b is -49.73649802371646\n",
      "Iteration 725, the loss is 4.528320707190154, parameters k is 11.523557197628563 and b is -49.73645849802476\n",
      "Iteration 726, the loss is 4.528320057608621, parameters k is 11.523539897233306 and b is -49.7364268774714\n",
      "Iteration 727, the loss is 4.528319408027083, parameters k is 11.523522596838049 and b is -49.736395256918044\n",
      "Iteration 728, the loss is 4.528318758445547, parameters k is 11.523505296442792 and b is -49.736363636364686\n",
      "Iteration 729, the loss is 4.528318408408516, parameters k is 11.523487996047535 and b is -49.73633201581133\n",
      "Iteration 730, the loss is 4.528317765920978, parameters k is 11.52352059288548 and b is -49.73629249011963\n",
      "Iteration 731, the loss is 4.528317116339448, parameters k is 11.523503292490224 and b is -49.73626086956627\n",
      "Iteration 732, the loss is 4.528316466757913, parameters k is 11.523485992094967 and b is -49.736229249012915\n",
      "Iteration 733, the loss is 4.52831606716235, parameters k is 11.52346869169971 and b is -49.73619762845956\n",
      "Iteration 734, the loss is 4.528315474233344, parameters k is 11.523501288537656 and b is -49.73615810276786\n",
      "Iteration 735, the loss is 4.528314824651807, parameters k is 11.523483988142399 and b is -49.7361264822145\n",
      "Iteration 736, the loss is 4.528314175070278, parameters k is 11.523466687747142 and b is -49.736094861661144\n",
      "Iteration 737, the loss is 4.5283137259161785, parameters k is 11.523449387351885 and b is -49.736063241107786\n",
      "Iteration 738, the loss is 4.528313182545706, parameters k is 11.52348198418983 and b is -49.73602371541609\n",
      "Iteration 739, the loss is 4.528312532964166, parameters k is 11.523464683794574 and b is -49.73599209486273\n",
      "Iteration 740, the loss is 4.528311883382634, parameters k is 11.523447383399317 and b is -49.73596047430937\n",
      "Iteration 741, the loss is 4.52831138467001, parameters k is 11.52343008300406 and b is -49.735928853756015\n",
      "Iteration 742, the loss is 4.52831089085807, parameters k is 11.523462679842005 and b is -49.73588932806432\n",
      "Iteration 743, the loss is 4.5283102412765315, parameters k is 11.523445379446748 and b is -49.73585770751096\n",
      "Iteration 744, the loss is 4.528309591694997, parameters k is 11.523428079051492 and b is -49.7358260869576\n",
      "Iteration 745, the loss is 4.528309043423845, parameters k is 11.523410778656235 and b is -49.73579446640424\n",
      "Iteration 746, the loss is 4.528308599170429, parameters k is 11.52344337549418 and b is -49.735754940712546\n",
      "Iteration 747, the loss is 4.528307949588897, parameters k is 11.523426075098923 and b is -49.73572332015919\n",
      "Iteration 748, the loss is 4.528307300007364, parameters k is 11.523408774703666 and b is -49.73569169960583\n",
      "Iteration 749, the loss is 4.528306702177675, parameters k is 11.52339147430841 and b is -49.73566007905247\n",
      "Iteration 750, the loss is 4.528306307482794, parameters k is 11.523424071146355 and b is -49.735620553360775\n",
      "Iteration 751, the loss is 4.528305657901257, parameters k is 11.523406770751098 and b is -49.73558893280742\n",
      "Iteration 752, the loss is 4.5283050083197205, parameters k is 11.523389470355841 and b is -49.73555731225406\n",
      "Iteration 753, the loss is 4.528304360931511, parameters k is 11.523372169960584 and b is -49.7355256917007\n",
      "Iteration 754, the loss is 4.528304015795158, parameters k is 11.52340476679853 and b is -49.735486166009004\n",
      "Iteration 755, the loss is 4.528303366213624, parameters k is 11.523387466403273 and b is -49.735454545455646\n",
      "Iteration 756, the loss is 4.528302716632086, parameters k is 11.523370166008016 and b is -49.73542292490229\n",
      "Iteration 757, the loss is 4.528302067050549, parameters k is 11.52335286561276 and b is -49.73539130434893\n",
      "Iteration 758, the loss is 4.528301676742307, parameters k is 11.523335565217502 and b is -49.73535968379557\n",
      "Iteration 759, the loss is 4.528301074525985, parameters k is 11.523368162055448 and b is -49.735320158103875\n",
      "Iteration 760, the loss is 4.5283004249444465, parameters k is 11.523350861660191 and b is -49.73528853755052\n",
      "Iteration 761, the loss is 4.528299775362911, parameters k is 11.523333561264934 and b is -49.73525691699716\n",
      "Iteration 762, the loss is 4.52829933549614, parameters k is 11.523316260869677 and b is -49.7352252964438\n",
      "Iteration 763, the loss is 4.528298782838344, parameters k is 11.523348857707623 and b is -49.7351857707521\n",
      "Iteration 764, the loss is 4.528298133256807, parameters k is 11.523331557312366 and b is -49.735154150198746\n",
      "Iteration 765, the loss is 4.528297483675275, parameters k is 11.523314256917109 and b is -49.73512252964539\n",
      "Iteration 766, the loss is 4.528296994249969, parameters k is 11.523296956521852 and b is -49.73509090909203\n",
      "Iteration 767, the loss is 4.528296491150711, parameters k is 11.523329553359797 and b is -49.73505138340033\n",
      "Iteration 768, the loss is 4.528295841569175, parameters k is 11.52331225296454 and b is -49.735019762846974\n",
      "Iteration 769, the loss is 4.52829519198764, parameters k is 11.523294952569284 and b is -49.734988142293616\n",
      "Iteration 770, the loss is 4.528294653003804, parameters k is 11.523277652174027 and b is -49.73495652174026\n",
      "Iteration 771, the loss is 4.528294199463067, parameters k is 11.523310249011972 and b is -49.73491699604856\n",
      "Iteration 772, the loss is 4.528293549881537, parameters k is 11.523292948616715 and b is -49.7348853754952\n",
      "Iteration 773, the loss is 4.528292900299999, parameters k is 11.523275648221459 and b is -49.734853754941845\n",
      "Iteration 774, the loss is 4.52829231175763, parameters k is 11.523258347826202 and b is -49.73482213438849\n",
      "Iteration 775, the loss is 4.528291907775431, parameters k is 11.523290944664147 and b is -49.73478260869679\n",
      "Iteration 776, the loss is 4.528291258193896, parameters k is 11.52327364426889 and b is -49.73475098814343\n",
      "Iteration 777, the loss is 4.5282906086123615, parameters k is 11.523256343873634 and b is -49.734719367590074\n",
      "Iteration 778, the loss is 4.528289970511467, parameters k is 11.523239043478377 and b is -49.734687747036716\n",
      "Iteration 779, the loss is 4.528289616087797, parameters k is 11.523271640316322 and b is -49.73464822134502\n",
      "Iteration 780, the loss is 4.52828896650626, parameters k is 11.523254339921065 and b is -49.73461660079166\n",
      "Iteration 781, the loss is 4.528288316924725, parameters k is 11.523237039525808 and b is -49.7345849802383\n",
      "Iteration 782, the loss is 4.528287667343188, parameters k is 11.523219739130552 and b is -49.734553359684945\n",
      "Iteration 783, the loss is 4.528287286322264, parameters k is 11.523202438735295 and b is -49.73452173913159\n",
      "Iteration 784, the loss is 4.5282866748186255, parameters k is 11.52323503557324 and b is -49.73448221343989\n",
      "Iteration 785, the loss is 4.528286025237092, parameters k is 11.523217735177983 and b is -49.73445059288653\n",
      "Iteration 786, the loss is 4.528285375655555, parameters k is 11.523200434782726 and b is -49.734418972333174\n",
      "Iteration 787, the loss is 4.528284945076094, parameters k is 11.52318313438747 and b is -49.734387351779816\n",
      "Iteration 788, the loss is 4.528284383130986, parameters k is 11.523215731225415 and b is -49.73434782608812\n",
      "Iteration 789, the loss is 4.528283733549454, parameters k is 11.523198430830158 and b is -49.73431620553476\n",
      "Iteration 790, the loss is 4.5282830839679145, parameters k is 11.523181130434901 and b is -49.7342845849814\n",
      "Iteration 791, the loss is 4.528282603829929, parameters k is 11.523163830039644 and b is -49.734252964428045\n",
      "Iteration 792, the loss is 4.5282820914433515, parameters k is 11.52319642687759 and b is -49.73421343873635\n",
      "Iteration 793, the loss is 4.528281441861808, parameters k is 11.523179126482333 and b is -49.73418181818299\n",
      "Iteration 794, the loss is 4.528280792280274, parameters k is 11.523161826087076 and b is -49.73415019762963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 795, the loss is 4.528280262583756, parameters k is 11.52314452569182 and b is -49.73411857707627\n",
      "Iteration 796, the loss is 4.528279799755707, parameters k is 11.523177122529765 and b is -49.734079051384576\n",
      "Iteration 797, the loss is 4.528279150174178, parameters k is 11.523159822134508 and b is -49.73404743083122\n",
      "Iteration 798, the loss is 4.528278500592636, parameters k is 11.523142521739251 and b is -49.73401581027786\n",
      "Iteration 799, the loss is 4.52827792133759, parameters k is 11.523125221343994 and b is -49.7339841897245\n",
      "Iteration 800, the loss is 4.52827750806807, parameters k is 11.52315781818194 and b is -49.733944664032805\n",
      "Iteration 801, the loss is 4.528276858486534, parameters k is 11.523140517786683 and b is -49.73391304347945\n",
      "Iteration 802, the loss is 4.528276208905004, parameters k is 11.523123217391426 and b is -49.73388142292609\n",
      "Iteration 803, the loss is 4.528275580091421, parameters k is 11.523105916996169 and b is -49.73384980237273\n",
      "Iteration 804, the loss is 4.528275216380433, parameters k is 11.523138513834114 and b is -49.733810276681034\n",
      "Iteration 805, the loss is 4.528274566798903, parameters k is 11.523121213438857 and b is -49.733778656127676\n",
      "Iteration 806, the loss is 4.52827391721736, parameters k is 11.5231039130436 and b is -49.73374703557432\n",
      "Iteration 807, the loss is 4.5282732676358295, parameters k is 11.523086612648344 and b is -49.73371541502096\n",
      "Iteration 808, the loss is 4.528272895902226, parameters k is 11.523069312253087 and b is -49.7336837944676\n",
      "Iteration 809, the loss is 4.528272275111265, parameters k is 11.523101909091032 and b is -49.733644268775905\n",
      "Iteration 810, the loss is 4.528271625529724, parameters k is 11.523084608695775 and b is -49.73361264822255\n",
      "Iteration 811, the loss is 4.52827097594819, parameters k is 11.523067308300519 and b is -49.73358102766919\n",
      "Iteration 812, the loss is 4.528270554656052, parameters k is 11.523050007905262 and b is -49.73354940711583\n",
      "Iteration 813, the loss is 4.528269983423626, parameters k is 11.523082604743207 and b is -49.73350988142413\n",
      "Iteration 814, the loss is 4.528269333842085, parameters k is 11.52306530434795 and b is -49.733478260870776\n",
      "Iteration 815, the loss is 4.5282686842605555, parameters k is 11.523048003952693 and b is -49.73344664031742\n",
      "Iteration 816, the loss is 4.52826821340989, parameters k is 11.523030703557437 and b is -49.73341501976406\n",
      "Iteration 817, the loss is 4.528267691735983, parameters k is 11.523063300395382 and b is -49.73337549407236\n",
      "Iteration 818, the loss is 4.528267042154451, parameters k is 11.523046000000125 and b is -49.733343873519004\n",
      "Iteration 819, the loss is 4.528266392572918, parameters k is 11.523028699604868 and b is -49.733312252965646\n",
      "Iteration 820, the loss is 4.5282658721637175, parameters k is 11.523011399209611 and b is -49.73328063241229\n",
      "Iteration 821, the loss is 4.528265400048348, parameters k is 11.523043996047557 and b is -49.73324110672059\n",
      "Iteration 822, the loss is 4.528264750466816, parameters k is 11.5230266956523 and b is -49.73320948616723\n",
      "Iteration 823, the loss is 4.528264100885278, parameters k is 11.523009395257043 and b is -49.733177865613875\n",
      "Iteration 824, the loss is 4.528263530917553, parameters k is 11.522992094861786 and b is -49.73314624506052\n",
      "Iteration 825, the loss is 4.528263108360712, parameters k is 11.523024691699732 and b is -49.73310671936882\n",
      "Iteration 826, the loss is 4.528262458779176, parameters k is 11.523007391304475 and b is -49.73307509881546\n",
      "Iteration 827, the loss is 4.528261809197646, parameters k is 11.522990090909218 and b is -49.733043478262104\n",
      "Iteration 828, the loss is 4.528261189671381, parameters k is 11.522972790513961 and b is -49.733011857708746\n",
      "Iteration 829, the loss is 4.528260816673077, parameters k is 11.523005387351906 and b is -49.73297233201705\n",
      "Iteration 830, the loss is 4.528260167091542, parameters k is 11.52298808695665 and b is -49.73294071146369\n",
      "Iteration 831, the loss is 4.528259517510009, parameters k is 11.522970786561393 and b is -49.73290909091033\n",
      "Iteration 832, the loss is 4.528258867928468, parameters k is 11.522953486166136 and b is -49.732877470356975\n",
      "Iteration 833, the loss is 4.528258505482182, parameters k is 11.52293618577088 and b is -49.73284584980362\n",
      "Iteration 834, the loss is 4.5282578754039005, parameters k is 11.522968782608825 and b is -49.73280632411192\n",
      "Iteration 835, the loss is 4.528257225822368, parameters k is 11.522951482213568 and b is -49.73277470355856\n",
      "Iteration 836, the loss is 4.528256576240831, parameters k is 11.52293418181831 and b is -49.732743083005204\n",
      "Iteration 837, the loss is 4.528256164236013, parameters k is 11.522916881423054 and b is -49.732711462451846\n",
      "Iteration 838, the loss is 4.528255583716266, parameters k is 11.522949478261 and b is -49.73267193676015\n",
      "Iteration 839, the loss is 4.528254934134728, parameters k is 11.522932177865743 and b is -49.73264031620679\n",
      "Iteration 840, the loss is 4.528254284553194, parameters k is 11.522914877470486 and b is -49.73260869565343\n",
      "Iteration 841, the loss is 4.5282538229898455, parameters k is 11.522897577075229 and b is -49.732577075100075\n",
      "Iteration 842, the loss is 4.528253292028627, parameters k is 11.522930173913174 and b is -49.73253754940838\n",
      "Iteration 843, the loss is 4.528252642447092, parameters k is 11.522912873517917 and b is -49.73250592885502\n",
      "Iteration 844, the loss is 4.5282519928655525, parameters k is 11.52289557312266 and b is -49.73247430830166\n",
      "Iteration 845, the loss is 4.5282514817436725, parameters k is 11.522878272727404 and b is -49.7324426877483\n",
      "Iteration 846, the loss is 4.528251000340986, parameters k is 11.522910869565349 and b is -49.732403162056606\n",
      "Iteration 847, the loss is 4.528250350759452, parameters k is 11.522893569170092 and b is -49.73237154150325\n",
      "Iteration 848, the loss is 4.528249701177917, parameters k is 11.522876268774835 and b is -49.73233992094989\n",
      "Iteration 849, the loss is 4.528249140497514, parameters k is 11.522858968379579 and b is -49.73230830039653\n",
      "Iteration 850, the loss is 4.528248708653351, parameters k is 11.522891565217524 and b is -49.732268774704835\n",
      "Iteration 851, the loss is 4.528248059071817, parameters k is 11.522874264822267 and b is -49.73223715415148\n",
      "Iteration 852, the loss is 4.528247409490279, parameters k is 11.52285696442701 and b is -49.73220553359812\n",
      "Iteration 853, the loss is 4.528246799251337, parameters k is 11.522839664031753 and b is -49.73217391304476\n",
      "Iteration 854, the loss is 4.528246416965714, parameters k is 11.522872260869699 and b is -49.732134387353064\n",
      "Iteration 855, the loss is 4.528245767384178, parameters k is 11.522854960474442 and b is -49.732102766799706\n",
      "Iteration 856, the loss is 4.528245117802647, parameters k is 11.522837660079185 and b is -49.73207114624635\n",
      "Iteration 857, the loss is 4.528244468221109, parameters k is 11.522820359683928 and b is -49.73203952569299\n",
      "Iteration 858, the loss is 4.528244115062137, parameters k is 11.522803059288671 and b is -49.73200790513963\n",
      "Iteration 859, the loss is 4.528243475696543, parameters k is 11.522835656126617 and b is -49.731968379447935\n",
      "Iteration 860, the loss is 4.528242826115008, parameters k is 11.52281835573136 and b is -49.73193675889458\n",
      "Iteration 861, the loss is 4.528242176533475, parameters k is 11.522801055336103 and b is -49.73190513834122\n",
      "Iteration 862, the loss is 4.528241773815967, parameters k is 11.522783754940846 and b is -49.73187351778786\n",
      "Iteration 863, the loss is 4.5282411840089, parameters k is 11.522816351778792 and b is -49.73183399209616\n",
      "Iteration 864, the loss is 4.528240534427366, parameters k is 11.522799051383535 and b is -49.731802371542805\n",
      "Iteration 865, the loss is 4.5282398848458305, parameters k is 11.522781750988278 and b is -49.73177075098945\n",
      "Iteration 866, the loss is 4.528239432569801, parameters k is 11.522764450593021 and b is -49.73173913043609\n",
      "Iteration 867, the loss is 4.528238892321265, parameters k is 11.522797047430966 and b is -49.73169960474439\n",
      "Iteration 868, the loss is 4.52823824273973, parameters k is 11.52277974703571 and b is -49.731667984191034\n",
      "Iteration 869, the loss is 4.5282375931581935, parameters k is 11.522762446640453 and b is -49.731636363637676\n",
      "Iteration 870, the loss is 4.528237091323631, parameters k is 11.522745146245196 and b is -49.73160474308432\n",
      "Iteration 871, the loss is 4.528236600633632, parameters k is 11.522777743083141 and b is -49.73156521739262\n",
      "Iteration 872, the loss is 4.528235951052092, parameters k is 11.522760442687884 and b is -49.73153359683926\n",
      "Iteration 873, the loss is 4.5282353014705565, parameters k is 11.522743142292628 and b is -49.731501976285905\n",
      "Iteration 874, the loss is 4.528234750077464, parameters k is 11.52272584189737 and b is -49.73147035573255\n",
      "Iteration 875, the loss is 4.528234308945989, parameters k is 11.522758438735316 and b is -49.73143083004085\n",
      "Iteration 876, the loss is 4.528233659364452, parameters k is 11.52274113834006 and b is -49.73139920948749\n",
      "Iteration 877, the loss is 4.528233009782917, parameters k is 11.522723837944802 and b is -49.731367588934134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 878, the loss is 4.528232408831301, parameters k is 11.522706537549546 and b is -49.731335968380776\n",
      "Iteration 879, the loss is 4.5282320172583574, parameters k is 11.522739134387491 and b is -49.73129644268908\n",
      "Iteration 880, the loss is 4.528231367676817, parameters k is 11.522721833992234 and b is -49.73126482213572\n",
      "Iteration 881, the loss is 4.528230718095279, parameters k is 11.522704533596977 and b is -49.73123320158236\n",
      "Iteration 882, the loss is 4.528230068513745, parameters k is 11.52268723320172 and b is -49.731201581029005\n",
      "Iteration 883, the loss is 4.528229724642096, parameters k is 11.522669932806464 and b is -49.73116996047565\n",
      "Iteration 884, the loss is 4.528229075989179, parameters k is 11.522702529644409 and b is -49.73113043478395\n",
      "Iteration 885, the loss is 4.528228426407641, parameters k is 11.522685229249152 and b is -49.73109881423059\n",
      "Iteration 886, the loss is 4.528227776826106, parameters k is 11.522667928853895 and b is -49.731067193677234\n",
      "Iteration 887, the loss is 4.528227383395931, parameters k is 11.522650628458639 and b is -49.731035573123876\n",
      "Iteration 888, the loss is 4.528226784301545, parameters k is 11.522683225296584 and b is -49.73099604743218\n",
      "Iteration 889, the loss is 4.528226134720007, parameters k is 11.522665924901327 and b is -49.73096442687882\n",
      "Iteration 890, the loss is 4.528225485138471, parameters k is 11.52264862450607 and b is -49.73093280632546\n",
      "Iteration 891, the loss is 4.528225042149766, parameters k is 11.522631324110813 and b is -49.730901185772105\n",
      "Iteration 892, the loss is 4.528224492613902, parameters k is 11.522663920948759 and b is -49.73086166008041\n",
      "Iteration 893, the loss is 4.5282238430323645, parameters k is 11.522646620553502 and b is -49.73083003952705\n",
      "Iteration 894, the loss is 4.528223193450832, parameters k is 11.522629320158245 and b is -49.73079841897369\n",
      "Iteration 895, the loss is 4.5282227009035925, parameters k is 11.522612019762988 and b is -49.73076679842033\n",
      "Iteration 896, the loss is 4.528222200926266, parameters k is 11.522644616600934 and b is -49.730727272728636\n",
      "Iteration 897, the loss is 4.5282215513447355, parameters k is 11.522627316205677 and b is -49.73069565217528\n",
      "Iteration 898, the loss is 4.528220901763195, parameters k is 11.52261001581042 and b is -49.73066403162192\n",
      "Iteration 899, the loss is 4.528220359657426, parameters k is 11.522592715415163 and b is -49.73063241106856\n",
      "Iteration 900, the loss is 4.528219909238625, parameters k is 11.522625312253108 and b is -49.730592885376865\n",
      "Iteration 901, the loss is 4.5282192596570905, parameters k is 11.522608011857852 and b is -49.73056126482351\n",
      "Iteration 902, the loss is 4.528218610075563, parameters k is 11.522590711462595 and b is -49.73052964427015\n",
      "Iteration 903, the loss is 4.528218018411262, parameters k is 11.522573411067338 and b is -49.73049802371679\n",
      "Iteration 904, the loss is 4.52821761755099, parameters k is 11.522606007905283 and b is -49.730458498025094\n",
      "Iteration 905, the loss is 4.528216967969457, parameters k is 11.522588707510026 and b is -49.730426877471736\n",
      "Iteration 906, the loss is 4.52821631838792, parameters k is 11.52257140711477 and b is -49.73039525691838\n",
      "Iteration 907, the loss is 4.5282156771650905, parameters k is 11.522554106719513 and b is -49.73036363636502\n",
      "Iteration 908, the loss is 4.528215325863353, parameters k is 11.522586703557458 and b is -49.73032411067332\n",
      "Iteration 909, the loss is 4.528214676281821, parameters k is 11.522569403162201 and b is -49.730292490119965\n",
      "Iteration 910, the loss is 4.528214026700283, parameters k is 11.522552102766944 and b is -49.73026086956661\n",
      "Iteration 911, the loss is 4.528213377118751, parameters k is 11.522534802371688 and b is -49.73022924901325\n",
      "Iteration 912, the loss is 4.528212992975892, parameters k is 11.52251750197643 and b is -49.73019762845989\n",
      "Iteration 913, the loss is 4.528212384594182, parameters k is 11.522550098814376 and b is -49.73015810276819\n",
      "Iteration 914, the loss is 4.528211735012646, parameters k is 11.52253279841912 and b is -49.730126482214835\n",
      "Iteration 915, the loss is 4.528211085431114, parameters k is 11.522515498023862 and b is -49.73009486166148\n",
      "Iteration 916, the loss is 4.528210651729721, parameters k is 11.522498197628606 and b is -49.73006324110812\n",
      "Iteration 917, the loss is 4.52821009290654, parameters k is 11.522530794466551 and b is -49.73002371541642\n",
      "Iteration 918, the loss is 4.528209443325013, parameters k is 11.522513494071294 and b is -49.729992094863064\n",
      "Iteration 919, the loss is 4.528208793743472, parameters k is 11.522496193676037 and b is -49.729960474309706\n",
      "Iteration 920, the loss is 4.528208310483557, parameters k is 11.52247889328078 and b is -49.72992885375635\n",
      "Iteration 921, the loss is 4.5282078012189055, parameters k is 11.522511490118726 and b is -49.72988932806465\n",
      "Iteration 922, the loss is 4.528207151637373, parameters k is 11.522494189723469 and b is -49.72985770751129\n",
      "Iteration 923, the loss is 4.528206502055837, parameters k is 11.522476889328212 and b is -49.729826086957935\n",
      "Iteration 924, the loss is 4.52820596923738, parameters k is 11.522459588932955 and b is -49.72979446640458\n",
      "Iteration 925, the loss is 4.528205509531269, parameters k is 11.5224921857709 and b is -49.72975494071288\n",
      "Iteration 926, the loss is 4.528204859949733, parameters k is 11.522474885375644 and b is -49.72972332015952\n",
      "Iteration 927, the loss is 4.528204210368201, parameters k is 11.522457584980387 and b is -49.729691699606164\n",
      "Iteration 928, the loss is 4.528203627991216, parameters k is 11.52244028458513 and b is -49.729660079052806\n",
      "Iteration 929, the loss is 4.528203217843628, parameters k is 11.522472881423075 and b is -49.72962055336111\n",
      "Iteration 930, the loss is 4.528202568262099, parameters k is 11.522455581027819 and b is -49.72958893280775\n",
      "Iteration 931, the loss is 4.528201918680559, parameters k is 11.522438280632562 and b is -49.72955731225439\n",
      "Iteration 932, the loss is 4.528201286745044, parameters k is 11.522420980237305 and b is -49.729525691701035\n",
      "Iteration 933, the loss is 4.52820092615599, parameters k is 11.52245357707525 and b is -49.72948616600934\n",
      "Iteration 934, the loss is 4.528200276574461, parameters k is 11.522436276679993 and b is -49.72945454545598\n",
      "Iteration 935, the loss is 4.528199626992925, parameters k is 11.522418976284737 and b is -49.72942292490262\n",
      "Iteration 936, the loss is 4.528198977411382, parameters k is 11.52240167588948 and b is -49.729391304349264\n",
      "Iteration 937, the loss is 4.528198602555845, parameters k is 11.522384375494223 and b is -49.729359683795906\n",
      "Iteration 938, the loss is 4.5281979848868215, parameters k is 11.522416972332168 and b is -49.72932015810421\n",
      "Iteration 939, the loss is 4.528197335305283, parameters k is 11.522399671936912 and b is -49.72928853755085\n",
      "Iteration 940, the loss is 4.528196685723749, parameters k is 11.522382371541655 and b is -49.72925691699749\n",
      "Iteration 941, the loss is 4.528196261309682, parameters k is 11.522365071146398 and b is -49.729225296444135\n",
      "Iteration 942, the loss is 4.528195693199185, parameters k is 11.522397667984343 and b is -49.72918577075244\n",
      "Iteration 943, the loss is 4.528195043617646, parameters k is 11.522380367589086 and b is -49.72915415019908\n",
      "Iteration 944, the loss is 4.528194394036117, parameters k is 11.52236306719383 and b is -49.72912252964572\n",
      "Iteration 945, the loss is 4.528193920063514, parameters k is 11.522345766798573 and b is -49.72909090909236\n",
      "Iteration 946, the loss is 4.528193401511538, parameters k is 11.522378363636518 and b is -49.729051383400666\n",
      "Iteration 947, the loss is 4.528192751930011, parameters k is 11.522361063241261 and b is -49.72901976284731\n",
      "Iteration 948, the loss is 4.528192102348475, parameters k is 11.522343762846004 and b is -49.72898814229395\n",
      "Iteration 949, the loss is 4.528191578817341, parameters k is 11.522326462450748 and b is -49.72895652174059\n",
      "Iteration 950, the loss is 4.528191109823913, parameters k is 11.522359059288693 and b is -49.728916996048895\n",
      "Iteration 951, the loss is 4.528190460242379, parameters k is 11.522341758893436 and b is -49.72888537549554\n",
      "Iteration 952, the loss is 4.528189810660838, parameters k is 11.52232445849818 and b is -49.72885375494218\n",
      "Iteration 953, the loss is 4.52818923757117, parameters k is 11.522307158102922 and b is -49.72882213438882\n",
      "Iteration 954, the loss is 4.52818881813627, parameters k is 11.522339754940868 and b is -49.728782608697124\n",
      "Iteration 955, the loss is 4.528188168554732, parameters k is 11.52232245454561 and b is -49.728750988143766\n",
      "Iteration 956, the loss is 4.5281875189731995, parameters k is 11.522305154150354 and b is -49.72871936759041\n",
      "Iteration 957, the loss is 4.528186896325007, parameters k is 11.522287853755097 and b is -49.72868774703705\n",
      "Iteration 958, the loss is 4.528186526448629, parameters k is 11.522320450593043 and b is -49.72864822134535\n",
      "Iteration 959, the loss is 4.5281858768670995, parameters k is 11.522303150197786 and b is -49.728616600791995\n",
      "Iteration 960, the loss is 4.5281852272855625, parameters k is 11.522285849802529 and b is -49.72858498023864\n",
      "Iteration 961, the loss is 4.528184577704029, parameters k is 11.522268549407272 and b is -49.72855335968528\n",
      "Iteration 962, the loss is 4.528184212135803, parameters k is 11.522251249012015 and b is -49.72852173913192\n",
      "Iteration 963, the loss is 4.528183585179457, parameters k is 11.52228384584996 and b is -49.72848221344022\n",
      "Iteration 964, the loss is 4.528182935597927, parameters k is 11.522266545454704 and b is -49.728450592886865\n",
      "Iteration 965, the loss is 4.5281822860163885, parameters k is 11.522249245059447 and b is -49.72841897233351\n",
      "Iteration 966, the loss is 4.528181870889635, parameters k is 11.52223194466419 and b is -49.72838735178015\n",
      "Iteration 967, the loss is 4.52818129349182, parameters k is 11.522264541502135 and b is -49.72834782608845\n",
      "Iteration 968, the loss is 4.528180643910286, parameters k is 11.522247241106879 and b is -49.728316205535094\n",
      "Iteration 969, the loss is 4.528179994328755, parameters k is 11.522229940711622 and b is -49.728284584981736\n",
      "Iteration 970, the loss is 4.5281795296434675, parameters k is 11.522212640316365 and b is -49.72825296442838\n",
      "Iteration 971, the loss is 4.5281790018041885, parameters k is 11.52224523715431 and b is -49.72821343873668\n",
      "Iteration 972, the loss is 4.528178352222652, parameters k is 11.522227936759053 and b is -49.72818181818332\n",
      "Iteration 973, the loss is 4.528177702641114, parameters k is 11.522210636363797 and b is -49.728150197629965\n",
      "Iteration 974, the loss is 4.5281771883973, parameters k is 11.52219333596854 and b is -49.72811857707661\n",
      "Iteration 975, the loss is 4.528176710116547, parameters k is 11.522225932806485 and b is -49.72807905138491\n",
      "Iteration 976, the loss is 4.528176060535011, parameters k is 11.522208632411228 and b is -49.72804743083155\n",
      "Iteration 977, the loss is 4.528175410953483, parameters k is 11.522191332015971 and b is -49.728015810278194\n",
      "Iteration 978, the loss is 4.528174847151128, parameters k is 11.522174031620715 and b is -49.727984189724836\n",
      "Iteration 979, the loss is 4.528174418428911, parameters k is 11.52220662845866 and b is -49.72794466403314\n",
      "Iteration 980, the loss is 4.528173768847375, parameters k is 11.522189328063403 and b is -49.72791304347978\n",
      "Iteration 981, the loss is 4.5281731192658405, parameters k is 11.522172027668146 and b is -49.72788142292642\n",
      "Iteration 982, the loss is 4.528172505904963, parameters k is 11.52215472727289 and b is -49.727849802373065\n",
      "Iteration 983, the loss is 4.528172126741274, parameters k is 11.522187324110835 and b is -49.72781027668137\n",
      "Iteration 984, the loss is 4.5281714771597406, parameters k is 11.522170023715578 and b is -49.72777865612801\n",
      "Iteration 985, the loss is 4.528170827578202, parameters k is 11.522152723320321 and b is -49.72774703557465\n",
      "Iteration 986, the loss is 4.528170177996666, parameters k is 11.522135422925064 and b is -49.727715415021294\n",
      "Iteration 987, the loss is 4.5281698217157595, parameters k is 11.522118122529807 and b is -49.727683794467936\n",
      "Iteration 988, the loss is 4.528169185472098, parameters k is 11.522150719367753 and b is -49.72764426877624\n",
      "Iteration 989, the loss is 4.528168535890566, parameters k is 11.522133418972496 and b is -49.72761264822288\n",
      "Iteration 990, the loss is 4.528167886309027, parameters k is 11.52211611857724 and b is -49.72758102766952\n",
      "Iteration 991, the loss is 4.528167480469597, parameters k is 11.522098818181982 and b is -49.727549407116165\n",
      "Iteration 992, the loss is 4.528166893784461, parameters k is 11.522131415019928 and b is -49.72750988142447\n",
      "Iteration 993, the loss is 4.528166244202924, parameters k is 11.52211411462467 and b is -49.72747826087111\n",
      "Iteration 994, the loss is 4.528165594621389, parameters k is 11.522096814229414 and b is -49.72744664031775\n",
      "Iteration 995, the loss is 4.528165139223425, parameters k is 11.522079513834157 and b is -49.72741501976439\n",
      "Iteration 996, the loss is 4.528164602096824, parameters k is 11.522112110672103 and b is -49.727375494072696\n",
      "Iteration 997, the loss is 4.528163952515294, parameters k is 11.522094810276846 and b is -49.72734387351934\n",
      "Iteration 998, the loss is 4.528163302933755, parameters k is 11.522077509881589 and b is -49.72731225296598\n",
      "Iteration 999, the loss is 4.52816279797726, parameters k is 11.522060209486332 and b is -49.72728063241262\n",
      "Iteration 1000, the loss is 4.528162310409185, parameters k is 11.522092806324277 and b is -49.727241106720925\n",
      "Iteration 1001, the loss is 4.528161660827649, parameters k is 11.52207550592902 and b is -49.72720948616757\n",
      "Iteration 1002, the loss is 4.528161011246119, parameters k is 11.522058205533764 and b is -49.72717786561421\n",
      "Iteration 1003, the loss is 4.528160456731093, parameters k is 11.522040905138507 and b is -49.72714624506085\n",
      "Iteration 1004, the loss is 4.528160018721549, parameters k is 11.522073501976452 and b is -49.727106719369154\n",
      "Iteration 1005, the loss is 4.528159369140014, parameters k is 11.522056201581195 and b is -49.727075098815796\n",
      "Iteration 1006, the loss is 4.5281587195584745, parameters k is 11.522038901185939 and b is -49.72704347826244\n",
      "Iteration 1007, the loss is 4.528158115484919, parameters k is 11.522021600790682 and b is -49.72701185770908\n",
      "Iteration 1008, the loss is 4.5281577270339115, parameters k is 11.522054197628627 and b is -49.72697233201738\n",
      "Iteration 1009, the loss is 4.528157077452376, parameters k is 11.52203689723337 and b is -49.726940711464025\n",
      "Iteration 1010, the loss is 4.528156427870839, parameters k is 11.522019596838113 and b is -49.72690909091067\n",
      "Iteration 1011, the loss is 4.528155778289308, parameters k is 11.522002296442857 and b is -49.72687747035731\n",
      "Iteration 1012, the loss is 4.528155431295721, parameters k is 11.5219849960476 and b is -49.72684584980395\n",
      "Iteration 1013, the loss is 4.528154785764746, parameters k is 11.522017592885545 and b is -49.72680632411225\n",
      "Iteration 1014, the loss is 4.5281541361832005, parameters k is 11.522000292490288 and b is -49.726774703558895\n",
      "Iteration 1015, the loss is 4.528153486601667, parameters k is 11.521982992095031 and b is -49.72674308300554\n",
      "Iteration 1016, the loss is 4.528153090049551, parameters k is 11.521965691699775 and b is -49.72671146245218\n",
      "Iteration 1017, the loss is 4.528152494077102, parameters k is 11.52199828853772 and b is -49.72667193676048\n",
      "Iteration 1018, the loss is 4.528151844495569, parameters k is 11.521980988142463 and b is -49.726640316207124\n",
      "Iteration 1019, the loss is 4.528151194914028, parameters k is 11.521963687747206 and b is -49.726608695653766\n",
      "Iteration 1020, the loss is 4.528150748803385, parameters k is 11.52194638735195 and b is -49.72657707510041\n",
      "Iteration 1021, the loss is 4.528150202389463, parameters k is 11.521978984189895 and b is -49.72653754940871\n",
      "Iteration 1022, the loss is 4.528149552807927, parameters k is 11.521961683794638 and b is -49.72650592885535\n",
      "Iteration 1023, the loss is 4.528148903226391, parameters k is 11.521944383399381 and b is -49.726474308301995\n",
      "Iteration 1024, the loss is 4.5281484075572145, parameters k is 11.521927083004124 and b is -49.72644268774864\n",
      "Iteration 1025, the loss is 4.528147910701828, parameters k is 11.52195967984207 and b is -49.72640316205694\n",
      "Iteration 1026, the loss is 4.528147261120289, parameters k is 11.521942379446813 and b is -49.72637154150358\n",
      "Iteration 1027, the loss is 4.528146611538758, parameters k is 11.521925079051556 and b is -49.726339920950224\n",
      "Iteration 1028, the loss is 4.528146066311048, parameters k is 11.5219077786563 and b is -49.726308300396866\n",
      "Iteration 1029, the loss is 4.528145619014187, parameters k is 11.521940375494244 and b is -49.72626877470517\n",
      "Iteration 1030, the loss is 4.52814496943265, parameters k is 11.521923075098988 and b is -49.72623715415181\n",
      "Iteration 1031, the loss is 4.528144319851116, parameters k is 11.52190577470373 and b is -49.72620553359845\n",
      "Iteration 1032, the loss is 4.528143725064879, parameters k is 11.521888474308474 and b is -49.726173913045095\n",
      "Iteration 1033, the loss is 4.528143327326551, parameters k is 11.52192107114642 and b is -49.7261343873534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1034, the loss is 4.528142677745014, parameters k is 11.521903770751162 and b is -49.72610276680004\n",
      "Iteration 1035, the loss is 4.528142028163485, parameters k is 11.521886470355906 and b is -49.72607114624668\n",
      "Iteration 1036, the loss is 4.528141383818709, parameters k is 11.521869169960649 and b is -49.726039525693324\n",
      "Iteration 1037, the loss is 4.528141035638916, parameters k is 11.521901766798594 and b is -49.726000000001626\n",
      "Iteration 1038, the loss is 4.52814038605738, parameters k is 11.521884466403337 and b is -49.72596837944827\n",
      "Iteration 1039, the loss is 4.528139736475842, parameters k is 11.52186716600808 and b is -49.72593675889491\n",
      "Iteration 1040, the loss is 4.528139086894305, parameters k is 11.521849865612824 and b is -49.72590513834155\n",
      "Iteration 1041, the loss is 4.528138699629514, parameters k is 11.521832565217567 and b is -49.725873517788195\n",
      "Iteration 1042, the loss is 4.528138094369746, parameters k is 11.521865162055512 and b is -49.7258339920965\n",
      "Iteration 1043, the loss is 4.528137444788206, parameters k is 11.521847861660255 and b is -49.72580237154314\n",
      "Iteration 1044, the loss is 4.52813679520667, parameters k is 11.521830561264998 and b is -49.72577075098978\n",
      "Iteration 1045, the loss is 4.528136358383344, parameters k is 11.521813260869742 and b is -49.72573913043642\n",
      "Iteration 1046, the loss is 4.528135802682103, parameters k is 11.521845857707687 and b is -49.725699604744726\n",
      "Iteration 1047, the loss is 4.528135153100569, parameters k is 11.52182855731243 and b is -49.72566798419137\n",
      "Iteration 1048, the loss is 4.528134503519034, parameters k is 11.521811256917173 and b is -49.72563636363801\n",
      "Iteration 1049, the loss is 4.528134017137174, parameters k is 11.521793956521917 and b is -49.72560474308465\n",
      "Iteration 1050, the loss is 4.528133510994467, parameters k is 11.521826553359862 and b is -49.725565217392955\n",
      "Iteration 1051, the loss is 4.528132861412931, parameters k is 11.521809252964605 and b is -49.7255335968396\n",
      "Iteration 1052, the loss is 4.528132211831399, parameters k is 11.521791952569348 and b is -49.72550197628624\n",
      "Iteration 1053, the loss is 4.528131675891005, parameters k is 11.521774652174091 and b is -49.72547035573288\n",
      "Iteration 1054, the loss is 4.528131219306828, parameters k is 11.521807249012037 and b is -49.725430830041184\n",
      "Iteration 1055, the loss is 4.528130569725296, parameters k is 11.52178994861678 and b is -49.725399209487826\n",
      "Iteration 1056, the loss is 4.528129920143757, parameters k is 11.521772648221523 and b is -49.72536758893447\n",
      "Iteration 1057, the loss is 4.528129334644832, parameters k is 11.521755347826266 and b is -49.72533596838111\n",
      "Iteration 1058, the loss is 4.528128927619193, parameters k is 11.521787944664212 and b is -49.72529644268941\n",
      "Iteration 1059, the loss is 4.528128278037653, parameters k is 11.521770644268955 and b is -49.725264822136054\n",
      "Iteration 1060, the loss is 4.5281276284561205, parameters k is 11.521753343873698 and b is -49.7252332015827\n",
      "Iteration 1061, the loss is 4.528126993398667, parameters k is 11.521736043478441 and b is -49.72520158102934\n",
      "Iteration 1062, the loss is 4.528126635931554, parameters k is 11.521768640316386 and b is -49.72516205533764\n",
      "Iteration 1063, the loss is 4.5281259863500205, parameters k is 11.52175133992113 and b is -49.72513043478428\n",
      "Iteration 1064, the loss is 4.528125336768479, parameters k is 11.521734039525873 and b is -49.725098814230925\n",
      "Iteration 1065, the loss is 4.528124687186943, parameters k is 11.521716739130616 and b is -49.72506719367757\n",
      "Iteration 1066, the loss is 4.52812430920947, parameters k is 11.521699438735359 and b is -49.72503557312421\n",
      "Iteration 1067, the loss is 4.528123694662378, parameters k is 11.521732035573304 and b is -49.72499604743251\n",
      "Iteration 1068, the loss is 4.528123045080846, parameters k is 11.521714735178048 and b is -49.724964426879154\n",
      "Iteration 1069, the loss is 4.52812239549931, parameters k is 11.52169743478279 and b is -49.724932806325796\n",
      "Iteration 1070, the loss is 4.528121967963302, parameters k is 11.521680134387534 and b is -49.72490118577244\n",
      "Iteration 1071, the loss is 4.528121402974744, parameters k is 11.52171273122548 and b is -49.72486166008074\n",
      "Iteration 1072, the loss is 4.528120753393212, parameters k is 11.521695430830222 and b is -49.72483003952738\n",
      "Iteration 1073, the loss is 4.528120103811674, parameters k is 11.521678130434966 and b is -49.724798418974025\n",
      "Iteration 1074, the loss is 4.528119626717137, parameters k is 11.521660830039709 and b is -49.72476679842067\n",
      "Iteration 1075, the loss is 4.528119111287104, parameters k is 11.521693426877654 and b is -49.72472727272897\n",
      "Iteration 1076, the loss is 4.5281184617055645, parameters k is 11.521676126482397 and b is -49.72469565217561\n",
      "Iteration 1077, the loss is 4.528117812124032, parameters k is 11.52165882608714 and b is -49.724664031622254\n",
      "Iteration 1078, the loss is 4.528117285470968, parameters k is 11.521641525691884 and b is -49.724632411068896\n",
      "Iteration 1079, the loss is 4.528116819599468, parameters k is 11.521674122529829 and b is -49.7245928853772\n",
      "Iteration 1080, the loss is 4.528116170017934, parameters k is 11.521656822134572 and b is -49.72456126482384\n",
      "Iteration 1081, the loss is 4.528115520436398, parameters k is 11.521639521739315 and b is -49.72452964427048\n",
      "Iteration 1082, the loss is 4.528114944224797, parameters k is 11.521622221344058 and b is -49.724498023717125\n",
      "Iteration 1083, the loss is 4.528114527911833, parameters k is 11.521654818182004 and b is -49.72445849802543\n",
      "Iteration 1084, the loss is 4.528113878330297, parameters k is 11.521637517786747 and b is -49.72442687747207\n",
      "Iteration 1085, the loss is 4.528113228748759, parameters k is 11.52162021739149 and b is -49.72439525691871\n",
      "Iteration 1086, the loss is 4.528112602978628, parameters k is 11.521602916996233 and b is -49.724363636365354\n",
      "Iteration 1087, the loss is 4.528112236224189, parameters k is 11.521635513834179 and b is -49.724324110673656\n",
      "Iteration 1088, the loss is 4.528111586642655, parameters k is 11.521618213438922 and b is -49.7242924901203\n",
      "Iteration 1089, the loss is 4.528110937061124, parameters k is 11.521600913043665 and b is -49.72426086956694\n",
      "Iteration 1090, the loss is 4.528110287479592, parameters k is 11.521583612648408 and b is -49.72422924901358\n",
      "Iteration 1091, the loss is 4.528109918789428, parameters k is 11.521566312253151 and b is -49.724197628460225\n",
      "Iteration 1092, the loss is 4.52810929495502, parameters k is 11.521598909091097 and b is -49.72415810276853\n",
      "Iteration 1093, the loss is 4.528108645373482, parameters k is 11.52158160869584 and b is -49.72412648221517\n",
      "Iteration 1094, the loss is 4.528107995791949, parameters k is 11.521564308300583 and b is -49.72409486166181\n",
      "Iteration 1095, the loss is 4.528107577543256, parameters k is 11.521547007905326 and b is -49.72406324110845\n",
      "Iteration 1096, the loss is 4.528107003267379, parameters k is 11.521579604743271 and b is -49.724023715416756\n",
      "Iteration 1097, the loss is 4.528106353685846, parameters k is 11.521562304348015 and b is -49.7239920948634\n",
      "Iteration 1098, the loss is 4.5281057041043145, parameters k is 11.521545003952758 and b is -49.72396047431004\n",
      "Iteration 1099, the loss is 4.528105236297089, parameters k is 11.521527703557501 and b is -49.72392885375668\n",
      "Iteration 1100, the loss is 4.528104711579741, parameters k is 11.521560300395446 and b is -49.723889328064985\n",
      "Iteration 1101, the loss is 4.528104061998208, parameters k is 11.52154300000019 and b is -49.72385770751163\n",
      "Iteration 1102, the loss is 4.528103412416676, parameters k is 11.521525699604933 and b is -49.72382608695827\n",
      "Iteration 1103, the loss is 4.528102895050925, parameters k is 11.521508399209676 and b is -49.72379446640491\n",
      "Iteration 1104, the loss is 4.5281024198921065, parameters k is 11.521540996047621 and b is -49.723754940713214\n",
      "Iteration 1105, the loss is 4.5281017703105695, parameters k is 11.521523695652364 and b is -49.723723320159856\n",
      "Iteration 1106, the loss is 4.52810112072904, parameters k is 11.521506395257108 and b is -49.7236916996065\n",
      "Iteration 1107, the loss is 4.5281005538047525, parameters k is 11.52148909486185 and b is -49.72366007905314\n",
      "Iteration 1108, the loss is 4.528100128204469, parameters k is 11.521521691699796 and b is -49.72362055336144\n",
      "Iteration 1109, the loss is 4.528099478622936, parameters k is 11.52150439130454 and b is -49.723588932808084\n",
      "Iteration 1110, the loss is 4.528098829041392, parameters k is 11.521487090909282 and b is -49.72355731225473\n",
      "Iteration 1111, the loss is 4.528098212558587, parameters k is 11.521469790514026 and b is -49.72352569170137\n",
      "Iteration 1112, the loss is 4.528097836516831, parameters k is 11.52150238735197 and b is -49.72348616600967\n",
      "Iteration 1113, the loss is 4.528097186935302, parameters k is 11.521485086956714 and b is -49.72345454545631\n",
      "Iteration 1114, the loss is 4.5280965373537585, parameters k is 11.521467786561457 and b is -49.723422924902955\n",
      "Iteration 1115, the loss is 4.528095887772226, parameters k is 11.5214504861662 and b is -49.7233913043496\n",
      "Iteration 1116, the loss is 4.528095528369387, parameters k is 11.521433185770944 and b is -49.72335968379624\n",
      "Iteration 1117, the loss is 4.528094895247657, parameters k is 11.521465782608889 and b is -49.72332015810454\n",
      "Iteration 1118, the loss is 4.528094245666123, parameters k is 11.521448482213632 and b is -49.723288537551184\n",
      "Iteration 1119, the loss is 4.528093596084588, parameters k is 11.521431181818375 and b is -49.723256916997826\n",
      "Iteration 1120, the loss is 4.528093187123217, parameters k is 11.521413881423118 and b is -49.72322529644447\n",
      "Iteration 1121, the loss is 4.528092603560023, parameters k is 11.521446478261064 and b is -49.72318577075277\n",
      "Iteration 1122, the loss is 4.528091953978485, parameters k is 11.521429177865807 and b is -49.72315415019941\n",
      "Iteration 1123, the loss is 4.52809130439695, parameters k is 11.52141187747055 and b is -49.723122529646055\n",
      "Iteration 1124, the loss is 4.52809084587705, parameters k is 11.521394577075293 and b is -49.7230909090927\n",
      "Iteration 1125, the loss is 4.528090311872383, parameters k is 11.521427173913239 and b is -49.723051383401\n",
      "Iteration 1126, the loss is 4.528089662290846, parameters k is 11.521409873517982 and b is -49.72301976284764\n",
      "Iteration 1127, the loss is 4.528089012709316, parameters k is 11.521392573122725 and b is -49.722988142294284\n",
      "Iteration 1128, the loss is 4.528088504630881, parameters k is 11.521375272727468 and b is -49.722956521740926\n",
      "Iteration 1129, the loss is 4.528088020184749, parameters k is 11.521407869565413 and b is -49.72291699604923\n",
      "Iteration 1130, the loss is 4.528087370603206, parameters k is 11.521390569170157 and b is -49.72288537549587\n",
      "Iteration 1131, the loss is 4.528086721021675, parameters k is 11.5213732687749 and b is -49.72285375494251\n",
      "Iteration 1132, the loss is 4.528086163384707, parameters k is 11.521355968379643 and b is -49.722822134389155\n",
      "Iteration 1133, the loss is 4.528085728497104, parameters k is 11.521388565217588 and b is -49.72278260869746\n",
      "Iteration 1134, the loss is 4.528085078915576, parameters k is 11.521371264822331 and b is -49.7227509881441\n",
      "Iteration 1135, the loss is 4.528084429334038, parameters k is 11.521353964427075 and b is -49.72271936759074\n",
      "Iteration 1136, the loss is 4.528083822138547, parameters k is 11.521336664031818 and b is -49.722687747037384\n",
      "Iteration 1137, the loss is 4.528083436809473, parameters k is 11.521369260869763 and b is -49.722648221345686\n",
      "Iteration 1138, the loss is 4.528082787227935, parameters k is 11.521351960474506 and b is -49.72261660079233\n",
      "Iteration 1139, the loss is 4.5280821376463996, parameters k is 11.52133466007925 and b is -49.72258498023897\n",
      "Iteration 1140, the loss is 4.528081488064862, parameters k is 11.521317359683993 and b is -49.72255335968561\n",
      "Iteration 1141, the loss is 4.528081137949344, parameters k is 11.521300059288736 and b is -49.722521739132254\n",
      "Iteration 1142, the loss is 4.528080495540299, parameters k is 11.521332656126681 and b is -49.72248221344056\n",
      "Iteration 1143, the loss is 4.528079845958762, parameters k is 11.521315355731424 and b is -49.7224505928872\n",
      "Iteration 1144, the loss is 4.528079196377228, parameters k is 11.521298055336167 and b is -49.72241897233384\n",
      "Iteration 1145, the loss is 4.528078796703176, parameters k is 11.52128075494091 and b is -49.72238735178048\n",
      "Iteration 1146, the loss is 4.52807820385266, parameters k is 11.521313351778856 and b is -49.722347826088786\n",
      "Iteration 1147, the loss is 4.528077554271119, parameters k is 11.5212960513836 and b is -49.72231620553543\n",
      "Iteration 1148, the loss is 4.528076904689584, parameters k is 11.521278750988342 and b is -49.72228458498207\n",
      "Iteration 1149, the loss is 4.528076455457007, parameters k is 11.521261450593085 and b is -49.72225296442871\n",
      "Iteration 1150, the loss is 4.528075912165017, parameters k is 11.52129404743103 and b is -49.722213438737015\n",
      "Iteration 1151, the loss is 4.528075262583484, parameters k is 11.521276747035774 and b is -49.72218181818366\n",
      "Iteration 1152, the loss is 4.528074613001954, parameters k is 11.521259446640517 and b is -49.7221501976303\n",
      "Iteration 1153, the loss is 4.528074114210838, parameters k is 11.52124214624526 and b is -49.72211857707694\n",
      "Iteration 1154, the loss is 4.528073620477385, parameters k is 11.521274743083206 and b is -49.72207905138524\n",
      "Iteration 1155, the loss is 4.528072970895852, parameters k is 11.521257442687949 and b is -49.722047430831886\n",
      "Iteration 1156, the loss is 4.5280723213143155, parameters k is 11.521240142292692 and b is -49.72201581027853\n",
      "Iteration 1157, the loss is 4.5280717729646724, parameters k is 11.521222841897435 and b is -49.72198418972517\n",
      "Iteration 1158, the loss is 4.528071328789749, parameters k is 11.52125543873538 and b is -49.72194466403347\n",
      "Iteration 1159, the loss is 4.528070679208212, parameters k is 11.521238138340124 and b is -49.721913043480114\n",
      "Iteration 1160, the loss is 4.528070029626673, parameters k is 11.521220837944867 and b is -49.72188142292676\n",
      "Iteration 1161, the loss is 4.528069431718506, parameters k is 11.52120353754961 and b is -49.7218498023734\n",
      "Iteration 1162, the loss is 4.528069037102115, parameters k is 11.521236134387555 and b is -49.7218102766817\n",
      "Iteration 1163, the loss is 4.528068387520573, parameters k is 11.521218833992299 and b is -49.72177865612834\n",
      "Iteration 1164, the loss is 4.52806773793904, parameters k is 11.521201533597042 and b is -49.721747035574985\n",
      "Iteration 1165, the loss is 4.528067090472336, parameters k is 11.521184233201785 and b is -49.72171541502163\n",
      "Iteration 1166, the loss is 4.528066745414477, parameters k is 11.52121683003973 and b is -49.72167588932993\n",
      "Iteration 1167, the loss is 4.528066095832937, parameters k is 11.521199529644473 and b is -49.72164426877657\n",
      "Iteration 1168, the loss is 4.528065446251407, parameters k is 11.521182229249217 and b is -49.721612648223214\n",
      "Iteration 1169, the loss is 4.528064796669867, parameters k is 11.52116492885396 and b is -49.721581027669856\n",
      "Iteration 1170, the loss is 4.52806440628314, parameters k is 11.521147628458703 and b is -49.7215494071165\n",
      "Iteration 1171, the loss is 4.5280638041453, parameters k is 11.521180225296648 and b is -49.7215098814248\n",
      "Iteration 1172, the loss is 4.5280631545637675, parameters k is 11.521162924901391 and b is -49.72147826087144\n",
      "Iteration 1173, the loss is 4.528062504982229, parameters k is 11.521145624506135 and b is -49.721446640318085\n",
      "Iteration 1174, the loss is 4.528062065036963, parameters k is 11.521128324110878 and b is -49.72141501976473\n",
      "Iteration 1175, the loss is 4.528061512457667, parameters k is 11.521160920948823 and b is -49.72137549407303\n",
      "Iteration 1176, the loss is 4.52806086287613, parameters k is 11.521143620553566 and b is -49.72134387351967\n",
      "Iteration 1177, the loss is 4.528060213294596, parameters k is 11.52112632015831 and b is -49.721312252966314\n",
      "Iteration 1178, the loss is 4.5280597237908005, parameters k is 11.521109019763053 and b is -49.721280632412956\n",
      "Iteration 1179, the loss is 4.528059220770026, parameters k is 11.521141616600998 and b is -49.72124110672126\n",
      "Iteration 1180, the loss is 4.528058571188489, parameters k is 11.521124316205741 and b is -49.7212094861679\n",
      "Iteration 1181, the loss is 4.528057921606957, parameters k is 11.521107015810484 and b is -49.72117786561454\n",
      "Iteration 1182, the loss is 4.528057382544626, parameters k is 11.521089715415227 and b is -49.721146245061185\n",
      "Iteration 1183, the loss is 4.528056929082386, parameters k is 11.521122312253173 and b is -49.72110671936949\n",
      "Iteration 1184, the loss is 4.528056279500851, parameters k is 11.521105011857916 and b is -49.72107509881613\n",
      "Iteration 1185, the loss is 4.528055629919324, parameters k is 11.521087711462659 and b is -49.72104347826277\n",
      "Iteration 1186, the loss is 4.528055041298462, parameters k is 11.521070411067402 and b is -49.721011857709414\n",
      "Iteration 1187, the loss is 4.528054637394752, parameters k is 11.521103007905348 and b is -49.720972332017716\n",
      "Iteration 1188, the loss is 4.528053987813213, parameters k is 11.52108570751009 and b is -49.72094071146436\n",
      "Iteration 1189, the loss is 4.528053338231677, parameters k is 11.521068407114834 and b is -49.720909090911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1190, the loss is 4.528052700052292, parameters k is 11.521051106719577 and b is -49.72087747035764\n",
      "Iteration 1191, the loss is 4.528052345707111, parameters k is 11.521083703557522 and b is -49.720837944665945\n",
      "Iteration 1192, the loss is 4.52805169612558, parameters k is 11.521066403162266 and b is -49.72080632411259\n",
      "Iteration 1193, the loss is 4.528051046544041, parameters k is 11.521049102767009 and b is -49.72077470355923\n",
      "Iteration 1194, the loss is 4.5280503969625086, parameters k is 11.521031802371752 and b is -49.72074308300587\n",
      "Iteration 1195, the loss is 4.528050015863092, parameters k is 11.521014501976495 and b is -49.72071146245251\n",
      "Iteration 1196, the loss is 4.528049404437942, parameters k is 11.52104709881444 and b is -49.720671936760816\n",
      "Iteration 1197, the loss is 4.528048754856406, parameters k is 11.521029798419184 and b is -49.72064031620746\n",
      "Iteration 1198, the loss is 4.5280481052748724, parameters k is 11.521012498023927 and b is -49.7206086956541\n",
      "Iteration 1199, the loss is 4.528047674616924, parameters k is 11.52099519762867 and b is -49.72057707510074\n",
      "Iteration 1200, the loss is 4.528047112750303, parameters k is 11.521027794466615 and b is -49.720537549409045\n",
      "Iteration 1201, the loss is 4.528046463168767, parameters k is 11.521010494071358 and b is -49.72050592885569\n",
      "Iteration 1202, the loss is 4.528045813587235, parameters k is 11.520993193676102 and b is -49.72047430830233\n",
      "Iteration 1203, the loss is 4.528045333370755, parameters k is 11.520975893280845 and b is -49.72044268774897\n",
      "Iteration 1204, the loss is 4.528044821062662, parameters k is 11.52100849011879 and b is -49.72040316205727\n",
      "Iteration 1205, the loss is 4.528044171481128, parameters k is 11.520991189723533 and b is -49.720371541503916\n",
      "Iteration 1206, the loss is 4.5280435218995905, parameters k is 11.520973889328276 and b is -49.72033992095056\n",
      "Iteration 1207, the loss is 4.528042992124587, parameters k is 11.52095658893302 and b is -49.7203083003972\n",
      "Iteration 1208, the loss is 4.528042529375032, parameters k is 11.520989185770965 and b is -49.7202687747055\n",
      "Iteration 1209, the loss is 4.528041879793491, parameters k is 11.520971885375708 and b is -49.720237154152144\n",
      "Iteration 1210, the loss is 4.528041230211955, parameters k is 11.520954584980451 and b is -49.72020553359879\n",
      "Iteration 1211, the loss is 4.52804065087842, parameters k is 11.520937284585195 and b is -49.72017391304543\n",
      "Iteration 1212, the loss is 4.528040237687386, parameters k is 11.52096988142314 and b is -49.72013438735373\n",
      "Iteration 1213, the loss is 4.528039588105855, parameters k is 11.520952581027883 and b is -49.72010276680037\n",
      "Iteration 1214, the loss is 4.528038938524315, parameters k is 11.520935280632626 and b is -49.720071146247015\n",
      "Iteration 1215, the loss is 4.52803830963225, parameters k is 11.52091798023737 and b is -49.72003952569366\n",
      "Iteration 1216, the loss is 4.528037945999748, parameters k is 11.520950577075315 and b is -49.72000000000196\n",
      "Iteration 1217, the loss is 4.528037296418217, parameters k is 11.520933276680058 and b is -49.7199683794486\n",
      "Iteration 1218, the loss is 4.528036646836678, parameters k is 11.520915976284801 and b is -49.719936758895244\n",
      "Iteration 1219, the loss is 4.528035997255144, parameters k is 11.520898675889544 and b is -49.719905138341886\n",
      "Iteration 1220, the loss is 4.528035625443048, parameters k is 11.520881375494287 and b is -49.71987351778853\n",
      "Iteration 1221, the loss is 4.528035004730582, parameters k is 11.520913972332233 and b is -49.71983399209683\n",
      "Iteration 1222, the loss is 4.528034355149045, parameters k is 11.520896671936976 and b is -49.71980237154347\n",
      "Iteration 1223, the loss is 4.528033705567504, parameters k is 11.520879371541719 and b is -49.719770750990115\n",
      "Iteration 1224, the loss is 4.528033284196884, parameters k is 11.520862071146462 and b is -49.71973913043676\n",
      "Iteration 1225, the loss is 4.528032713042938, parameters k is 11.520894667984408 and b is -49.71969960474506\n",
      "Iteration 1226, the loss is 4.528032063461403, parameters k is 11.52087736758915 and b is -49.7196679841917\n",
      "Iteration 1227, the loss is 4.528031413879877, parameters k is 11.520860067193894 and b is -49.719636363638344\n",
      "Iteration 1228, the loss is 4.528030942950719, parameters k is 11.520842766798637 and b is -49.719604743084986\n",
      "Iteration 1229, the loss is 4.528030421355303, parameters k is 11.520875363636582 and b is -49.71956521739329\n",
      "Iteration 1230, the loss is 4.528029771773765, parameters k is 11.520858063241326 and b is -49.71953359683993\n",
      "Iteration 1231, the loss is 4.528029122192234, parameters k is 11.520840762846069 and b is -49.71950197628657\n",
      "Iteration 1232, the loss is 4.528028601704547, parameters k is 11.520823462450812 and b is -49.719470355733215\n",
      "Iteration 1233, the loss is 4.528028129667666, parameters k is 11.520856059288757 and b is -49.71943083004152\n",
      "Iteration 1234, the loss is 4.52802748008613, parameters k is 11.5208387588935 and b is -49.71939920948816\n",
      "Iteration 1235, the loss is 4.52802683050459, parameters k is 11.520821458498244 and b is -49.7193675889348\n",
      "Iteration 1236, the loss is 4.528026260458376, parameters k is 11.520804158102987 and b is -49.71933596838144\n",
      "Iteration 1237, the loss is 4.52802583798003, parameters k is 11.520836754940932 and b is -49.719296442689746\n",
      "Iteration 1238, the loss is 4.528025188398492, parameters k is 11.520819454545675 and b is -49.71926482213639\n",
      "Iteration 1239, the loss is 4.528024538816957, parameters k is 11.520802154150418 and b is -49.71923320158303\n",
      "Iteration 1240, the loss is 4.528023919212213, parameters k is 11.520784853755162 and b is -49.71920158102967\n",
      "Iteration 1241, the loss is 4.528023546292389, parameters k is 11.520817450593107 and b is -49.719162055337975\n",
      "Iteration 1242, the loss is 4.528022896710855, parameters k is 11.52080015019785 and b is -49.71913043478462\n",
      "Iteration 1243, the loss is 4.528022247129317, parameters k is 11.520782849802593 and b is -49.71909881423126\n",
      "Iteration 1244, the loss is 4.528021597547783, parameters k is 11.520765549407336 and b is -49.7190671936779\n",
      "Iteration 1245, the loss is 4.52802123502301, parameters k is 11.52074824901208 and b is -49.71903557312454\n",
      "Iteration 1246, the loss is 4.528020605023215, parameters k is 11.520780845850025 and b is -49.718996047432846\n",
      "Iteration 1247, the loss is 4.528019955441682, parameters k is 11.520763545454768 and b is -49.71896442687949\n",
      "Iteration 1248, the loss is 4.528019305860148, parameters k is 11.520746245059511 and b is -49.71893280632613\n",
      "Iteration 1249, the loss is 4.528018893776842, parameters k is 11.520728944664254 and b is -49.71890118577277\n",
      "Iteration 1250, the loss is 4.528018313335582, parameters k is 11.5207615415022 and b is -49.718861660081075\n",
      "Iteration 1251, the loss is 4.5280176637540475, parameters k is 11.520744241106943 and b is -49.71883003952772\n",
      "Iteration 1252, the loss is 4.528017014172513, parameters k is 11.520726940711686 and b is -49.71879841897436\n",
      "Iteration 1253, the loss is 4.528016552530676, parameters k is 11.52070964031643 and b is -49.718766798421\n",
      "Iteration 1254, the loss is 4.528016021647944, parameters k is 11.520742237154375 and b is -49.7187272727293\n",
      "Iteration 1255, the loss is 4.528015372066408, parameters k is 11.520724936759118 and b is -49.718695652175946\n",
      "Iteration 1256, the loss is 4.52801472248487, parameters k is 11.520707636363861 and b is -49.71866403162259\n",
      "Iteration 1257, the loss is 4.528014211284503, parameters k is 11.520690335968604 and b is -49.71863241106923\n",
      "Iteration 1258, the loss is 4.528013729960302, parameters k is 11.52072293280655 and b is -49.71859288537753\n",
      "Iteration 1259, the loss is 4.528013080378767, parameters k is 11.520705632411293 and b is -49.718561264824174\n",
      "Iteration 1260, the loss is 4.528012430797234, parameters k is 11.520688332016036 and b is -49.71852964427082\n",
      "Iteration 1261, the loss is 4.528011870038336, parameters k is 11.520671031620779 and b is -49.71849802371746\n",
      "Iteration 1262, the loss is 4.528011438272673, parameters k is 11.520703628458724 and b is -49.71845849802576\n",
      "Iteration 1263, the loss is 4.528010788691135, parameters k is 11.520686328063467 and b is -49.7184268774724\n",
      "Iteration 1264, the loss is 4.5280101391096, parameters k is 11.52066902766821 and b is -49.718395256919045\n",
      "Iteration 1265, the loss is 4.528009528792165, parameters k is 11.520651727272954 and b is -49.71836363636569\n",
      "Iteration 1266, the loss is 4.52800914658503, parameters k is 11.5206843241109 and b is -49.71832411067399\n",
      "Iteration 1267, the loss is 4.528008497003493, parameters k is 11.520667023715642 and b is -49.71829249012063\n",
      "Iteration 1268, the loss is 4.52800784742196, parameters k is 11.520649723320386 and b is -49.718260869567274\n",
      "Iteration 1269, the loss is 4.52800719784042, parameters k is 11.520632422925129 and b is -49.718229249013916\n",
      "Iteration 1270, the loss is 4.528006844602965, parameters k is 11.520615122529872 and b is -49.71819762846056\n",
      "Iteration 1271, the loss is 4.5280062053158545, parameters k is 11.520647719367817 and b is -49.71815810276886\n",
      "Iteration 1272, the loss is 4.528005555734323, parameters k is 11.52063041897256 and b is -49.7181264822155\n",
      "Iteration 1273, the loss is 4.528004906152788, parameters k is 11.520613118577304 and b is -49.718094861662145\n",
      "Iteration 1274, the loss is 4.528004503356801, parameters k is 11.520595818182047 and b is -49.71806324110879\n",
      "Iteration 1275, the loss is 4.5280039136282175, parameters k is 11.520628415019992 and b is -49.71802371541709\n",
      "Iteration 1276, the loss is 4.5280032640466805, parameters k is 11.520611114624735 and b is -49.71799209486373\n",
      "Iteration 1277, the loss is 4.528002614465147, parameters k is 11.520593814229478 and b is -49.717960474310374\n",
      "Iteration 1278, the loss is 4.528002162110633, parameters k is 11.520576513834222 and b is -49.717928853757016\n",
      "Iteration 1279, the loss is 4.528001621940582, parameters k is 11.520609110672167 and b is -49.71788932806532\n",
      "Iteration 1280, the loss is 4.528000972359048, parameters k is 11.52059181027691 and b is -49.71785770751196\n",
      "Iteration 1281, the loss is 4.52800032277751, parameters k is 11.520574509881653 and b is -49.7178260869586\n",
      "Iteration 1282, the loss is 4.5279998208644585, parameters k is 11.520557209486396 and b is -49.717794466405245\n",
      "Iteration 1283, the loss is 4.527999330252949, parameters k is 11.520589806324342 and b is -49.71775494071355\n",
      "Iteration 1284, the loss is 4.527998680671414, parameters k is 11.520572505929085 and b is -49.71772332016019\n",
      "Iteration 1285, the loss is 4.527998031089875, parameters k is 11.520555205533828 and b is -49.71769169960683\n",
      "Iteration 1286, the loss is 4.527997479618297, parameters k is 11.520537905138571 and b is -49.71766007905347\n",
      "Iteration 1287, the loss is 4.527997038565311, parameters k is 11.520570501976517 and b is -49.717620553361776\n",
      "Iteration 1288, the loss is 4.527996388983771, parameters k is 11.52055320158126 and b is -49.71758893280842\n",
      "Iteration 1289, the loss is 4.527995739402234, parameters k is 11.520535901186003 and b is -49.71755731225506\n",
      "Iteration 1290, the loss is 4.527995138372126, parameters k is 11.520518600790746 and b is -49.7175256917017\n",
      "Iteration 1291, the loss is 4.527994746877675, parameters k is 11.520551197628691 and b is -49.717486166010005\n",
      "Iteration 1292, the loss is 4.527994097296133, parameters k is 11.520533897233435 and b is -49.71745454545665\n",
      "Iteration 1293, the loss is 4.527993447714599, parameters k is 11.520516596838178 and b is -49.71742292490329\n",
      "Iteration 1294, the loss is 4.527992798133064, parameters k is 11.520499296442921 and b is -49.71739130434993\n",
      "Iteration 1295, the loss is 4.527992454182926, parameters k is 11.520481996047664 and b is -49.71735968379657\n",
      "Iteration 1296, the loss is 4.527991805608493, parameters k is 11.52051459288561 and b is -49.717320158104876\n",
      "Iteration 1297, the loss is 4.527991156026961, parameters k is 11.520497292490353 and b is -49.71728853755152\n",
      "Iteration 1298, the loss is 4.527990506445427, parameters k is 11.520479992095096 and b is -49.71725691699816\n",
      "Iteration 1299, the loss is 4.527990112936757, parameters k is 11.520462691699839 and b is -49.7172252964448\n",
      "Iteration 1300, the loss is 4.527989513920862, parameters k is 11.520495288537784 and b is -49.717185770753105\n",
      "Iteration 1301, the loss is 4.527988864339325, parameters k is 11.520477988142527 and b is -49.71715415019975\n",
      "Iteration 1302, the loss is 4.527988214757791, parameters k is 11.52046068774727 and b is -49.71712252964639\n",
      "Iteration 1303, the loss is 4.527987771690591, parameters k is 11.520443387352014 and b is -49.71709090909303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1304, the loss is 4.52798722223322, parameters k is 11.520475984189959 and b is -49.71705138340133\n",
      "Iteration 1305, the loss is 4.527986572651688, parameters k is 11.520458683794702 and b is -49.717019762847976\n",
      "Iteration 1306, the loss is 4.527985923070149, parameters k is 11.520441383399445 and b is -49.71698814229462\n",
      "Iteration 1307, the loss is 4.5279854304444225, parameters k is 11.520424083004189 and b is -49.71695652174126\n",
      "Iteration 1308, the loss is 4.527984930545588, parameters k is 11.520456679842134 and b is -49.71691699604956\n",
      "Iteration 1309, the loss is 4.5279842809640485, parameters k is 11.520439379446877 and b is -49.716885375496204\n",
      "Iteration 1310, the loss is 4.527983631382516, parameters k is 11.52042207905162 and b is -49.716853754942846\n",
      "Iteration 1311, the loss is 4.527983089198253, parameters k is 11.520404778656363 and b is -49.71682213438949\n",
      "Iteration 1312, the loss is 4.527982638857943, parameters k is 11.520437375494309 and b is -49.71678260869779\n",
      "Iteration 1313, the loss is 4.527981989276411, parameters k is 11.520420075099052 and b is -49.71675098814443\n",
      "Iteration 1314, the loss is 4.527981339694871, parameters k is 11.520402774703795 and b is -49.716719367591075\n",
      "Iteration 1315, the loss is 4.527980747952084, parameters k is 11.520385474308538 and b is -49.71668774703772\n",
      "Iteration 1316, the loss is 4.527980347170308, parameters k is 11.520418071146484 and b is -49.71664822134602\n",
      "Iteration 1317, the loss is 4.527979697588775, parameters k is 11.520400770751227 and b is -49.71661660079266\n",
      "Iteration 1318, the loss is 4.527979048007237, parameters k is 11.52038347035597 and b is -49.716584980239304\n",
      "Iteration 1319, the loss is 4.527978406705918, parameters k is 11.520366169960713 and b is -49.716553359685946\n",
      "Iteration 1320, the loss is 4.527978055482669, parameters k is 11.520398766798658 and b is -49.71651383399425\n",
      "Iteration 1321, the loss is 4.527977405901135, parameters k is 11.520381466403402 and b is -49.71648221344089\n",
      "Iteration 1322, the loss is 4.527976756319603, parameters k is 11.520364166008145 and b is -49.71645059288753\n",
      "Iteration 1323, the loss is 4.527976106738065, parameters k is 11.520346865612888 and b is -49.716418972334175\n",
      "Iteration 1324, the loss is 4.527975722516718, parameters k is 11.520329565217631 and b is -49.71638735178082\n",
      "Iteration 1325, the loss is 4.527975114213496, parameters k is 11.520362162055577 and b is -49.71634782608912\n",
      "Iteration 1326, the loss is 4.527974464631963, parameters k is 11.52034486166032 and b is -49.71631620553576\n",
      "Iteration 1327, the loss is 4.527973815050427, parameters k is 11.520327561265063 and b is -49.716284584982404\n",
      "Iteration 1328, the loss is 4.527973381270547, parameters k is 11.520310260869806 and b is -49.716252964429046\n",
      "Iteration 1329, the loss is 4.527972822525863, parameters k is 11.520342857707751 and b is -49.71621343873735\n",
      "Iteration 1330, the loss is 4.527972172944325, parameters k is 11.520325557312495 and b is -49.71618181818399\n",
      "Iteration 1331, the loss is 4.52797152336279, parameters k is 11.520308256917238 and b is -49.71615019763063\n",
      "Iteration 1332, the loss is 4.527971040024375, parameters k is 11.52029095652198 and b is -49.716118577077275\n",
      "Iteration 1333, the loss is 4.527970530838224, parameters k is 11.520323553359926 and b is -49.71607905138558\n",
      "Iteration 1334, the loss is 4.527969881256689, parameters k is 11.52030625296467 and b is -49.71604743083222\n",
      "Iteration 1335, the loss is 4.527969231675151, parameters k is 11.520288952569413 and b is -49.71601581027886\n",
      "Iteration 1336, the loss is 4.527968698778206, parameters k is 11.520271652174156 and b is -49.7159841897255\n",
      "Iteration 1337, the loss is 4.527968239150585, parameters k is 11.520304249012101 and b is -49.715944664033806\n",
      "Iteration 1338, the loss is 4.527967589569047, parameters k is 11.520286948616844 and b is -49.71591304348045\n",
      "Iteration 1339, the loss is 4.527966939987514, parameters k is 11.520269648221587 and b is -49.71588142292709\n",
      "Iteration 1340, the loss is 4.527966357532045, parameters k is 11.52025234782633 and b is -49.71584980237373\n",
      "Iteration 1341, the loss is 4.527965947462947, parameters k is 11.520284944664276 and b is -49.715810276682035\n",
      "Iteration 1342, the loss is 4.527965297881414, parameters k is 11.520267644269019 and b is -49.71577865612868\n",
      "Iteration 1343, the loss is 4.527964648299877, parameters k is 11.520250343873762 and b is -49.71574703557532\n",
      "Iteration 1344, the loss is 4.527964016285871, parameters k is 11.520233043478505 and b is -49.71571541502196\n",
      "Iteration 1345, the loss is 4.527963655775308, parameters k is 11.52026564031645 and b is -49.715675889330264\n",
      "Iteration 1346, the loss is 4.527963006193775, parameters k is 11.520248339921194 and b is -49.715644268776906\n",
      "Iteration 1347, the loss is 4.527962356612239, parameters k is 11.520231039525937 and b is -49.71561264822355\n",
      "Iteration 1348, the loss is 4.527961707030702, parameters k is 11.52021373913068 and b is -49.71558102767019\n",
      "Iteration 1349, the loss is 4.527961332096676, parameters k is 11.520196438735423 and b is -49.71554940711683\n",
      "Iteration 1350, the loss is 4.527960714506138, parameters k is 11.520229035573369 and b is -49.715509881425135\n",
      "Iteration 1351, the loss is 4.527960064924604, parameters k is 11.520211735178112 and b is -49.71547826087178\n",
      "Iteration 1352, the loss is 4.527959415343071, parameters k is 11.520194434782855 and b is -49.71544664031842\n",
      "Iteration 1353, the loss is 4.5279589908505065, parameters k is 11.520177134387598 and b is -49.71541501976506\n",
      "Iteration 1354, the loss is 4.5279584228185, parameters k is 11.520209731225544 and b is -49.71537549407336\n",
      "Iteration 1355, the loss is 4.527957773236963, parameters k is 11.520192430830287 and b is -49.715343873520006\n",
      "Iteration 1356, the loss is 4.527957123655427, parameters k is 11.52017513043503 and b is -49.71531225296665\n",
      "Iteration 1357, the loss is 4.527956649604345, parameters k is 11.520157830039773 and b is -49.71528063241329\n",
      "Iteration 1358, the loss is 4.527956131130861, parameters k is 11.520190426877718 and b is -49.71524110672159\n",
      "Iteration 1359, the loss is 4.527955481549328, parameters k is 11.520173126482462 and b is -49.715209486168234\n",
      "Iteration 1360, the loss is 4.5279548319677945, parameters k is 11.520155826087205 and b is -49.715177865614876\n",
      "Iteration 1361, the loss is 4.5279543083581695, parameters k is 11.520138525691948 and b is -49.71514624506152\n",
      "Iteration 1362, the loss is 4.527953839443225, parameters k is 11.520171122529893 and b is -49.71510671936982\n",
      "Iteration 1363, the loss is 4.527953189861685, parameters k is 11.520153822134636 and b is -49.71507509881646\n",
      "Iteration 1364, the loss is 4.527952540280154, parameters k is 11.52013652173938 and b is -49.715043478263105\n",
      "Iteration 1365, the loss is 4.5279519671120045, parameters k is 11.520119221344123 and b is -49.71501185770975\n",
      "Iteration 1366, the loss is 4.527951547755589, parameters k is 11.520151818182068 and b is -49.71497233201805\n",
      "Iteration 1367, the loss is 4.527950898174052, parameters k is 11.520134517786811 and b is -49.71494071146469\n",
      "Iteration 1368, the loss is 4.52795024859252, parameters k is 11.520117217391554 and b is -49.714909090911334\n",
      "Iteration 1369, the loss is 4.52794962586583, parameters k is 11.520099916996298 and b is -49.714877470357976\n",
      "Iteration 1370, the loss is 4.527949256067949, parameters k is 11.520132513834243 and b is -49.71483794466628\n",
      "Iteration 1371, the loss is 4.52794860648641, parameters k is 11.520115213438986 and b is -49.71480632411292\n",
      "Iteration 1372, the loss is 4.527947956904882, parameters k is 11.52009791304373 and b is -49.71477470355956\n",
      "Iteration 1373, the loss is 4.527947307323344, parameters k is 11.520080612648472 and b is -49.714743083006205\n",
      "Iteration 1374, the loss is 4.527946941676633, parameters k is 11.520063312253216 and b is -49.71471146245285\n",
      "Iteration 1375, the loss is 4.5279463147987755, parameters k is 11.520095909091161 and b is -49.71467193676115\n",
      "Iteration 1376, the loss is 4.527945665217245, parameters k is 11.520078608695904 and b is -49.71464031620779\n",
      "Iteration 1377, the loss is 4.527945015635702, parameters k is 11.520061308300647 and b is -49.714608695654434\n",
      "Iteration 1378, the loss is 4.527944600430467, parameters k is 11.52004400790539 and b is -49.714577075101076\n",
      "Iteration 1379, the loss is 4.52794402311114, parameters k is 11.520076604743336 and b is -49.71453754940938\n",
      "Iteration 1380, the loss is 4.527943373529607, parameters k is 11.520059304348079 and b is -49.71450592885602\n",
      "Iteration 1381, the loss is 4.527942723948067, parameters k is 11.520042003952822 and b is -49.71447430830266\n",
      "Iteration 1382, the loss is 4.527942259184297, parameters k is 11.520024703557565 and b is -49.714442687749305\n",
      "Iteration 1383, the loss is 4.527941731423501, parameters k is 11.52005730039551 and b is -49.71440316205761\n",
      "Iteration 1384, the loss is 4.527941081841969, parameters k is 11.520040000000254 and b is -49.71437154150425\n",
      "Iteration 1385, the loss is 4.527940432260429, parameters k is 11.520022699604997 and b is -49.71433992095089\n",
      "Iteration 1386, the loss is 4.527939917938128, parameters k is 11.52000539920974 and b is -49.71430830039753\n",
      "Iteration 1387, the loss is 4.527939439735864, parameters k is 11.520037996047686 and b is -49.714268774705836\n",
      "Iteration 1388, the loss is 4.52793879015433, parameters k is 11.520020695652429 and b is -49.71423715415248\n",
      "Iteration 1389, the loss is 4.527938140572793, parameters k is 11.520003395257172 and b is -49.71420553359912\n",
      "Iteration 1390, the loss is 4.52793757669196, parameters k is 11.519986094861915 and b is -49.71417391304576\n",
      "Iteration 1391, the loss is 4.5279371480482276, parameters k is 11.52001869169986 and b is -49.714134387354065\n",
      "Iteration 1392, the loss is 4.527936498466693, parameters k is 11.520001391304604 and b is -49.71410276680071\n",
      "Iteration 1393, the loss is 4.527935848885158, parameters k is 11.519984090909347 and b is -49.71407114624735\n",
      "Iteration 1394, the loss is 4.52793523544579, parameters k is 11.51996679051409 and b is -49.71403952569399\n",
      "Iteration 1395, the loss is 4.527934856360588, parameters k is 11.519999387352035 and b is -49.714000000002294\n",
      "Iteration 1396, the loss is 4.527934206779054, parameters k is 11.519982086956778 and b is -49.713968379448936\n",
      "Iteration 1397, the loss is 4.527933557197515, parameters k is 11.519964786561522 and b is -49.71393675889558\n",
      "Iteration 1398, the loss is 4.527932907615985, parameters k is 11.519947486166265 and b is -49.71390513834222\n",
      "Iteration 1399, the loss is 4.527932551256597, parameters k is 11.519930185771008 and b is -49.71387351778886\n",
      "Iteration 1400, the loss is 4.527931915091414, parameters k is 11.519962782608953 and b is -49.713833992097165\n",
      "Iteration 1401, the loss is 4.527931265509881, parameters k is 11.519945482213696 and b is -49.71380237154381\n",
      "Iteration 1402, the loss is 4.527930615928345, parameters k is 11.51992818181844 and b is -49.71377075099045\n",
      "Iteration 1403, the loss is 4.527930210010423, parameters k is 11.519910881423183 and b is -49.71373913043709\n",
      "Iteration 1404, the loss is 4.527929623403775, parameters k is 11.519943478261128 and b is -49.71369960474539\n",
      "Iteration 1405, the loss is 4.527928973822246, parameters k is 11.519926177865871 and b is -49.713667984192035\n",
      "Iteration 1406, the loss is 4.527928324240712, parameters k is 11.519908877470614 and b is -49.71363636363868\n",
      "Iteration 1407, the loss is 4.527927868764251, parameters k is 11.519891577075358 and b is -49.71360474308532\n",
      "Iteration 1408, the loss is 4.5279273317161435, parameters k is 11.519924173913303 and b is -49.71356521739362\n",
      "Iteration 1409, the loss is 4.527926682134607, parameters k is 11.519906873518046 and b is -49.713533596840264\n",
      "Iteration 1410, the loss is 4.527926032553068, parameters k is 11.51988957312279 and b is -49.713501976286906\n",
      "Iteration 1411, the loss is 4.527925527518087, parameters k is 11.519872272727532 and b is -49.71347035573355\n",
      "Iteration 1412, the loss is 4.527925040028506, parameters k is 11.519904869565478 and b is -49.71343083004185\n",
      "Iteration 1413, the loss is 4.527924390446968, parameters k is 11.519887569170221 and b is -49.71339920948849\n",
      "Iteration 1414, the loss is 4.527923740865436, parameters k is 11.519870268774964 and b is -49.713367588935135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1415, the loss is 4.52792318627192, parameters k is 11.519852968379707 and b is -49.71333596838178\n",
      "Iteration 1416, the loss is 4.527922748340867, parameters k is 11.519885565217653 and b is -49.71329644269008\n",
      "Iteration 1417, the loss is 4.527922098759327, parameters k is 11.519868264822396 and b is -49.71326482213672\n",
      "Iteration 1418, the loss is 4.527921449177795, parameters k is 11.519850964427139 and b is -49.713233201583364\n",
      "Iteration 1419, the loss is 4.527920845025746, parameters k is 11.519833664031882 and b is -49.713201581030006\n",
      "Iteration 1420, the loss is 4.5279204566532245, parameters k is 11.519866260869827 and b is -49.71316205533831\n",
      "Iteration 1421, the loss is 4.527919807071696, parameters k is 11.51984896047457 and b is -49.71313043478495\n",
      "Iteration 1422, the loss is 4.527919157490159, parameters k is 11.519831660079314 and b is -49.71309881423159\n",
      "Iteration 1423, the loss is 4.527918507908624, parameters k is 11.519814359684057 and b is -49.713067193678235\n",
      "Iteration 1424, the loss is 4.527918160836546, parameters k is 11.5197970592888 and b is -49.71303557312488\n",
      "Iteration 1425, the loss is 4.527917515384054, parameters k is 11.519829656126745 and b is -49.71299604743318\n",
      "Iteration 1426, the loss is 4.527916865802518, parameters k is 11.519812355731489 and b is -49.71296442687982\n",
      "Iteration 1427, the loss is 4.527916216220987, parameters k is 11.519795055336232 and b is -49.712932806326464\n",
      "Iteration 1428, the loss is 4.5279158195903815, parameters k is 11.519777754940975 and b is -49.712901185773106\n",
      "Iteration 1429, the loss is 4.527915223696417, parameters k is 11.51981035177892 and b is -49.71286166008141\n",
      "Iteration 1430, the loss is 4.527914574114879, parameters k is 11.519793051383663 and b is -49.71283003952805\n",
      "Iteration 1431, the loss is 4.527913924533355, parameters k is 11.519775750988407 and b is -49.71279841897469\n",
      "Iteration 1432, the loss is 4.527913478344209, parameters k is 11.51975845059315 and b is -49.712766798421335\n",
      "Iteration 1433, the loss is 4.527912932008778, parameters k is 11.519791047431095 and b is -49.71272727272964\n",
      "Iteration 1434, the loss is 4.527912282427243, parameters k is 11.519773747035838 and b is -49.71269565217628\n",
      "Iteration 1435, the loss is 4.527911632845713, parameters k is 11.519756446640582 and b is -49.71266403162292\n",
      "Iteration 1436, the loss is 4.527911137098038, parameters k is 11.519739146245325 and b is -49.71263241106956\n",
      "Iteration 1437, the loss is 4.52791064032114, parameters k is 11.51977174308327 and b is -49.712592885377866\n",
      "Iteration 1438, the loss is 4.5279099907396105, parameters k is 11.519754442688013 and b is -49.71256126482451\n",
      "Iteration 1439, the loss is 4.5279093411580735, parameters k is 11.519737142292756 and b is -49.71252964427115\n",
      "Iteration 1440, the loss is 4.527908795851875, parameters k is 11.5197198418975 and b is -49.71249802371779\n",
      "Iteration 1441, the loss is 4.527908348633508, parameters k is 11.519752438735445 and b is -49.712458498026095\n",
      "Iteration 1442, the loss is 4.527907699051972, parameters k is 11.519735138340188 and b is -49.71242687747274\n",
      "Iteration 1443, the loss is 4.527907049470437, parameters k is 11.519717837944931 and b is -49.71239525691938\n",
      "Iteration 1444, the loss is 4.5279064546057075, parameters k is 11.519700537549674 and b is -49.71236363636602\n",
      "Iteration 1445, the loss is 4.527906056945866, parameters k is 11.51973313438762 and b is -49.712324110674324\n",
      "Iteration 1446, the loss is 4.527905407364333, parameters k is 11.519715833992363 and b is -49.712292490120966\n",
      "Iteration 1447, the loss is 4.527904757782799, parameters k is 11.519698533597106 and b is -49.71226086956761\n",
      "Iteration 1448, the loss is 4.527904113359537, parameters k is 11.51968123320185 and b is -49.71222924901425\n",
      "Iteration 1449, the loss is 4.527903765258234, parameters k is 11.519713830039795 and b is -49.71218972332255\n",
      "Iteration 1450, the loss is 4.527903115676695, parameters k is 11.519696529644538 and b is -49.712158102769195\n",
      "Iteration 1451, the loss is 4.527902466095159, parameters k is 11.519679229249281 and b is -49.71212648221584\n",
      "Iteration 1452, the loss is 4.527901816513626, parameters k is 11.519661928854024 and b is -49.71209486166248\n",
      "Iteration 1453, the loss is 4.5279014291703366, parameters k is 11.519644628458767 and b is -49.71206324110912\n",
      "Iteration 1454, the loss is 4.527900823989056, parameters k is 11.519677225296713 and b is -49.71202371541742\n",
      "Iteration 1455, the loss is 4.527900174407522, parameters k is 11.519659924901456 and b is -49.711992094864065\n",
      "Iteration 1456, the loss is 4.527899524825982, parameters k is 11.519642624506199 and b is -49.71196047431071\n",
      "Iteration 1457, the loss is 4.527899087924172, parameters k is 11.519625324110942 and b is -49.71192885375735\n",
      "Iteration 1458, the loss is 4.527898532301424, parameters k is 11.519657920948887 and b is -49.71188932806565\n",
      "Iteration 1459, the loss is 4.527897882719883, parameters k is 11.51964062055363 and b is -49.711857707512294\n",
      "Iteration 1460, the loss is 4.527897233138347, parameters k is 11.519623320158374 and b is -49.711826086958936\n",
      "Iteration 1461, the loss is 4.527896746678001, parameters k is 11.519606019763117 and b is -49.71179446640558\n",
      "Iteration 1462, the loss is 4.527896240613785, parameters k is 11.519638616601062 and b is -49.71175494071388\n",
      "Iteration 1463, the loss is 4.527895591032249, parameters k is 11.519621316205805 and b is -49.71172332016052\n",
      "Iteration 1464, the loss is 4.527894941450712, parameters k is 11.519604015810549 and b is -49.711691699607165\n",
      "Iteration 1465, the loss is 4.527894405431831, parameters k is 11.519586715415292 and b is -49.71166007905381\n",
      "Iteration 1466, the loss is 4.527893948926147, parameters k is 11.519619312253237 and b is -49.71162055336211\n",
      "Iteration 1467, the loss is 4.527893299344609, parameters k is 11.51960201185798 and b is -49.71158893280875\n",
      "Iteration 1468, the loss is 4.527892649763076, parameters k is 11.519584711462723 and b is -49.711557312255394\n",
      "Iteration 1469, the loss is 4.527892064185664, parameters k is 11.519567411067467 and b is -49.711525691702036\n",
      "Iteration 1470, the loss is 4.527891657238505, parameters k is 11.519600007905412 and b is -49.71148616601034\n",
      "Iteration 1471, the loss is 4.52789100765697, parameters k is 11.519582707510155 and b is -49.71145454545698\n",
      "Iteration 1472, the loss is 4.527890358075436, parameters k is 11.519565407114898 and b is -49.71142292490362\n",
      "Iteration 1473, the loss is 4.527889722939498, parameters k is 11.519548106719641 and b is -49.711391304350265\n",
      "Iteration 1474, the loss is 4.527889365550871, parameters k is 11.519580703557587 and b is -49.71135177865857\n",
      "Iteration 1475, the loss is 4.527888715969336, parameters k is 11.51956340316233 and b is -49.71132015810521\n",
      "Iteration 1476, the loss is 4.527888066387797, parameters k is 11.519546102767073 and b is -49.71128853755185\n",
      "Iteration 1477, the loss is 4.527887416806262, parameters k is 11.519528802371816 and b is -49.711256916998494\n",
      "Iteration 1478, the loss is 4.527887038750299, parameters k is 11.51951150197656 and b is -49.711225296445136\n",
      "Iteration 1479, the loss is 4.527886424281697, parameters k is 11.519544098814505 and b is -49.71118577075344\n",
      "Iteration 1480, the loss is 4.5278857747001595, parameters k is 11.519526798419248 and b is -49.71115415020008\n",
      "Iteration 1481, the loss is 4.527885125118627, parameters k is 11.519509498023991 and b is -49.71112252964672\n",
      "Iteration 1482, the loss is 4.527884697504135, parameters k is 11.519492197628734 and b is -49.711090909093365\n",
      "Iteration 1483, the loss is 4.527884132594063, parameters k is 11.51952479446668 and b is -49.71105138340167\n",
      "Iteration 1484, the loss is 4.5278834830125225, parameters k is 11.519507494071423 and b is -49.71101976284831\n",
      "Iteration 1485, the loss is 4.527882833430992, parameters k is 11.519490193676166 and b is -49.71098814229495\n",
      "Iteration 1486, the loss is 4.527882356257962, parameters k is 11.51947289328091 and b is -49.71095652174159\n",
      "Iteration 1487, the loss is 4.52788184090642, parameters k is 11.519505490118854 and b is -49.710916996049896\n",
      "Iteration 1488, the loss is 4.5278811913248855, parameters k is 11.519488189723598 and b is -49.71088537549654\n",
      "Iteration 1489, the loss is 4.527880541743349, parameters k is 11.51947088932834 and b is -49.71085375494318\n",
      "Iteration 1490, the loss is 4.527880015011795, parameters k is 11.519453588933084 and b is -49.71082213438982\n",
      "Iteration 1491, the loss is 4.527879549218784, parameters k is 11.51948618577103 and b is -49.710782608698125\n",
      "Iteration 1492, the loss is 4.5278788996372485, parameters k is 11.519468885375773 and b is -49.71075098814477\n",
      "Iteration 1493, the loss is 4.527878250055713, parameters k is 11.519451584980516 and b is -49.71071936759141\n",
      "Iteration 1494, the loss is 4.5278776737656266, parameters k is 11.519434284585259 and b is -49.71068774703805\n",
      "Iteration 1495, the loss is 4.527877257531148, parameters k is 11.519466881423204 and b is -49.710648221346354\n",
      "Iteration 1496, the loss is 4.527876607949607, parameters k is 11.519449581027947 and b is -49.710616600792996\n",
      "Iteration 1497, the loss is 4.527875958368077, parameters k is 11.51943228063269 and b is -49.71058498023964\n",
      "Iteration 1498, the loss is 4.527875332519458, parameters k is 11.519414980237434 and b is -49.71055335968628\n",
      "Iteration 1499, the loss is 4.527874965843512, parameters k is 11.519447577075379 and b is -49.71051383399458\n",
      "Iteration 1500, the loss is 4.527874316261974, parameters k is 11.519430276680122 and b is -49.710482213441225\n",
      "Iteration 1501, the loss is 4.527873666680438, parameters k is 11.519412976284865 and b is -49.71045059288787\n",
      "Iteration 1502, the loss is 4.527873017098906, parameters k is 11.519395675889609 and b is -49.71041897233451\n",
      "Iteration 1503, the loss is 4.527872648330252, parameters k is 11.519378375494352 and b is -49.71038735178115\n",
      "Iteration 1504, the loss is 4.527872024574336, parameters k is 11.519410972332297 and b is -49.71034782608945\n",
      "Iteration 1505, the loss is 4.527871374992804, parameters k is 11.51939367193704 and b is -49.710316205536095\n",
      "Iteration 1506, the loss is 4.527870725411266, parameters k is 11.519376371541783 and b is -49.71028458498274\n",
      "Iteration 1507, the loss is 4.527870307084092, parameters k is 11.519359071146527 and b is -49.71025296442938\n",
      "Iteration 1508, the loss is 4.527869732886701, parameters k is 11.519391667984472 and b is -49.71021343873768\n",
      "Iteration 1509, the loss is 4.527869083305166, parameters k is 11.519374367589215 and b is -49.710181818184324\n",
      "Iteration 1510, the loss is 4.527868433723632, parameters k is 11.519357067193958 and b is -49.710150197630966\n",
      "Iteration 1511, the loss is 4.52786796583792, parameters k is 11.519339766798701 and b is -49.71011857707761\n",
      "Iteration 1512, the loss is 4.527867441199062, parameters k is 11.519372363636647 and b is -49.71007905138591\n",
      "Iteration 1513, the loss is 4.527866791617523, parameters k is 11.51935506324139 and b is -49.71004743083255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1514, the loss is 4.527866142035991, parameters k is 11.519337762846133 and b is -49.710015810279195\n",
      "Iteration 1515, the loss is 4.527865624591753, parameters k is 11.519320462450876 and b is -49.70998418972584\n",
      "Iteration 1516, the loss is 4.527865149511425, parameters k is 11.519353059288822 and b is -49.70994466403414\n",
      "Iteration 1517, the loss is 4.527864499929883, parameters k is 11.519335758893565 and b is -49.70991304348078\n",
      "Iteration 1518, the loss is 4.527863850348352, parameters k is 11.519318458498308 and b is -49.709881422927424\n",
      "Iteration 1519, the loss is 4.52786328334558, parameters k is 11.519301158103051 and b is -49.709849802374066\n",
      "Iteration 1520, the loss is 4.527862857823788, parameters k is 11.519333754940996 and b is -49.70981027668237\n",
      "Iteration 1521, the loss is 4.527862208242249, parameters k is 11.51931645454574 and b is -49.70977865612901\n",
      "Iteration 1522, the loss is 4.527861558660715, parameters k is 11.519299154150483 and b is -49.70974703557565\n",
      "Iteration 1523, the loss is 4.527860942099416, parameters k is 11.519281853755226 and b is -49.709715415022295\n",
      "Iteration 1524, the loss is 4.527860566136147, parameters k is 11.519314450593171 and b is -49.7096758893306\n",
      "Iteration 1525, the loss is 4.527859916554614, parameters k is 11.519297150197914 and b is -49.70964426877724\n",
      "Iteration 1526, the loss is 4.5278592669730795, parameters k is 11.519279849802658 and b is -49.70961264822388\n",
      "Iteration 1527, the loss is 4.527858617391542, parameters k is 11.5192625494074 and b is -49.709581027670524\n",
      "Iteration 1528, the loss is 4.527858257910214, parameters k is 11.519245249012144 and b is -49.709549407117166\n",
      "Iteration 1529, the loss is 4.5278576248669715, parameters k is 11.51927784585009 and b is -49.70950988142547\n",
      "Iteration 1530, the loss is 4.527856975285436, parameters k is 11.519260545454832 and b is -49.70947826087211\n",
      "Iteration 1531, the loss is 4.527856325703904, parameters k is 11.519243245059576 and b is -49.70944664031875\n",
      "Iteration 1532, the loss is 4.527855916664042, parameters k is 11.519225944664319 and b is -49.709415019765395\n",
      "Iteration 1533, the loss is 4.527855333179335, parameters k is 11.519258541502264 and b is -49.7093754940737\n",
      "Iteration 1534, the loss is 4.527854683597802, parameters k is 11.519241241107007 and b is -49.70934387352034\n",
      "Iteration 1535, the loss is 4.5278540340162685, parameters k is 11.51922394071175 and b is -49.70931225296698\n",
      "Iteration 1536, the loss is 4.527853575417873, parameters k is 11.519206640316494 and b is -49.70928063241362\n",
      "Iteration 1537, the loss is 4.5278530414917, parameters k is 11.519239237154439 and b is -49.709241106721926\n",
      "Iteration 1538, the loss is 4.527852391910166, parameters k is 11.519221936759182 and b is -49.70920948616857\n",
      "Iteration 1539, the loss is 4.527851742328634, parameters k is 11.519204636363925 and b is -49.70917786561521\n",
      "Iteration 1540, the loss is 4.527851234171708, parameters k is 11.519187335968669 and b is -49.70914624506185\n",
      "Iteration 1541, the loss is 4.527850749804062, parameters k is 11.519219932806614 and b is -49.709106719370155\n",
      "Iteration 1542, the loss is 4.527850100222528, parameters k is 11.519202632411357 and b is -49.7090750988168\n",
      "Iteration 1543, the loss is 4.527849450640993, parameters k is 11.5191853320161 and b is -49.70904347826344\n",
      "Iteration 1544, the loss is 4.52784889292554, parameters k is 11.519168031620843 and b is -49.70901185771008\n",
      "Iteration 1545, the loss is 4.527848458116425, parameters k is 11.519200628458789 and b is -49.708972332018384\n",
      "Iteration 1546, the loss is 4.527847808534891, parameters k is 11.519183328063532 and b is -49.708940711465026\n",
      "Iteration 1547, the loss is 4.527847158953355, parameters k is 11.519166027668275 and b is -49.70890909091167\n",
      "Iteration 1548, the loss is 4.527846551679372, parameters k is 11.519148727273018 and b is -49.70887747035831\n",
      "Iteration 1549, the loss is 4.527846166428786, parameters k is 11.519181324110964 and b is -49.70883794466661\n",
      "Iteration 1550, the loss is 4.5278455168472505, parameters k is 11.519164023715707 and b is -49.708806324113255\n",
      "Iteration 1551, the loss is 4.527844867265717, parameters k is 11.51914672332045 and b is -49.7087747035599\n",
      "Iteration 1552, the loss is 4.527844217684183, parameters k is 11.519129422925193 and b is -49.70874308300654\n",
      "Iteration 1553, the loss is 4.527843867490174, parameters k is 11.519112122529936 and b is -49.70871146245318\n",
      "Iteration 1554, the loss is 4.527843225159616, parameters k is 11.519144719367882 and b is -49.70867193676148\n",
      "Iteration 1555, the loss is 4.527842575578082, parameters k is 11.519127418972625 and b is -49.708640316208125\n",
      "Iteration 1556, the loss is 4.527841925996545, parameters k is 11.519110118577368 and b is -49.70860869565477\n",
      "Iteration 1557, the loss is 4.5278415262440035, parameters k is 11.519092818182111 and b is -49.70857707510141\n",
      "Iteration 1558, the loss is 4.527840933471982, parameters k is 11.519125415020056 and b is -49.70853754940971\n",
      "Iteration 1559, the loss is 4.527840283890438, parameters k is 11.5191081146248 and b is -49.708505928856354\n",
      "Iteration 1560, the loss is 4.527839634308905, parameters k is 11.519090814229543 and b is -49.708474308302996\n",
      "Iteration 1561, the loss is 4.527839184997838, parameters k is 11.519073513834286 and b is -49.70844268774964\n",
      "Iteration 1562, the loss is 4.527838641784341, parameters k is 11.519106110672231 and b is -49.70840316205794\n",
      "Iteration 1563, the loss is 4.527837992202802, parameters k is 11.519088810276974 and b is -49.70837154150458\n",
      "Iteration 1564, the loss is 4.527837342621273, parameters k is 11.519071509881718 and b is -49.708339920951225\n",
      "Iteration 1565, the loss is 4.527836843751673, parameters k is 11.51905420948646 and b is -49.70830830039787\n",
      "Iteration 1566, the loss is 4.527836350096703, parameters k is 11.519086806324406 and b is -49.70826877470617\n",
      "Iteration 1567, the loss is 4.527835700515168, parameters k is 11.51906950592915 and b is -49.70823715415281\n",
      "Iteration 1568, the loss is 4.527835050933636, parameters k is 11.519052205533892 and b is -49.708205533599454\n",
      "Iteration 1569, the loss is 4.527834502505502, parameters k is 11.519034905138636 and b is -49.708173913046096\n",
      "Iteration 1570, the loss is 4.527834058409065, parameters k is 11.519067501976581 and b is -49.7081343873544\n",
      "Iteration 1571, the loss is 4.527833408827529, parameters k is 11.519050201581324 and b is -49.70810276680104\n",
      "Iteration 1572, the loss is 4.527832759245994, parameters k is 11.519032901186067 and b is -49.70807114624768\n",
      "Iteration 1573, the loss is 4.527832161259332, parameters k is 11.51901560079081 and b is -49.708039525694325\n",
      "Iteration 1574, the loss is 4.527831766721426, parameters k is 11.519048197628756 and b is -49.70800000000263\n",
      "Iteration 1575, the loss is 4.527831117139896, parameters k is 11.519030897233499 and b is -49.70796837944927\n",
      "Iteration 1576, the loss is 4.52783046755836, parameters k is 11.519013596838242 and b is -49.70793675889591\n",
      "Iteration 1577, the loss is 4.527829820013165, parameters k is 11.518996296442985 and b is -49.707905138342554\n",
      "Iteration 1578, the loss is 4.527829475033789, parameters k is 11.51902889328093 and b is -49.707865612650856\n",
      "Iteration 1579, the loss is 4.527828825452255, parameters k is 11.519011592885674 and b is -49.7078339920975\n",
      "Iteration 1580, the loss is 4.527828175870721, parameters k is 11.518994292490417 and b is -49.70780237154414\n",
      "Iteration 1581, the loss is 4.52782752628919, parameters k is 11.51897699209516 and b is -49.70777075099078\n",
      "Iteration 1582, the loss is 4.52782713582396, parameters k is 11.518959691699903 and b is -49.707739130437425\n",
      "Iteration 1583, the loss is 4.527826533764617, parameters k is 11.518992288537849 and b is -49.70769960474573\n",
      "Iteration 1584, the loss is 4.527825884183082, parameters k is 11.518974988142592 and b is -49.70766798419237\n",
      "Iteration 1585, the loss is 4.527825234601545, parameters k is 11.518957687747335 and b is -49.70763636363901\n",
      "Iteration 1586, the loss is 4.527824794577795, parameters k is 11.518940387352078 and b is -49.70760474308565\n",
      "Iteration 1587, the loss is 4.527824242076979, parameters k is 11.518972984190023 and b is -49.707565217393956\n",
      "Iteration 1588, the loss is 4.527823592495442, parameters k is 11.518955683794767 and b is -49.7075335968406\n",
      "Iteration 1589, the loss is 4.5278229429139065, parameters k is 11.51893838339951 and b is -49.70750197628724\n",
      "Iteration 1590, the loss is 4.527822453331628, parameters k is 11.518921083004253 and b is -49.70747035573388\n",
      "Iteration 1591, the loss is 4.527821950389345, parameters k is 11.518953679842198 and b is -49.707430830042185\n",
      "Iteration 1592, the loss is 4.527821300807806, parameters k is 11.518936379446941 and b is -49.70739920948883\n",
      "Iteration 1593, the loss is 4.527820651226274, parameters k is 11.518919079051685 and b is -49.70736758893547\n",
      "Iteration 1594, the loss is 4.527820112085458, parameters k is 11.518901778656428 and b is -49.70733596838211\n",
      "Iteration 1595, the loss is 4.527819658701705, parameters k is 11.518934375494373 and b is -49.707296442690414\n",
      "Iteration 1596, the loss is 4.527819009120165, parameters k is 11.518917075099116 and b is -49.707264822137056\n",
      "Iteration 1597, the loss is 4.527818359538634, parameters k is 11.51889977470386 and b is -49.7072332015837\n",
      "Iteration 1598, the loss is 4.52781777083929, parameters k is 11.518882474308603 and b is -49.70720158103034\n",
      "Iteration 1599, the loss is 4.527817367014068, parameters k is 11.518915071146548 and b is -49.70716205533864\n",
      "Iteration 1600, the loss is 4.527816717432531, parameters k is 11.518897770751291 and b is -49.707130434785284\n",
      "Iteration 1601, the loss is 4.527816067850994, parameters k is 11.518880470356034 and b is -49.70709881423193\n",
      "Iteration 1602, the loss is 4.527815429593122, parameters k is 11.518863169960778 and b is -49.70706719367857\n",
      "Iteration 1603, the loss is 4.527815075326433, parameters k is 11.518895766798723 and b is -49.70702766798687\n",
      "Iteration 1604, the loss is 4.527814425744892, parameters k is 11.518878466403466 and b is -49.70699604743351\n",
      "Iteration 1605, the loss is 4.527813776163359, parameters k is 11.51886116600821 and b is -49.706964426880155\n",
      "Iteration 1606, the loss is 4.527813126581822, parameters k is 11.518843865612952 and b is -49.7069328063268\n",
      "Iteration 1607, the loss is 4.527812745403921, parameters k is 11.518826565217696 and b is -49.70690118577344\n",
      "Iteration 1608, the loss is 4.527812134057255, parameters k is 11.51885916205564 and b is -49.70686166008174\n",
      "Iteration 1609, the loss is 4.5278114844757225, parameters k is 11.518841861660384 and b is -49.706830039528384\n",
      "Iteration 1610, the loss is 4.527810834894183, parameters k is 11.518824561265127 and b is -49.706798418975026\n",
      "Iteration 1611, the loss is 4.527810404157751, parameters k is 11.51880726086987 and b is -49.70676679842167\n",
      "Iteration 1612, the loss is 4.527809842369617, parameters k is 11.518839857707816 and b is -49.70672727272997\n",
      "Iteration 1613, the loss is 4.52780919278808, parameters k is 11.518822557312559 and b is -49.70669565217661\n",
      "Iteration 1614, the loss is 4.527808543206547, parameters k is 11.518805256917302 and b is -49.706664031623255\n",
      "Iteration 1615, the loss is 4.5278080629115856, parameters k is 11.518787956522045 and b is -49.7066324110699\n",
      "Iteration 1616, the loss is 4.527807550681983, parameters k is 11.51882055335999 and b is -49.7065928853782\n",
      "Iteration 1617, the loss is 4.527806901100451, parameters k is 11.518803252964734 and b is -49.70656126482484\n",
      "Iteration 1618, the loss is 4.527806251518906, parameters k is 11.518785952569477 and b is -49.706529644271484\n",
      "Iteration 1619, the loss is 4.527805721665417, parameters k is 11.51876865217422 and b is -49.706498023718126\n",
      "Iteration 1620, the loss is 4.527805258994343, parameters k is 11.518801249012165 and b is -49.70645849802643\n",
      "Iteration 1621, the loss is 4.527804609412811, parameters k is 11.518783948616909 and b is -49.70642687747307\n",
      "Iteration 1622, the loss is 4.527803959831272, parameters k is 11.518766648221652 and b is -49.70639525691971\n",
      "Iteration 1623, the loss is 4.527803380419249, parameters k is 11.518749347826395 and b is -49.706363636366355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1624, the loss is 4.527802967306703, parameters k is 11.51878194466434 and b is -49.70632411067466\n",
      "Iteration 1625, the loss is 4.527802317725174, parameters k is 11.518764644269083 and b is -49.7062924901213\n",
      "Iteration 1626, the loss is 4.527801668143633, parameters k is 11.518747343873827 and b is -49.70626086956794\n",
      "Iteration 1627, the loss is 4.527801039173084, parameters k is 11.51873004347857 and b is -49.706229249014584\n",
      "Iteration 1628, the loss is 4.527800675619066, parameters k is 11.518762640316515 and b is -49.706189723322886\n",
      "Iteration 1629, the loss is 4.527800026037533, parameters k is 11.518745339921258 and b is -49.70615810276953\n",
      "Iteration 1630, the loss is 4.5277993764559925, parameters k is 11.518728039526001 and b is -49.70612648221617\n",
      "Iteration 1631, the loss is 4.527798726874461, parameters k is 11.518710739130745 and b is -49.70609486166281\n",
      "Iteration 1632, the loss is 4.527798354983878, parameters k is 11.518693438735488 and b is -49.706063241109455\n",
      "Iteration 1633, the loss is 4.527797734349895, parameters k is 11.518726035573433 and b is -49.70602371541776\n",
      "Iteration 1634, the loss is 4.527797084768359, parameters k is 11.518708735178176 and b is -49.7059920948644\n",
      "Iteration 1635, the loss is 4.527796435186831, parameters k is 11.51869143478292 and b is -49.70596047431104\n",
      "Iteration 1636, the loss is 4.527796013737712, parameters k is 11.518674134387663 and b is -49.70592885375768\n",
      "Iteration 1637, the loss is 4.527795442662258, parameters k is 11.518706731225608 and b is -49.705889328065986\n",
      "Iteration 1638, the loss is 4.5277947930807185, parameters k is 11.518689430830351 and b is -49.70585770751263\n",
      "Iteration 1639, the loss is 4.527794143499186, parameters k is 11.518672130435094 and b is -49.70582608695927\n",
      "Iteration 1640, the loss is 4.527793672491544, parameters k is 11.518654830039837 and b is -49.70579446640591\n",
      "Iteration 1641, the loss is 4.5277931509746185, parameters k is 11.518687426877783 and b is -49.705754940714215\n",
      "Iteration 1642, the loss is 4.52779250139308, parameters k is 11.518670126482526 and b is -49.70572332016086\n",
      "Iteration 1643, the loss is 4.527791851811548, parameters k is 11.51865282608727 and b is -49.7056916996075\n",
      "Iteration 1644, the loss is 4.52779133124537, parameters k is 11.518635525692012 and b is -49.70566007905414\n",
      "Iteration 1645, the loss is 4.527790859286984, parameters k is 11.518668122529958 and b is -49.705620553362444\n",
      "Iteration 1646, the loss is 4.527790209705446, parameters k is 11.5186508221347 and b is -49.705588932809086\n",
      "Iteration 1647, the loss is 4.5277895601239075, parameters k is 11.518633521739444 and b is -49.70555731225573\n",
      "Iteration 1648, the loss is 4.527788989999205, parameters k is 11.518616221344187 and b is -49.70552569170237\n",
      "Iteration 1649, the loss is 4.527788567599348, parameters k is 11.518648818182132 and b is -49.70548616601067\n",
      "Iteration 1650, the loss is 4.527787918017809, parameters k is 11.518631517786876 and b is -49.705454545457314\n",
      "Iteration 1651, the loss is 4.5277872684362706, parameters k is 11.518614217391619 and b is -49.70542292490396\n",
      "Iteration 1652, the loss is 4.527786648753036, parameters k is 11.518596916996362 and b is -49.7053913043506\n",
      "Iteration 1653, the loss is 4.527786275911709, parameters k is 11.518629513834307 and b is -49.7053517786589\n",
      "Iteration 1654, the loss is 4.52778562633017, parameters k is 11.51861221343905 and b is -49.70532015810554\n",
      "Iteration 1655, the loss is 4.527784976748634, parameters k is 11.518594913043794 and b is -49.705288537552185\n",
      "Iteration 1656, the loss is 4.527784327167102, parameters k is 11.518577612648537 and b is -49.70525691699883\n",
      "Iteration 1657, the loss is 4.527783964563836, parameters k is 11.51856031225328 and b is -49.70522529644547\n",
      "Iteration 1658, the loss is 4.527783334642538, parameters k is 11.518592909091225 and b is -49.70518577075377\n",
      "Iteration 1659, the loss is 4.5277826850610055, parameters k is 11.518575608695969 and b is -49.705154150200414\n",
      "Iteration 1660, the loss is 4.527782035479461, parameters k is 11.518558308300712 and b is -49.705122529647056\n",
      "Iteration 1661, the loss is 4.527781623317667, parameters k is 11.518541007905455 and b is -49.7050909090937\n",
      "Iteration 1662, the loss is 4.527781042954901, parameters k is 11.5185736047434 and b is -49.705051383402\n",
      "Iteration 1663, the loss is 4.52778039337336, parameters k is 11.518556304348143 and b is -49.70501976284864\n",
      "Iteration 1664, the loss is 4.5277797437918315, parameters k is 11.518539003952887 and b is -49.704988142295285\n",
      "Iteration 1665, the loss is 4.527779282071505, parameters k is 11.51852170355763 and b is -49.70495652174193\n",
      "Iteration 1666, the loss is 4.527778751267257, parameters k is 11.518554300395575 and b is -49.70491699605023\n",
      "Iteration 1667, the loss is 4.527778101685721, parameters k is 11.518537000000318 and b is -49.70488537549687\n",
      "Iteration 1668, the loss is 4.527777452104188, parameters k is 11.518519699605061 and b is -49.704853754943514\n",
      "Iteration 1669, the loss is 4.527776940825331, parameters k is 11.518502399209805 and b is -49.704822134390156\n",
      "Iteration 1670, the loss is 4.5277764595796235, parameters k is 11.51853499604775 and b is -49.70478260869846\n",
      "Iteration 1671, the loss is 4.527775809998089, parameters k is 11.518517695652493 and b is -49.7047509881451\n",
      "Iteration 1672, the loss is 4.527775160416552, parameters k is 11.518500395257236 and b is -49.70471936759174\n",
      "Iteration 1673, the loss is 4.527774599579166, parameters k is 11.51848309486198 and b is -49.704687747038385\n",
      "Iteration 1674, the loss is 4.527774167891983, parameters k is 11.518515691699925 and b is -49.70464822134669\n",
      "Iteration 1675, the loss is 4.527773518310445, parameters k is 11.518498391304668 and b is -49.70461660079333\n",
      "Iteration 1676, the loss is 4.527772868728914, parameters k is 11.518481090909411 and b is -49.70458498023997\n",
      "Iteration 1677, the loss is 4.5277722583329965, parameters k is 11.518463790514154 and b is -49.704553359686614\n",
      "Iteration 1678, the loss is 4.527771876204343, parameters k is 11.5184963873521 and b is -49.704513833994916\n",
      "Iteration 1679, the loss is 4.5277712266228125, parameters k is 11.518479086956843 and b is -49.70448221344156\n",
      "Iteration 1680, the loss is 4.527770577041274, parameters k is 11.518461786561586 and b is -49.7044505928882\n",
      "Iteration 1681, the loss is 4.527769927459739, parameters k is 11.518444486166329 and b is -49.70441897233484\n",
      "Iteration 1682, the loss is 4.527769574143797, parameters k is 11.518427185771072 and b is -49.704387351781484\n",
      "Iteration 1683, the loss is 4.527768934935172, parameters k is 11.518459782609018 and b is -49.70434782608979\n",
      "Iteration 1684, the loss is 4.527768285353633, parameters k is 11.51844248221376 and b is -49.70431620553643\n",
      "Iteration 1685, the loss is 4.527767635772101, parameters k is 11.518425181818504 and b is -49.70428458498307\n",
      "Iteration 1686, the loss is 4.527767232897631, parameters k is 11.518407881423247 and b is -49.70425296442971\n",
      "Iteration 1687, the loss is 4.527766643247537, parameters k is 11.518440478261192 and b is -49.704213438738016\n",
      "Iteration 1688, the loss is 4.527765993666003, parameters k is 11.518423177865936 and b is -49.70418181818466\n",
      "Iteration 1689, the loss is 4.527765344084468, parameters k is 11.518405877470679 and b is -49.7041501976313\n",
      "Iteration 1690, the loss is 4.527764891651461, parameters k is 11.518388577075422 and b is -49.70411857707794\n",
      "Iteration 1691, the loss is 4.527764351559894, parameters k is 11.518421173913367 and b is -49.704079051386245\n",
      "Iteration 1692, the loss is 4.527763701978362, parameters k is 11.51840387351811 and b is -49.70404743083289\n",
      "Iteration 1693, the loss is 4.527763052396823, parameters k is 11.518386573122854 and b is -49.70401581027953\n",
      "Iteration 1694, the loss is 4.527762550405293, parameters k is 11.518369272727597 and b is -49.70398418972617\n",
      "Iteration 1695, the loss is 4.527762059872263, parameters k is 11.518401869565542 and b is -49.70394466403447\n",
      "Iteration 1696, the loss is 4.527761410290727, parameters k is 11.518384569170285 and b is -49.703913043481116\n",
      "Iteration 1697, the loss is 4.527760760709187, parameters k is 11.518367268775028 and b is -49.70388142292776\n",
      "Iteration 1698, the loss is 4.5277602091591245, parameters k is 11.518349968379772 and b is -49.7038498023744\n",
      "Iteration 1699, the loss is 4.527759768184619, parameters k is 11.518382565217717 and b is -49.7038102766827\n",
      "Iteration 1700, the loss is 4.527759118603088, parameters k is 11.51836526482246 and b is -49.703778656129344\n",
      "Iteration 1701, the loss is 4.527758469021552, parameters k is 11.518347964427203 and b is -49.70374703557599\n",
      "Iteration 1702, the loss is 4.527757867912956, parameters k is 11.518330664031946 and b is -49.70371541502263\n",
      "Iteration 1703, the loss is 4.527757476496987, parameters k is 11.518363260869892 and b is -49.70367588933093\n",
      "Iteration 1704, the loss is 4.527756826915457, parameters k is 11.518345960474635 and b is -49.70364426877757\n",
      "Iteration 1705, the loss is 4.527756177333912, parameters k is 11.518328660079378 and b is -49.703612648224215\n",
      "Iteration 1706, the loss is 4.5277555277523795, parameters k is 11.518311359684121 and b is -49.70358102767086\n",
      "Iteration 1707, the loss is 4.527755183723753, parameters k is 11.518294059288865 and b is -49.7035494071175\n",
      "Iteration 1708, the loss is 4.527754535227811, parameters k is 11.51832665612681 and b is -49.7035098814258\n",
      "Iteration 1709, the loss is 4.5277538856462805, parameters k is 11.518309355731553 and b is -49.703478260872444\n",
      "Iteration 1710, the loss is 4.527753236064744, parameters k is 11.518292055336296 and b is -49.703446640319086\n",
      "Iteration 1711, the loss is 4.527752842477587, parameters k is 11.51827475494104 and b is -49.70341501976573\n",
      "Iteration 1712, the loss is 4.527752243540174, parameters k is 11.518307351778985 and b is -49.70337549407403\n",
      "Iteration 1713, the loss is 4.527751593958641, parameters k is 11.518290051383728 and b is -49.70334387352067\n",
      "Iteration 1714, the loss is 4.527750944377108, parameters k is 11.518272750988471 and b is -49.703312252967315\n",
      "Iteration 1715, the loss is 4.527750501231418, parameters k is 11.518255450593214 and b is -49.70328063241396\n",
      "Iteration 1716, the loss is 4.527749951852539, parameters k is 11.51828804743116 and b is -49.70324110672226\n",
      "Iteration 1717, the loss is 4.527749302271, parameters k is 11.518270747035903 and b is -49.7032094861689\n",
      "Iteration 1718, the loss is 4.527748652689467, parameters k is 11.518253446640646 and b is -49.703177865615544\n",
      "Iteration 1719, the loss is 4.527748159985252, parameters k is 11.518236146245389 and b is -49.703146245062186\n",
      "Iteration 1720, the loss is 4.527747660164897, parameters k is 11.518268743083334 and b is -49.70310671937049\n",
      "Iteration 1721, the loss is 4.52774701058337, parameters k is 11.518251442688078 and b is -49.70307509881713\n",
      "Iteration 1722, the loss is 4.527746361001835, parameters k is 11.51823414229282 and b is -49.70304347826377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1723, the loss is 4.52774581873908, parameters k is 11.518216841897564 and b is -49.703011857710415\n",
      "Iteration 1724, the loss is 4.527745368477261, parameters k is 11.51824943873551 and b is -49.70297233201872\n",
      "Iteration 1725, the loss is 4.527744718895729, parameters k is 11.518232138340252 and b is -49.70294071146536\n",
      "Iteration 1726, the loss is 4.52774406931419, parameters k is 11.518214837944996 and b is -49.702909090912\n",
      "Iteration 1727, the loss is 4.527743477492911, parameters k is 11.518197537549739 and b is -49.702877470358644\n",
      "Iteration 1728, the loss is 4.5277430767896245, parameters k is 11.518230134387684 and b is -49.702837944666946\n",
      "Iteration 1729, the loss is 4.527742427208091, parameters k is 11.518212833992427 and b is -49.70280632411359\n",
      "Iteration 1730, the loss is 4.527741777626554, parameters k is 11.51819553359717 and b is -49.70277470356023\n",
      "Iteration 1731, the loss is 4.527741136246742, parameters k is 11.518178233201914 and b is -49.70274308300687\n",
      "Iteration 1732, the loss is 4.5277407851019875, parameters k is 11.518210830039859 and b is -49.702703557315175\n",
      "Iteration 1733, the loss is 4.527740135520452, parameters k is 11.518193529644602 and b is -49.70267193676182\n",
      "Iteration 1734, the loss is 4.527739485938914, parameters k is 11.518176229249345 and b is -49.70264031620846\n",
      "Iteration 1735, the loss is 4.527738836357382, parameters k is 11.518158928854088 and b is -49.7026086956551\n",
      "Iteration 1736, the loss is 4.527738452057548, parameters k is 11.518141628458832 and b is -49.70257707510174\n",
      "Iteration 1737, the loss is 4.527737843832817, parameters k is 11.518174225296777 and b is -49.702537549410046\n",
      "Iteration 1738, the loss is 4.527737194251278, parameters k is 11.51815692490152 and b is -49.70250592885669\n",
      "Iteration 1739, the loss is 4.527736544669744, parameters k is 11.518139624506263 and b is -49.70247430830333\n",
      "Iteration 1740, the loss is 4.527736110811376, parameters k is 11.518122324111006 and b is -49.70244268774997\n",
      "Iteration 1741, the loss is 4.52773555214518, parameters k is 11.518154920948952 and b is -49.702403162058275\n",
      "Iteration 1742, the loss is 4.527734902563644, parameters k is 11.518137620553695 and b is -49.70237154150492\n",
      "Iteration 1743, the loss is 4.527734252982106, parameters k is 11.518120320158438 and b is -49.70233992095156\n",
      "Iteration 1744, the loss is 4.527733769565204, parameters k is 11.518103019763181 and b is -49.7023083003982\n",
      "Iteration 1745, the loss is 4.527733260457539, parameters k is 11.518135616601127 and b is -49.7022687747065\n",
      "Iteration 1746, the loss is 4.527732610876005, parameters k is 11.51811831620587 and b is -49.702237154153146\n",
      "Iteration 1747, the loss is 4.527731961294468, parameters k is 11.518101015810613 and b is -49.70220553359979\n",
      "Iteration 1748, the loss is 4.52773142831904, parameters k is 11.518083715415356 and b is -49.70217391304643\n",
      "Iteration 1749, the loss is 4.5277309687699026, parameters k is 11.518116312253301 and b is -49.70213438735473\n",
      "Iteration 1750, the loss is 4.527730319188363, parameters k is 11.518099011858045 and b is -49.702102766801374\n",
      "Iteration 1751, the loss is 4.527729669606831, parameters k is 11.518081711462788 and b is -49.70207114624802\n",
      "Iteration 1752, the loss is 4.52772908707287, parameters k is 11.518064411067531 and b is -49.70203952569466\n",
      "Iteration 1753, the loss is 4.527728677082262, parameters k is 11.518097007905476 and b is -49.70200000000296\n",
      "Iteration 1754, the loss is 4.527728027500728, parameters k is 11.51807970751022 and b is -49.7019683794496\n",
      "Iteration 1755, the loss is 4.527727377919195, parameters k is 11.518062407114963 and b is -49.701936758896245\n",
      "Iteration 1756, the loss is 4.5277267458266985, parameters k is 11.518045106719706 and b is -49.70190513834289\n",
      "Iteration 1757, the loss is 4.527726385394633, parameters k is 11.518077703557651 and b is -49.70186561265119\n",
      "Iteration 1758, the loss is 4.527725735813091, parameters k is 11.518060403162394 and b is -49.70183399209783\n",
      "Iteration 1759, the loss is 4.527725086231557, parameters k is 11.518043102767137 and b is -49.701802371544474\n",
      "Iteration 1760, the loss is 4.5277244366500184, parameters k is 11.51802580237188 and b is -49.701770750991116\n",
      "Iteration 1761, the loss is 4.527724061637505, parameters k is 11.518008501976624 and b is -49.70173913043776\n",
      "Iteration 1762, the loss is 4.527723444125453, parameters k is 11.51804109881457 and b is -49.70169960474606\n",
      "Iteration 1763, the loss is 4.5277227945439185, parameters k is 11.518023798419312 and b is -49.7016679841927\n",
      "Iteration 1764, the loss is 4.527722144962383, parameters k is 11.518006498024056 and b is -49.701636363639345\n",
      "Iteration 1765, the loss is 4.527721720391338, parameters k is 11.517989197628799 and b is -49.70160474308599\n",
      "Iteration 1766, the loss is 4.527721152437816, parameters k is 11.518021794466744 and b is -49.70156521739429\n",
      "Iteration 1767, the loss is 4.527720502856279, parameters k is 11.518004494071487 and b is -49.70153359684093\n",
      "Iteration 1768, the loss is 4.5277198532747445, parameters k is 11.51798719367623 and b is -49.701501976287574\n",
      "Iteration 1769, the loss is 4.527719379145164, parameters k is 11.517969893280974 and b is -49.701470355734216\n",
      "Iteration 1770, the loss is 4.527718860750181, parameters k is 11.518002490118919 and b is -49.70143083004252\n",
      "Iteration 1771, the loss is 4.52771821116864, parameters k is 11.517985189723662 and b is -49.70139920948916\n",
      "Iteration 1772, the loss is 4.527717561587106, parameters k is 11.517967889328405 and b is -49.7013675889358\n",
      "Iteration 1773, the loss is 4.527717037898997, parameters k is 11.517950588933148 and b is -49.701335968382445\n",
      "Iteration 1774, the loss is 4.527716569062538, parameters k is 11.517983185771094 and b is -49.70129644269075\n",
      "Iteration 1775, the loss is 4.527715919481002, parameters k is 11.517965885375837 and b is -49.70126482213739\n",
      "Iteration 1776, the loss is 4.52771526989947, parameters k is 11.51794858498058 and b is -49.70123320158403\n",
      "Iteration 1777, the loss is 4.527714696652831, parameters k is 11.517931284585323 and b is -49.70120158103067\n",
      "Iteration 1778, the loss is 4.5277142773749, parameters k is 11.517963881423269 and b is -49.701162055338976\n",
      "Iteration 1779, the loss is 4.52771362779337, parameters k is 11.517946581028012 and b is -49.70113043478562\n",
      "Iteration 1780, the loss is 4.527712978211832, parameters k is 11.517929280632755 and b is -49.70109881423226\n",
      "Iteration 1781, the loss is 4.52771235540666, parameters k is 11.517911980237498 and b is -49.7010671936789\n",
      "Iteration 1782, the loss is 4.5277119856872705, parameters k is 11.517944577075443 and b is -49.701027667987205\n",
      "Iteration 1783, the loss is 4.52771133610573, parameters k is 11.517927276680187 and b is -49.70099604743385\n",
      "Iteration 1784, the loss is 4.5277106865241965, parameters k is 11.51790997628493 and b is -49.70096442688049\n",
      "Iteration 1785, the loss is 4.5277100369426595, parameters k is 11.517892675889673 and b is -49.70093280632713\n",
      "Iteration 1786, the loss is 4.527709671217457, parameters k is 11.517875375494416 and b is -49.70090118577377\n",
      "Iteration 1787, the loss is 4.527709044418094, parameters k is 11.517907972332361 and b is -49.700861660082076\n",
      "Iteration 1788, the loss is 4.527708394836561, parameters k is 11.517890671937105 and b is -49.70083003952872\n",
      "Iteration 1789, the loss is 4.527707745255021, parameters k is 11.517873371541848 and b is -49.70079841897536\n",
      "Iteration 1790, the loss is 4.5277073299712915, parameters k is 11.517856071146591 and b is -49.700766798422\n",
      "Iteration 1791, the loss is 4.5277067527304595, parameters k is 11.517888667984536 and b is -49.700727272730305\n",
      "Iteration 1792, the loss is 4.527706103148923, parameters k is 11.51787136758928 and b is -49.70069565217695\n",
      "Iteration 1793, the loss is 4.527705453567384, parameters k is 11.517854067194023 and b is -49.70066403162359\n",
      "Iteration 1794, the loss is 4.527704988725126, parameters k is 11.517836766798766 and b is -49.70063241107023\n",
      "Iteration 1795, the loss is 4.527704461042822, parameters k is 11.517869363636711 and b is -49.70059288537853\n",
      "Iteration 1796, the loss is 4.527703811461284, parameters k is 11.517852063241454 and b is -49.700561264825176\n",
      "Iteration 1797, the loss is 4.527703161879747, parameters k is 11.517834762846197 and b is -49.70052964427182\n",
      "Iteration 1798, the loss is 4.527702647478957, parameters k is 11.51781746245094 and b is -49.70049802371846\n",
      "Iteration 1799, the loss is 4.527702169355179, parameters k is 11.517850059288886 and b is -49.70045849802676\n",
      "Iteration 1800, the loss is 4.5277015197736405, parameters k is 11.51783275889363 and b is -49.700426877473404\n",
      "Iteration 1801, the loss is 4.527700870192113, parameters k is 11.517815458498372 and b is -49.70039525692005\n",
      "Iteration 1802, the loss is 4.527700306232785, parameters k is 11.517798158103115 and b is -49.70036363636669\n",
      "Iteration 1803, the loss is 4.527699877667546, parameters k is 11.51783075494106 and b is -49.70032411067499\n",
      "Iteration 1804, the loss is 4.5276992280860116, parameters k is 11.517813454545804 and b is -49.70029249012163\n",
      "Iteration 1805, the loss is 4.527698578504473, parameters k is 11.517796154150547 and b is -49.700260869568275\n",
      "Iteration 1806, the loss is 4.527697964986615, parameters k is 11.51777885375529 and b is -49.70022924901492\n",
      "Iteration 1807, the loss is 4.527697585979901, parameters k is 11.517811450593236 and b is -49.70018972332322\n",
      "Iteration 1808, the loss is 4.527696936398368, parameters k is 11.517794150197979 and b is -49.70015810276986\n",
      "Iteration 1809, the loss is 4.527696286816835, parameters k is 11.517776849802722 and b is -49.700126482216504\n",
      "Iteration 1810, the loss is 4.527695637235296, parameters k is 11.517759549407465 and b is -49.700094861663146\n",
      "Iteration 1811, the loss is 4.527695280797421, parameters k is 11.517742249012208 and b is -49.70006324110979\n",
      "Iteration 1812, the loss is 4.527694644710734, parameters k is 11.517774845850154 and b is -49.70002371541809\n",
      "Iteration 1813, the loss is 4.527693995129195, parameters k is 11.517757545454897 and b is -49.69999209486473\n",
      "Iteration 1814, the loss is 4.527693345547659, parameters k is 11.51774024505964 and b is -49.699960474311375\n",
      "Iteration 1815, the loss is 4.527692939551248, parameters k is 11.517722944664383 and b is -49.69992885375802\n",
      "Iteration 1816, the loss is 4.527692353023096, parameters k is 11.517755541502328 and b is -49.69988932806632\n",
      "Iteration 1817, the loss is 4.527691703441559, parameters k is 11.517738241107072 and b is -49.69985770751296\n",
      "Iteration 1818, the loss is 4.527691053860027, parameters k is 11.517720940711815 and b is -49.699826086959604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1819, the loss is 4.527690598305081, parameters k is 11.517703640316558 and b is -49.699794466406246\n",
      "Iteration 1820, the loss is 4.527690061335457, parameters k is 11.517736237154503 and b is -49.69975494071455\n",
      "Iteration 1821, the loss is 4.527689411753923, parameters k is 11.517718936759247 and b is -49.69972332016119\n",
      "Iteration 1822, the loss is 4.527688762172384, parameters k is 11.51770163636399 and b is -49.69969169960783\n",
      "Iteration 1823, the loss is 4.527688257058916, parameters k is 11.517684335968733 and b is -49.699660079054475\n",
      "Iteration 1824, the loss is 4.527687769647819, parameters k is 11.517716932806678 and b is -49.69962055336278\n",
      "Iteration 1825, the loss is 4.5276871200662825, parameters k is 11.517699632411421 and b is -49.69958893280942\n",
      "Iteration 1826, the loss is 4.527686470484751, parameters k is 11.517682332016165 and b is -49.69955731225606\n",
      "Iteration 1827, the loss is 4.527685915812751, parameters k is 11.517665031620908 and b is -49.6995256917027\n",
      "Iteration 1828, the loss is 4.5276854779601825, parameters k is 11.517697628458853 and b is -49.699486166011006\n",
      "Iteration 1829, the loss is 4.5276848283786455, parameters k is 11.517680328063596 and b is -49.69945454545765\n",
      "Iteration 1830, the loss is 4.527684178797115, parameters k is 11.51766302766834 and b is -49.69942292490429\n",
      "Iteration 1831, the loss is 4.527683574566576, parameters k is 11.517645727273083 and b is -49.69939130435093\n",
      "Iteration 1832, the loss is 4.52768318627255, parameters k is 11.517678324111028 and b is -49.699351778659235\n",
      "Iteration 1833, the loss is 4.527682536691009, parameters k is 11.517661023715771 and b is -49.69932015810588\n",
      "Iteration 1834, the loss is 4.52768188710948, parameters k is 11.517643723320514 and b is -49.69928853755252\n",
      "Iteration 1835, the loss is 4.527681237527945, parameters k is 11.517626422925257 and b is -49.69925691699916\n",
      "Iteration 1836, the loss is 4.527680890377375, parameters k is 11.51760912253 and b is -49.6992252964458\n",
      "Iteration 1837, the loss is 4.527680245003369, parameters k is 11.517641719367946 and b is -49.699185770754106\n",
      "Iteration 1838, the loss is 4.527679595421837, parameters k is 11.517624418972689 and b is -49.69915415020075\n",
      "Iteration 1839, the loss is 4.5276789458402975, parameters k is 11.517607118577432 and b is -49.69912252964739\n",
      "Iteration 1840, the loss is 4.527678549131211, parameters k is 11.517589818182175 and b is -49.69909090909403\n",
      "Iteration 1841, the loss is 4.5276779533157345, parameters k is 11.51762241502012 and b is -49.699051383402335\n",
      "Iteration 1842, the loss is 4.5276773037342, parameters k is 11.517605114624864 and b is -49.69901976284898\n",
      "Iteration 1843, the loss is 4.527676654152666, parameters k is 11.517587814229607 and b is -49.69898814229562\n",
      "Iteration 1844, the loss is 4.52767620788504, parameters k is 11.51757051383435 and b is -49.69895652174226\n",
      "Iteration 1845, the loss is 4.527675661628096, parameters k is 11.517603110672296 and b is -49.69891699605056\n",
      "Iteration 1846, the loss is 4.527675012046562, parameters k is 11.517585810277039 and b is -49.698885375497206\n",
      "Iteration 1847, the loss is 4.527674362465022, parameters k is 11.517568509881782 and b is -49.69885375494385\n",
      "Iteration 1848, the loss is 4.5276738666388745, parameters k is 11.517551209486525 and b is -49.69882213439049\n",
      "Iteration 1849, the loss is 4.527673369940459, parameters k is 11.51758380632447 and b is -49.69878260869879\n",
      "Iteration 1850, the loss is 4.5276727203589235, parameters k is 11.517566505929214 and b is -49.698750988145434\n",
      "Iteration 1851, the loss is 4.52767207077739, parameters k is 11.517549205533957 and b is -49.698719367592076\n",
      "Iteration 1852, the loss is 4.527671525392704, parameters k is 11.5175319051387 and b is -49.69868774703872\n",
      "Iteration 1853, the loss is 4.527671078252819, parameters k is 11.517564501976645 and b is -49.69864822134702\n",
      "Iteration 1854, the loss is 4.527670428671293, parameters k is 11.517547201581388 and b is -49.69861660079366\n",
      "Iteration 1855, the loss is 4.527669779089752, parameters k is 11.517529901186132 and b is -49.698584980240305\n",
      "Iteration 1856, the loss is 4.527669184146532, parameters k is 11.517512600790875 and b is -49.69855335968695\n",
      "Iteration 1857, the loss is 4.527668786565185, parameters k is 11.51754519762882 and b is -49.69851383399525\n",
      "Iteration 1858, the loss is 4.527668136983648, parameters k is 11.517527897233563 and b is -49.69848221344189\n",
      "Iteration 1859, the loss is 4.527667487402112, parameters k is 11.517510596838306 and b is -49.698450592888534\n",
      "Iteration 1860, the loss is 4.527666842900366, parameters k is 11.51749329644305 and b is -49.698418972335176\n",
      "Iteration 1861, the loss is 4.527666494877547, parameters k is 11.517525893280995 and b is -49.69837944664348\n",
      "Iteration 1862, the loss is 4.527665845296007, parameters k is 11.517508592885738 and b is -49.69834782609012\n",
      "Iteration 1863, the loss is 4.527665195714476, parameters k is 11.517491292490481 and b is -49.69831620553676\n",
      "Iteration 1864, the loss is 4.5276645461329394, parameters k is 11.517473992095224 and b is -49.698284584983405\n",
      "Iteration 1865, the loss is 4.52766415871117, parameters k is 11.517456691699968 and b is -49.69825296443005\n",
      "Iteration 1866, the loss is 4.5276635536083685, parameters k is 11.517489288537913 and b is -49.69821343873835\n",
      "Iteration 1867, the loss is 4.527662904026835, parameters k is 11.517471988142656 and b is -49.69818181818499\n",
      "Iteration 1868, the loss is 4.527662254445301, parameters k is 11.5174546877474 and b is -49.698150197631634\n",
      "Iteration 1869, the loss is 4.527661817464998, parameters k is 11.517437387352143 and b is -49.698118577078276\n",
      "Iteration 1870, the loss is 4.527661261920736, parameters k is 11.517469984190088 and b is -49.69807905138658\n",
      "Iteration 1871, the loss is 4.527660612339199, parameters k is 11.517452683794831 and b is -49.69804743083322\n",
      "Iteration 1872, the loss is 4.527659962757665, parameters k is 11.517435383399574 and b is -49.69801581027986\n",
      "Iteration 1873, the loss is 4.5276594762188305, parameters k is 11.517418083004317 and b is -49.697984189726505\n",
      "Iteration 1874, the loss is 4.527658970233099, parameters k is 11.517450679842263 and b is -49.69794466403481\n",
      "Iteration 1875, the loss is 4.527658320651564, parameters k is 11.517433379447006 and b is -49.69791304348145\n",
      "Iteration 1876, the loss is 4.527657671070025, parameters k is 11.517416079051749 and b is -49.69788142292809\n",
      "Iteration 1877, the loss is 4.527657134972668, parameters k is 11.517398778656492 and b is -49.69784980237473\n",
      "Iteration 1878, the loss is 4.527656678545463, parameters k is 11.517431375494438 and b is -49.697810276683036\n",
      "Iteration 1879, the loss is 4.527656028963926, parameters k is 11.51741407509918 and b is -49.69777865612968\n",
      "Iteration 1880, the loss is 4.5276553793823915, parameters k is 11.517396774703924 and b is -49.69774703557632\n",
      "Iteration 1881, the loss is 4.52765479372649, parameters k is 11.517379474308667 and b is -49.69771541502296\n",
      "Iteration 1882, the loss is 4.527654386857822, parameters k is 11.517412071146612 and b is -49.697675889331265\n",
      "Iteration 1883, the loss is 4.527653737276285, parameters k is 11.517394770751356 and b is -49.69764426877791\n",
      "Iteration 1884, the loss is 4.527653087694751, parameters k is 11.517377470356099 and b is -49.69761264822455\n",
      "Iteration 1885, the loss is 4.527652452480325, parameters k is 11.517360169960842 and b is -49.69758102767119\n",
      "Iteration 1886, the loss is 4.527652095170186, parameters k is 11.517392766798787 and b is -49.697541501979494\n",
      "Iteration 1887, the loss is 4.527651445588651, parameters k is 11.51737546640353 and b is -49.697509881426136\n",
      "Iteration 1888, the loss is 4.527650796007117, parameters k is 11.517358166008274 and b is -49.69747826087278\n",
      "Iteration 1889, the loss is 4.52765014642558, parameters k is 11.517340865613017 and b is -49.69744664031942\n",
      "Iteration 1890, the loss is 4.5276497682911305, parameters k is 11.51732356521776 and b is -49.69741501976606\n",
      "Iteration 1891, the loss is 4.527649153901014, parameters k is 11.517356162055705 and b is -49.697375494074365\n",
      "Iteration 1892, the loss is 4.52764850431948, parameters k is 11.517338861660448 and b is -49.69734387352101\n",
      "Iteration 1893, the loss is 4.527647854737939, parameters k is 11.517321561265192 and b is -49.69731225296765\n",
      "Iteration 1894, the loss is 4.527647427044957, parameters k is 11.517304260869935 and b is -49.69728063241429\n",
      "Iteration 1895, the loss is 4.527646862213375, parameters k is 11.51733685770788 and b is -49.69724110672259\n",
      "Iteration 1896, the loss is 4.527646212631842, parameters k is 11.517319557312623 and b is -49.697209486169236\n",
      "Iteration 1897, the loss is 4.527645563050304, parameters k is 11.517302256917366 and b is -49.69717786561588\n",
      "Iteration 1898, the loss is 4.52764508579879, parameters k is 11.51728495652211 and b is -49.69714624506252\n",
      "Iteration 1899, the loss is 4.527644570525738, parameters k is 11.517317553360055 and b is -49.69710671937082\n",
      "Iteration 1900, the loss is 4.527643920944202, parameters k is 11.517300252964798 and b is -49.697075098817464\n",
      "Iteration 1901, the loss is 4.527643271362667, parameters k is 11.517282952569541 and b is -49.697043478264106\n",
      "Iteration 1902, the loss is 4.527642744552621, parameters k is 11.517265652174284 and b is -49.69701185771075\n",
      "Iteration 1903, the loss is 4.5276422788381, parameters k is 11.51729824901223 and b is -49.69697233201905\n",
      "Iteration 1904, the loss is 4.527641629256566, parameters k is 11.517280948616973 and b is -49.69694071146569\n",
      "Iteration 1905, the loss is 4.527640979675028, parameters k is 11.517263648221716 and b is -49.696909090912335\n",
      "Iteration 1906, the loss is 4.527640403306457, parameters k is 11.51724634782646 and b is -49.69687747035898\n",
      "Iteration 1907, the loss is 4.527639987150464, parameters k is 11.517278944664405 and b is -49.69683794466728\n",
      "Iteration 1908, the loss is 4.527639337568928, parameters k is 11.517261644269148 and b is -49.69680632411392\n",
      "Iteration 1909, the loss is 4.527638687987391, parameters k is 11.517244343873891 and b is -49.696774703560564\n",
      "Iteration 1910, the loss is 4.527638062060285, parameters k is 11.517227043478634 and b is -49.696743083007206\n",
      "Iteration 1911, the loss is 4.527637695462827, parameters k is 11.51725964031658 and b is -49.69670355731551\n",
      "Iteration 1912, the loss is 4.527637045881288, parameters k is 11.517242339921323 and b is -49.69667193676215\n",
      "Iteration 1913, the loss is 4.5276363962997515, parameters k is 11.517225039526066 and b is -49.69664031620879\n",
      "Iteration 1914, the loss is 4.527635746718219, parameters k is 11.517207739130809 and b is -49.696608695655435\n",
      "Iteration 1915, the loss is 4.527635377871083, parameters k is 11.517190438735552 and b is -49.69657707510208\n",
      "Iteration 1916, the loss is 4.5276347541936515, parameters k is 11.517223035573497 and b is -49.69653754941038\n",
      "Iteration 1917, the loss is 4.527634104612119, parameters k is 11.51720573517824 and b is -49.69650592885702\n",
      "Iteration 1918, the loss is 4.527633455030581, parameters k is 11.517188434782984 and b is -49.696474308303664\n",
      "Iteration 1919, the loss is 4.5276330366249145, parameters k is 11.517171134387727 and b is -49.696442687750306\n",
      "Iteration 1920, the loss is 4.527632462506012, parameters k is 11.517203731225672 and b is -49.69640316205861\n",
      "Iteration 1921, the loss is 4.527631812924479, parameters k is 11.517186430830415 and b is -49.69637154150525\n",
      "Iteration 1922, the loss is 4.527631163342947, parameters k is 11.517169130435159 and b is -49.69633992095189\n",
      "Iteration 1923, the loss is 4.527630695378747, parameters k is 11.517151830039902 and b is -49.696308300398535\n",
      "Iteration 1924, the loss is 4.527630170818378, parameters k is 11.517184426877847 and b is -49.69626877470684\n",
      "Iteration 1925, the loss is 4.527629521236845, parameters k is 11.51716712648259 and b is -49.69623715415348\n",
      "Iteration 1926, the loss is 4.527628871655311, parameters k is 11.517149826087334 and b is -49.69620553360012\n",
      "Iteration 1927, the loss is 4.527628354132577, parameters k is 11.517132525692077 and b is -49.69617391304676\n",
      "Iteration 1928, the loss is 4.527627879130737, parameters k is 11.517165122530022 and b is -49.696134387355066\n",
      "Iteration 1929, the loss is 4.5276272295492035, parameters k is 11.517147822134765 and b is -49.69610276680171\n",
      "Iteration 1930, the loss is 4.527626579967668, parameters k is 11.517130521739508 and b is -49.69607114624835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1931, the loss is 4.527626012886409, parameters k is 11.517113221344252 and b is -49.69603952569499\n",
      "Iteration 1932, the loss is 4.527625587443101, parameters k is 11.517145818182197 and b is -49.696000000003295\n",
      "Iteration 1933, the loss is 4.5276249378615745, parameters k is 11.51712851778694 and b is -49.69596837944994\n",
      "Iteration 1934, the loss is 4.527624288280033, parameters k is 11.517111217391683 and b is -49.69593675889658\n",
      "Iteration 1935, the loss is 4.52762367164024, parameters k is 11.517093916996426 and b is -49.69590513834322\n",
      "Iteration 1936, the loss is 4.527623295755463, parameters k is 11.517126513834372 and b is -49.695865612651524\n",
      "Iteration 1937, the loss is 4.527622646173929, parameters k is 11.517109213439115 and b is -49.695833992098166\n",
      "Iteration 1938, the loss is 4.527621996592392, parameters k is 11.517091913043858 and b is -49.69580237154481\n",
      "Iteration 1939, the loss is 4.527621347010862, parameters k is 11.517074612648601 and b is -49.69577075099145\n",
      "Iteration 1940, the loss is 4.527620987451036, parameters k is 11.517057312253344 and b is -49.69573913043809\n",
      "Iteration 1941, the loss is 4.527620354486295, parameters k is 11.51708990909129 and b is -49.695699604746395\n",
      "Iteration 1942, the loss is 4.5276197049047555, parameters k is 11.517072608696033 and b is -49.69566798419304\n",
      "Iteration 1943, the loss is 4.52761905532322, parameters k is 11.517055308300776 and b is -49.69563636363968\n",
      "Iteration 1944, the loss is 4.527618646204872, parameters k is 11.51703800790552 and b is -49.69560474308632\n",
      "Iteration 1945, the loss is 4.527618062798656, parameters k is 11.517070604743465 and b is -49.69556521739462\n",
      "Iteration 1946, the loss is 4.527617413217125, parameters k is 11.517053304348208 and b is -49.695533596841265\n",
      "Iteration 1947, the loss is 4.527616763635586, parameters k is 11.517036003952951 and b is -49.69550197628791\n",
      "Iteration 1948, the loss is 4.527616304958708, parameters k is 11.517018703557694 and b is -49.69547035573455\n",
      "Iteration 1949, the loss is 4.527615771111017, parameters k is 11.51705130039564 and b is -49.69543083004285\n",
      "Iteration 1950, the loss is 4.527615121529479, parameters k is 11.517034000000383 and b is -49.695399209489494\n",
      "Iteration 1951, the loss is 4.527614471947947, parameters k is 11.517016699605126 and b is -49.695367588936136\n",
      "Iteration 1952, the loss is 4.5276139637125326, parameters k is 11.516999399209869 and b is -49.69533596838278\n",
      "Iteration 1953, the loss is 4.527613479423378, parameters k is 11.517031996047814 and b is -49.69529644269108\n",
      "Iteration 1954, the loss is 4.52761282984184, parameters k is 11.517014695652557 and b is -49.69526482213772\n",
      "Iteration 1955, the loss is 4.527612180260305, parameters k is 11.5169973952573 and b is -49.695233201584365\n",
      "Iteration 1956, the loss is 4.527611622466366, parameters k is 11.516980094862044 and b is -49.69520158103101\n",
      "Iteration 1957, the loss is 4.527611187735741, parameters k is 11.517012691699989 and b is -49.69516205533931\n",
      "Iteration 1958, the loss is 4.527610538154205, parameters k is 11.516995391304732 and b is -49.69513043478595\n",
      "Iteration 1959, the loss is 4.527609888572675, parameters k is 11.516978090909475 and b is -49.695098814232594\n",
      "Iteration 1960, the loss is 4.527609281220202, parameters k is 11.516960790514219 and b is -49.695067193679236\n",
      "Iteration 1961, the loss is 4.527608896048101, parameters k is 11.516993387352164 and b is -49.69502766798754\n",
      "Iteration 1962, the loss is 4.527608246466569, parameters k is 11.516976086956907 and b is -49.69499604743418\n",
      "Iteration 1963, the loss is 4.5276075968850344, parameters k is 11.51695878656165 and b is -49.69496442688082\n",
      "Iteration 1964, the loss is 4.527606947303499, parameters k is 11.516941486166393 and b is -49.694932806327465\n",
      "Iteration 1965, the loss is 4.527606597031002, parameters k is 11.516924185771137 and b is -49.69490118577411\n",
      "Iteration 1966, the loss is 4.527605954778926, parameters k is 11.516956782609082 and b is -49.69486166008241\n",
      "Iteration 1967, the loss is 4.527605305197395, parameters k is 11.516939482213825 and b is -49.69483003952905\n",
      "Iteration 1968, the loss is 4.527604655615863, parameters k is 11.516922181818568 and b is -49.694798418975694\n",
      "Iteration 1969, the loss is 4.527604255784832, parameters k is 11.516904881423311 and b is -49.694766798422336\n",
      "Iteration 1970, the loss is 4.527603663091294, parameters k is 11.516937478261257 and b is -49.69472727273064\n",
      "Iteration 1971, the loss is 4.527603013509755, parameters k is 11.516920177866 and b is -49.69469565217728\n",
      "Iteration 1972, the loss is 4.527602363928226, parameters k is 11.516902877470743 and b is -49.69466403162392\n",
      "Iteration 1973, the loss is 4.527601914538658, parameters k is 11.516885577075486 and b is -49.694632411070565\n",
      "Iteration 1974, the loss is 4.527601371403656, parameters k is 11.516918173913432 and b is -49.69459288537887\n",
      "Iteration 1975, the loss is 4.52760072182212, parameters k is 11.516900873518175 and b is -49.69456126482551\n",
      "Iteration 1976, the loss is 4.527600072240588, parameters k is 11.516883573122918 and b is -49.69452964427215\n",
      "Iteration 1977, the loss is 4.527599573292498, parameters k is 11.516866272727661 and b is -49.69449802371879\n",
      "Iteration 1978, the loss is 4.527599079716017, parameters k is 11.516898869565606 and b is -49.694458498027096\n",
      "Iteration 1979, the loss is 4.5275984301344865, parameters k is 11.51688156917035 and b is -49.69442687747374\n",
      "Iteration 1980, the loss is 4.527597780552949, parameters k is 11.516864268775093 and b is -49.69439525692038\n",
      "Iteration 1981, the loss is 4.527597232046321, parameters k is 11.516846968379836 and b is -49.69436363636702\n",
      "Iteration 1982, the loss is 4.527596788028383, parameters k is 11.516879565217781 and b is -49.694324110675325\n",
      "Iteration 1983, the loss is 4.527596138446849, parameters k is 11.516862264822525 and b is -49.69429249012197\n",
      "Iteration 1984, the loss is 4.527595488865308, parameters k is 11.516844964427268 and b is -49.69426086956861\n",
      "Iteration 1985, the loss is 4.527594890800157, parameters k is 11.51682766403201 and b is -49.69422924901525\n",
      "Iteration 1986, the loss is 4.527594496340744, parameters k is 11.516860260869956 and b is -49.694189723323554\n",
      "Iteration 1987, the loss is 4.527593846759204, parameters k is 11.5168429604747 and b is -49.694158102770196\n",
      "Iteration 1988, the loss is 4.527593197177672, parameters k is 11.516825660079443 and b is -49.69412648221684\n",
      "Iteration 1989, the loss is 4.527592549553991, parameters k is 11.516808359684186 and b is -49.69409486166348\n",
      "Iteration 1990, the loss is 4.527592204653106, parameters k is 11.516840956522131 and b is -49.69405533597178\n",
      "Iteration 1991, the loss is 4.527591555071568, parameters k is 11.516823656126874 and b is -49.694023715418425\n",
      "Iteration 1992, the loss is 4.527590905490036, parameters k is 11.516806355731617 and b is -49.69399209486507\n",
      "Iteration 1993, the loss is 4.527590255908502, parameters k is 11.51678905533636 and b is -49.69396047431171\n",
      "Iteration 1994, the loss is 4.527589865364786, parameters k is 11.516771754941104 and b is -49.69392885375835\n",
      "Iteration 1995, the loss is 4.527589263383932, parameters k is 11.516804351779049 and b is -49.69388932806665\n",
      "Iteration 1996, the loss is 4.527588613802393, parameters k is 11.516787051383792 and b is -49.693857707513295\n",
      "Iteration 1997, the loss is 4.527587964220861, parameters k is 11.516769750988535 and b is -49.69382608695994\n",
      "Iteration 1998, the loss is 4.5275875241186245, parameters k is 11.516752450593279 and b is -49.69379446640658\n",
      "Iteration 1999, the loss is 4.527586971696295, parameters k is 11.516785047431224 and b is -49.69375494071488\n",
      "Iteration 2000, the loss is 4.527586322114756, parameters k is 11.516767747035967 and b is -49.693723320161524\n",
      "Iteration 2001, the loss is 4.5275856725332275, parameters k is 11.51675044664071 and b is -49.693691699608166\n",
      "Iteration 2002, the loss is 4.527585182872453, parameters k is 11.516733146245453 and b is -49.69366007905481\n",
      "Iteration 2003, the loss is 4.527584680008657, parameters k is 11.516765743083399 and b is -49.69362055336311\n",
      "Iteration 2004, the loss is 4.52758403042712, parameters k is 11.516748442688142 and b is -49.69358893280975\n",
      "Iteration 2005, the loss is 4.527583380845586, parameters k is 11.516731142292885 and b is -49.693557312256395\n",
      "Iteration 2006, the loss is 4.527582841626284, parameters k is 11.516713841897628 and b is -49.69352569170304\n",
      "Iteration 2007, the loss is 4.5275823883210204, parameters k is 11.516746438735574 and b is -49.69348616601134\n",
      "Iteration 2008, the loss is 4.527581738739484, parameters k is 11.516729138340317 and b is -49.69345454545798\n",
      "Iteration 2009, the loss is 4.52758108915795, parameters k is 11.51671183794506 and b is -49.693422924904624\n",
      "Iteration 2010, the loss is 4.527580500380115, parameters k is 11.516694537549803 and b is -49.693391304351266\n",
      "Iteration 2011, the loss is 4.5275800966333835, parameters k is 11.516727134387748 and b is -49.69335177865957\n",
      "Iteration 2012, the loss is 4.527579447051851, parameters k is 11.516709833992492 and b is -49.69332015810621\n",
      "Iteration 2013, the loss is 4.527578797470314, parameters k is 11.516692533597235 and b is -49.69328853755285\n",
      "Iteration 2014, the loss is 4.527578159133949, parameters k is 11.516675233201978 and b is -49.693256916999495\n",
      "Iteration 2015, the loss is 4.52757780494575, parameters k is 11.516707830039923 and b is -49.6932173913078\n",
      "Iteration 2016, the loss is 4.527577155364215, parameters k is 11.516690529644666 and b is -49.69318577075444\n",
      "Iteration 2017, the loss is 4.527576505782675, parameters k is 11.51667322924941 and b is -49.69315415020108\n",
      "Iteration 2018, the loss is 4.527575856201142, parameters k is 11.516655928854153 and b is -49.693122529647724\n",
      "Iteration 2019, the loss is 4.527575474944748, parameters k is 11.516638628458896 and b is -49.693090909094366\n",
      "Iteration 2020, the loss is 4.527574863676574, parameters k is 11.516671225296841 and b is -49.69305138340267\n",
      "Iteration 2021, the loss is 4.527574214095031, parameters k is 11.516653924901584 and b is -49.69301976284931\n",
      "Iteration 2022, the loss is 4.527573564513501, parameters k is 11.516636624506328 and b is -49.69298814229595\n",
      "Iteration 2023, the loss is 4.527573133698582, parameters k is 11.51661932411107 and b is -49.692956521742595\n",
      "Iteration 2024, the loss is 4.527572571988932, parameters k is 11.516651920949016 and b is -49.6929169960509\n",
      "Iteration 2025, the loss is 4.527571922407398, parameters k is 11.51663462055376 and b is -49.69288537549754\n",
      "Iteration 2026, the loss is 4.527571272825864, parameters k is 11.516617320158502 and b is -49.69285375494418\n",
      "Iteration 2027, the loss is 4.527570792452413, parameters k is 11.516600019763246 and b is -49.69282213439082\n",
      "Iteration 2028, the loss is 4.5275702803013, parameters k is 11.516632616601191 and b is -49.692782608699126\n",
      "Iteration 2029, the loss is 4.527569630719762, parameters k is 11.516615316205934 and b is -49.69275098814577\n",
      "Iteration 2030, the loss is 4.527568981138231, parameters k is 11.516598015810677 and b is -49.69271936759241\n",
      "Iteration 2031, the loss is 4.527568451206246, parameters k is 11.51658071541542 and b is -49.69268774703905\n",
      "Iteration 2032, the loss is 4.527567988613657, parameters k is 11.516613312253366 and b is -49.692648221347355\n",
      "Iteration 2033, the loss is 4.527567339032124, parameters k is 11.516596011858109 and b is -49.692616600794\n",
      "Iteration 2034, the loss is 4.527566689450593, parameters k is 11.516578711462852 and b is -49.69258498024064\n",
      "Iteration 2035, the loss is 4.527566109960079, parameters k is 11.516561411067595 and b is -49.69255335968728\n",
      "Iteration 2036, the loss is 4.527565696926023, parameters k is 11.51659400790554 and b is -49.692513833995584\n",
      "Iteration 2037, the loss is 4.527565047344483, parameters k is 11.516576707510284 and b is -49.692482213442226\n",
      "Iteration 2038, the loss is 4.527564397762951, parameters k is 11.516559407115027 and b is -49.69245059288887\n",
      "Iteration 2039, the loss is 4.527563768713907, parameters k is 11.51654210671977 and b is -49.69241897233551\n",
      "Iteration 2040, the loss is 4.527563405238384, parameters k is 11.516574703557716 and b is -49.69237944664381\n",
      "Iteration 2041, the loss is 4.52756275565685, parameters k is 11.516557403162459 and b is -49.692347826090455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2042, the loss is 4.527562106075311, parameters k is 11.516540102767202 and b is -49.6923162055371\n",
      "Iteration 2043, the loss is 4.527561456493778, parameters k is 11.516522802371945 and b is -49.69228458498374\n",
      "Iteration 2044, the loss is 4.527561084524705, parameters k is 11.516505501976688 and b is -49.69225296443038\n",
      "Iteration 2045, the loss is 4.527560463969216, parameters k is 11.516538098814634 and b is -49.69221343873868\n",
      "Iteration 2046, the loss is 4.52755981438768, parameters k is 11.516520798419377 and b is -49.692181818185325\n",
      "Iteration 2047, the loss is 4.527559164806142, parameters k is 11.51650349802412 and b is -49.69215019763197\n",
      "Iteration 2048, the loss is 4.52755874327854, parameters k is 11.516486197628863 and b is -49.69211857707861\n",
      "Iteration 2049, the loss is 4.52755817228158, parameters k is 11.516518794466808 and b is -49.69207905138691\n",
      "Iteration 2050, the loss is 4.527557522700038, parameters k is 11.516501494071552 and b is -49.692047430833554\n",
      "Iteration 2051, the loss is 4.527556873118507, parameters k is 11.516484193676295 and b is -49.692015810280196\n",
      "Iteration 2052, the loss is 4.5275564020323715, parameters k is 11.516466893281038 and b is -49.69198418972684\n",
      "Iteration 2053, the loss is 4.527555880593937, parameters k is 11.516499490118983 and b is -49.69194466403514\n",
      "Iteration 2054, the loss is 4.527555231012403, parameters k is 11.516482189723726 and b is -49.69191304348178\n",
      "Iteration 2055, the loss is 4.5275545814308655, parameters k is 11.51646488932847 and b is -49.691881422928425\n",
      "Iteration 2056, the loss is 4.527554060786205, parameters k is 11.516447588933213 and b is -49.69184980237507\n",
      "Iteration 2057, the loss is 4.527553588906304, parameters k is 11.516480185771158 and b is -49.69181027668337\n",
      "Iteration 2058, the loss is 4.527552939324766, parameters k is 11.516462885375901 and b is -49.69177865613001\n",
      "Iteration 2059, the loss is 4.527552289743229, parameters k is 11.516445584980644 and b is -49.691747035576654\n",
      "Iteration 2060, the loss is 4.52755171954003, parameters k is 11.516428284585388 and b is -49.691715415023296\n",
      "Iteration 2061, the loss is 4.527551297218662, parameters k is 11.516460881423333 and b is -49.6916758893316\n",
      "Iteration 2062, the loss is 4.52755064763713, parameters k is 11.516443581028076 and b is -49.69164426877824\n",
      "Iteration 2063, the loss is 4.527549998055591, parameters k is 11.51642628063282 and b is -49.69161264822488\n",
      "Iteration 2064, the loss is 4.527549378293865, parameters k is 11.516408980237562 and b is -49.691581027671525\n",
      "Iteration 2065, the loss is 4.527549005531023, parameters k is 11.516441577075508 and b is -49.69154150197983\n",
      "Iteration 2066, the loss is 4.52754835594949, parameters k is 11.516424276680251 and b is -49.69150988142647\n",
      "Iteration 2067, the loss is 4.5275477063679554, parameters k is 11.516406976284994 and b is -49.69147826087311\n",
      "Iteration 2068, the loss is 4.527547056786416, parameters k is 11.516389675889737 and b is -49.691446640319754\n",
      "Iteration 2069, the loss is 4.52754669410467, parameters k is 11.51637237549448 and b is -49.691415019766396\n",
      "Iteration 2070, the loss is 4.527546064261853, parameters k is 11.516404972332426 and b is -49.6913754940747\n",
      "Iteration 2071, the loss is 4.527545414680316, parameters k is 11.516387671937169 and b is -49.69134387352134\n",
      "Iteration 2072, the loss is 4.527544765098781, parameters k is 11.516370371541912 and b is -49.69131225296798\n",
      "Iteration 2073, the loss is 4.5275443528584915, parameters k is 11.516353071146655 and b is -49.691280632414625\n",
      "Iteration 2074, the loss is 4.5275437725742105, parameters k is 11.5163856679846 and b is -49.69124110672293\n",
      "Iteration 2075, the loss is 4.527543122992675, parameters k is 11.516368367589344 and b is -49.69120948616957\n",
      "Iteration 2076, the loss is 4.527542473411142, parameters k is 11.516351067194087 and b is -49.69117786561621\n",
      "Iteration 2077, the loss is 4.527542011612332, parameters k is 11.51633376679883 and b is -49.69114624506285\n",
      "Iteration 2078, the loss is 4.527541480886575, parameters k is 11.516366363636775 and b is -49.691106719371156\n",
      "Iteration 2079, the loss is 4.52754083130504, parameters k is 11.516349063241519 and b is -49.6910750988178\n",
      "Iteration 2080, the loss is 4.527540181723501, parameters k is 11.516331762846262 and b is -49.69104347826444\n",
      "Iteration 2081, the loss is 4.527539670366162, parameters k is 11.516314462451005 and b is -49.69101185771108\n",
      "Iteration 2082, the loss is 4.527539189198938, parameters k is 11.51634705928895 and b is -49.690972332019385\n",
      "Iteration 2083, the loss is 4.527538539617402, parameters k is 11.516329758893693 and b is -49.69094071146603\n",
      "Iteration 2084, the loss is 4.527537890035868, parameters k is 11.516312458498437 and b is -49.69090909091267\n",
      "Iteration 2085, the loss is 4.52753732911999, parameters k is 11.51629515810318 and b is -49.69087747035931\n",
      "Iteration 2086, the loss is 4.527536897511302, parameters k is 11.516327754941125 and b is -49.690837944667614\n",
      "Iteration 2087, the loss is 4.527536247929765, parameters k is 11.516310454545868 and b is -49.690806324114256\n",
      "Iteration 2088, the loss is 4.5275355983482335, parameters k is 11.516293154150611 and b is -49.6907747035609\n",
      "Iteration 2089, the loss is 4.527534987873826, parameters k is 11.516275853755355 and b is -49.69074308300754\n",
      "Iteration 2090, the loss is 4.527534605823662, parameters k is 11.5163084505933 and b is -49.69070355731584\n",
      "Iteration 2091, the loss is 4.527533956242126, parameters k is 11.516291150198043 and b is -49.690671936762485\n",
      "Iteration 2092, the loss is 4.527533306660593, parameters k is 11.516273849802786 and b is -49.69064031620913\n",
      "Iteration 2093, the loss is 4.527532657079055, parameters k is 11.51625654940753 and b is -49.69060869565577\n",
      "Iteration 2094, the loss is 4.527532303684621, parameters k is 11.516239249012273 and b is -49.69057707510241\n",
      "Iteration 2095, the loss is 4.527531664554487, parameters k is 11.516271845850218 and b is -49.69053754941071\n",
      "Iteration 2096, the loss is 4.527531014972953, parameters k is 11.516254545454961 and b is -49.690505928857355\n",
      "Iteration 2097, the loss is 4.527530365391421, parameters k is 11.516237245059704 and b is -49.690474308304\n",
      "Iteration 2098, the loss is 4.527529962438458, parameters k is 11.516219944664448 and b is -49.69044268775064\n",
      "Iteration 2099, the loss is 4.527529372866854, parameters k is 11.516252541502393 and b is -49.69040316205894\n",
      "Iteration 2100, the loss is 4.527528723285316, parameters k is 11.516235241107136 and b is -49.690371541505584\n",
      "Iteration 2101, the loss is 4.527528073703782, parameters k is 11.51621794071188 and b is -49.690339920952226\n",
      "Iteration 2102, the loss is 4.52752762119229, parameters k is 11.516200640316622 and b is -49.69030830039887\n",
      "Iteration 2103, the loss is 4.527527081179217, parameters k is 11.516233237154568 and b is -49.69026877470717\n",
      "Iteration 2104, the loss is 4.527526431597681, parameters k is 11.51621593675931 and b is -49.69023715415381\n",
      "Iteration 2105, the loss is 4.527525782016147, parameters k is 11.516198636364054 and b is -49.690205533600455\n",
      "Iteration 2106, the loss is 4.527525279946122, parameters k is 11.516181335968797 and b is -49.6901739130471\n",
      "Iteration 2107, the loss is 4.527524789491583, parameters k is 11.516213932806743 and b is -49.6901343873554\n",
      "Iteration 2108, the loss is 4.527524139910041, parameters k is 11.516196632411486 and b is -49.69010276680204\n",
      "Iteration 2109, the loss is 4.527523490328505, parameters k is 11.516179332016229 and b is -49.690071146248684\n",
      "Iteration 2110, the loss is 4.527522938699951, parameters k is 11.516162031620972 and b is -49.690039525695326\n",
      "Iteration 2111, the loss is 4.527522497803945, parameters k is 11.516194628458917 and b is -49.69000000000363\n",
      "Iteration 2112, the loss is 4.527521848222409, parameters k is 11.51617732806366 and b is -49.68996837945027\n",
      "Iteration 2113, the loss is 4.5275211986408666, parameters k is 11.516160027668404 and b is -49.68993675889691\n",
      "Iteration 2114, the loss is 4.527520597453783, parameters k is 11.516142727273147 and b is -49.689905138343555\n",
      "Iteration 2115, the loss is 4.527520206116302, parameters k is 11.516175324111092 and b is -49.68986561265186\n",
      "Iteration 2116, the loss is 4.527519556534762, parameters k is 11.516158023715835 and b is -49.6898339920985\n",
      "Iteration 2117, the loss is 4.5275189069532304, parameters k is 11.516140723320579 and b is -49.68980237154514\n",
      "Iteration 2118, the loss is 4.5275182573717, parameters k is 11.516123422925322 and b is -49.689770750991784\n",
      "Iteration 2119, the loss is 4.5275179132645835, parameters k is 11.516106122530065 and b is -49.689739130438426\n",
      "Iteration 2120, the loss is 4.52751726484713, parameters k is 11.51613871936801 and b is -49.68969960474673\n",
      "Iteration 2121, the loss is 4.52751661526559, parameters k is 11.516121418972753 and b is -49.68966798419337\n",
      "Iteration 2122, the loss is 4.527515965684059, parameters k is 11.516104118577497 and b is -49.68963636364001\n",
      "Iteration 2123, the loss is 4.527515572018412, parameters k is 11.51608681818224 and b is -49.689604743086655\n",
      "Iteration 2124, the loss is 4.52751497315949, parameters k is 11.516119415020185 and b is -49.68956521739496\n",
      "Iteration 2125, the loss is 4.527514323577954, parameters k is 11.516102114624928 and b is -49.6895335968416\n",
      "Iteration 2126, the loss is 4.527513673996419, parameters k is 11.516084814229671 and b is -49.68950197628824\n",
      "Iteration 2127, the loss is 4.527513230772247, parameters k is 11.516067513834415 and b is -49.68947035573488\n",
      "Iteration 2128, the loss is 4.5275126814718565, parameters k is 11.51610011067236 and b is -49.689430830043186\n",
      "Iteration 2129, the loss is 4.5275120318903195, parameters k is 11.516082810277103 and b is -49.68939920948983\n",
      "Iteration 2130, the loss is 4.527511382308785, parameters k is 11.516065509881846 and b is -49.68936758893647\n",
      "Iteration 2131, the loss is 4.527510889526078, parameters k is 11.51604820948659 and b is -49.68933596838311\n",
      "Iteration 2132, the loss is 4.527510389784212, parameters k is 11.516080806324535 and b is -49.689296442691415\n",
      "Iteration 2133, the loss is 4.52750974020268, parameters k is 11.516063505929278 and b is -49.68926482213806\n",
      "Iteration 2134, the loss is 4.527509090621145, parameters k is 11.516046205534021 and b is -49.6892332015847\n",
      "Iteration 2135, the loss is 4.527508548279907, parameters k is 11.516028905138764 and b is -49.68920158103134\n",
      "Iteration 2136, the loss is 4.527508098096579, parameters k is 11.51606150197671 and b is -49.689162055339644\n",
      "Iteration 2137, the loss is 4.527507448515043, parameters k is 11.516044201581453 and b is -49.689130434786286\n",
      "Iteration 2138, the loss is 4.527506798933507, parameters k is 11.516026901186196 and b is -49.68909881423293\n",
      "Iteration 2139, the loss is 4.527506207033738, parameters k is 11.51600960079094 and b is -49.68906719367957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2140, the loss is 4.527505806408944, parameters k is 11.516042197628884 and b is -49.68902766798787\n",
      "Iteration 2141, the loss is 4.527505156827405, parameters k is 11.516024897233628 and b is -49.688996047434514\n",
      "Iteration 2142, the loss is 4.527504507245871, parameters k is 11.51600759683837 and b is -49.68896442688116\n",
      "Iteration 2143, the loss is 4.527503865787571, parameters k is 11.515990296443114 and b is -49.6889328063278\n",
      "Iteration 2144, the loss is 4.527503514721301, parameters k is 11.51602289328106 and b is -49.6888932806361\n",
      "Iteration 2145, the loss is 4.527502865139771, parameters k is 11.516005592885802 and b is -49.68886166008274\n",
      "Iteration 2146, the loss is 4.527502215558227, parameters k is 11.515988292490546 and b is -49.688830039529385\n",
      "Iteration 2147, the loss is 4.527501565976698, parameters k is 11.515970992095289 and b is -49.68879841897603\n",
      "Iteration 2148, the loss is 4.527501181598376, parameters k is 11.515953691700032 and b is -49.68876679842267\n",
      "Iteration 2149, the loss is 4.527500573452131, parameters k is 11.515986288537977 and b is -49.68872727273097\n",
      "Iteration 2150, the loss is 4.527499923870598, parameters k is 11.51596898814272 and b is -49.688695652177614\n",
      "Iteration 2151, the loss is 4.5274992742890605, parameters k is 11.515951687747464 and b is -49.688664031624256\n",
      "Iteration 2152, the loss is 4.52749884035221, parameters k is 11.515934387352207 and b is -49.6886324110709\n",
      "Iteration 2153, the loss is 4.527498281764492, parameters k is 11.515966984190152 and b is -49.6885928853792\n",
      "Iteration 2154, the loss is 4.527497632182958, parameters k is 11.515949683794895 and b is -49.68856126482584\n",
      "Iteration 2155, the loss is 4.527496982601418, parameters k is 11.515932383399639 and b is -49.688529644272485\n",
      "Iteration 2156, the loss is 4.527496499106036, parameters k is 11.515915083004382 and b is -49.68849802371913\n",
      "Iteration 2157, the loss is 4.527495990076856, parameters k is 11.515947679842327 and b is -49.68845849802743\n",
      "Iteration 2158, the loss is 4.527495340495327, parameters k is 11.51593037944707 and b is -49.68842687747407\n",
      "Iteration 2159, the loss is 4.52749469091379, parameters k is 11.515913079051813 and b is -49.688395256920714\n",
      "Iteration 2160, the loss is 4.527494157859868, parameters k is 11.515895778656557 and b is -49.688363636367356\n",
      "Iteration 2161, the loss is 4.527493698389215, parameters k is 11.515928375494502 and b is -49.68832411067566\n",
      "Iteration 2162, the loss is 4.527493048807681, parameters k is 11.515911075099245 and b is -49.6882924901223\n",
      "Iteration 2163, the loss is 4.5274923992261495, parameters k is 11.515893774703988 and b is -49.68826086956894\n",
      "Iteration 2164, the loss is 4.527491816613699, parameters k is 11.515876474308731 and b is -49.688229249015585\n",
      "Iteration 2165, the loss is 4.527491406701581, parameters k is 11.515909071146677 and b is -49.68818972332389\n",
      "Iteration 2166, the loss is 4.527490757120044, parameters k is 11.51589177075142 and b is -49.68815810277053\n",
      "Iteration 2167, the loss is 4.527490107538512, parameters k is 11.515874470356163 and b is -49.68812648221717\n",
      "Iteration 2168, the loss is 4.527489475367529, parameters k is 11.515857169960906 and b is -49.688094861663814\n",
      "Iteration 2169, the loss is 4.527489115013943, parameters k is 11.515889766798852 and b is -49.688055335972116\n",
      "Iteration 2170, the loss is 4.527488465432409, parameters k is 11.515872466403595 and b is -49.68802371541876\n",
      "Iteration 2171, the loss is 4.527487815850874, parameters k is 11.515855166008338 and b is -49.6879920948654\n",
      "Iteration 2172, the loss is 4.527487166269342, parameters k is 11.515837865613081 and b is -49.68796047431204\n",
      "Iteration 2173, the loss is 4.527486791178333, parameters k is 11.515820565217824 and b is -49.687928853758685\n",
      "Iteration 2174, the loss is 4.52748617374477, parameters k is 11.51585316205577 and b is -49.68788932806699\n",
      "Iteration 2175, the loss is 4.527485524163238, parameters k is 11.515835861660513 and b is -49.68785770751363\n",
      "Iteration 2176, the loss is 4.5274848745816945, parameters k is 11.515818561265256 and b is -49.68782608696027\n",
      "Iteration 2177, the loss is 4.52748444993216, parameters k is 11.51580126087 and b is -49.68779446640691\n",
      "Iteration 2178, the loss is 4.527483882057134, parameters k is 11.515833857707944 and b is -49.687754940715216\n",
      "Iteration 2179, the loss is 4.527483232475594, parameters k is 11.515816557312688 and b is -49.68772332016186\n",
      "Iteration 2180, the loss is 4.527482582894063, parameters k is 11.51579925691743 and b is -49.6876916996085\n",
      "Iteration 2181, the loss is 4.527482108685996, parameters k is 11.515781956522174 and b is -49.68766007905514\n",
      "Iteration 2182, the loss is 4.527481590369494, parameters k is 11.51581455336012 and b is -49.687620553363445\n",
      "Iteration 2183, the loss is 4.527480940787963, parameters k is 11.515797252964862 and b is -49.68758893281009\n",
      "Iteration 2184, the loss is 4.527480291206425, parameters k is 11.515779952569606 and b is -49.68755731225673\n",
      "Iteration 2185, the loss is 4.527479767439826, parameters k is 11.515762652174349 and b is -49.68752569170337\n",
      "Iteration 2186, the loss is 4.527479298681853, parameters k is 11.515795249012294 and b is -49.687486166011674\n",
      "Iteration 2187, the loss is 4.527478649100322, parameters k is 11.515777948617037 and b is -49.687454545458316\n",
      "Iteration 2188, the loss is 4.527477999518786, parameters k is 11.51576064822178 and b is -49.68742292490496\n",
      "Iteration 2189, the loss is 4.52747742619366, parameters k is 11.515743347826524 and b is -49.6873913043516\n",
      "Iteration 2190, the loss is 4.52747700699422, parameters k is 11.515775944664469 and b is -49.6873517786599\n",
      "Iteration 2191, the loss is 4.527476357412682, parameters k is 11.515758644269212 and b is -49.687320158106544\n",
      "Iteration 2192, the loss is 4.527475707831149, parameters k is 11.515741343873955 and b is -49.68728853755319\n",
      "Iteration 2193, the loss is 4.52747508494749, parameters k is 11.515724043478698 and b is -49.68725691699983\n",
      "Iteration 2194, the loss is 4.527474715306583, parameters k is 11.515756640316644 and b is -49.68721739130813\n",
      "Iteration 2195, the loss is 4.527474065725051, parameters k is 11.515739339921387 and b is -49.68718577075477\n",
      "Iteration 2196, the loss is 4.527473416143515, parameters k is 11.51572203952613 and b is -49.687154150201415\n",
      "Iteration 2197, the loss is 4.527472766561976, parameters k is 11.515704739130873 and b is -49.68712252964806\n",
      "Iteration 2198, the loss is 4.5274724007582865, parameters k is 11.515687438735617 and b is -49.6870909090947\n",
      "Iteration 2199, the loss is 4.527471774037411, parameters k is 11.515720035573562 and b is -49.687051383403\n",
      "Iteration 2200, the loss is 4.527471124455875, parameters k is 11.515702735178305 and b is -49.687019762849644\n",
      "Iteration 2201, the loss is 4.527470474874342, parameters k is 11.515685434783048 and b is -49.686988142296286\n",
      "Iteration 2202, the loss is 4.527470059512118, parameters k is 11.515668134387791 and b is -49.68695652174293\n",
      "Iteration 2203, the loss is 4.52746948234977, parameters k is 11.515700731225737 and b is -49.68691699605123\n",
      "Iteration 2204, the loss is 4.527468832768237, parameters k is 11.51568343083048 and b is -49.68688537549787\n",
      "Iteration 2205, the loss is 4.527468183186702, parameters k is 11.515666130435223 and b is -49.686853754944515\n",
      "Iteration 2206, the loss is 4.5274677182659495, parameters k is 11.515648830039966 and b is -49.68682213439116\n",
      "Iteration 2207, the loss is 4.527467190662134, parameters k is 11.515681426877912 and b is -49.68678260869946\n",
      "Iteration 2208, the loss is 4.5274665410806, parameters k is 11.515664126482655 and b is -49.6867509881461\n",
      "Iteration 2209, the loss is 4.5274658914990615, parameters k is 11.515646826087398 and b is -49.686719367592744\n",
      "Iteration 2210, the loss is 4.527465377019784, parameters k is 11.515629525692141 and b is -49.686687747039386\n",
      "Iteration 2211, the loss is 4.527464898974499, parameters k is 11.515662122530086 and b is -49.68664822134769\n",
      "Iteration 2212, the loss is 4.527464249392962, parameters k is 11.51564482213483 and b is -49.68661660079433\n",
      "Iteration 2213, the loss is 4.527463599811425, parameters k is 11.515627521739573 and b is -49.68658498024097\n",
      "Iteration 2214, the loss is 4.527463035773615, parameters k is 11.515610221344316 and b is -49.686553359687615\n",
      "Iteration 2215, the loss is 4.527462607286859, parameters k is 11.515642818182261 and b is -49.68651383399592\n",
      "Iteration 2216, the loss is 4.527461957705324, parameters k is 11.515625517787004 and b is -49.68648221344256\n",
      "Iteration 2217, the loss is 4.527461308123785, parameters k is 11.515608217391748 and b is -49.6864505928892\n",
      "Iteration 2218, the loss is 4.527460694527448, parameters k is 11.51559091699649 and b is -49.686418972335844\n",
      "Iteration 2219, the loss is 4.527460315599223, parameters k is 11.515623513834436 and b is -49.686379446644146\n",
      "Iteration 2220, the loss is 4.527459666017688, parameters k is 11.51560621343918 and b is -49.68634782609079\n",
      "Iteration 2221, the loss is 4.52745901643615, parameters k is 11.515588913043922 and b is -49.68631620553743\n",
      "Iteration 2222, the loss is 4.527458366854614, parameters k is 11.515571612648666 and b is -49.68628458498407\n",
      "Iteration 2223, the loss is 4.527458010338247, parameters k is 11.515554312253409 and b is -49.686252964430714\n",
      "Iteration 2224, the loss is 4.527457374330046, parameters k is 11.515586909091354 and b is -49.68621343873902\n",
      "Iteration 2225, the loss is 4.527456724748518, parameters k is 11.515569608696097 and b is -49.68618181818566\n",
      "Iteration 2226, the loss is 4.527456075166982, parameters k is 11.51555230830084 and b is -49.6861501976323\n",
      "Iteration 2227, the loss is 4.52745566909208, parameters k is 11.515535007905584 and b is -49.68611857707894\n",
      "Iteration 2228, the loss is 4.527455082642415, parameters k is 11.515567604743529 and b is -49.686079051387246\n",
      "Iteration 2229, the loss is 4.527454433060877, parameters k is 11.515550304348272 and b is -49.68604743083389\n",
      "Iteration 2230, the loss is 4.527453783479346, parameters k is 11.515533003953015 and b is -49.68601581028053\n",
      "Iteration 2231, the loss is 4.527453327845907, parameters k is 11.515515703557758 and b is -49.68598418972717\n",
      "Iteration 2232, the loss is 4.527452790954775, parameters k is 11.515548300395704 and b is -49.685944664035475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2233, the loss is 4.527452141373237, parameters k is 11.515531000000447 and b is -49.68591304348212\n",
      "Iteration 2234, the loss is 4.5274514917917, parameters k is 11.51551369960519 and b is -49.68588142292876\n",
      "Iteration 2235, the loss is 4.527450986599741, parameters k is 11.515496399209933 and b is -49.6858498023754\n",
      "Iteration 2236, the loss is 4.527450499267134, parameters k is 11.515528996047879 and b is -49.6858102766837\n",
      "Iteration 2237, the loss is 4.5274498496856, parameters k is 11.515511695652622 and b is -49.685778656130346\n",
      "Iteration 2238, the loss is 4.527449200104065, parameters k is 11.515494395257365 and b is -49.68574703557699\n",
      "Iteration 2239, the loss is 4.527448645353572, parameters k is 11.515477094862108 and b is -49.68571541502363\n",
      "Iteration 2240, the loss is 4.527448207579502, parameters k is 11.515509691700053 and b is -49.68567588933193\n",
      "Iteration 2241, the loss is 4.527447557997963, parameters k is 11.515492391304797 and b is -49.685644268778574\n",
      "Iteration 2242, the loss is 4.527446908416429, parameters k is 11.51547509090954 and b is -49.68561264822522\n",
      "Iteration 2243, the loss is 4.527446304107405, parameters k is 11.515457790514283 and b is -49.68558102767186\n",
      "Iteration 2244, the loss is 4.52744591589186, parameters k is 11.515490387352228 and b is -49.68554150198016\n",
      "Iteration 2245, the loss is 4.527445266310327, parameters k is 11.515473086956971 and b is -49.6855098814268\n",
      "Iteration 2246, the loss is 4.5274446167287925, parameters k is 11.515455786561715 and b is -49.685478260873445\n",
      "Iteration 2247, the loss is 4.52744396714726, parameters k is 11.515438486166458 and b is -49.68544664032009\n",
      "Iteration 2248, the loss is 4.527443619918208, parameters k is 11.515421185771201 and b is -49.68541501976673\n",
      "Iteration 2249, the loss is 4.5274429746226925, parameters k is 11.515453782609146 and b is -49.68537549407503\n",
      "Iteration 2250, the loss is 4.527442325041157, parameters k is 11.51543648221389 and b is -49.685343873521674\n",
      "Iteration 2251, the loss is 4.527441675459618, parameters k is 11.515419181818633 and b is -49.685312252968316\n",
      "Iteration 2252, the loss is 4.527441278672039, parameters k is 11.515401881423376 and b is -49.68528063241496\n",
      "Iteration 2253, the loss is 4.5274406829350475, parameters k is 11.515434478261321 and b is -49.68524110672326\n",
      "Iteration 2254, the loss is 4.527440033353515, parameters k is 11.515417177866064 and b is -49.6852094861699\n",
      "Iteration 2255, the loss is 4.52743938377198, parameters k is 11.515399877470808 and b is -49.685177865616545\n",
      "Iteration 2256, the loss is 4.527438937425873, parameters k is 11.51538257707555 and b is -49.68514624506319\n",
      "Iteration 2257, the loss is 4.527438391247415, parameters k is 11.515415173913496 and b is -49.68510671937149\n",
      "Iteration 2258, the loss is 4.527437741665876, parameters k is 11.51539787351824 and b is -49.68507509881813\n",
      "Iteration 2259, the loss is 4.527437092084339, parameters k is 11.515380573122982 and b is -49.685043478264774\n",
      "Iteration 2260, the loss is 4.527436596179701, parameters k is 11.515363272727726 and b is -49.685011857711416\n",
      "Iteration 2261, the loss is 4.527436099559773, parameters k is 11.51539586956567 and b is -49.68497233201972\n",
      "Iteration 2262, the loss is 4.527435449978239, parameters k is 11.515378569170414 and b is -49.68494071146636\n",
      "Iteration 2263, the loss is 4.527434800396707, parameters k is 11.515361268775157 and b is -49.684909090913\n",
      "Iteration 2264, the loss is 4.527434254933532, parameters k is 11.5153439683799 and b is -49.684877470359645\n",
      "Iteration 2265, the loss is 4.52743380787214, parameters k is 11.515376565217846 and b is -49.68483794466795\n",
      "Iteration 2266, the loss is 4.527433158290603, parameters k is 11.515359264822589 and b is -49.68480632411459\n",
      "Iteration 2267, the loss is 4.527432508709066, parameters k is 11.515341964427332 and b is -49.68477470356123\n",
      "Iteration 2268, the loss is 4.527431913687363, parameters k is 11.515324664032075 and b is -49.684743083007874\n",
      "Iteration 2269, the loss is 4.5274315161845, parameters k is 11.51535726087002 and b is -49.684703557316176\n",
      "Iteration 2270, the loss is 4.5274308666029635, parameters k is 11.515339960474764 and b is -49.68467193676282\n",
      "Iteration 2271, the loss is 4.527430217021432, parameters k is 11.515322660079507 and b is -49.68464031620946\n",
      "Iteration 2272, the loss is 4.527429572441194, parameters k is 11.51530535968425 and b is -49.6846086956561\n",
      "Iteration 2273, the loss is 4.527429224496862, parameters k is 11.515337956522195 and b is -49.684569169964405\n",
      "Iteration 2274, the loss is 4.527428574915328, parameters k is 11.515320656126939 and b is -49.68453754941105\n",
      "Iteration 2275, the loss is 4.52742792533379, parameters k is 11.515303355731682 and b is -49.68450592885769\n",
      "Iteration 2276, the loss is 4.527427275752257, parameters k is 11.515286055336425 and b is -49.68447430830433\n",
      "Iteration 2277, the loss is 4.527426888251994, parameters k is 11.515268754941168 and b is -49.68444268775097\n",
      "Iteration 2278, the loss is 4.527426283227692, parameters k is 11.515301351779113 and b is -49.684403162059276\n",
      "Iteration 2279, the loss is 4.5274256336461525, parameters k is 11.515284051383857 and b is -49.68437154150592\n",
      "Iteration 2280, the loss is 4.527424984064616, parameters k is 11.5152667509886 and b is -49.68433992095256\n",
      "Iteration 2281, the loss is 4.527424547005825, parameters k is 11.515249450593343 and b is -49.6843083003992\n",
      "Iteration 2282, the loss is 4.527423991540055, parameters k is 11.515282047431288 and b is -49.684268774707505\n",
      "Iteration 2283, the loss is 4.527423341958519, parameters k is 11.515264747036031 and b is -49.68423715415415\n",
      "Iteration 2284, the loss is 4.5274226923769785, parameters k is 11.515247446640775 and b is -49.68420553360079\n",
      "Iteration 2285, the loss is 4.527422205759657, parameters k is 11.515230146245518 and b is -49.68417391304743\n",
      "Iteration 2286, the loss is 4.527421699852415, parameters k is 11.515262743083463 and b is -49.68413438735573\n",
      "Iteration 2287, the loss is 4.527421050270877, parameters k is 11.515245442688206 and b is -49.684102766802376\n",
      "Iteration 2288, the loss is 4.52742040068934, parameters k is 11.51522814229295 and b is -49.68407114624902\n",
      "Iteration 2289, the loss is 4.527419864513491, parameters k is 11.515210841897693 and b is -49.68403952569566\n",
      "Iteration 2290, the loss is 4.5274194081647785, parameters k is 11.515243438735638 and b is -49.68400000000396\n",
      "Iteration 2291, the loss is 4.527418758583243, parameters k is 11.515226138340381 and b is -49.683968379450604\n",
      "Iteration 2292, the loss is 4.527418109001712, parameters k is 11.515208837945124 and b is -49.68393675889725\n",
      "Iteration 2293, the loss is 4.5274175232673235, parameters k is 11.515191537549867 and b is -49.68390513834389\n",
      "Iteration 2294, the loss is 4.527417116477139, parameters k is 11.515224134387813 and b is -49.68386561265219\n",
      "Iteration 2295, the loss is 4.527416466895604, parameters k is 11.515206833992556 and b is -49.68383399209883\n",
      "Iteration 2296, the loss is 4.527415817314068, parameters k is 11.5151895335973 and b is -49.683802371545475\n",
      "Iteration 2297, the loss is 4.527415182021152, parameters k is 11.515172233202042 and b is -49.68377075099212\n",
      "Iteration 2298, the loss is 4.527414824789505, parameters k is 11.515204830039988 and b is -49.68373122530042\n",
      "Iteration 2299, the loss is 4.527414175207967, parameters k is 11.51518752964473 and b is -49.68369960474706\n",
      "Iteration 2300, the loss is 4.527413525626431, parameters k is 11.515170229249474 and b is -49.683667984193704\n",
      "Iteration 2301, the loss is 4.527412876044901, parameters k is 11.515152928854217 and b is -49.683636363640346\n",
      "Iteration 2302, the loss is 4.527412497831953, parameters k is 11.51513562845896 and b is -49.68360474308699\n",
      "Iteration 2303, the loss is 4.527411883520324, parameters k is 11.515168225296906 and b is -49.68356521739529\n",
      "Iteration 2304, the loss is 4.527411233938794, parameters k is 11.515150924901649 and b is -49.68353359684193\n",
      "Iteration 2305, the loss is 4.527410584357259, parameters k is 11.515133624506392 and b is -49.683501976288575\n",
      "Iteration 2306, the loss is 4.527410156585785, parameters k is 11.515116324111135 and b is -49.68347035573522\n",
      "Iteration 2307, the loss is 4.527409591832696, parameters k is 11.51514892094908 and b is -49.68343083004352\n",
      "Iteration 2308, the loss is 4.527408942251153, parameters k is 11.515131620553824 and b is -49.68339920949016\n",
      "Iteration 2309, the loss is 4.527408292669623, parameters k is 11.515114320158567 and b is -49.683367588936804\n",
      "Iteration 2310, the loss is 4.527407815339613, parameters k is 11.51509701976331 and b is -49.683335968383446\n",
      "Iteration 2311, the loss is 4.527407300145055, parameters k is 11.515129616601255 and b is -49.68329644269175\n",
      "Iteration 2312, the loss is 4.527406650563522, parameters k is 11.515112316205999 and b is -49.68326482213839\n",
      "Iteration 2313, the loss is 4.527406000981986, parameters k is 11.515095015810742 and b is -49.68323320158503\n",
      "Iteration 2314, the loss is 4.527405474093455, parameters k is 11.515077715415485 and b is -49.683201581031675\n",
      "Iteration 2315, the loss is 4.527405008457419, parameters k is 11.51511031225343 and b is -49.68316205533998\n",
      "Iteration 2316, the loss is 4.527404358875881, parameters k is 11.515093011858173 and b is -49.68313043478662\n",
      "Iteration 2317, the loss is 4.527403709294347, parameters k is 11.515075711462917 and b is -49.68309881423326\n",
      "Iteration 2318, the loss is 4.527403132847281, parameters k is 11.51505841106766 and b is -49.6830671936799\n",
      "Iteration 2319, the loss is 4.5274027167697835, parameters k is 11.515091007905605 and b is -49.683027667988206\n",
      "Iteration 2320, the loss is 4.527402067188244, parameters k is 11.515073707510348 and b is -49.68299604743485\n",
      "Iteration 2321, the loss is 4.527401417606713, parameters k is 11.515056407115091 and b is -49.68296442688149\n",
      "Iteration 2322, the loss is 4.52740079160111, parameters k is 11.515039106719835 and b is -49.68293280632813\n",
      "Iteration 2323, the loss is 4.527400425082145, parameters k is 11.51507170355778 and b is -49.682893280636435\n",
      "Iteration 2324, the loss is 4.527399775500601, parameters k is 11.515054403162523 and b is -49.68286166008308\n",
      "Iteration 2325, the loss is 4.527399125919073, parameters k is 11.515037102767266 and b is -49.68283003952972\n",
      "Iteration 2326, the loss is 4.527398476337535, parameters k is 11.51501980237201 and b is -49.68279841897636\n",
      "Iteration 2327, the loss is 4.527398107411911, parameters k is 11.515002501976753 and b is -49.682766798423\n",
      "Iteration 2328, the loss is 4.5273974838129725, parameters k is 11.515035098814698 and b is -49.682727272731306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2329, the loss is 4.527396834231438, parameters k is 11.515017798419441 and b is -49.68269565217795\n",
      "Iteration 2330, the loss is 4.527396184649903, parameters k is 11.515000498024184 and b is -49.68266403162459\n",
      "Iteration 2331, the loss is 4.527395766165746, parameters k is 11.514983197628927 and b is -49.68263241107123\n",
      "Iteration 2332, the loss is 4.527395192125328, parameters k is 11.515015794466873 and b is -49.682592885379535\n",
      "Iteration 2333, the loss is 4.527394542543799, parameters k is 11.514998494071616 and b is -49.68256126482618\n",
      "Iteration 2334, the loss is 4.527393892962264, parameters k is 11.514981193676359 and b is -49.68252964427282\n",
      "Iteration 2335, the loss is 4.52739342491957, parameters k is 11.514963893281102 and b is -49.68249802371946\n",
      "Iteration 2336, the loss is 4.527392900437697, parameters k is 11.514996490119048 and b is -49.68245849802776\n",
      "Iteration 2337, the loss is 4.527392250856157, parameters k is 11.51497918972379 and b is -49.682426877474406\n",
      "Iteration 2338, the loss is 4.527391601274624, parameters k is 11.514961889328534 and b is -49.68239525692105\n",
      "Iteration 2339, the loss is 4.527391083673409, parameters k is 11.514944588933277 and b is -49.68236363636769\n",
      "Iteration 2340, the loss is 4.527390608750055, parameters k is 11.514977185771222 and b is -49.68232411067599\n",
      "Iteration 2341, the loss is 4.527389959168521, parameters k is 11.514959885375966 and b is -49.682292490122634\n",
      "Iteration 2342, the loss is 4.527389309586991, parameters k is 11.514942584980709 and b is -49.68226086956928\n",
      "Iteration 2343, the loss is 4.527388742427237, parameters k is 11.514925284585452 and b is -49.68222924901592\n",
      "Iteration 2344, the loss is 4.527388317062422, parameters k is 11.514957881423397 and b is -49.68218972332422\n",
      "Iteration 2345, the loss is 4.527387667480884, parameters k is 11.51494058102814 and b is -49.68215810277086\n",
      "Iteration 2346, the loss is 4.527387017899349, parameters k is 11.514923280632884 and b is -49.682126482217505\n",
      "Iteration 2347, the loss is 4.52738640118107, parameters k is 11.514905980237627 and b is -49.68209486166415\n",
      "Iteration 2348, the loss is 4.5273860253747795, parameters k is 11.514938577075572 and b is -49.68205533597245\n",
      "Iteration 2349, the loss is 4.527385375793243, parameters k is 11.514921276680315 and b is -49.68202371541909\n",
      "Iteration 2350, the loss is 4.52738472621171, parameters k is 11.514903976285058 and b is -49.681992094865734\n",
      "Iteration 2351, the loss is 4.527384076630174, parameters k is 11.514886675889802 and b is -49.681960474312376\n",
      "Iteration 2352, the loss is 4.5273837169918725, parameters k is 11.514869375494545 and b is -49.68192885375902\n",
      "Iteration 2353, the loss is 4.527383084105608, parameters k is 11.51490197233249 and b is -49.68188932806732\n",
      "Iteration 2354, the loss is 4.527382434524069, parameters k is 11.514884671937233 and b is -49.68185770751396\n",
      "Iteration 2355, the loss is 4.52738178494254, parameters k is 11.514867371541976 and b is -49.681826086960605\n",
      "Iteration 2356, the loss is 4.5273813757457, parameters k is 11.51485007114672 and b is -49.68179446640725\n",
      "Iteration 2357, the loss is 4.527380792417963, parameters k is 11.514882667984665 and b is -49.68175494071555\n",
      "Iteration 2358, the loss is 4.527380142836433, parameters k is 11.514865367589408 and b is -49.68172332016219\n",
      "Iteration 2359, the loss is 4.527379493254902, parameters k is 11.514848067194151 and b is -49.681691699608834\n",
      "Iteration 2360, the loss is 4.527379034499528, parameters k is 11.514830766798895 and b is -49.681660079055476\n",
      "Iteration 2361, the loss is 4.527378500730338, parameters k is 11.51486336363684 and b is -49.68162055336378\n",
      "Iteration 2362, the loss is 4.527377851148797, parameters k is 11.514846063241583 and b is -49.68158893281042\n",
      "Iteration 2363, the loss is 4.527377201567264, parameters k is 11.514828762846326 and b is -49.68155731225706\n",
      "Iteration 2364, the loss is 4.527376693253365, parameters k is 11.51481146245107 and b is -49.681525691703705\n",
      "Iteration 2365, the loss is 4.527376209042698, parameters k is 11.514844059289015 and b is -49.68148616601201\n",
      "Iteration 2366, the loss is 4.5273755594611576, parameters k is 11.514826758893758 and b is -49.68145454545865\n",
      "Iteration 2367, the loss is 4.527374909879624, parameters k is 11.514809458498501 and b is -49.68142292490529\n",
      "Iteration 2368, the loss is 4.527374352007197, parameters k is 11.514792158103244 and b is -49.68139130435193\n",
      "Iteration 2369, the loss is 4.527373917355062, parameters k is 11.51482475494119 and b is -49.681351778660236\n",
      "Iteration 2370, the loss is 4.527373267773523, parameters k is 11.514807454545933 and b is -49.68132015810688\n",
      "Iteration 2371, the loss is 4.52737261819199, parameters k is 11.514790154150676 and b is -49.68128853755352\n",
      "Iteration 2372, the loss is 4.527372010761027, parameters k is 11.514772853755419 and b is -49.68125691700016\n",
      "Iteration 2373, the loss is 4.5273716256674215, parameters k is 11.514805450593364 and b is -49.681217391308465\n",
      "Iteration 2374, the loss is 4.527370976085886, parameters k is 11.514788150198108 and b is -49.68118577075511\n",
      "Iteration 2375, the loss is 4.527370326504353, parameters k is 11.51477084980285 and b is -49.68115415020175\n",
      "Iteration 2376, the loss is 4.527369676922811, parameters k is 11.514753549407594 and b is -49.68112252964839\n",
      "Iteration 2377, the loss is 4.527369326571825, parameters k is 11.514736249012337 and b is -49.68109090909503\n",
      "Iteration 2378, the loss is 4.527368684398247, parameters k is 11.514768845850282 and b is -49.681051383403336\n",
      "Iteration 2379, the loss is 4.527368034816713, parameters k is 11.514751545455026 and b is -49.68101976284998\n",
      "Iteration 2380, the loss is 4.5273673852351735, parameters k is 11.514734245059769 and b is -49.68098814229662\n",
      "Iteration 2381, the loss is 4.527366985325657, parameters k is 11.514716944664512 and b is -49.68095652174326\n",
      "Iteration 2382, the loss is 4.527366392710613, parameters k is 11.514749541502457 and b is -49.680916996051565\n",
      "Iteration 2383, the loss is 4.527365743129082, parameters k is 11.5147322411072 and b is -49.68088537549821\n",
      "Iteration 2384, the loss is 4.527365093547538, parameters k is 11.514714940711944 and b is -49.68085375494485\n",
      "Iteration 2385, the loss is 4.527364644079499, parameters k is 11.514697640316687 and b is -49.68082213439149\n",
      "Iteration 2386, the loss is 4.527364101022974, parameters k is 11.514730237154632 and b is -49.68078260869979\n",
      "Iteration 2387, the loss is 4.527363451441438, parameters k is 11.514712936759375 and b is -49.680750988146436\n",
      "Iteration 2388, the loss is 4.52736280185991, parameters k is 11.514695636364118 and b is -49.68071936759308\n",
      "Iteration 2389, the loss is 4.527362302833321, parameters k is 11.514678335968862 and b is -49.68068774703972\n",
      "Iteration 2390, the loss is 4.5273618093353365, parameters k is 11.514710932806807 and b is -49.68064822134802\n",
      "Iteration 2391, the loss is 4.527361159753797, parameters k is 11.51469363241155 and b is -49.680616600794664\n",
      "Iteration 2392, the loss is 4.527360510172261, parameters k is 11.514676332016293 and b is -49.680584980241306\n",
      "Iteration 2393, the loss is 4.527359961587151, parameters k is 11.514659031621036 and b is -49.68055335968795\n",
      "Iteration 2394, the loss is 4.527359517647697, parameters k is 11.514691628458982 and b is -49.68051383399625\n",
      "Iteration 2395, the loss is 4.527358868066162, parameters k is 11.514674328063725 and b is -49.68048221344289\n",
      "Iteration 2396, the loss is 4.527358218484628, parameters k is 11.514657027668468 and b is -49.680450592889535\n",
      "Iteration 2397, the loss is 4.527357620340986, parameters k is 11.514639727273211 and b is -49.68041897233618\n",
      "Iteration 2398, the loss is 4.527357225960061, parameters k is 11.514672324111157 and b is -49.68037944664448\n",
      "Iteration 2399, the loss is 4.527356576378523, parameters k is 11.5146550237159 and b is -49.68034782609112\n",
      "Iteration 2400, the loss is 4.527355926796992, parameters k is 11.514637723320643 and b is -49.680316205537764\n",
      "Iteration 2401, the loss is 4.527355279094819, parameters k is 11.514620422925386 and b is -49.680284584984406\n",
      "Iteration 2402, the loss is 4.527354934272426, parameters k is 11.514653019763331 and b is -49.68024505929271\n",
      "Iteration 2403, the loss is 4.527354284690888, parameters k is 11.514635719368075 and b is -49.68021343873935\n",
      "Iteration 2404, the loss is 4.527353635109353, parameters k is 11.514618418972818 and b is -49.68018181818599\n",
      "Iteration 2405, the loss is 4.527352985527816, parameters k is 11.514601118577561 and b is -49.680150197632635\n",
      "Iteration 2406, the loss is 4.527352594905618, parameters k is 11.514583818182304 and b is -49.68011857707928\n",
      "Iteration 2407, the loss is 4.527351993003249, parameters k is 11.51461641502025 and b is -49.68007905138758\n",
      "Iteration 2408, the loss is 4.5273513434217145, parameters k is 11.514599114624993 and b is -49.68004743083422\n",
      "Iteration 2409, the loss is 4.527350693840176, parameters k is 11.514581814229736 and b is -49.680015810280864\n",
      "Iteration 2410, the loss is 4.527350253659449, parameters k is 11.514564513834479 and b is -49.679984189727506\n",
      "Iteration 2411, the loss is 4.527349701315613, parameters k is 11.514597110672424 and b is -49.67994466403581\n",
      "Iteration 2412, the loss is 4.527349051734076, parameters k is 11.514579810277167 and b is -49.67991304348245\n",
      "Iteration 2413, the loss is 4.527348402152538, parameters k is 11.51456250988191 and b is -49.67988142292909\n",
      "Iteration 2414, the loss is 4.527347912413284, parameters k is 11.514545209486654 and b is -49.679849802375735\n",
      "Iteration 2415, the loss is 4.527347409627976, parameters k is 11.5145778063246 and b is -49.67981027668404\n",
      "Iteration 2416, the loss is 4.527346760046436, parameters k is 11.514560505929342 and b is -49.67977865613068\n",
      "Iteration 2417, the loss is 4.5273461104649035, parameters k is 11.514543205534086 and b is -49.67974703557732\n",
      "Iteration 2418, the loss is 4.527345571167118, parameters k is 11.514525905138829 and b is -49.67971541502396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2419, the loss is 4.527345117940335, parameters k is 11.514558501976774 and b is -49.679675889332266\n",
      "Iteration 2420, the loss is 4.527344468358803, parameters k is 11.514541201581517 and b is -49.67964426877891\n",
      "Iteration 2421, the loss is 4.527343818777264, parameters k is 11.51452390118626 and b is -49.67961264822555\n",
      "Iteration 2422, the loss is 4.527343229920944, parameters k is 11.514506600791004 and b is -49.67958102767219\n",
      "Iteration 2423, the loss is 4.527342826252701, parameters k is 11.514539197628949 and b is -49.679541501980495\n",
      "Iteration 2424, the loss is 4.527342176671163, parameters k is 11.514521897233692 and b is -49.67950988142714\n",
      "Iteration 2425, the loss is 4.527341527089632, parameters k is 11.514504596838435 and b is -49.67947826087378\n",
      "Iteration 2426, the loss is 4.52734088867478, parameters k is 11.514487296443178 and b is -49.67944664032042\n",
      "Iteration 2427, the loss is 4.527340534565064, parameters k is 11.514519893281124 and b is -49.679407114628724\n",
      "Iteration 2428, the loss is 4.527339884983525, parameters k is 11.514502592885867 and b is -49.679375494075366\n",
      "Iteration 2429, the loss is 4.527339235401988, parameters k is 11.51448529249061 and b is -49.67934387352201\n",
      "Iteration 2430, the loss is 4.5273385858204565, parameters k is 11.514467992095353 and b is -49.67931225296865\n",
      "Iteration 2431, the loss is 4.527338204485573, parameters k is 11.514450691700096 and b is -49.67928063241529\n",
      "Iteration 2432, the loss is 4.527337593295888, parameters k is 11.514483288538042 and b is -49.679241106723595\n",
      "Iteration 2433, the loss is 4.527336943714354, parameters k is 11.514465988142785 and b is -49.67920948617024\n",
      "Iteration 2434, the loss is 4.527336294132816, parameters k is 11.514448687747528 and b is -49.67917786561688\n",
      "Iteration 2435, the loss is 4.527335863239408, parameters k is 11.514431387352271 and b is -49.67914624506352\n",
      "Iteration 2436, the loss is 4.527335301608252, parameters k is 11.514463984190217 and b is -49.67910671937182\n",
      "Iteration 2437, the loss is 4.527334652026717, parameters k is 11.51444668379496 and b is -49.679075098818466\n",
      "Iteration 2438, the loss is 4.52733400244518, parameters k is 11.514429383399703 and b is -49.67904347826511\n",
      "Iteration 2439, the loss is 4.527333521993241, parameters k is 11.514412083004446 and b is -49.67901185771175\n",
      "Iteration 2440, the loss is 4.527333009920612, parameters k is 11.514444679842391 and b is -49.67897233202005\n",
      "Iteration 2441, the loss is 4.527332360339078, parameters k is 11.514427379447135 and b is -49.678940711466694\n",
      "Iteration 2442, the loss is 4.527331710757548, parameters k is 11.514410079051878 and b is -49.678909090913336\n",
      "Iteration 2443, the loss is 4.527331180747076, parameters k is 11.514392778656621 and b is -49.67887747035998\n",
      "Iteration 2444, the loss is 4.527330718232975, parameters k is 11.514425375494566 and b is -49.67883794466828\n",
      "Iteration 2445, the loss is 4.527330068651437, parameters k is 11.51440807509931 and b is -49.67880632411492\n",
      "Iteration 2446, the loss is 4.527329419069901, parameters k is 11.514390774704053 and b is -49.678774703561565\n",
      "Iteration 2447, the loss is 4.527328839500901, parameters k is 11.514373474308796 and b is -49.67874308300821\n",
      "Iteration 2448, the loss is 4.527328426545337, parameters k is 11.514406071146741 and b is -49.67870355731651\n",
      "Iteration 2449, the loss is 4.52732777696381, parameters k is 11.514388770751484 and b is -49.67867193676315\n",
      "Iteration 2450, the loss is 4.527327127382268, parameters k is 11.514371470356227 and b is -49.678640316209794\n",
      "Iteration 2451, the loss is 4.52732649825474, parameters k is 11.51435416996097 and b is -49.678608695656436\n",
      "Iteration 2452, the loss is 4.527326134857702, parameters k is 11.514386766798916 and b is -49.67856916996474\n",
      "Iteration 2453, the loss is 4.527325485276162, parameters k is 11.514369466403659 and b is -49.67853754941138\n",
      "Iteration 2454, the loss is 4.52732483569463, parameters k is 11.514352166008402 and b is -49.67850592885802\n",
      "Iteration 2455, the loss is 4.5273241861130975, parameters k is 11.514334865613145 and b is -49.678474308304665\n",
      "Iteration 2456, the loss is 4.527323814065536, parameters k is 11.514317565217889 and b is -49.67844268775131\n",
      "Iteration 2457, the loss is 4.52732319358853, parameters k is 11.514350162055834 and b is -49.67840316205961\n",
      "Iteration 2458, the loss is 4.527322544006992, parameters k is 11.514332861660577 and b is -49.67837154150625\n",
      "Iteration 2459, the loss is 4.527321894425458, parameters k is 11.51431556126532 and b is -49.678339920952894\n",
      "Iteration 2460, the loss is 4.527321472819367, parameters k is 11.514298260870063 and b is -49.678308300399536\n",
      "Iteration 2461, the loss is 4.527320901900892, parameters k is 11.514330857708009 and b is -49.67826877470784\n",
      "Iteration 2462, the loss is 4.527320252319353, parameters k is 11.514313557312752 and b is -49.67823715415448\n",
      "Iteration 2463, the loss is 4.527319602737817, parameters k is 11.514296256917495 and b is -49.67820553360112\n",
      "Iteration 2464, the loss is 4.5273191315732, parameters k is 11.514278956522238 and b is -49.678173913047765\n",
      "Iteration 2465, the loss is 4.527318610213254, parameters k is 11.514311553360184 and b is -49.67813438735607\n",
      "Iteration 2466, the loss is 4.527317960631721, parameters k is 11.514294252964927 and b is -49.67810276680271\n",
      "Iteration 2467, the loss is 4.52731731105018, parameters k is 11.51427695256967 and b is -49.67807114624935\n",
      "Iteration 2468, the loss is 4.527316790327029, parameters k is 11.514259652174413 and b is -49.67803952569599\n",
      "Iteration 2469, the loss is 4.527316318525612, parameters k is 11.514292249012358 and b is -49.678000000004296\n",
      "Iteration 2470, the loss is 4.52731566894408, parameters k is 11.514274948617102 and b is -49.67796837945094\n",
      "Iteration 2471, the loss is 4.527315019362544, parameters k is 11.514257648221845 and b is -49.67793675889758\n",
      "Iteration 2472, the loss is 4.527314449080865, parameters k is 11.514240347826588 and b is -49.67790513834422\n",
      "Iteration 2473, the loss is 4.527314026837977, parameters k is 11.514272944664533 and b is -49.677865612652525\n",
      "Iteration 2474, the loss is 4.527313377256441, parameters k is 11.514255644269277 and b is -49.67783399209917\n",
      "Iteration 2475, the loss is 4.527312727674908, parameters k is 11.51423834387402 and b is -49.67780237154581\n",
      "Iteration 2476, the loss is 4.527312107834695, parameters k is 11.514221043478763 and b is -49.67777075099245\n",
      "Iteration 2477, the loss is 4.527311735150341, parameters k is 11.514253640316708 and b is -49.677731225300754\n",
      "Iteration 2478, the loss is 4.527311085568806, parameters k is 11.514236339921451 and b is -49.677699604747396\n",
      "Iteration 2479, the loss is 4.527310435987269, parameters k is 11.514219039526195 and b is -49.67766798419404\n",
      "Iteration 2480, the loss is 4.527309786405737, parameters k is 11.514201739130938 and b is -49.67763636364068\n",
      "Iteration 2481, the loss is 4.5273094236454945, parameters k is 11.51418443873568 and b is -49.67760474308732\n",
      "Iteration 2482, the loss is 4.527308793881168, parameters k is 11.514217035573626 and b is -49.677565217395625\n",
      "Iteration 2483, the loss is 4.527308144299633, parameters k is 11.51419973517837 and b is -49.67753359684227\n",
      "Iteration 2484, the loss is 4.5273074947180945, parameters k is 11.514182434783113 and b is -49.67750197628891\n",
      "Iteration 2485, the loss is 4.527307082399325, parameters k is 11.514165134387856 and b is -49.67747035573555\n",
      "Iteration 2486, the loss is 4.527306502193525, parameters k is 11.514197731225801 and b is -49.67743083004385\n",
      "Iteration 2487, the loss is 4.5273058526119945, parameters k is 11.514180430830544 and b is -49.677399209490495\n",
      "Iteration 2488, the loss is 4.527305203030463, parameters k is 11.514163130435287 and b is -49.67736758893714\n",
      "Iteration 2489, the loss is 4.527304741153163, parameters k is 11.51414583004003 and b is -49.67733596838378\n",
      "Iteration 2490, the loss is 4.527304210505891, parameters k is 11.514178426877976 and b is -49.67729644269208\n",
      "Iteration 2491, the loss is 4.527303560924355, parameters k is 11.514161126482719 and b is -49.677264822138724\n",
      "Iteration 2492, the loss is 4.5273029113428205, parameters k is 11.514143826087462 and b is -49.677233201585366\n",
      "Iteration 2493, the loss is 4.52730239990699, parameters k is 11.514126525692205 and b is -49.67720158103201\n",
      "Iteration 2494, the loss is 4.527301918818254, parameters k is 11.51415912253015 and b is -49.67716205534031\n",
      "Iteration 2495, the loss is 4.527301269236723, parameters k is 11.514141822134894 and b is -49.67713043478695\n",
      "Iteration 2496, the loss is 4.527300619655184, parameters k is 11.514124521739637 and b is -49.677098814233595\n",
      "Iteration 2497, the loss is 4.5273000586608205, parameters k is 11.51410722134438 and b is -49.67706719368024\n",
      "Iteration 2498, the loss is 4.527299627130615, parameters k is 11.514139818182326 and b is -49.67702766798854\n",
      "Iteration 2499, the loss is 4.52729897754908, parameters k is 11.514122517787069 and b is -49.67699604743518\n",
      "Iteration 2500, the loss is 4.527298327967546, parameters k is 11.514105217391812 and b is -49.676964426881824\n",
      "Iteration 2501, the loss is 4.527297717414654, parameters k is 11.514087916996555 and b is -49.676932806328466\n",
      "Iteration 2502, the loss is 4.52729733544298, parameters k is 11.5141205138345 and b is -49.67689328063677\n",
      "Iteration 2503, the loss is 4.527296685861449, parameters k is 11.514103213439244 and b is -49.67686166008341\n",
      "Iteration 2504, the loss is 4.527296036279906, parameters k is 11.514085913043987 and b is -49.67683003953005\n",
      "Iteration 2505, the loss is 4.527295386698373, parameters k is 11.51406861264873 and b is -49.676798418976695\n",
      "Iteration 2506, the loss is 4.527295033225454, parameters k is 11.514051312253473 and b is -49.67676679842334\n",
      "Iteration 2507, the loss is 4.527294394173809, parameters k is 11.514083909091418 and b is -49.67672727273164\n",
      "Iteration 2508, the loss is 4.527293744592274, parameters k is 11.514066608696162 and b is -49.67669565217828\n",
      "Iteration 2509, the loss is 4.5272930950107355, parameters k is 11.514049308300905 and b is -49.676664031624924\n",
      "Iteration 2510, the loss is 4.527292691979283, parameters k is 11.514032007905648 and b is -49.676632411071566\n",
      "Iteration 2511, the loss is 4.527292102486174, parameters k is 11.514064604743593 and b is -49.67659288537987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2512, the loss is 4.527291452904631, parameters k is 11.514047304348336 and b is -49.67656126482651\n",
      "Iteration 2513, the loss is 4.527290803323102, parameters k is 11.51403000395308 and b is -49.67652964427315\n",
      "Iteration 2514, the loss is 4.527290350733115, parameters k is 11.514012703557823 and b is -49.676498023719795\n",
      "Iteration 2515, the loss is 4.527289810798528, parameters k is 11.514045300395768 and b is -49.6764584980281\n",
      "Iteration 2516, the loss is 4.527289161216996, parameters k is 11.514028000000511 and b is -49.67642687747474\n",
      "Iteration 2517, the loss is 4.5272885116354615, parameters k is 11.514010699605254 and b is -49.67639525692138\n",
      "Iteration 2518, the loss is 4.527288009486945, parameters k is 11.513993399209998 and b is -49.67636363636802\n",
      "Iteration 2519, the loss is 4.527287519110893, parameters k is 11.514025996047943 and b is -49.676324110676326\n",
      "Iteration 2520, the loss is 4.527286869529361, parameters k is 11.514008695652686 and b is -49.67629249012297\n",
      "Iteration 2521, the loss is 4.527286219947821, parameters k is 11.51399139525743 and b is -49.67626086956961\n",
      "Iteration 2522, the loss is 4.527285668240776, parameters k is 11.513974094862172 and b is -49.67622924901625\n",
      "Iteration 2523, the loss is 4.52728522742326, parameters k is 11.514006691700118 and b is -49.676189723324555\n",
      "Iteration 2524, the loss is 4.527284577841716, parameters k is 11.513989391304861 and b is -49.6761581027712\n",
      "Iteration 2525, the loss is 4.527283928260189, parameters k is 11.513972090909604 and b is -49.67612648221784\n",
      "Iteration 2526, the loss is 4.527283326994609, parameters k is 11.513954790514347 and b is -49.67609486166448\n",
      "Iteration 2527, the loss is 4.527282935735618, parameters k is 11.513987387352293 and b is -49.676055335972784\n",
      "Iteration 2528, the loss is 4.527282286154083, parameters k is 11.513970086957036 and b is -49.676023715419426\n",
      "Iteration 2529, the loss is 4.527281636572548, parameters k is 11.513952786561779 and b is -49.67599209486607\n",
      "Iteration 2530, the loss is 4.527280986991011, parameters k is 11.513935486166522 and b is -49.67596047431271\n",
      "Iteration 2531, the loss is 4.52728064280541, parameters k is 11.513918185771265 and b is -49.67592885375935\n",
      "Iteration 2532, the loss is 4.527279994466444, parameters k is 11.51395078260921 and b is -49.675889328067655\n",
      "Iteration 2533, the loss is 4.527279344884908, parameters k is 11.513933482213954 and b is -49.6758577075143\n",
      "Iteration 2534, the loss is 4.527278695303375, parameters k is 11.513916181818697 and b is -49.67582608696094\n",
      "Iteration 2535, the loss is 4.527278301559241, parameters k is 11.51389888142344 and b is -49.67579446640758\n",
      "Iteration 2536, the loss is 4.527277702778808, parameters k is 11.513931478261386 and b is -49.67575494071588\n",
      "Iteration 2537, the loss is 4.527277053197274, parameters k is 11.513914177866129 and b is -49.675723320162525\n",
      "Iteration 2538, the loss is 4.527276403615734, parameters k is 11.513896877470872 and b is -49.67569169960917\n",
      "Iteration 2539, the loss is 4.527275960313073, parameters k is 11.513879577075615 and b is -49.67566007905581\n",
      "Iteration 2540, the loss is 4.52727541109117, parameters k is 11.51391217391356 and b is -49.67562055336411\n",
      "Iteration 2541, the loss is 4.527274761509636, parameters k is 11.513894873518304 and b is -49.675588932810754\n",
      "Iteration 2542, the loss is 4.5272741119281, parameters k is 11.513877573123047 and b is -49.675557312257396\n",
      "Iteration 2543, the loss is 4.527273619066907, parameters k is 11.51386027272779 and b is -49.67552569170404\n",
      "Iteration 2544, the loss is 4.527273119403534, parameters k is 11.513892869565735 and b is -49.67548616601234\n",
      "Iteration 2545, the loss is 4.527272469821998, parameters k is 11.513875569170478 and b is -49.67545454545898\n",
      "Iteration 2546, the loss is 4.527271820240462, parameters k is 11.513858268775222 and b is -49.675422924905625\n",
      "Iteration 2547, the loss is 4.527271277820737, parameters k is 11.513840968379965 and b is -49.67539130435227\n",
      "Iteration 2548, the loss is 4.527270827715896, parameters k is 11.51387356521791 and b is -49.67535177866057\n",
      "Iteration 2549, the loss is 4.52727017813436, parameters k is 11.513856264822653 and b is -49.67532015810721\n",
      "Iteration 2550, the loss is 4.5272695285528295, parameters k is 11.513838964427396 and b is -49.675288537553854\n",
      "Iteration 2551, the loss is 4.527268936574567, parameters k is 11.51382166403214 and b is -49.675256917000496\n",
      "Iteration 2552, the loss is 4.527268536028258, parameters k is 11.513854260870085 and b is -49.6752173913088\n",
      "Iteration 2553, the loss is 4.527267886446726, parameters k is 11.513836960474828 and b is -49.67518577075544\n",
      "Iteration 2554, the loss is 4.527267236865185, parameters k is 11.513819660079571 and b is -49.67515415020208\n",
      "Iteration 2555, the loss is 4.5272665953284035, parameters k is 11.513802359684314 and b is -49.675122529648725\n",
      "Iteration 2556, the loss is 4.527266244340621, parameters k is 11.51383495652226 and b is -49.67508300395703\n",
      "Iteration 2557, the loss is 4.527265594759087, parameters k is 11.513817656127003 and b is -49.67505138340367\n",
      "Iteration 2558, the loss is 4.527264945177549, parameters k is 11.513800355731746 and b is -49.67501976285031\n",
      "Iteration 2559, the loss is 4.527264295596009, parameters k is 11.51378305533649 and b is -49.674988142296954\n",
      "Iteration 2560, the loss is 4.527263911139195, parameters k is 11.513765754941232 and b is -49.674956521743596\n",
      "Iteration 2561, the loss is 4.527263303071451, parameters k is 11.513798351779178 and b is -49.6749169960519\n",
      "Iteration 2562, the loss is 4.527262653489914, parameters k is 11.513781051383921 and b is -49.67488537549854\n",
      "Iteration 2563, the loss is 4.527262003908376, parameters k is 11.513763750988664 and b is -49.67485375494518\n",
      "Iteration 2564, the loss is 4.527261569893031, parameters k is 11.513746450593407 and b is -49.674822134391825\n",
      "Iteration 2565, the loss is 4.527261011383806, parameters k is 11.513779047431353 and b is -49.67478260870013\n",
      "Iteration 2566, the loss is 4.527260361802277, parameters k is 11.513761747036096 and b is -49.67475098814677\n",
      "Iteration 2567, the loss is 4.527259712220737, parameters k is 11.513744446640839 and b is -49.67471936759341\n",
      "Iteration 2568, the loss is 4.5272592286468605, parameters k is 11.513727146245582 and b is -49.67468774704005\n",
      "Iteration 2569, the loss is 4.527258719696176, parameters k is 11.513759743083527 and b is -49.674648221348356\n",
      "Iteration 2570, the loss is 4.527258070114638, parameters k is 11.51374244268827 and b is -49.674616600795\n",
      "Iteration 2571, the loss is 4.527257420533099, parameters k is 11.513725142293014 and b is -49.67458498024164\n",
      "Iteration 2572, the loss is 4.527256887400699, parameters k is 11.513707841897757 and b is -49.67455335968828\n",
      "Iteration 2573, the loss is 4.527256428008531, parameters k is 11.513740438735702 and b is -49.674513833996585\n",
      "Iteration 2574, the loss is 4.527255778427, parameters k is 11.513723138340445 and b is -49.67448221344323\n",
      "Iteration 2575, the loss is 4.527255128845466, parameters k is 11.513705837945189 and b is -49.67445059288987\n",
      "Iteration 2576, the loss is 4.527254546154528, parameters k is 11.513688537549932 and b is -49.67441897233651\n",
      "Iteration 2577, the loss is 4.527254136320896, parameters k is 11.513721134387877 and b is -49.674379446644814\n",
      "Iteration 2578, the loss is 4.527253486739359, parameters k is 11.51370383399262 and b is -49.674347826091456\n",
      "Iteration 2579, the loss is 4.527252837157826, parameters k is 11.513686533597363 and b is -49.6743162055381\n",
      "Iteration 2580, the loss is 4.527252204908366, parameters k is 11.513669233202107 and b is -49.67428458498474\n",
      "Iteration 2581, the loss is 4.52725184463326, parameters k is 11.513701830040052 and b is -49.67424505929304\n",
      "Iteration 2582, the loss is 4.527251195051725, parameters k is 11.513684529644795 and b is -49.674213438739685\n",
      "Iteration 2583, the loss is 4.527250545470192, parameters k is 11.513667229249538 and b is -49.67418181818633\n",
      "Iteration 2584, the loss is 4.527249895888657, parameters k is 11.513649928854282 and b is -49.67415019763297\n",
      "Iteration 2585, the loss is 4.527249520719159, parameters k is 11.513632628459025 and b is -49.67411857707961\n",
      "Iteration 2586, the loss is 4.5272489033640895, parameters k is 11.51366522529697 and b is -49.67407905138791\n",
      "Iteration 2587, the loss is 4.527248253782551, parameters k is 11.513647924901713 and b is -49.674047430834555\n",
      "Iteration 2588, the loss is 4.527247604201017, parameters k is 11.513630624506456 and b is -49.6740158102812\n",
      "Iteration 2589, the loss is 4.527247179472995, parameters k is 11.5136133241112 and b is -49.67398418972784\n",
      "Iteration 2590, the loss is 4.527246611676445, parameters k is 11.513645920949145 and b is -49.67394466403614\n",
      "Iteration 2591, the loss is 4.527245962094914, parameters k is 11.513628620553888 and b is -49.673913043482784\n",
      "Iteration 2592, the loss is 4.527245312513381, parameters k is 11.513611320158631 and b is -49.673881422929426\n",
      "Iteration 2593, the loss is 4.527244838226819, parameters k is 11.513594019763374 and b is -49.67384980237607\n",
      "Iteration 2594, the loss is 4.52724431998881, parameters k is 11.51362661660132 and b is -49.67381027668437\n",
      "Iteration 2595, the loss is 4.527243670407275, parameters k is 11.513609316206063 and b is -49.67377865613101\n",
      "Iteration 2596, the loss is 4.527243020825739, parameters k is 11.513592015810806 and b is -49.673747035577655\n",
      "Iteration 2597, the loss is 4.52724249698065, parameters k is 11.51357471541555 and b is -49.6737154150243\n",
      "Iteration 2598, the loss is 4.5272420283011785, parameters k is 11.513607312253495 and b is -49.6736758893326\n",
      "Iteration 2599, the loss is 4.527241378719639, parameters k is 11.513590011858238 and b is -49.67364426877924\n",
      "Iteration 2600, the loss is 4.527240729138109, parameters k is 11.513572711462981 and b is -49.673612648225884\n",
      "Iteration 2601, the loss is 4.527240155734487, parameters k is 11.513555411067724 and b is -49.673581027672526\n",
      "Iteration 2602, the loss is 4.527239736613539, parameters k is 11.51358800790567 and b is -49.67354150198083\n",
      "Iteration 2603, the loss is 4.527239087032002, parameters k is 11.513570707510413 and b is -49.67350988142747\n",
      "Iteration 2604, the loss is 4.527238437450463, parameters k is 11.513553407115156 and b is -49.67347826087411\n",
      "Iteration 2605, the loss is 4.5272378144883145, parameters k is 11.513536106719899 and b is -49.673446640320755\n",
      "Iteration 2606, the loss is 4.527237444925897, parameters k is 11.513568703557844 and b is -49.67340711462906\n",
      "Iteration 2607, the loss is 4.527236795344365, parameters k is 11.513551403162587 and b is -49.6733754940757\n",
      "Iteration 2608, the loss is 4.52723614576283, parameters k is 11.51353410276733 and b is -49.67334387352234\n",
      "Iteration 2609, the loss is 4.527235496181292, parameters k is 11.513516802372074 and b is -49.673312252968984\n",
      "Iteration 2610, the loss is 4.527235130299114, parameters k is 11.513499501976817 and b is -49.673280632415626\n",
      "Iteration 2611, the loss is 4.527234503656727, parameters k is 11.513532098814762 and b is -49.67324110672393\n",
      "Iteration 2612, the loss is 4.527233854075187, parameters k is 11.513514798419505 and b is -49.67320948617057\n",
      "Iteration 2613, the loss is 4.527233204493651, parameters k is 11.513497498024249 and b is -49.67317786561721\n",
      "Iteration 2614, the loss is 4.52723278905295, parameters k is 11.513480197628992 and b is -49.673146245063855\n",
      "Iteration 2615, the loss is 4.527232211969092, parameters k is 11.513512794466937 and b is -49.67310671937216\n",
      "Iteration 2616, the loss is 4.5272315623875565, parameters k is 11.51349549407168 and b is -49.6730750988188\n",
      "Iteration 2617, the loss is 4.527230912806015, parameters k is 11.513478193676423 and b is -49.67304347826544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2618, the loss is 4.527230447806783, parameters k is 11.513460893281167 and b is -49.67301185771208\n",
      "Iteration 2619, the loss is 4.527229920281453, parameters k is 11.513493490119112 and b is -49.672972332020386\n",
      "Iteration 2620, the loss is 4.527229270699918, parameters k is 11.513476189723855 and b is -49.67294071146703\n",
      "Iteration 2621, the loss is 4.527228621118384, parameters k is 11.513458889328598 and b is -49.67290909091367\n",
      "Iteration 2622, the loss is 4.5272281065606155, parameters k is 11.513441588933341 and b is -49.67287747036031\n",
      "Iteration 2623, the loss is 4.527227628593814, parameters k is 11.513474185771287 and b is -49.672837944668615\n",
      "Iteration 2624, the loss is 4.5272269790122825, parameters k is 11.51345688537603 and b is -49.67280632411526\n",
      "Iteration 2625, the loss is 4.527226329430744, parameters k is 11.513439584980773 and b is -49.6727747035619\n",
      "Iteration 2626, the loss is 4.527225765314442, parameters k is 11.513422284585516 and b is -49.67274308300854\n",
      "Iteration 2627, the loss is 4.527225336906173, parameters k is 11.513454881423462 and b is -49.672703557316844\n",
      "Iteration 2628, the loss is 4.527224687324638, parameters k is 11.513437581028205 and b is -49.672671936763486\n",
      "Iteration 2629, the loss is 4.5272240377431086, parameters k is 11.513420280632948 and b is -49.67264031621013\n",
      "Iteration 2630, the loss is 4.527223424068274, parameters k is 11.513402980237691 and b is -49.67260869565677\n",
      "Iteration 2631, the loss is 4.52722304521854, parameters k is 11.513435577075636 and b is -49.67256916996507\n",
      "Iteration 2632, the loss is 4.527222395637002, parameters k is 11.51341827668038 and b is -49.672537549411715\n",
      "Iteration 2633, the loss is 4.527221746055466, parameters k is 11.513400976285123 and b is -49.67250592885836\n",
      "Iteration 2634, the loss is 4.527221096473931, parameters k is 11.513383675889866 and b is -49.672474308305\n",
      "Iteration 2635, the loss is 4.527220739879076, parameters k is 11.51336637549461 and b is -49.67244268775164\n",
      "Iteration 2636, the loss is 4.527220103949366, parameters k is 11.513398972332554 and b is -49.67240316205994\n",
      "Iteration 2637, the loss is 4.527219454367835, parameters k is 11.513381671937298 and b is -49.672371541506585\n",
      "Iteration 2638, the loss is 4.527218804786298, parameters k is 11.51336437154204 and b is -49.67233992095323\n",
      "Iteration 2639, the loss is 4.52721839863291, parameters k is 11.513347071146784 and b is -49.67230830039987\n",
      "Iteration 2640, the loss is 4.527217812261729, parameters k is 11.51337966798473 and b is -49.67226877470817\n",
      "Iteration 2641, the loss is 4.52721716268019, parameters k is 11.513362367589473 and b is -49.672237154154814\n",
      "Iteration 2642, the loss is 4.52721651309865, parameters k is 11.513345067194216 and b is -49.672205533601456\n",
      "Iteration 2643, the loss is 4.52721605738674, parameters k is 11.513327766798959 and b is -49.6721739130481\n",
      "Iteration 2644, the loss is 4.527215520574091, parameters k is 11.513360363636904 and b is -49.6721343873564\n",
      "Iteration 2645, the loss is 4.527214870992553, parameters k is 11.513343063241647 and b is -49.67210276680304\n",
      "Iteration 2646, the loss is 4.527214221411024, parameters k is 11.51332576284639 and b is -49.672071146249685\n",
      "Iteration 2647, the loss is 4.52721371614057, parameters k is 11.513308462451134 and b is -49.67203952569633\n",
      "Iteration 2648, the loss is 4.527213228886454, parameters k is 11.513341059289079 and b is -49.67200000000463\n",
      "Iteration 2649, the loss is 4.527212579304915, parameters k is 11.513323758893822 and b is -49.67196837945127\n",
      "Iteration 2650, the loss is 4.527211929723383, parameters k is 11.513306458498565 and b is -49.671936758897914\n",
      "Iteration 2651, the loss is 4.527211374894403, parameters k is 11.513289158103309 and b is -49.671905138344556\n",
      "Iteration 2652, the loss is 4.527210937198816, parameters k is 11.513321754941254 and b is -49.67186561265286\n",
      "Iteration 2653, the loss is 4.527210287617281, parameters k is 11.513304454545997 and b is -49.6718339920995\n",
      "Iteration 2654, the loss is 4.527209638035748, parameters k is 11.51328715415074 and b is -49.67180237154614\n",
      "Iteration 2655, the loss is 4.527209033648234, parameters k is 11.513269853755483 and b is -49.671770750992785\n",
      "Iteration 2656, the loss is 4.52720864551118, parameters k is 11.513302450593429 and b is -49.67173122530109\n",
      "Iteration 2657, the loss is 4.527207995929641, parameters k is 11.513285150198172 and b is -49.67169960474773\n",
      "Iteration 2658, the loss is 4.527207346348107, parameters k is 11.513267849802915 and b is -49.67166798419437\n",
      "Iteration 2659, the loss is 4.52720669676657, parameters k is 11.513250549407658 and b is -49.671636363641014\n",
      "Iteration 2660, the loss is 4.527206349459035, parameters k is 11.513233249012401 and b is -49.671604743087656\n",
      "Iteration 2661, the loss is 4.527205704242005, parameters k is 11.513265845850347 and b is -49.67156521739596\n",
      "Iteration 2662, the loss is 4.527205054660473, parameters k is 11.51324854545509 and b is -49.6715335968426\n",
      "Iteration 2663, the loss is 4.527204405078936, parameters k is 11.513231245059833 and b is -49.67150197628924\n",
      "Iteration 2664, the loss is 4.527204008212868, parameters k is 11.513213944664576 and b is -49.671470355735885\n",
      "Iteration 2665, the loss is 4.527203412554367, parameters k is 11.513246541502522 and b is -49.67143083004419\n",
      "Iteration 2666, the loss is 4.527202762972832, parameters k is 11.513229241107265 and b is -49.67139920949083\n",
      "Iteration 2667, the loss is 4.527202113391295, parameters k is 11.513211940712008 and b is -49.67136758893747\n",
      "Iteration 2668, the loss is 4.5272016669666995, parameters k is 11.513194640316751 and b is -49.67133596838411\n",
      "Iteration 2669, the loss is 4.527201120866731, parameters k is 11.513227237154696 and b is -49.671296442692416\n",
      "Iteration 2670, the loss is 4.527200471285199, parameters k is 11.51320993675944 and b is -49.67126482213906\n",
      "Iteration 2671, the loss is 4.527199821703657, parameters k is 11.513192636364183 and b is -49.6712332015857\n",
      "Iteration 2672, the loss is 4.527199325720525, parameters k is 11.513175335968926 and b is -49.67120158103234\n",
      "Iteration 2673, the loss is 4.527198829179088, parameters k is 11.513207932806871 and b is -49.671162055340645\n",
      "Iteration 2674, the loss is 4.527198179597557, parameters k is 11.513190632411614 and b is -49.67113043478729\n",
      "Iteration 2675, the loss is 4.5271975300160205, parameters k is 11.513173332016358 and b is -49.67109881423393\n",
      "Iteration 2676, the loss is 4.527196984474361, parameters k is 11.5131560316211 and b is -49.67106719368057\n",
      "Iteration 2677, the loss is 4.527196537491455, parameters k is 11.513188628459046 and b is -49.671027667988874\n",
      "Iteration 2678, the loss is 4.527195887909918, parameters k is 11.51317132806379 and b is -49.670996047435516\n",
      "Iteration 2679, the loss is 4.527195238328382, parameters k is 11.513154027668532 and b is -49.67096442688216\n",
      "Iteration 2680, the loss is 4.527194643228188, parameters k is 11.513136727273276 and b is -49.6709328063288\n",
      "Iteration 2681, the loss is 4.527194245803818, parameters k is 11.513169324111221 and b is -49.6708932806371\n",
      "Iteration 2682, the loss is 4.527193596222283, parameters k is 11.513152023715964 and b is -49.670861660083744\n",
      "Iteration 2683, the loss is 4.527192946640747, parameters k is 11.513134723320707 and b is -49.67083003953039\n",
      "Iteration 2684, the loss is 4.527192301982023, parameters k is 11.51311742292545 and b is -49.67079841897703\n",
      "Iteration 2685, the loss is 4.527191954116178, parameters k is 11.513150019763396 and b is -49.67075889328533\n",
      "Iteration 2686, the loss is 4.527191304534642, parameters k is 11.513132719368139 and b is -49.67072727273197\n",
      "Iteration 2687, the loss is 4.5271906549531105, parameters k is 11.513115418972882 and b is -49.670695652178615\n",
      "Iteration 2688, the loss is 4.527190005371572, parameters k is 11.513098118577625 and b is -49.67066403162526\n",
      "Iteration 2689, the loss is 4.527189617792824, parameters k is 11.513080818182369 and b is -49.6706324110719\n",
      "Iteration 2690, the loss is 4.527189012847009, parameters k is 11.513113415020314 and b is -49.6705928853802\n",
      "Iteration 2691, the loss is 4.527188363265474, parameters k is 11.513096114625057 and b is -49.670561264826844\n",
      "Iteration 2692, the loss is 4.52718771368394, parameters k is 11.5130788142298 and b is -49.670529644273486\n",
      "Iteration 2693, the loss is 4.52718727654666, parameters k is 11.513061513834543 and b is -49.67049802372013\n",
      "Iteration 2694, the loss is 4.527186721159369, parameters k is 11.513094110672489 and b is -49.67045849802843\n",
      "Iteration 2695, the loss is 4.527186071577834, parameters k is 11.513076810277232 and b is -49.67042687747507\n",
      "Iteration 2696, the loss is 4.527185421996295, parameters k is 11.513059509881975 and b is -49.670395256921715\n",
      "Iteration 2697, the loss is 4.527184935300487, parameters k is 11.513042209486718 and b is -49.67036363636836\n",
      "Iteration 2698, the loss is 4.527184429471734, parameters k is 11.513074806324664 and b is -49.67032411067666\n",
      "Iteration 2699, the loss is 4.527183779890199, parameters k is 11.513057505929407 and b is -49.6702924901233\n",
      "Iteration 2700, the loss is 4.5271831303086625, parameters k is 11.51304020553415 and b is -49.670260869569944\n",
      "Iteration 2701, the loss is 4.527182594054318, parameters k is 11.513022905138893 and b is -49.670229249016586\n",
      "Iteration 2702, the loss is 4.527182137784095, parameters k is 11.513055501976838 and b is -49.67018972332489\n",
      "Iteration 2703, the loss is 4.527181488202559, parameters k is 11.513038201581582 and b is -49.67015810277153\n",
      "Iteration 2704, the loss is 4.527180838621023, parameters k is 11.513020901186325 and b is -49.67012648221817\n",
      "Iteration 2705, the loss is 4.527180252808151, parameters k is 11.513003600791068 and b is -49.670094861664815\n",
      "Iteration 2706, the loss is 4.52717984609646, parameters k is 11.513036197629013 and b is -49.67005533597312\n",
      "Iteration 2707, the loss is 4.527179196514921, parameters k is 11.513018897233756 and b is -49.67002371541976\n",
      "Iteration 2708, the loss is 4.527178546933388, parameters k is 11.5130015968385 and b is -49.6699920948664\n",
      "Iteration 2709, the loss is 4.527177911561984, parameters k is 11.512984296443243 and b is -49.669960474313044\n",
      "Iteration 2710, the loss is 4.527177554408817, parameters k is 11.513016893281188 and b is -49.669920948621346\n",
      "Iteration 2711, the loss is 4.527176904827286, parameters k is 11.512999592885931 and b is -49.66988932806799\n",
      "Iteration 2712, the loss is 4.52717625524575, parameters k is 11.512982292490674 and b is -49.66985770751463\n",
      "Iteration 2713, the loss is 4.527175605664213, parameters k is 11.512964992095418 and b is -49.66982608696127\n",
      "Iteration 2714, the loss is 4.527175227372783, parameters k is 11.51294769170016 and b is -49.669794466407915\n",
      "Iteration 2715, the loss is 4.527174613139646, parameters k is 11.512980288538106 and b is -49.66975494071622\n",
      "Iteration 2716, the loss is 4.527173963558109, parameters k is 11.51296298814285 and b is -49.66972332016286\n",
      "Iteration 2717, the loss is 4.527173313976574, parameters k is 11.512945687747592 and b is -49.6696916996095\n",
      "Iteration 2718, the loss is 4.527172886126614, parameters k is 11.512928387352336 and b is -49.66966007905614\n",
      "Iteration 2719, the loss is 4.527172321452006, parameters k is 11.512960984190281 and b is -49.669620553364446\n",
      "Iteration 2720, the loss is 4.527171671870471, parameters k is 11.512943683795024 and b is -49.66958893281109\n",
      "Iteration 2721, the loss is 4.52717102228894, parameters k is 11.512926383399767 and b is -49.66955731225773\n",
      "Iteration 2722, the loss is 4.5271705448804465, parameters k is 11.51290908300451 and b is -49.66952569170437\n",
      "Iteration 2723, the loss is 4.52717002976437, parameters k is 11.512941679842456 and b is -49.669486166012675\n",
      "Iteration 2724, the loss is 4.527169380182839, parameters k is 11.512924379447199 and b is -49.66945454545932\n",
      "Iteration 2725, the loss is 4.527168730601303, parameters k is 11.512907079051942 and b is -49.66942292490596\n",
      "Iteration 2726, the loss is 4.527168203634277, parameters k is 11.512889778656685 and b is -49.6693913043526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2727, the loss is 4.5271677380767334, parameters k is 11.51292237549463 and b is -49.669351778660904\n",
      "Iteration 2728, the loss is 4.527167088495196, parameters k is 11.512905075099374 and b is -49.669320158107546\n",
      "Iteration 2729, the loss is 4.527166438913666, parameters k is 11.512887774704117 and b is -49.66928853755419\n",
      "Iteration 2730, the loss is 4.527165862388109, parameters k is 11.51287047430886 and b is -49.66925691700083\n",
      "Iteration 2731, the loss is 4.5271654463890965, parameters k is 11.512903071146805 and b is -49.66921739130913\n",
      "Iteration 2732, the loss is 4.527164796807561, parameters k is 11.512885770751549 and b is -49.669185770755774\n",
      "Iteration 2733, the loss is 4.527164147226024, parameters k is 11.512868470356292 and b is -49.66915415020242\n",
      "Iteration 2734, the loss is 4.527163521141939, parameters k is 11.512851169961035 and b is -49.66912252964906\n",
      "Iteration 2735, the loss is 4.5271631547014595, parameters k is 11.51288376679898 and b is -49.66908300395736\n",
      "Iteration 2736, the loss is 4.527162505119925, parameters k is 11.512866466403723 and b is -49.669051383404\n",
      "Iteration 2737, the loss is 4.527161855538386, parameters k is 11.512849166008467 and b is -49.669019762850645\n",
      "Iteration 2738, the loss is 4.527161205956855, parameters k is 11.51283186561321 and b is -49.66898814229729\n",
      "Iteration 2739, the loss is 4.527160836952739, parameters k is 11.512814565217953 and b is -49.66895652174393\n",
      "Iteration 2740, the loss is 4.527160213432283, parameters k is 11.512847162055898 and b is -49.66891699605223\n",
      "Iteration 2741, the loss is 4.527159563850748, parameters k is 11.512829861660641 and b is -49.668885375498874\n",
      "Iteration 2742, the loss is 4.527158914269215, parameters k is 11.512812561265385 and b is -49.668853754945516\n",
      "Iteration 2743, the loss is 4.527158495706572, parameters k is 11.512795260870128 and b is -49.66882213439216\n",
      "Iteration 2744, the loss is 4.52715792174465, parameters k is 11.512827857708073 and b is -49.66878260870046\n",
      "Iteration 2745, the loss is 4.5271572721631115, parameters k is 11.512810557312816 and b is -49.6687509881471\n",
      "Iteration 2746, the loss is 4.5271566225815745, parameters k is 11.51279325691756 and b is -49.668719367593745\n",
      "Iteration 2747, the loss is 4.527156154460401, parameters k is 11.512775956522303 and b is -49.66868774704039\n",
      "Iteration 2748, the loss is 4.527155630057006, parameters k is 11.512808553360248 and b is -49.66864822134869\n",
      "Iteration 2749, the loss is 4.527154980475473, parameters k is 11.512791252964991 and b is -49.66861660079533\n",
      "Iteration 2750, the loss is 4.527154330893944, parameters k is 11.512773952569734 and b is -49.668584980241974\n",
      "Iteration 2751, the loss is 4.527153813214237, parameters k is 11.512756652174478 and b is -49.668553359688616\n",
      "Iteration 2752, the loss is 4.527153338369367, parameters k is 11.512789249012423 and b is -49.66851383399692\n",
      "Iteration 2753, the loss is 4.527152688787836, parameters k is 11.512771948617166 and b is -49.66848221344356\n",
      "Iteration 2754, the loss is 4.527152039206306, parameters k is 11.51275464822191 and b is -49.6684505928902\n",
      "Iteration 2755, the loss is 4.527151471968069, parameters k is 11.512737347826652 and b is -49.668418972336845\n",
      "Iteration 2756, the loss is 4.5271510466817375, parameters k is 11.512769944664598 and b is -49.66837944664515\n",
      "Iteration 2757, the loss is 4.527150397100201, parameters k is 11.51275264426934 and b is -49.66834782609179\n",
      "Iteration 2758, the loss is 4.527149747518671, parameters k is 11.512735343874084 and b is -49.66831620553843\n",
      "Iteration 2759, the loss is 4.527149130721897, parameters k is 11.512718043478827 and b is -49.668284584985074\n",
      "Iteration 2760, the loss is 4.5271487549941, parameters k is 11.512750640316773 and b is -49.668245059293376\n",
      "Iteration 2761, the loss is 4.5271481054125635, parameters k is 11.512733339921516 and b is -49.66821343874002\n",
      "Iteration 2762, the loss is 4.527147455831026, parameters k is 11.512716039526259 and b is -49.66818181818666\n",
      "Iteration 2763, the loss is 4.527146806249494, parameters k is 11.512698739131002 and b is -49.6681501976333\n",
      "Iteration 2764, the loss is 4.527146446532703, parameters k is 11.512681438735745 and b is -49.668118577079944\n",
      "Iteration 2765, the loss is 4.527145813724925, parameters k is 11.51271403557369 and b is -49.66807905138825\n",
      "Iteration 2766, the loss is 4.527145164143389, parameters k is 11.512696735178434 and b is -49.66804743083489\n",
      "Iteration 2767, the loss is 4.527144514561854, parameters k is 11.512679434783177 and b is -49.66801581028153\n",
      "Iteration 2768, the loss is 4.527144105286532, parameters k is 11.51266213438792 and b is -49.66798418972817\n",
      "Iteration 2769, the loss is 4.527143522037284, parameters k is 11.512694731225865 and b is -49.667944664036476\n",
      "Iteration 2770, the loss is 4.52714287245575, parameters k is 11.512677430830609 and b is -49.66791304348312\n",
      "Iteration 2771, the loss is 4.527142222874217, parameters k is 11.512660130435352 and b is -49.66788142292976\n",
      "Iteration 2772, the loss is 4.527141764040361, parameters k is 11.512642830040095 and b is -49.6678498023764\n",
      "Iteration 2773, the loss is 4.527141230349649, parameters k is 11.51267542687804 and b is -49.667810276684705\n",
      "Iteration 2774, the loss is 4.527140580768111, parameters k is 11.512658126482783 and b is -49.66777865613135\n",
      "Iteration 2775, the loss is 4.52713993118658, parameters k is 11.512640826087527 and b is -49.66774703557799\n",
      "Iteration 2776, the loss is 4.527139422794194, parameters k is 11.51262352569227 and b is -49.66771541502463\n",
      "Iteration 2777, the loss is 4.527138938662014, parameters k is 11.512656122530215 and b is -49.66767588933293\n",
      "Iteration 2778, the loss is 4.527138289080478, parameters k is 11.512638822134958 and b is -49.667644268779576\n",
      "Iteration 2779, the loss is 4.527137639498941, parameters k is 11.512621521739701 and b is -49.66761264822622\n",
      "Iteration 2780, the loss is 4.527137081548026, parameters k is 11.512604221344445 and b is -49.66758102767286\n",
      "Iteration 2781, the loss is 4.527136646974379, parameters k is 11.51263681818239 and b is -49.66754150198116\n",
      "Iteration 2782, the loss is 4.5271359973928424, parameters k is 11.512619517787133 and b is -49.667509881427804\n",
      "Iteration 2783, the loss is 4.527135347811301, parameters k is 11.512602217391876 and b is -49.66747826087445\n",
      "Iteration 2784, the loss is 4.52713474030186, parameters k is 11.51258491699662 and b is -49.66744664032109\n",
      "Iteration 2785, the loss is 4.527134355286736, parameters k is 11.512617513834565 and b is -49.66740711462939\n",
      "Iteration 2786, the loss is 4.527133705705203, parameters k is 11.512600213439308 and b is -49.66737549407603\n",
      "Iteration 2787, the loss is 4.527133056123669, parameters k is 11.512582913044051 and b is -49.667343873522675\n",
      "Iteration 2788, the loss is 4.5271324065421314, parameters k is 11.512565612648794 and b is -49.66731225296932\n",
      "Iteration 2789, the loss is 4.527132056112654, parameters k is 11.512548312253537 and b is -49.66728063241596\n",
      "Iteration 2790, the loss is 4.5271314140175605, parameters k is 11.512580909091483 and b is -49.66724110672426\n",
      "Iteration 2791, the loss is 4.527130764436029, parameters k is 11.512563608696226 and b is -49.667209486170904\n",
      "Iteration 2792, the loss is 4.527130114854492, parameters k is 11.51254630830097 and b is -49.667177865617546\n",
      "Iteration 2793, the loss is 4.5271297148664855, parameters k is 11.512529007905712 and b is -49.66714624506419\n",
      "Iteration 2794, the loss is 4.527129122329923, parameters k is 11.512561604743658 and b is -49.66710671937249\n",
      "Iteration 2795, the loss is 4.527128472748392, parameters k is 11.5125443043484 and b is -49.66707509881913\n",
      "Iteration 2796, the loss is 4.527127823166856, parameters k is 11.512527003953144 and b is -49.667043478265775\n",
      "Iteration 2797, the loss is 4.527127373620323, parameters k is 11.512509703557887 and b is -49.66701185771242\n",
      "Iteration 2798, the loss is 4.527126830642287, parameters k is 11.512542300395832 and b is -49.66697233202072\n",
      "Iteration 2799, the loss is 4.527126181060754, parameters k is 11.512525000000576 and b is -49.66694071146736\n",
      "Iteration 2800, the loss is 4.527125531479216, parameters k is 11.512507699605319 and b is -49.666909090914004\n",
      "Iteration 2801, the loss is 4.527125032374145, parameters k is 11.512490399210062 and b is -49.666877470360646\n",
      "Iteration 2802, the loss is 4.527124538954653, parameters k is 11.512522996048007 and b is -49.66683794466895\n",
      "Iteration 2803, the loss is 4.527123889373119, parameters k is 11.51250569565275 and b is -49.66680632411559\n",
      "Iteration 2804, the loss is 4.527123239791581, parameters k is 11.512488395257494 and b is -49.66677470356223\n",
      "Iteration 2805, the loss is 4.527122691127988, parameters k is 11.512471094862237 and b is -49.666743083008875\n",
      "Iteration 2806, the loss is 4.527122247267016, parameters k is 11.512503691700182 and b is -49.66670355731718\n",
      "Iteration 2807, the loss is 4.527121597685481, parameters k is 11.512486391304925 and b is -49.66667193676382\n",
      "Iteration 2808, the loss is 4.527120948103939, parameters k is 11.512469090909669 and b is -49.66664031621046\n",
      "Iteration 2809, the loss is 4.527120349881816, parameters k is 11.512451790514412 and b is -49.666608695657104\n",
      "Iteration 2810, the loss is 4.52711995557938, parameters k is 11.512484387352357 and b is -49.666569169965406\n",
      "Iteration 2811, the loss is 4.527119305997842, parameters k is 11.5124670869571 and b is -49.66653754941205\n",
      "Iteration 2812, the loss is 4.527118656416306, parameters k is 11.512449786561843 and b is -49.66650592885869\n",
      "Iteration 2813, the loss is 4.527118008635647, parameters k is 11.512432486166587 and b is -49.66647430830533\n",
      "Iteration 2814, the loss is 4.5271176638917385, parameters k is 11.512465083004532 and b is -49.666434782613635\n",
      "Iteration 2815, the loss is 4.527117014310202, parameters k is 11.512447782609275 and b is -49.66640316206028\n",
      "Iteration 2816, the loss is 4.527116364728668, parameters k is 11.512430482214018 and b is -49.66637154150692\n",
      "Iteration 2817, the loss is 4.527115715147135, parameters k is 11.512413181818761 and b is -49.66633992095356\n",
      "Iteration 2818, the loss is 4.527115324446446, parameters k is 11.512395881423505 and b is -49.6663083004002\n",
      "Iteration 2819, the loss is 4.527114722622566, parameters k is 11.51242847826145 and b is -49.666268774708506\n",
      "Iteration 2820, the loss is 4.527114073041034, parameters k is 11.512411177866193 and b is -49.66623715415515\n",
      "Iteration 2821, the loss is 4.527113423459494, parameters k is 11.512393877470936 and b is -49.66620553360179\n",
      "Iteration 2822, the loss is 4.52711298320028, parameters k is 11.51237657707568 and b is -49.66617391304843\n",
      "Iteration 2823, the loss is 4.527112430934926, parameters k is 11.512409173913625 and b is -49.666134387356735\n",
      "Iteration 2824, the loss is 4.527111781353393, parameters k is 11.512391873518368 and b is -49.66610276680338\n",
      "Iteration 2825, the loss is 4.52711113177186, parameters k is 11.512374573123111 and b is -49.66607114625002\n",
      "Iteration 2826, the loss is 4.52711064195411, parameters k is 11.512357272727854 and b is -49.66603952569666\n",
      "Iteration 2827, the loss is 4.527110139247287, parameters k is 11.5123898695658 and b is -49.66600000000496\n",
      "Iteration 2828, the loss is 4.52710948966575, parameters k is 11.512372569170543 and b is -49.665968379451606\n",
      "Iteration 2829, the loss is 4.52710884008422, parameters k is 11.512355268775286 and b is -49.66593675889825\n",
      "Iteration 2830, the loss is 4.527108300707942, parameters k is 11.512337968380029 and b is -49.66590513834489\n",
      "Iteration 2831, the loss is 4.527107847559656, parameters k is 11.512370565217974 and b is -49.66586561265319\n",
      "Iteration 2832, the loss is 4.52710719797812, parameters k is 11.512353264822718 and b is -49.665833992099834\n",
      "Iteration 2833, the loss is 4.527106548396584, parameters k is 11.51233596442746 and b is -49.66580237154648\n",
      "Iteration 2834, the loss is 4.527105959461773, parameters k is 11.512318664032204 and b is -49.66577075099312\n",
      "Iteration 2835, the loss is 4.527105555872013, parameters k is 11.51235126087015 and b is -49.66573122530142\n",
      "Iteration 2836, the loss is 4.527104906290475, parameters k is 11.512333960474892 and b is -49.66569960474806\n",
      "Iteration 2837, the loss is 4.527104256708945, parameters k is 11.512316660079636 and b is -49.665667984194705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2838, the loss is 4.527103618215608, parameters k is 11.512299359684379 and b is -49.66563636364135\n",
      "Iteration 2839, the loss is 4.5271032641843805, parameters k is 11.512331956522324 and b is -49.66559683794965\n",
      "Iteration 2840, the loss is 4.527102614602843, parameters k is 11.512314656127067 and b is -49.66556521739629\n",
      "Iteration 2841, the loss is 4.527101965021308, parameters k is 11.51229735573181 and b is -49.665533596842934\n",
      "Iteration 2842, the loss is 4.527101315439772, parameters k is 11.512280055336554 and b is -49.665501976289576\n",
      "Iteration 2843, the loss is 4.52710093402641, parameters k is 11.512262754941297 and b is -49.66547035573622\n",
      "Iteration 2844, the loss is 4.52710032291521, parameters k is 11.512295351779242 and b is -49.66543083004452\n",
      "Iteration 2845, the loss is 4.5270996733336695, parameters k is 11.512278051383985 and b is -49.66539920949116\n",
      "Iteration 2846, the loss is 4.527099023752133, parameters k is 11.512260750988728 and b is -49.665367588937805\n",
      "Iteration 2847, the loss is 4.527098592780239, parameters k is 11.512243450593472 and b is -49.66533596838445\n",
      "Iteration 2848, the loss is 4.527098031227569, parameters k is 11.512276047431417 and b is -49.66529644269275\n",
      "Iteration 2849, the loss is 4.527097381646032, parameters k is 11.51225874703616 and b is -49.66526482213939\n",
      "Iteration 2850, the loss is 4.527096732064499, parameters k is 11.512241446640903 and b is -49.665233201586034\n",
      "Iteration 2851, the loss is 4.52709625153407, parameters k is 11.512224146245646 and b is -49.665201581032676\n",
      "Iteration 2852, the loss is 4.527095739539931, parameters k is 11.512256743083592 and b is -49.66516205534098\n",
      "Iteration 2853, the loss is 4.52709508995839, parameters k is 11.512239442688335 and b is -49.66513043478762\n",
      "Iteration 2854, the loss is 4.527094440376859, parameters k is 11.512222142293078 and b is -49.66509881423426\n",
      "Iteration 2855, the loss is 4.527093910287898, parameters k is 11.512204841897821 and b is -49.665067193680905\n",
      "Iteration 2856, the loss is 4.5270934478523, parameters k is 11.512237438735767 and b is -49.66502766798921\n",
      "Iteration 2857, the loss is 4.527092798270754, parameters k is 11.51222013834051 and b is -49.66499604743585\n",
      "Iteration 2858, the loss is 4.527092148689224, parameters k is 11.512202837945253 and b is -49.66496442688249\n",
      "Iteration 2859, the loss is 4.527091569041734, parameters k is 11.512185537549996 and b is -49.66493280632913\n",
      "Iteration 2860, the loss is 4.527091156164654, parameters k is 11.512218134387942 and b is -49.664893280637436\n",
      "Iteration 2861, the loss is 4.527090506583116, parameters k is 11.512200833992685 and b is -49.66486166008408\n",
      "Iteration 2862, the loss is 4.527089857001583, parameters k is 11.512183533597428 and b is -49.66483003953072\n",
      "Iteration 2863, the loss is 4.527089227795565, parameters k is 11.512166233202171 and b is -49.66479841897736\n",
      "Iteration 2864, the loss is 4.527088864477015, parameters k is 11.512198830040116 and b is -49.664758893285665\n",
      "Iteration 2865, the loss is 4.527088214895479, parameters k is 11.51218152964486 and b is -49.66472727273231\n",
      "Iteration 2866, the loss is 4.527087565313946, parameters k is 11.512164229249603 and b is -49.66469565217895\n",
      "Iteration 2867, the loss is 4.527086915732413, parameters k is 11.512146928854346 and b is -49.66466403162559\n",
      "Iteration 2868, the loss is 4.527086543606368, parameters k is 11.512129628459089 and b is -49.66463241107223\n",
      "Iteration 2869, the loss is 4.527085923207844, parameters k is 11.512162225297034 and b is -49.664592885380536\n",
      "Iteration 2870, the loss is 4.527085273626307, parameters k is 11.512144924901778 and b is -49.66456126482718\n",
      "Iteration 2871, the loss is 4.527084624044775, parameters k is 11.51212762450652 and b is -49.66452964427382\n",
      "Iteration 2872, the loss is 4.527084202360191, parameters k is 11.512110324111264 and b is -49.66449802372046\n",
      "Iteration 2873, the loss is 4.527083631520207, parameters k is 11.51214292094921 and b is -49.664458498028765\n",
      "Iteration 2874, the loss is 4.527082981938675, parameters k is 11.512125620553952 and b is -49.66442687747541\n",
      "Iteration 2875, the loss is 4.527082332357131, parameters k is 11.512108320158696 and b is -49.66439525692205\n",
      "Iteration 2876, the loss is 4.5270818611140315, parameters k is 11.512091019763439 and b is -49.66436363636869\n",
      "Iteration 2877, the loss is 4.5270813398325735, parameters k is 11.512123616601384 and b is -49.66432411067699\n",
      "Iteration 2878, the loss is 4.527080690251034, parameters k is 11.512106316206127 and b is -49.664292490123636\n",
      "Iteration 2879, the loss is 4.5270800406694995, parameters k is 11.51208901581087 and b is -49.66426086957028\n",
      "Iteration 2880, the loss is 4.5270795198678595, parameters k is 11.512071715415614 and b is -49.66422924901692\n",
      "Iteration 2881, the loss is 4.527079048144932, parameters k is 11.512104312253559 and b is -49.66418972332522\n",
      "Iteration 2882, the loss is 4.527078398563395, parameters k is 11.512087011858302 and b is -49.664158102771864\n",
      "Iteration 2883, the loss is 4.527077748981858, parameters k is 11.512069711463045 and b is -49.66412648221851\n",
      "Iteration 2884, the loss is 4.527077178621691, parameters k is 11.512052411067788 and b is -49.66409486166515\n",
      "Iteration 2885, the loss is 4.527076756457297, parameters k is 11.512085007905734 and b is -49.66405533597345\n",
      "Iteration 2886, the loss is 4.527076106875762, parameters k is 11.512067707510477 and b is -49.66402371542009\n",
      "Iteration 2887, the loss is 4.527075457294223, parameters k is 11.51205040711522 and b is -49.663992094866735\n",
      "Iteration 2888, the loss is 4.527074837375526, parameters k is 11.512033106719963 and b is -49.66396047431338\n",
      "Iteration 2889, the loss is 4.527074464769659, parameters k is 11.512065703557909 and b is -49.66392094862168\n",
      "Iteration 2890, the loss is 4.527073815188121, parameters k is 11.512048403162652 and b is -49.66388932806832\n",
      "Iteration 2891, the loss is 4.527073165606585, parameters k is 11.512031102767395 and b is -49.663857707514964\n",
      "Iteration 2892, the loss is 4.527072516025048, parameters k is 11.512013802372138 and b is -49.663826086961606\n",
      "Iteration 2893, the loss is 4.527072153186323, parameters k is 11.511996501976881 and b is -49.66379446640825\n",
      "Iteration 2894, the loss is 4.527071523500483, parameters k is 11.512029098814827 and b is -49.66375494071655\n",
      "Iteration 2895, the loss is 4.527070873918948, parameters k is 11.51201179841957 and b is -49.66372332016319\n",
      "Iteration 2896, the loss is 4.527070224337418, parameters k is 11.511994498024313 and b is -49.663691699609835\n",
      "Iteration 2897, the loss is 4.527069811940157, parameters k is 11.511977197629056 and b is -49.66366007905648\n",
      "Iteration 2898, the loss is 4.527069231812846, parameters k is 11.512009794467001 and b is -49.66362055336478\n",
      "Iteration 2899, the loss is 4.527068582231309, parameters k is 11.511992494071745 and b is -49.66358893281142\n",
      "Iteration 2900, the loss is 4.527067932649774, parameters k is 11.511975193676488 and b is -49.663557312258064\n",
      "Iteration 2901, the loss is 4.527067470693987, parameters k is 11.511957893281231 and b is -49.663525691704706\n",
      "Iteration 2902, the loss is 4.5270669401252075, parameters k is 11.511990490119176 and b is -49.66348616601301\n",
      "Iteration 2903, the loss is 4.527066290543671, parameters k is 11.51197318972392 and b is -49.66345454545965\n",
      "Iteration 2904, the loss is 4.527065640962139, parameters k is 11.511955889328663 and b is -49.66342292490629\n",
      "Iteration 2905, the loss is 4.527065129447819, parameters k is 11.511938588933406 and b is -49.663391304352935\n",
      "Iteration 2906, the loss is 4.52706464843757, parameters k is 11.511971185771351 and b is -49.66335177866124\n",
      "Iteration 2907, the loss is 4.527063998856036, parameters k is 11.511953885376094 and b is -49.66332015810788\n",
      "Iteration 2908, the loss is 4.527063349274497, parameters k is 11.511936584980837 and b is -49.66328853755452\n",
      "Iteration 2909, the loss is 4.527062788201652, parameters k is 11.51191928458558 and b is -49.66325691700116\n",
      "Iteration 2910, the loss is 4.527062356749935, parameters k is 11.511951881423526 and b is -49.663217391309466\n",
      "Iteration 2911, the loss is 4.527061707168395, parameters k is 11.51193458102827 and b is -49.66318577075611\n",
      "Iteration 2912, the loss is 4.527061057586864, parameters k is 11.511917280633012 and b is -49.66315415020275\n",
      "Iteration 2913, the loss is 4.52706044695548, parameters k is 11.511899980237756 and b is -49.66312252964939\n",
      "Iteration 2914, the loss is 4.527060065062296, parameters k is 11.5119325770757 and b is -49.663083003957695\n",
      "Iteration 2915, the loss is 4.527059415480761, parameters k is 11.511915276680444 and b is -49.66305138340434\n",
      "Iteration 2916, the loss is 4.527058765899228, parameters k is 11.511897976285187 and b is -49.66301976285098\n",
      "Iteration 2917, the loss is 4.52705811631769, parameters k is 11.51188067588993 and b is -49.66298814229762\n",
      "Iteration 2918, the loss is 4.527057762766282, parameters k is 11.511863375494674 and b is -49.66295652174426\n",
      "Iteration 2919, the loss is 4.527057123793128, parameters k is 11.511895972332619 and b is -49.662916996052566\n",
      "Iteration 2920, the loss is 4.52705647421159, parameters k is 11.511878671937362 and b is -49.66288537549921\n",
      "Iteration 2921, the loss is 4.527055824630051, parameters k is 11.511861371542105 and b is -49.66285375494585\n",
      "Iteration 2922, the loss is 4.527055421520111, parameters k is 11.511844071146848 and b is -49.66282213439249\n",
      "Iteration 2923, the loss is 4.5270548321054775, parameters k is 11.511876667984794 and b is -49.662782608700795\n",
      "Iteration 2924, the loss is 4.527054182523956, parameters k is 11.511859367589537 and b is -49.66275098814744\n",
      "Iteration 2925, the loss is 4.527053532942415, parameters k is 11.51184206719428 and b is -49.66271936759408\n",
      "Iteration 2926, the loss is 4.527053080273942, parameters k is 11.511824766799023 and b is -49.66268774704072\n",
      "Iteration 2927, the loss is 4.527052540417847, parameters k is 11.511857363636969 and b is -49.66264822134902\n",
      "Iteration 2928, the loss is 4.5270518908363115, parameters k is 11.511840063241712 and b is -49.662616600795666\n",
      "Iteration 2929, the loss is 4.527051241254781, parameters k is 11.511822762846455 and b is -49.66258498024231\n",
      "Iteration 2930, the loss is 4.527050739027775, parameters k is 11.511805462451198 and b is -49.66255335968895\n",
      "Iteration 2931, the loss is 4.527050248730211, parameters k is 11.511838059289143 and b is -49.66251383399725\n",
      "Iteration 2932, the loss is 4.527049599148675, parameters k is 11.511820758893887 and b is -49.662482213443894\n",
      "Iteration 2933, the loss is 4.527048949567142, parameters k is 11.51180345849863 and b is -49.662450592890536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2934, the loss is 4.527048397781607, parameters k is 11.511786158103373 and b is -49.66241897233718\n",
      "Iteration 2935, the loss is 4.527047957042572, parameters k is 11.511818754941318 and b is -49.66237944664548\n",
      "Iteration 2936, the loss is 4.52704730746104, parameters k is 11.511801454546061 and b is -49.66234782609212\n",
      "Iteration 2937, the loss is 4.527046657879507, parameters k is 11.511784154150805 and b is -49.662316205538765\n",
      "Iteration 2938, the loss is 4.527046056535442, parameters k is 11.511766853755548 and b is -49.66228458498541\n",
      "Iteration 2939, the loss is 4.5270456653549385, parameters k is 11.511799450593493 and b is -49.66224505929371\n",
      "Iteration 2940, the loss is 4.527045015773402, parameters k is 11.511782150198236 and b is -49.66221343874035\n",
      "Iteration 2941, the loss is 4.527044366191859, parameters k is 11.51176484980298 and b is -49.662181818186994\n",
      "Iteration 2942, the loss is 4.52704371661033, parameters k is 11.511747549407723 and b is -49.662150197633636\n",
      "Iteration 2943, the loss is 4.527043372346244, parameters k is 11.511730249012466 and b is -49.66211857708028\n",
      "Iteration 2944, the loss is 4.527042724085764, parameters k is 11.511762845850411 and b is -49.66207905138858\n",
      "Iteration 2945, the loss is 4.527042074504228, parameters k is 11.511745545455154 and b is -49.66204743083522\n",
      "Iteration 2946, the loss is 4.52704142492269, parameters k is 11.511728245059897 and b is -49.662015810281865\n",
      "Iteration 2947, the loss is 4.527041031100072, parameters k is 11.51171094466464 and b is -49.66198418972851\n",
      "Iteration 2948, the loss is 4.527040432398125, parameters k is 11.511743541502586 and b is -49.66194466403681\n",
      "Iteration 2949, the loss is 4.527039782816588, parameters k is 11.51172624110733 and b is -49.66191304348345\n",
      "Iteration 2950, the loss is 4.527039133235052, parameters k is 11.511708940712072 and b is -49.661881422930094\n",
      "Iteration 2951, the loss is 4.5270386898538995, parameters k is 11.511691640316815 and b is -49.661849802376736\n",
      "Iteration 2952, the loss is 4.527038140710487, parameters k is 11.51172423715476 and b is -49.66181027668504\n",
      "Iteration 2953, the loss is 4.527037491128955, parameters k is 11.511706936759504 and b is -49.66177865613168\n",
      "Iteration 2954, the loss is 4.527036841547416, parameters k is 11.511689636364247 and b is -49.66174703557832\n",
      "Iteration 2955, the loss is 4.527036348607733, parameters k is 11.51167233596899 and b is -49.661715415024965\n",
      "Iteration 2956, the loss is 4.5270358490228455, parameters k is 11.511704932806936 and b is -49.66167588933327\n",
      "Iteration 2957, the loss is 4.527035199441316, parameters k is 11.511687632411679 and b is -49.66164426877991\n",
      "Iteration 2958, the loss is 4.527034549859777, parameters k is 11.511670332016422 and b is -49.66161264822655\n",
      "Iteration 2959, the loss is 4.527034007361559, parameters k is 11.511653031621165 and b is -49.66158102767319\n",
      "Iteration 2960, the loss is 4.527033557335212, parameters k is 11.51168562845911 and b is -49.661541501981496\n",
      "Iteration 2961, the loss is 4.527032907753676, parameters k is 11.511668328063854 and b is -49.66150988142814\n",
      "Iteration 2962, the loss is 4.527032258172142, parameters k is 11.511651027668597 and b is -49.66147826087478\n",
      "Iteration 2963, the loss is 4.527031666115393, parameters k is 11.51163372727334 and b is -49.66144664032142\n",
      "Iteration 2964, the loss is 4.527031265647575, parameters k is 11.511666324111285 and b is -49.661407114629725\n",
      "Iteration 2965, the loss is 4.527030616066042, parameters k is 11.511649023716028 and b is -49.66137549407637\n",
      "Iteration 2966, the loss is 4.527029966484507, parameters k is 11.511631723320772 and b is -49.66134387352301\n",
      "Iteration 2967, the loss is 4.527029324869231, parameters k is 11.511614422925515 and b is -49.66131225296965\n",
      "Iteration 2968, the loss is 4.527028973959938, parameters k is 11.51164701976346 and b is -49.661272727277954\n",
      "Iteration 2969, the loss is 4.527028324378403, parameters k is 11.511629719368203 and b is -49.661241106724596\n",
      "Iteration 2970, the loss is 4.527027674796868, parameters k is 11.511612418972947 and b is -49.66120948617124\n",
      "Iteration 2971, the loss is 4.527027025215326, parameters k is 11.51159511857769 and b is -49.66117786561788\n",
      "Iteration 2972, the loss is 4.5270266406800275, parameters k is 11.511577818182433 and b is -49.66114624506452\n",
      "Iteration 2973, the loss is 4.527026032690763, parameters k is 11.511610415020378 and b is -49.661106719372825\n",
      "Iteration 2974, the loss is 4.527025383109226, parameters k is 11.511593114625121 and b is -49.66107509881947\n",
      "Iteration 2975, the loss is 4.527024733527696, parameters k is 11.511575814229865 and b is -49.66104347826611\n",
      "Iteration 2976, the loss is 4.527024299433861, parameters k is 11.511558513834608 and b is -49.66101185771275\n",
      "Iteration 2977, the loss is 4.527023741003128, parameters k is 11.511591110672553 and b is -49.66097233202105\n",
      "Iteration 2978, the loss is 4.527023091421593, parameters k is 11.511573810277296 and b is -49.660940711467696\n",
      "Iteration 2979, the loss is 4.527022441840057, parameters k is 11.51155650988204 and b is -49.66090909091434\n",
      "Iteration 2980, the loss is 4.527021958187694, parameters k is 11.511539209486783 and b is -49.66087747036098\n",
      "Iteration 2981, the loss is 4.52702144931549, parameters k is 11.511571806324728 and b is -49.66083794466928\n",
      "Iteration 2982, the loss is 4.527020799733952, parameters k is 11.511554505929471 and b is -49.660806324115924\n",
      "Iteration 2983, the loss is 4.527020150152413, parameters k is 11.511537205534214 and b is -49.660774703562566\n",
      "Iteration 2984, the loss is 4.527019616941523, parameters k is 11.511519905138957 and b is -49.66074308300921\n",
      "Iteration 2985, the loss is 4.5270191576278505, parameters k is 11.511552501976903 and b is -49.66070355731751\n",
      "Iteration 2986, the loss is 4.527018508046318, parameters k is 11.511535201581646 and b is -49.66067193676415\n",
      "Iteration 2987, the loss is 4.527017858464777, parameters k is 11.511517901186389 and b is -49.660640316210795\n",
      "Iteration 2988, the loss is 4.527017275695355, parameters k is 11.511500600791132 and b is -49.66060869565744\n",
      "Iteration 2989, the loss is 4.527016865940214, parameters k is 11.511533197629078 and b is -49.66056916996574\n",
      "Iteration 2990, the loss is 4.527016216358679, parameters k is 11.51151589723382 and b is -49.66053754941238\n",
      "Iteration 2991, the loss is 4.527015566777142, parameters k is 11.511498596838564 and b is -49.660505928859024\n",
      "Iteration 2992, the loss is 4.527014934449191, parameters k is 11.511481296443307 and b is -49.660474308305666\n",
      "Iteration 2993, the loss is 4.527014574252572, parameters k is 11.511513893281252 and b is -49.66043478261397\n",
      "Iteration 2994, the loss is 4.527013924671042, parameters k is 11.511496592885996 and b is -49.66040316206061\n",
      "Iteration 2995, the loss is 4.527013275089504, parameters k is 11.511479292490739 and b is -49.66037154150725\n",
      "Iteration 2996, the loss is 4.527012625507966, parameters k is 11.511461992095482 and b is -49.660339920953895\n",
      "Iteration 2997, the loss is 4.527012250259991, parameters k is 11.511444691700225 and b is -49.66030830040054\n",
      "Iteration 2998, the loss is 4.5270116329834, parameters k is 11.51147728853817 and b is -49.66026877470884\n",
      "Iteration 2999, the loss is 4.527010983401867, parameters k is 11.511459988142914 and b is -49.66023715415548\n",
      "Iteration 3000, the loss is 4.527010333820336, parameters k is 11.511442687747657 and b is -49.660205533602124\n",
      "Iteration 3001, the loss is 4.527009909013821, parameters k is 11.5114253873524 and b is -49.660173913048766\n",
      "Iteration 3002, the loss is 4.527009341295767, parameters k is 11.511457984190345 and b is -49.66013438735707\n",
      "Iteration 3003, the loss is 4.5270086917142365, parameters k is 11.511440683795088 and b is -49.66010276680371\n",
      "Iteration 3004, the loss is 4.527008042132692, parameters k is 11.511423383399832 and b is -49.66007114625035\n",
      "Iteration 3005, the loss is 4.527007567767649, parameters k is 11.511406083004575 and b is -49.660039525696995\n",
      "Iteration 3006, the loss is 4.527007049608131, parameters k is 11.51143867984252 and b is -49.6600000000053\n",
      "Iteration 3007, the loss is 4.527006400026592, parameters k is 11.511421379447263 and b is -49.65996837945194\n",
      "Iteration 3008, the loss is 4.527005750445058, parameters k is 11.511404079052006 and b is -49.65993675889858\n",
      "Iteration 3009, the loss is 4.527005226521484, parameters k is 11.51138677865675 and b is -49.65990513834522\n",
      "Iteration 3010, the loss is 4.527004757920489, parameters k is 11.511419375494695 and b is -49.659865612653526\n",
      "Iteration 3011, the loss is 4.52700410833896, parameters k is 11.511402075099438 and b is -49.65983399210017\n",
      "Iteration 3012, the loss is 4.527003458757416, parameters k is 11.511384774704181 and b is -49.65980237154681\n",
      "Iteration 3013, the loss is 4.527002885275316, parameters k is 11.511367474308924 and b is -49.65977075099345\n",
      "Iteration 3014, the loss is 4.527002466232856, parameters k is 11.51140007114687 and b is -49.659731225301755\n",
      "Iteration 3015, the loss is 4.527001816651316, parameters k is 11.511382770751613 and b is -49.6596996047484\n",
      "Iteration 3016, the loss is 4.527001167069781, parameters k is 11.511365470356356 and b is -49.65966798419504\n",
      "Iteration 3017, the loss is 4.5270005440291445, parameters k is 11.5113481699611 and b is -49.65963636364168\n",
      "Iteration 3018, the loss is 4.527000174545219, parameters k is 11.511380766799045 and b is -49.659596837949984\n",
      "Iteration 3019, the loss is 4.526999524963683, parameters k is 11.511363466403788 and b is -49.659565217396626\n",
      "Iteration 3020, the loss is 4.526998875382146, parameters k is 11.511346166008531 and b is -49.65953359684327\n",
      "Iteration 3021, the loss is 4.526998225800608, parameters k is 11.511328865613274 and b is -49.65950197628991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3022, the loss is 4.526997859839946, parameters k is 11.511311565218017 and b is -49.65947035573655\n",
      "Iteration 3023, the loss is 4.526997233276038, parameters k is 11.511344162055963 and b is -49.659430830044855\n",
      "Iteration 3024, the loss is 4.526996583694506, parameters k is 11.511326861660706 and b is -49.6593992094915\n",
      "Iteration 3025, the loss is 4.526995934112971, parameters k is 11.511309561265449 and b is -49.65936758893814\n",
      "Iteration 3026, the loss is 4.52699551859378, parameters k is 11.511292260870192 and b is -49.65933596838478\n",
      "Iteration 3027, the loss is 4.526994941588408, parameters k is 11.511324857708138 and b is -49.65929644269308\n",
      "Iteration 3028, the loss is 4.5269942920068695, parameters k is 11.51130755731288 and b is -49.659264822139725\n",
      "Iteration 3029, the loss is 4.526993642425338, parameters k is 11.511290256917624 and b is -49.65923320158637\n",
      "Iteration 3030, the loss is 4.5269931773476095, parameters k is 11.511272956522367 and b is -49.65920158103301\n",
      "Iteration 3031, the loss is 4.526992649900767, parameters k is 11.511305553360312 and b is -49.65916205534131\n",
      "Iteration 3032, the loss is 4.526992000319231, parameters k is 11.511288252965056 and b is -49.659130434787954\n",
      "Iteration 3033, the loss is 4.526991350737695, parameters k is 11.511270952569799 and b is -49.659098814234596\n",
      "Iteration 3034, the loss is 4.526990836101438, parameters k is 11.511253652174542 and b is -49.65906719368124\n",
      "Iteration 3035, the loss is 4.526990358213131, parameters k is 11.511286249012487 and b is -49.65902766798954\n",
      "Iteration 3036, the loss is 4.526989708631596, parameters k is 11.51126894861723 and b is -49.65899604743618\n",
      "Iteration 3037, the loss is 4.5269890590500586, parameters k is 11.511251648221974 and b is -49.658964426882825\n",
      "Iteration 3038, the loss is 4.5269884948552725, parameters k is 11.511234347826717 and b is -49.65893280632947\n",
      "Iteration 3039, the loss is 4.526988066525494, parameters k is 11.511266944664662 and b is -49.65889328063777\n",
      "Iteration 3040, the loss is 4.5269874169439595, parameters k is 11.511249644269405 and b is -49.65886166008441\n",
      "Iteration 3041, the loss is 4.526986767362415, parameters k is 11.511232343874148 and b is -49.658830039531054\n",
      "Iteration 3042, the loss is 4.526986153609098, parameters k is 11.511215043478892 and b is -49.658798418977696\n",
      "Iteration 3043, the loss is 4.526985774837854, parameters k is 11.511247640316837 and b is -49.658758893286\n",
      "Iteration 3044, the loss is 4.526985125256326, parameters k is 11.51123033992158 and b is -49.65872727273264\n",
      "Iteration 3045, the loss is 4.526984475674789, parameters k is 11.511213039526323 and b is -49.65869565217928\n",
      "Iteration 3046, the loss is 4.526983826093246, parameters k is 11.511195739131066 and b is -49.658664031625925\n",
      "Iteration 3047, the loss is 4.526983469419907, parameters k is 11.51117843873581 and b is -49.65863241107257\n",
      "Iteration 3048, the loss is 4.526982833568682, parameters k is 11.511211035573755 and b is -49.65859288538087\n",
      "Iteration 3049, the loss is 4.526982183987148, parameters k is 11.511193735178498 and b is -49.65856126482751\n",
      "Iteration 3050, the loss is 4.526981534405607, parameters k is 11.511176434783241 and b is -49.658529644274154\n",
      "Iteration 3051, the loss is 4.526981128173737, parameters k is 11.511159134387984 and b is -49.658498023720796\n",
      "Iteration 3052, the loss is 4.526980541881042, parameters k is 11.51119173122593 and b is -49.6584584980291\n",
      "Iteration 3053, the loss is 4.526979892299509, parameters k is 11.511174430830673 and b is -49.65842687747574\n",
      "Iteration 3054, the loss is 4.526979242717973, parameters k is 11.511157130435416 and b is -49.65839525692238\n",
      "Iteration 3055, the loss is 4.526978786927566, parameters k is 11.51113983004016 and b is -49.658363636369025\n",
      "Iteration 3056, the loss is 4.526978250193407, parameters k is 11.511172426878105 and b is -49.65832411067733\n",
      "Iteration 3057, the loss is 4.526977600611875, parameters k is 11.511155126482848 and b is -49.65829249012397\n",
      "Iteration 3058, the loss is 4.526976951030336, parameters k is 11.511137826087591 and b is -49.65826086957061\n",
      "Iteration 3059, the loss is 4.526976445681402, parameters k is 11.511120525692334 and b is -49.65822924901725\n",
      "Iteration 3060, the loss is 4.526975958505769, parameters k is 11.51115312253028 and b is -49.658189723325556\n",
      "Iteration 3061, the loss is 4.526975308924234, parameters k is 11.511135822135023 and b is -49.6581581027722\n",
      "Iteration 3062, the loss is 4.526974659342695, parameters k is 11.511118521739766 and b is -49.65812648221884\n",
      "Iteration 3063, the loss is 4.526974104435229, parameters k is 11.511101221344509 and b is -49.65809486166548\n",
      "Iteration 3064, the loss is 4.526973666818131, parameters k is 11.511133818182454 and b is -49.658055335973785\n",
      "Iteration 3065, the loss is 4.526973017236594, parameters k is 11.511116517787197 and b is -49.65802371542043\n",
      "Iteration 3066, the loss is 4.5269723676550635, parameters k is 11.51109921739194 and b is -49.65799209486707\n",
      "Iteration 3067, the loss is 4.526971763189063, parameters k is 11.511081916996684 and b is -49.65796047431371\n",
      "Iteration 3068, the loss is 4.526971375130496, parameters k is 11.51111451383463 and b is -49.657920948622014\n",
      "Iteration 3069, the loss is 4.526970725548957, parameters k is 11.511097213439372 and b is -49.657889328068656\n",
      "Iteration 3070, the loss is 4.526970075967419, parameters k is 11.511079913044115 and b is -49.6578577075153\n",
      "Iteration 3071, the loss is 4.526969426385887, parameters k is 11.511062612648859 and b is -49.65782608696194\n",
      "Iteration 3072, the loss is 4.526969078999861, parameters k is 11.511045312253602 and b is -49.65779446640858\n",
      "Iteration 3073, the loss is 4.5269684338613185, parameters k is 11.511077909091547 and b is -49.657754940716885\n",
      "Iteration 3074, the loss is 4.526967784279788, parameters k is 11.51106060869629 and b is -49.65772332016353\n",
      "Iteration 3075, the loss is 4.52696713469825, parameters k is 11.511043308301034 and b is -49.65769169961017\n",
      "Iteration 3076, the loss is 4.526966737753697, parameters k is 11.511026007905777 and b is -49.65766007905681\n",
      "Iteration 3077, the loss is 4.526966142173682, parameters k is 11.511058604743722 and b is -49.65762055336511\n",
      "Iteration 3078, the loss is 4.526965492592146, parameters k is 11.511041304348465 and b is -49.657588932811755\n",
      "Iteration 3079, the loss is 4.526964843010614, parameters k is 11.511024003953208 and b is -49.6575573122584\n",
      "Iteration 3080, the loss is 4.526964396507528, parameters k is 11.511006703557952 and b is -49.65752569170504\n",
      "Iteration 3081, the loss is 4.5269638504860445, parameters k is 11.511039300395897 and b is -49.65748616601334\n",
      "Iteration 3082, the loss is 4.526963200904509, parameters k is 11.51102200000064 and b is -49.657454545459984\n",
      "Iteration 3083, the loss is 4.526962551322977, parameters k is 11.511004699605383 and b is -49.657422924906626\n",
      "Iteration 3084, the loss is 4.52696205526136, parameters k is 11.510987399210126 and b is -49.65739130435327\n",
      "Iteration 3085, the loss is 4.5269615587984084, parameters k is 11.511019996048072 and b is -49.65735177866157\n",
      "Iteration 3086, the loss is 4.526960909216868, parameters k is 11.511002695652815 and b is -49.65732015810821\n",
      "Iteration 3087, the loss is 4.526960259635339, parameters k is 11.510985395257558 and b is -49.657288537554855\n",
      "Iteration 3088, the loss is 4.526959714015188, parameters k is 11.510968094862301 and b is -49.6572569170015\n",
      "Iteration 3089, the loss is 4.526959267110769, parameters k is 11.511000691700247 and b is -49.6572173913098\n",
      "Iteration 3090, the loss is 4.526958617529235, parameters k is 11.51098339130499 and b is -49.65718577075644\n",
      "Iteration 3091, the loss is 4.526957967947704, parameters k is 11.510966090909733 and b is -49.657154150203084\n",
      "Iteration 3092, the loss is 4.526957372769019, parameters k is 11.510948790514476 and b is -49.657122529649726\n",
      "Iteration 3093, the loss is 4.526956975423135, parameters k is 11.510981387352421 and b is -49.65708300395803\n",
      "Iteration 3094, the loss is 4.526956325841598, parameters k is 11.510964086957165 and b is -49.65705138340467\n",
      "Iteration 3095, the loss is 4.526955676260066, parameters k is 11.510946786561908 and b is -49.65701976285131\n",
      "Iteration 3096, the loss is 4.526955031522852, parameters k is 11.510929486166651 and b is -49.656988142297955\n",
      "Iteration 3097, the loss is 4.526954683735495, parameters k is 11.510962083004596 and b is -49.65694861660626\n",
      "Iteration 3098, the loss is 4.526954034153954, parameters k is 11.51094478260934 and b is -49.6569169960529\n",
      "Iteration 3099, the loss is 4.526953384572425, parameters k is 11.510927482214083 and b is -49.65688537549954\n",
      "Iteration 3100, the loss is 4.526952734990892, parameters k is 11.510910181818826 and b is -49.656853754946184\n",
      "Iteration 3101, the loss is 4.526952347333649, parameters k is 11.510892881423569 and b is -49.656822134392826\n",
      "Iteration 3102, the loss is 4.526951742466326, parameters k is 11.510925478261514 and b is -49.65678260870113\n",
      "Iteration 3103, the loss is 4.526951092884788, parameters k is 11.510908177866257 and b is -49.65675098814777\n",
      "Iteration 3104, the loss is 4.526950443303253, parameters k is 11.510890877471 and b is -49.65671936759441\n",
      "Iteration 3105, the loss is 4.526950006087482, parameters k is 11.510873577075744 and b is -49.656687747041055\n",
      "Iteration 3106, the loss is 4.526949450778683, parameters k is 11.510906173913689 and b is -49.65664822134936\n",
      "Iteration 3107, the loss is 4.526948801197154, parameters k is 11.510888873518432 and b is -49.656616600796\n",
      "Iteration 3108, the loss is 4.526948151615611, parameters k is 11.510871573123175 and b is -49.65658498024264\n",
      "Iteration 3109, the loss is 4.526947664841316, parameters k is 11.510854272727919 and b is -49.65655335968928\n",
      "Iteration 3110, the loss is 4.526947159091053, parameters k is 11.510886869565864 and b is -49.656513833997586\n",
      "Iteration 3111, the loss is 4.5269465095095125, parameters k is 11.510869569170607 and b is -49.65648221344423\n",
      "Iteration 3112, the loss is 4.52694585992798, parameters k is 11.51085226877535 and b is -49.65645059289087\n",
      "Iteration 3113, the loss is 4.526945323595149, parameters k is 11.510834968380093 and b is -49.65641897233751\n",
      "Iteration 3114, the loss is 4.526944867403409, parameters k is 11.510867565218039 and b is -49.656379446645815\n",
      "Iteration 3115, the loss is 4.526944217821876, parameters k is 11.510850264822782 and b is -49.65634782609246\n",
      "Iteration 3116, the loss is 4.526943568240336, parameters k is 11.510832964427525 and b is -49.6563162055391\n",
      "Iteration 3117, the loss is 4.526942982348976, parameters k is 11.510815664032268 and b is -49.65628458498574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3118, the loss is 4.526942575715772, parameters k is 11.510848260870214 and b is -49.656245059294044\n",
      "Iteration 3119, the loss is 4.5269419261342385, parameters k is 11.510830960474957 and b is -49.656213438740686\n",
      "Iteration 3120, the loss is 4.526941276552697, parameters k is 11.5108136600797 and b is -49.65618181818733\n",
      "Iteration 3121, the loss is 4.526940641102814, parameters k is 11.510796359684443 and b is -49.65615019763397\n",
      "Iteration 3122, the loss is 4.526940284028131, parameters k is 11.510828956522388 and b is -49.65611067194227\n",
      "Iteration 3123, the loss is 4.526939634446605, parameters k is 11.510811656127132 and b is -49.656079051388915\n",
      "Iteration 3124, the loss is 4.526938984865066, parameters k is 11.510794355731875 and b is -49.65604743083556\n",
      "Iteration 3125, the loss is 4.526938335283533, parameters k is 11.510777055336618 and b is -49.6560158102822\n",
      "Iteration 3126, the loss is 4.526937956913613, parameters k is 11.510759754941361 and b is -49.65598418972884\n",
      "Iteration 3127, the loss is 4.526937342758964, parameters k is 11.510792351779306 and b is -49.65594466403714\n",
      "Iteration 3128, the loss is 4.5269366931774275, parameters k is 11.51077505138405 and b is -49.655913043483785\n",
      "Iteration 3129, the loss is 4.526936043595892, parameters k is 11.510757750988793 and b is -49.65588142293043\n",
      "Iteration 3130, the loss is 4.526935615667441, parameters k is 11.510740450593536 and b is -49.65584980237707\n",
      "Iteration 3131, the loss is 4.526935051071324, parameters k is 11.510773047431481 and b is -49.65581027668537\n",
      "Iteration 3132, the loss is 4.5269344014897905, parameters k is 11.510755747036225 and b is -49.655778656132014\n",
      "Iteration 3133, the loss is 4.526933751908255, parameters k is 11.510738446640968 and b is -49.655747035578656\n",
      "Iteration 3134, the loss is 4.526933274421275, parameters k is 11.51072114624571 and b is -49.6557154150253\n",
      "Iteration 3135, the loss is 4.526932759383691, parameters k is 11.510753743083656 and b is -49.6556758893336\n",
      "Iteration 3136, the loss is 4.526932109802149, parameters k is 11.5107364426884 and b is -49.65564426878024\n",
      "Iteration 3137, the loss is 4.5269314602206165, parameters k is 11.510719142293143 and b is -49.655612648226885\n",
      "Iteration 3138, the loss is 4.526930933175102, parameters k is 11.510701841897886 and b is -49.65558102767353\n",
      "Iteration 3139, the loss is 4.526930467696045, parameters k is 11.510734438735831 and b is -49.65554150198183\n",
      "Iteration 3140, the loss is 4.52692981811452, parameters k is 11.510717138340574 and b is -49.65550988142847\n",
      "Iteration 3141, the loss is 4.526929168532978, parameters k is 11.510699837945317 and b is -49.655478260875114\n",
      "Iteration 3142, the loss is 4.526928591928934, parameters k is 11.51068253755006 and b is -49.655446640321756\n",
      "Iteration 3143, the loss is 4.526928176008411, parameters k is 11.510715134388006 and b is -49.65540711463006\n",
      "Iteration 3144, the loss is 4.526927526426873, parameters k is 11.510697833992749 and b is -49.6553754940767\n",
      "Iteration 3145, the loss is 4.526926876845342, parameters k is 11.510680533597492 and b is -49.65534387352334\n",
      "Iteration 3146, the loss is 4.5269262506827666, parameters k is 11.510663233202235 and b is -49.655312252969985\n",
      "Iteration 3147, the loss is 4.526925884320773, parameters k is 11.51069583004018 and b is -49.65527272727829\n",
      "Iteration 3148, the loss is 4.526925234739242, parameters k is 11.510678529644924 and b is -49.65524110672493\n",
      "Iteration 3149, the loss is 4.526924585157706, parameters k is 11.510661229249667 and b is -49.65520948617157\n",
      "Iteration 3150, the loss is 4.526923935576172, parameters k is 11.51064392885441 and b is -49.655177865618214\n",
      "Iteration 3151, the loss is 4.526923566493571, parameters k is 11.510626628459153 and b is -49.655146245064856\n",
      "Iteration 3152, the loss is 4.526922943051604, parameters k is 11.510659225297099 and b is -49.65510671937316\n",
      "Iteration 3153, the loss is 4.526922293470069, parameters k is 11.510641924901842 and b is -49.6550750988198\n",
      "Iteration 3154, the loss is 4.526921643888529, parameters k is 11.510624624506585 and b is -49.65504347826644\n",
      "Iteration 3155, the loss is 4.526921225247403, parameters k is 11.510607324111328 and b is -49.655011857713085\n",
      "Iteration 3156, the loss is 4.526920651363968, parameters k is 11.510639920949274 and b is -49.65497233202139\n",
      "Iteration 3157, the loss is 4.526920001782433, parameters k is 11.510622620554017 and b is -49.65494071146803\n",
      "Iteration 3158, the loss is 4.526919352200898, parameters k is 11.51060532015876 and b is -49.65490909091467\n",
      "Iteration 3159, the loss is 4.5269188840012315, parameters k is 11.510588019763503 and b is -49.65487747036131\n",
      "Iteration 3160, the loss is 4.526918359676322, parameters k is 11.510620616601448 and b is -49.654837944669616\n",
      "Iteration 3161, the loss is 4.526917710094794, parameters k is 11.510603316206192 and b is -49.65480632411626\n",
      "Iteration 3162, the loss is 4.526917060513259, parameters k is 11.510586015810935 and b is -49.6547747035629\n",
      "Iteration 3163, the loss is 4.526916542755064, parameters k is 11.510568715415678 and b is -49.65474308300954\n",
      "Iteration 3164, the loss is 4.526916067988694, parameters k is 11.510601312253623 and b is -49.654703557317845\n",
      "Iteration 3165, the loss is 4.526915418407153, parameters k is 11.510584011858366 and b is -49.65467193676449\n",
      "Iteration 3166, the loss is 4.526914768825619, parameters k is 11.51056671146311 and b is -49.65464031621113\n",
      "Iteration 3167, the loss is 4.526914201508897, parameters k is 11.510549411067853 and b is -49.65460869565777\n",
      "Iteration 3168, the loss is 4.526913776301056, parameters k is 11.510582007905798 and b is -49.654569169966074\n",
      "Iteration 3169, the loss is 4.526913126719516, parameters k is 11.510564707510541 and b is -49.654537549412716\n",
      "Iteration 3170, the loss is 4.52691247713798, parameters k is 11.510547407115284 and b is -49.65450592885936\n",
      "Iteration 3171, the loss is 4.526911860262729, parameters k is 11.510530106720028 and b is -49.654474308306\n",
      "Iteration 3172, the loss is 4.526911484613416, parameters k is 11.510562703557973 and b is -49.6544347826143\n",
      "Iteration 3173, the loss is 4.52691083503188, parameters k is 11.510545403162716 and b is -49.654403162060945\n",
      "Iteration 3174, the loss is 4.526910185450345, parameters k is 11.51052810276746 and b is -49.65437154150759\n",
      "Iteration 3175, the loss is 4.526909535868807, parameters k is 11.510510802372202 and b is -49.65433992095423\n",
      "Iteration 3176, the loss is 4.526909176073527, parameters k is 11.510493501976946 and b is -49.65430830040087\n",
      "Iteration 3177, the loss is 4.526908543344243, parameters k is 11.510526098814891 and b is -49.65426877470917\n",
      "Iteration 3178, the loss is 4.526907893762709, parameters k is 11.510508798419634 and b is -49.654237154155815\n",
      "Iteration 3179, the loss is 4.5269072441811735, parameters k is 11.510491498024377 and b is -49.65420553360246\n",
      "Iteration 3180, the loss is 4.526906834827364, parameters k is 11.51047419762912 and b is -49.6541739130491\n",
      "Iteration 3181, the loss is 4.526906251656602, parameters k is 11.510506794467066 and b is -49.6541343873574\n",
      "Iteration 3182, the loss is 4.526905602075069, parameters k is 11.510489494071809 and b is -49.654102766804044\n",
      "Iteration 3183, the loss is 4.52690495249353, parameters k is 11.510472193676552 and b is -49.654071146250686\n",
      "Iteration 3184, the loss is 4.5269044935811875, parameters k is 11.510454893281295 and b is -49.65403952569733\n",
      "Iteration 3185, the loss is 4.526903959968966, parameters k is 11.51048749011924 and b is -49.65400000000563\n",
      "Iteration 3186, the loss is 4.526903310387432, parameters k is 11.510470189723984 and b is -49.65396837945227\n",
      "Iteration 3187, the loss is 4.526902660805899, parameters k is 11.510452889328727 and b is -49.653936758898915\n",
      "Iteration 3188, the loss is 4.526902152335022, parameters k is 11.51043558893347 and b is -49.65390513834556\n",
      "Iteration 3189, the loss is 4.52690166828133, parameters k is 11.510468185771416 and b is -49.65386561265386\n",
      "Iteration 3190, the loss is 4.52690101869979, parameters k is 11.510450885376159 and b is -49.6538339921005\n",
      "Iteration 3191, the loss is 4.526900369118255, parameters k is 11.510433584980902 and b is -49.653802371547144\n",
      "Iteration 3192, the loss is 4.526899811088858, parameters k is 11.510416284585645 and b is -49.653770750993786\n",
      "Iteration 3193, the loss is 4.5268993765936925, parameters k is 11.51044888142359 and b is -49.65373122530209\n",
      "Iteration 3194, the loss is 4.5268987270121555, parameters k is 11.510431581028334 and b is -49.65369960474873\n",
      "Iteration 3195, the loss is 4.526898077430625, parameters k is 11.510414280633077 and b is -49.65366798419537\n",
      "Iteration 3196, the loss is 4.526897469842686, parameters k is 11.51039698023782 and b is -49.653636363642015\n",
      "Iteration 3197, the loss is 4.526897084906055, parameters k is 11.510429577075765 and b is -49.65359683795032\n",
      "Iteration 3198, the loss is 4.526896435324515, parameters k is 11.510412276680508 and b is -49.65356521739696\n",
      "Iteration 3199, the loss is 4.5268957857429815, parameters k is 11.510394976285252 and b is -49.6535335968436\n",
      "Iteration 3200, the loss is 4.526895136161449, parameters k is 11.510377675889995 and b is -49.653501976290244\n",
      "Iteration 3201, the loss is 4.526894785653484, parameters k is 11.510360375494738 and b is -49.653470355736886\n",
      "Iteration 3202, the loss is 4.5268941436368815, parameters k is 11.510392972332683 and b is -49.65343083004519\n",
      "Iteration 3203, the loss is 4.526893494055346, parameters k is 11.510375671937426 and b is -49.65339920949183\n",
      "Iteration 3204, the loss is 4.526892844473811, parameters k is 11.51035837154217 and b is -49.65336758893847\n",
      "Iteration 3205, the loss is 4.526892444407313, parameters k is 11.510341071146913 and b is -49.653335968385115\n",
      "Iteration 3206, the loss is 4.526891851949243, parameters k is 11.510373667984858 and b is -49.65329644269342\n",
      "Iteration 3207, the loss is 4.5268912023677075, parameters k is 11.510356367589601 and b is -49.65326482214006\n",
      "Iteration 3208, the loss is 4.526890552786176, parameters k is 11.510339067194344 and b is -49.6532332015867\n",
      "Iteration 3209, the loss is 4.526890103161146, parameters k is 11.510321766799088 and b is -49.65320158103334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3210, the loss is 4.526889560261607, parameters k is 11.510354363637033 and b is -49.653162055341646\n",
      "Iteration 3211, the loss is 4.526888910680074, parameters k is 11.510337063241776 and b is -49.65313043478829\n",
      "Iteration 3212, the loss is 4.526888261098533, parameters k is 11.51031976284652 and b is -49.65309881423493\n",
      "Iteration 3213, the loss is 4.526887761914986, parameters k is 11.510302462451262 and b is -49.65306719368157\n",
      "Iteration 3214, the loss is 4.5268872685739705, parameters k is 11.510335059289208 and b is -49.653027667989875\n",
      "Iteration 3215, the loss is 4.526886618992431, parameters k is 11.510317758893951 and b is -49.65299604743652\n",
      "Iteration 3216, the loss is 4.526885969410897, parameters k is 11.510300458498694 and b is -49.65296442688316\n",
      "Iteration 3217, the loss is 4.526885420668815, parameters k is 11.510283158103437 and b is -49.6529328063298\n",
      "Iteration 3218, the loss is 4.52688497688633, parameters k is 11.510315754941383 and b is -49.652893280638104\n",
      "Iteration 3219, the loss is 4.526884327304795, parameters k is 11.510298454546126 and b is -49.652861660084746\n",
      "Iteration 3220, the loss is 4.526883677723259, parameters k is 11.510281154150869 and b is -49.65283003953139\n",
      "Iteration 3221, the loss is 4.526883079422643, parameters k is 11.510263853755612 and b is -49.65279841897803\n",
      "Iteration 3222, the loss is 4.52688268519869, parameters k is 11.510296450593557 and b is -49.65275889328633\n",
      "Iteration 3223, the loss is 4.52688203561716, parameters k is 11.5102791501983 and b is -49.652727272732974\n",
      "Iteration 3224, the loss is 4.526881386035621, parameters k is 11.510261849803044 and b is -49.65269565217962\n",
      "Iteration 3225, the loss is 4.5268807381764775, parameters k is 11.510244549407787 and b is -49.65266403162626\n",
      "Iteration 3226, the loss is 4.526880393511055, parameters k is 11.510277146245732 and b is -49.65262450593456\n",
      "Iteration 3227, the loss is 4.526879743929519, parameters k is 11.510259845850475 and b is -49.6525928853812\n",
      "Iteration 3228, the loss is 4.526879094347983, parameters k is 11.510242545455219 and b is -49.652561264827845\n",
      "Iteration 3229, the loss is 4.526878444766446, parameters k is 11.510225245059962 and b is -49.65252964427449\n",
      "Iteration 3230, the loss is 4.526878053987272, parameters k is 11.510207944664705 and b is -49.65249802372113\n",
      "Iteration 3231, the loss is 4.526877452241883, parameters k is 11.51024054150265 and b is -49.65245849802943\n",
      "Iteration 3232, the loss is 4.526876802660347, parameters k is 11.510223241107393 and b is -49.652426877476074\n",
      "Iteration 3233, the loss is 4.526876153078811, parameters k is 11.510205940712137 and b is -49.652395256922716\n",
      "Iteration 3234, the loss is 4.52687571274111, parameters k is 11.51018864031688 and b is -49.65236363636936\n",
      "Iteration 3235, the loss is 4.526875160554245, parameters k is 11.510221237154825 and b is -49.65232411067766\n",
      "Iteration 3236, the loss is 4.5268745109727035, parameters k is 11.510203936759568 and b is -49.6522924901243\n",
      "Iteration 3237, the loss is 4.526873861391174, parameters k is 11.510186636364311 and b is -49.652260869570945\n",
      "Iteration 3238, the loss is 4.526873371494941, parameters k is 11.510169335969055 and b is -49.65222924901759\n",
      "Iteration 3239, the loss is 4.52687286886661, parameters k is 11.510201932807 and b is -49.65218972332589\n",
      "Iteration 3240, the loss is 4.526872219285072, parameters k is 11.510184632411743 and b is -49.65215810277253\n",
      "Iteration 3241, the loss is 4.5268715697035375, parameters k is 11.510167332016486 and b is -49.652126482219174\n",
      "Iteration 3242, the loss is 4.526871030248771, parameters k is 11.51015003162123 and b is -49.652094861665816\n",
      "Iteration 3243, the loss is 4.526870577178971, parameters k is 11.510182628459175 and b is -49.65205533597412\n",
      "Iteration 3244, the loss is 4.526869927597437, parameters k is 11.510165328063918 and b is -49.65202371542076\n",
      "Iteration 3245, the loss is 4.526869278015896, parameters k is 11.510148027668661 and b is -49.6519920948674\n",
      "Iteration 3246, the loss is 4.526868689002607, parameters k is 11.510130727273404 and b is -49.651960474314045\n",
      "Iteration 3247, the loss is 4.52686828549133, parameters k is 11.51016332411135 and b is -49.65192094862235\n",
      "Iteration 3248, the loss is 4.526867635909797, parameters k is 11.510146023716093 and b is -49.65188932806899\n",
      "Iteration 3249, the loss is 4.526866986328261, parameters k is 11.510128723320836 and b is -49.65185770751563\n",
      "Iteration 3250, the loss is 4.5268663477564335, parameters k is 11.51011142292558 and b is -49.651826086962274\n",
      "Iteration 3251, the loss is 4.526865993803696, parameters k is 11.510144019763525 and b is -49.651786561270576\n",
      "Iteration 3252, the loss is 4.52686534422216, parameters k is 11.510126719368268 and b is -49.65175494071722\n",
      "Iteration 3253, the loss is 4.5268646946406195, parameters k is 11.51010941897301 and b is -49.65172332016386\n",
      "Iteration 3254, the loss is 4.526864045059092, parameters k is 11.510092118577754 and b is -49.6516916996105\n",
      "Iteration 3255, the loss is 4.526863663567239, parameters k is 11.510074818182497 and b is -49.651660079057145\n",
      "Iteration 3256, the loss is 4.52686305253452, parameters k is 11.510107415020443 and b is -49.65162055336545\n",
      "Iteration 3257, the loss is 4.526862402952986, parameters k is 11.510090114625186 and b is -49.65158893281209\n",
      "Iteration 3258, the loss is 4.526861753371451, parameters k is 11.510072814229929 and b is -49.65155731225873\n",
      "Iteration 3259, the loss is 4.526861322321064, parameters k is 11.510055513834672 and b is -49.65152569170537\n",
      "Iteration 3260, the loss is 4.526860760846884, parameters k is 11.510088110672617 and b is -49.651486166013676\n",
      "Iteration 3261, the loss is 4.526860111265349, parameters k is 11.51007081027736 and b is -49.65145454546032\n",
      "Iteration 3262, the loss is 4.526859461683813, parameters k is 11.510053509882104 and b is -49.65142292490696\n",
      "Iteration 3263, the loss is 4.526858981074895, parameters k is 11.510036209486847 and b is -49.6513913043536\n",
      "Iteration 3264, the loss is 4.526858469159243, parameters k is 11.510068806324792 and b is -49.651351778661905\n",
      "Iteration 3265, the loss is 4.5268578195777085, parameters k is 11.510051505929535 and b is -49.65132015810855\n",
      "Iteration 3266, the loss is 4.526857169996173, parameters k is 11.510034205534279 and b is -49.65128853755519\n",
      "Iteration 3267, the loss is 4.526856639828728, parameters k is 11.510016905139022 and b is -49.65125691700183\n",
      "Iteration 3268, the loss is 4.52685617747161, parameters k is 11.510049501976967 and b is -49.651217391310134\n",
      "Iteration 3269, the loss is 4.526855527890074, parameters k is 11.51003220158171 and b is -49.651185770756776\n",
      "Iteration 3270, the loss is 4.526854878308541, parameters k is 11.510014901186453 and b is -49.65115415020342\n",
      "Iteration 3271, the loss is 4.526854298582557, parameters k is 11.509997600791197 and b is -49.65112252965006\n",
      "Iteration 3272, the loss is 4.526853885783967, parameters k is 11.510030197629142 and b is -49.65108300395836\n",
      "Iteration 3273, the loss is 4.526853236202435, parameters k is 11.510012897233885 and b is -49.651051383405004\n",
      "Iteration 3274, the loss is 4.526852586620907, parameters k is 11.509995596838628 and b is -49.65101976285165\n",
      "Iteration 3275, the loss is 4.5268519573363895, parameters k is 11.509978296443371 and b is -49.65098814229829\n",
      "Iteration 3276, the loss is 4.526851594096333, parameters k is 11.510010893281317 and b is -49.65094861660659\n",
      "Iteration 3277, the loss is 4.526850944514802, parameters k is 11.50999359288606 and b is -49.65091699605323\n",
      "Iteration 3278, the loss is 4.526850294933261, parameters k is 11.509976292490803 and b is -49.650885375499875\n",
      "Iteration 3279, the loss is 4.526849645351729, parameters k is 11.509958992095546 and b is -49.65085375494652\n",
      "Iteration 3280, the loss is 4.526849273147194, parameters k is 11.50994169170029 and b is -49.65082213439316\n",
      "Iteration 3281, the loss is 4.526848652827162, parameters k is 11.509974288538235 and b is -49.65078260870146\n",
      "Iteration 3282, the loss is 4.526848003245631, parameters k is 11.509956988142978 and b is -49.650750988148104\n",
      "Iteration 3283, the loss is 4.526847353664085, parameters k is 11.509939687747721 and b is -49.650719367594746\n",
      "Iteration 3284, the loss is 4.526846931901022, parameters k is 11.509922387352464 and b is -49.65068774704139\n",
      "Iteration 3285, the loss is 4.526846361139528, parameters k is 11.50995498419041 and b is -49.65064822134969\n",
      "Iteration 3286, the loss is 4.526845711557989, parameters k is 11.509937683795153 and b is -49.65061660079633\n",
      "Iteration 3287, the loss is 4.526845061976453, parameters k is 11.509920383399896 and b is -49.650584980242975\n",
      "Iteration 3288, the loss is 4.526844590654854, parameters k is 11.50990308300464 and b is -49.65055335968962\n",
      "Iteration 3289, the loss is 4.52684406945189, parameters k is 11.509935679842584 and b is -49.65051383399792\n",
      "Iteration 3290, the loss is 4.52684341987035, parameters k is 11.509918379447328 and b is -49.65048221344456\n",
      "Iteration 3291, the loss is 4.526842770288817, parameters k is 11.50990107905207 and b is -49.650450592891204\n",
      "Iteration 3292, the loss is 4.526842249408691, parameters k is 11.509883778656814 and b is -49.650418972337846\n",
      "Iteration 3293, the loss is 4.526841777764249, parameters k is 11.50991637549476 and b is -49.65037944664615\n",
      "Iteration 3294, the loss is 4.526841128182712, parameters k is 11.509899075099502 and b is -49.65034782609279\n",
      "Iteration 3295, the loss is 4.526840478601181, parameters k is 11.509881774704246 and b is -49.65031620553943\n",
      "Iteration 3296, the loss is 4.526839908162519, parameters k is 11.509864474308989 and b is -49.650284584986075\n",
      "Iteration 3297, the loss is 4.5268394860766135, parameters k is 11.509897071146934 and b is -49.65024505929438\n",
      "Iteration 3298, the loss is 4.526838836495075, parameters k is 11.509879770751677 and b is -49.65021343874102\n",
      "Iteration 3299, the loss is 4.52683818691354, parameters k is 11.50986247035642 and b is -49.65018181818766\n",
      "Iteration 3300, the loss is 4.526837566916352, parameters k is 11.509845169961164 and b is -49.650150197634304\n",
      "Iteration 3301, the loss is 4.526837194388971, parameters k is 11.509877766799109 and b is -49.650110671942606\n",
      "Iteration 3302, the loss is 4.5268365448074395, parameters k is 11.509860466403852 and b is -49.65007905138925\n",
      "Iteration 3303, the loss is 4.526835895225901, parameters k is 11.509843166008595 and b is -49.65004743083589\n",
      "Iteration 3304, the loss is 4.526835245644366, parameters k is 11.509825865613339 and b is -49.65001581028253\n",
      "Iteration 3305, the loss is 4.526834882727152, parameters k is 11.509808565218082 and b is -49.649984189729174\n",
      "Iteration 3306, the loss is 4.526834253119802, parameters k is 11.509841162056027 and b is -49.64994466403748\n",
      "Iteration 3307, the loss is 4.526833603538267, parameters k is 11.50982386166077 and b is -49.64991304348412\n",
      "Iteration 3308, the loss is 4.526832953956728, parameters k is 11.509806561265513 and b is -49.64988142293076\n",
      "Iteration 3309, the loss is 4.526832541480979, parameters k is 11.509789260870257 and b is -49.6498498023774\n",
      "Iteration 3310, the loss is 4.526831961432167, parameters k is 11.509821857708202 and b is -49.649810276685706\n",
      "Iteration 3311, the loss is 4.526831311850625, parameters k is 11.509804557312945 and b is -49.64977865613235\n",
      "Iteration 3312, the loss is 4.52683066226909, parameters k is 11.509787256917688 and b is -49.64974703557899\n",
      "Iteration 3313, the loss is 4.526830200234815, parameters k is 11.509769956522431 and b is -49.64971541502563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3314, the loss is 4.526829669744526, parameters k is 11.509802553360377 and b is -49.649675889333935\n",
      "Iteration 3315, the loss is 4.526829020162991, parameters k is 11.50978525296512 and b is -49.64964426878058\n",
      "Iteration 3316, the loss is 4.526828370581456, parameters k is 11.509767952569863 and b is -49.64961264822722\n",
      "Iteration 3317, the loss is 4.526827858988646, parameters k is 11.509750652174606 and b is -49.64958102767386\n",
      "Iteration 3318, the loss is 4.526827378056891, parameters k is 11.509783249012552 and b is -49.64954150198216\n",
      "Iteration 3319, the loss is 4.52682672847535, parameters k is 11.509765948617295 and b is -49.649509881428806\n",
      "Iteration 3320, the loss is 4.526826078893818, parameters k is 11.509748648222038 and b is -49.64947826087545\n",
      "Iteration 3321, the loss is 4.526825517742473, parameters k is 11.509731347826781 and b is -49.64944664032209\n",
      "Iteration 3322, the loss is 4.526825086369248, parameters k is 11.509763944664726 and b is -49.64940711463039\n",
      "Iteration 3323, the loss is 4.526824436787713, parameters k is 11.50974664426947 and b is -49.649375494077034\n",
      "Iteration 3324, the loss is 4.526823787206178, parameters k is 11.509729343874213 and b is -49.64934387352368\n",
      "Iteration 3325, the loss is 4.526823176496312, parameters k is 11.509712043478956 and b is -49.64931225297032\n",
      "Iteration 3326, the loss is 4.526822794681614, parameters k is 11.509744640316901 and b is -49.64927272727862\n",
      "Iteration 3327, the loss is 4.526822145100078, parameters k is 11.509727339921644 and b is -49.64924110672526\n",
      "Iteration 3328, the loss is 4.526821495518541, parameters k is 11.509710039526388 and b is -49.649209486171905\n",
      "Iteration 3329, the loss is 4.526820845937003, parameters k is 11.50969273913113 and b is -49.64917786561855\n",
      "Iteration 3330, the loss is 4.526820492307112, parameters k is 11.509675438735874 and b is -49.64914624506519\n",
      "Iteration 3331, the loss is 4.526819853412437, parameters k is 11.50970803557382 and b is -49.64910671937349\n",
      "Iteration 3332, the loss is 4.526819203830908, parameters k is 11.509690735178562 and b is -49.649075098820134\n",
      "Iteration 3333, the loss is 4.52681855424937, parameters k is 11.509673434783306 and b is -49.649043478266776\n",
      "Iteration 3334, the loss is 4.526818151060937, parameters k is 11.509656134388049 and b is -49.64901185771342\n",
      "Iteration 3335, the loss is 4.526817561724802, parameters k is 11.509688731225994 and b is -49.64897233202172\n",
      "Iteration 3336, the loss is 4.526816912143266, parameters k is 11.509671430830737 and b is -49.64894071146836\n",
      "Iteration 3337, the loss is 4.526816262561736, parameters k is 11.50965413043548 and b is -49.648909090915005\n",
      "Iteration 3338, the loss is 4.5268158098147735, parameters k is 11.509636830040224 and b is -49.64887747036165\n",
      "Iteration 3339, the loss is 4.526815270037165, parameters k is 11.509669426878169 and b is -49.64883794466995\n",
      "Iteration 3340, the loss is 4.52681462045563, parameters k is 11.509652126482912 and b is -49.64880632411659\n",
      "Iteration 3341, the loss is 4.526813970874093, parameters k is 11.509634826087655 and b is -49.648774703563234\n",
      "Iteration 3342, the loss is 4.526813468568604, parameters k is 11.509617525692398 and b is -49.648743083009876\n",
      "Iteration 3343, the loss is 4.526812978349524, parameters k is 11.509650122530344 and b is -49.64870355731818\n",
      "Iteration 3344, the loss is 4.526812328767991, parameters k is 11.509632822135087 and b is -49.64867193676482\n",
      "Iteration 3345, the loss is 4.526811679186458, parameters k is 11.50961552173983 and b is -49.64864031621146\n",
      "Iteration 3346, the loss is 4.526811127322438, parameters k is 11.509598221344573 and b is -49.648608695658105\n",
      "Iteration 3347, the loss is 4.526810686661886, parameters k is 11.509630818182519 and b is -49.64856916996641\n",
      "Iteration 3348, the loss is 4.526810037080355, parameters k is 11.509613517787262 and b is -49.64853754941305\n",
      "Iteration 3349, the loss is 4.526809387498815, parameters k is 11.509596217392005 and b is -49.64850592885969\n",
      "Iteration 3350, the loss is 4.526808786076269, parameters k is 11.509578916996748 and b is -49.648474308306334\n",
      "Iteration 3351, the loss is 4.5268083949742515, parameters k is 11.509611513834693 and b is -49.648434782614636\n",
      "Iteration 3352, the loss is 4.526807745392717, parameters k is 11.509594213439437 and b is -49.64840316206128\n",
      "Iteration 3353, the loss is 4.526807095811181, parameters k is 11.50957691304418 and b is -49.64837154150792\n",
      "Iteration 3354, the loss is 4.526806446229647, parameters k is 11.509559612648923 and b is -49.64833992095456\n",
      "Iteration 3355, the loss is 4.526806101887069, parameters k is 11.509542312253666 and b is -49.648308300401204\n",
      "Iteration 3356, the loss is 4.52680545370508, parameters k is 11.509574909091612 and b is -49.64826877470951\n",
      "Iteration 3357, the loss is 4.526804804123542, parameters k is 11.509557608696355 and b is -49.64823715415615\n",
      "Iteration 3358, the loss is 4.526804154542008, parameters k is 11.509540308301098 and b is -49.64820553360279\n",
      "Iteration 3359, the loss is 4.5268037606409, parameters k is 11.509523007905841 and b is -49.64817391304943\n",
      "Iteration 3360, the loss is 4.5268031620174405, parameters k is 11.509555604743786 and b is -49.648134387357736\n",
      "Iteration 3361, the loss is 4.526802512435908, parameters k is 11.50953830434853 and b is -49.64810276680438\n",
      "Iteration 3362, the loss is 4.526801862854367, parameters k is 11.509521003953273 and b is -49.64807114625102\n",
      "Iteration 3363, the loss is 4.526801419394731, parameters k is 11.509503703558016 and b is -49.64803952569766\n",
      "Iteration 3364, the loss is 4.526800870329805, parameters k is 11.509536300395961 and b is -49.648000000005965\n",
      "Iteration 3365, the loss is 4.526800220748263, parameters k is 11.509519000000704 and b is -49.64796837945261\n",
      "Iteration 3366, the loss is 4.526799571166732, parameters k is 11.509501699605448 and b is -49.64793675889925\n",
      "Iteration 3367, the loss is 4.5267990781485645, parameters k is 11.50948439921019 and b is -49.64790513834589\n",
      "Iteration 3368, the loss is 4.526798578642169, parameters k is 11.509516996048136 and b is -49.64786561265419\n",
      "Iteration 3369, the loss is 4.526797929060632, parameters k is 11.50949969565288 and b is -49.647833992100836\n",
      "Iteration 3370, the loss is 4.526797279479093, parameters k is 11.509482395257622 and b is -49.64780237154748\n",
      "Iteration 3371, the loss is 4.526796736902393, parameters k is 11.509465094862366 and b is -49.64777075099412\n",
      "Iteration 3372, the loss is 4.5267962869545295, parameters k is 11.509497691700311 and b is -49.64773122530242\n",
      "Iteration 3373, the loss is 4.5267956373729925, parameters k is 11.509480391305054 and b is -49.647699604749064\n",
      "Iteration 3374, the loss is 4.526794987791457, parameters k is 11.509463090909797 and b is -49.64766798419571\n",
      "Iteration 3375, the loss is 4.52679439565623, parameters k is 11.50944579051454 and b is -49.64763636364235\n",
      "Iteration 3376, the loss is 4.526793995266889, parameters k is 11.509478387352486 and b is -49.64759683795065\n",
      "Iteration 3377, the loss is 4.526793345685358, parameters k is 11.509461086957229 and b is -49.64756521739729\n",
      "Iteration 3378, the loss is 4.526792696103821, parameters k is 11.509443786561972 and b is -49.647533596843935\n",
      "Iteration 3379, the loss is 4.526792054410054, parameters k is 11.509426486166715 and b is -49.64750197629058\n",
      "Iteration 3380, the loss is 4.5267917035792555, parameters k is 11.50945908300466 and b is -49.64746245059888\n",
      "Iteration 3381, the loss is 4.5267910539977185, parameters k is 11.509441782609404 and b is -49.64743083004552\n",
      "Iteration 3382, the loss is 4.526790404416186, parameters k is 11.509424482214147 and b is -49.647399209492164\n",
      "Iteration 3383, the loss is 4.526789754834652, parameters k is 11.50940718181889 and b is -49.647367588938806\n",
      "Iteration 3384, the loss is 4.52678937022086, parameters k is 11.509389881423633 and b is -49.64733596838545\n",
      "Iteration 3385, the loss is 4.52678876231008, parameters k is 11.509422478261579 and b is -49.64729644269375\n",
      "Iteration 3386, the loss is 4.526788112728547, parameters k is 11.509405177866322 and b is -49.64726482214039\n",
      "Iteration 3387, the loss is 4.52678746314701, parameters k is 11.509387877471065 and b is -49.647233201587035\n",
      "Iteration 3388, the loss is 4.526787028974689, parameters k is 11.509370577075808 and b is -49.64720158103368\n",
      "Iteration 3389, the loss is 4.526786470622442, parameters k is 11.509403173913753 and b is -49.64716205534198\n",
      "Iteration 3390, the loss is 4.526785821040909, parameters k is 11.509385873518497 and b is -49.64713043478862\n",
      "Iteration 3391, the loss is 4.526785171459369, parameters k is 11.50936857312324 and b is -49.647098814235264\n",
      "Iteration 3392, the loss is 4.52678468772852, parameters k is 11.509351272727983 and b is -49.647067193681906\n",
      "Iteration 3393, the loss is 4.526784178934807, parameters k is 11.509383869565928 and b is -49.64702766799021\n",
      "Iteration 3394, the loss is 4.5267835293532706, parameters k is 11.509366569170671 and b is -49.64699604743685\n",
      "Iteration 3395, the loss is 4.526782879771732, parameters k is 11.509349268775415 and b is -49.64696442688349\n",
      "Iteration 3396, the loss is 4.52678234648235, parameters k is 11.509331968380158 and b is -49.646932806330135\n",
      "Iteration 3397, the loss is 4.526781887247173, parameters k is 11.509364565218103 and b is -49.64689328063844\n",
      "Iteration 3398, the loss is 4.5267812376656344, parameters k is 11.509347264822846 and b is -49.64686166008508\n",
      "Iteration 3399, the loss is 4.526780588084097, parameters k is 11.50932996442759 and b is -49.64683003953172\n",
      "Iteration 3400, the loss is 4.526780005236184, parameters k is 11.509312664032333 and b is -49.64679841897836\n",
      "Iteration 3401, the loss is 4.52677959555953, parameters k is 11.509345260870278 and b is -49.646758893286666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3402, the loss is 4.526778945977992, parameters k is 11.509327960475021 and b is -49.64672727273331\n",
      "Iteration 3403, the loss is 4.52677829639646, parameters k is 11.509310660079764 and b is -49.64669565217995\n",
      "Iteration 3404, the loss is 4.526777663990012, parameters k is 11.509293359684508 and b is -49.64666403162659\n",
      "Iteration 3405, the loss is 4.526777303871894, parameters k is 11.509325956522453 and b is -49.646624505934895\n",
      "Iteration 3406, the loss is 4.526776654290357, parameters k is 11.509308656127196 and b is -49.64659288538154\n",
      "Iteration 3407, the loss is 4.526776004708823, parameters k is 11.50929135573194 and b is -49.64656126482818\n",
      "Iteration 3408, the loss is 4.526775355127286, parameters k is 11.509274055336682 and b is -49.64652964427482\n",
      "Iteration 3409, the loss is 4.526774979800818, parameters k is 11.509256754941426 and b is -49.64649802372146\n",
      "Iteration 3410, the loss is 4.526774362602719, parameters k is 11.50928935177937 and b is -49.646458498029766\n",
      "Iteration 3411, the loss is 4.526773713021188, parameters k is 11.509272051384114 and b is -49.64642687747641\n",
      "Iteration 3412, the loss is 4.526773063439648, parameters k is 11.509254750988857 and b is -49.64639525692305\n",
      "Iteration 3413, the loss is 4.526772638554646, parameters k is 11.5092374505936 and b is -49.64636363636969\n",
      "Iteration 3414, the loss is 4.526772070915079, parameters k is 11.509270047431546 and b is -49.646324110677995\n",
      "Iteration 3415, the loss is 4.526771421333546, parameters k is 11.509252747036289 and b is -49.64629249012464\n",
      "Iteration 3416, the loss is 4.526770771752011, parameters k is 11.509235446641032 and b is -49.64626086957128\n",
      "Iteration 3417, the loss is 4.526770297308479, parameters k is 11.509218146245775 and b is -49.64622924901792\n",
      "Iteration 3418, the loss is 4.526769779227446, parameters k is 11.50925074308372 and b is -49.64618972332622\n",
      "Iteration 3419, the loss is 4.526769129645906, parameters k is 11.509233442688464 and b is -49.646158102772866\n",
      "Iteration 3420, the loss is 4.526768480064375, parameters k is 11.509216142293207 and b is -49.64612648221951\n",
      "Iteration 3421, the loss is 4.526767956062309, parameters k is 11.50919884189795 and b is -49.64609486166615\n",
      "Iteration 3422, the loss is 4.526767487539806, parameters k is 11.509231438735895 and b is -49.64605533597445\n",
      "Iteration 3423, the loss is 4.526766837958273, parameters k is 11.509214138340639 and b is -49.646023715421094\n",
      "Iteration 3424, the loss is 4.526766188376738, parameters k is 11.509196837945382 and b is -49.64599209486774\n",
      "Iteration 3425, the loss is 4.526765614816141, parameters k is 11.509179537550125 and b is -49.64596047431438\n",
      "Iteration 3426, the loss is 4.526765195852171, parameters k is 11.50921213438807 and b is -49.64592094862268\n",
      "Iteration 3427, the loss is 4.5267645462706385, parameters k is 11.509194833992813 and b is -49.64588932806932\n",
      "Iteration 3428, the loss is 4.526763896689102, parameters k is 11.509177533597557 and b is -49.645857707515965\n",
      "Iteration 3429, the loss is 4.526763273569976, parameters k is 11.5091602332023 and b is -49.64582608696261\n",
      "Iteration 3430, the loss is 4.526762904164536, parameters k is 11.509192830040245 and b is -49.64578656127091\n",
      "Iteration 3431, the loss is 4.526762254582998, parameters k is 11.509175529644988 and b is -49.64575494071755\n",
      "Iteration 3432, the loss is 4.526761605001466, parameters k is 11.509158229249731 and b is -49.645723320164194\n",
      "Iteration 3433, the loss is 4.526760955419927, parameters k is 11.509140928854475 and b is -49.645691699610836\n",
      "Iteration 3434, the loss is 4.526760589380774, parameters k is 11.509123628459218 and b is -49.64566007905748\n",
      "Iteration 3435, the loss is 4.526759962895363, parameters k is 11.509156225297163 and b is -49.64562055336578\n",
      "Iteration 3436, the loss is 4.526759313313826, parameters k is 11.509138924901906 and b is -49.64558893281242\n",
      "Iteration 3437, the loss is 4.52675866373229, parameters k is 11.50912162450665 and b is -49.645557312259065\n",
      "Iteration 3438, the loss is 4.526758248134605, parameters k is 11.509104324111393 and b is -49.64552569170571\n",
      "Iteration 3439, the loss is 4.52675767120772, parameters k is 11.509136920949338 and b is -49.64548616601401\n",
      "Iteration 3440, the loss is 4.526757021626183, parameters k is 11.509119620554081 and b is -49.64545454546065\n",
      "Iteration 3441, the loss is 4.526756372044652, parameters k is 11.509102320158824 and b is -49.645422924907294\n",
      "Iteration 3442, the loss is 4.526755906888433, parameters k is 11.509085019763567 and b is -49.645391304353936\n",
      "Iteration 3443, the loss is 4.5267553795200834, parameters k is 11.509117616601513 and b is -49.64535177866224\n",
      "Iteration 3444, the loss is 4.526754729938553, parameters k is 11.509100316206256 and b is -49.64532015810888\n",
      "Iteration 3445, the loss is 4.526754080357011, parameters k is 11.509083015811 and b is -49.64528853755552\n",
      "Iteration 3446, the loss is 4.5267535656422675, parameters k is 11.509065715415742 and b is -49.645256917002165\n",
      "Iteration 3447, the loss is 4.526753087832445, parameters k is 11.509098312253688 and b is -49.64521739131047\n",
      "Iteration 3448, the loss is 4.526752438250915, parameters k is 11.50908101185843 and b is -49.64518577075711\n",
      "Iteration 3449, the loss is 4.526751788669372, parameters k is 11.509063711463174 and b is -49.64515415020375\n",
      "Iteration 3450, the loss is 4.5267512243961, parameters k is 11.509046411067917 and b is -49.64512252965039\n",
      "Iteration 3451, the loss is 4.5267507961448095, parameters k is 11.509079007905862 and b is -49.645083003958696\n",
      "Iteration 3452, the loss is 4.526750146563272, parameters k is 11.509061707510606 and b is -49.64505138340534\n",
      "Iteration 3453, the loss is 4.526749496981737, parameters k is 11.509044407115349 and b is -49.64501976285198\n",
      "Iteration 3454, the loss is 4.526748883149931, parameters k is 11.509027106720092 and b is -49.64498814229862\n",
      "Iteration 3455, the loss is 4.526748504457171, parameters k is 11.509059703558037 and b is -49.644948616606925\n",
      "Iteration 3456, the loss is 4.526747854875639, parameters k is 11.50904240316278 and b is -49.64491699605357\n",
      "Iteration 3457, the loss is 4.526747205294102, parameters k is 11.509025102767524 and b is -49.64488537550021\n",
      "Iteration 3458, the loss is 4.526746555712562, parameters k is 11.509007802372267 and b is -49.64485375494685\n",
      "Iteration 3459, the loss is 4.5267461989607325, parameters k is 11.50899050197701 and b is -49.64482213439349\n",
      "Iteration 3460, the loss is 4.526745563187997, parameters k is 11.509023098814955 and b is -49.644782608701796\n",
      "Iteration 3461, the loss is 4.5267449136064615, parameters k is 11.509005798419699 and b is -49.64475098814844\n",
      "Iteration 3462, the loss is 4.526744264024931, parameters k is 11.508988498024442 and b is -49.64471936759508\n",
      "Iteration 3463, the loss is 4.526743857714561, parameters k is 11.508971197629185 and b is -49.64468774704172\n",
      "Iteration 3464, the loss is 4.526743271500361, parameters k is 11.50900379446713 and b is -49.644648221350025\n",
      "Iteration 3465, the loss is 4.5267426219188245, parameters k is 11.508986494071873 and b is -49.64461660079667\n",
      "Iteration 3466, the loss is 4.526741972337286, parameters k is 11.508969193676617 and b is -49.64458498024331\n",
      "Iteration 3467, the loss is 4.526741516468394, parameters k is 11.50895189328136 and b is -49.64455335968995\n",
      "Iteration 3468, the loss is 4.526740979812726, parameters k is 11.508984490119305 and b is -49.64451383399825\n",
      "Iteration 3469, the loss is 4.5267403302311875, parameters k is 11.508967189724048 and b is -49.644482213444896\n",
      "Iteration 3470, the loss is 4.526739680649658, parameters k is 11.508949889328791 and b is -49.64445059289154\n",
      "Iteration 3471, the loss is 4.526739175222229, parameters k is 11.508932588933535 and b is -49.64441897233818\n",
      "Iteration 3472, the loss is 4.526738688125086, parameters k is 11.50896518577148 and b is -49.64437944664648\n",
      "Iteration 3473, the loss is 4.526738038543551, parameters k is 11.508947885376223 and b is -49.644347826093124\n",
      "Iteration 3474, the loss is 4.526737388962013, parameters k is 11.508930584980966 and b is -49.644316205539766\n",
      "Iteration 3475, the loss is 4.526736833976056, parameters k is 11.50891328458571 and b is -49.64428458498641\n",
      "Iteration 3476, the loss is 4.52673639643745, parameters k is 11.508945881423655 and b is -49.64424505929471\n",
      "Iteration 3477, the loss is 4.526735746855914, parameters k is 11.508928581028398 and b is -49.64421343874135\n",
      "Iteration 3478, the loss is 4.526735097274377, parameters k is 11.508911280633141 and b is -49.644181818187995\n",
      "Iteration 3479, the loss is 4.526734492729889, parameters k is 11.508893980237884 and b is -49.64415019763464\n",
      "Iteration 3480, the loss is 4.52673410474981, parameters k is 11.50892657707583 and b is -49.64411067194294\n",
      "Iteration 3481, the loss is 4.526733455168275, parameters k is 11.508909276680573 and b is -49.64407905138958\n",
      "Iteration 3482, the loss is 4.52673280558674, parameters k is 11.508891976285316 and b is -49.644047430836224\n",
      "Iteration 3483, the loss is 4.526732156005204, parameters k is 11.508874675890059 and b is -49.644015810282866\n",
      "Iteration 3484, the loss is 4.52673180854069, parameters k is 11.508857375494802 and b is -49.64398418972951\n",
      "Iteration 3485, the loss is 4.526731163480634, parameters k is 11.508889972332748 and b is -49.64394466403781\n",
      "Iteration 3486, the loss is 4.526730513899099, parameters k is 11.50887267193749 and b is -49.64391304348445\n",
      "Iteration 3487, the loss is 4.526729864317568, parameters k is 11.508855371542234 and b is -49.643881422931095\n",
      "Iteration 3488, the loss is 4.526729467294524, parameters k is 11.508838071146977 and b is -49.64384980237774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3489, the loss is 4.526728871792997, parameters k is 11.508870667984922 and b is -49.64381027668604\n",
      "Iteration 3490, the loss is 4.526728222211464, parameters k is 11.508853367589666 and b is -49.64377865613268\n",
      "Iteration 3491, the loss is 4.526727572629926, parameters k is 11.508836067194409 and b is -49.643747035579324\n",
      "Iteration 3492, the loss is 4.526727126048352, parameters k is 11.508818766799152 and b is -49.643715415025966\n",
      "Iteration 3493, the loss is 4.526726580105363, parameters k is 11.508851363637097 and b is -49.64367588933427\n",
      "Iteration 3494, the loss is 4.526725930523827, parameters k is 11.50883406324184 and b is -49.64364426878091\n",
      "Iteration 3495, the loss is 4.526725280942296, parameters k is 11.508816762846584 and b is -49.64361264822755\n",
      "Iteration 3496, the loss is 4.526724784802186, parameters k is 11.508799462451327 and b is -49.643581027674195\n",
      "Iteration 3497, the loss is 4.526724288417722, parameters k is 11.508832059289272 and b is -49.6435415019825\n",
      "Iteration 3498, the loss is 4.526723638836186, parameters k is 11.508814758894015 and b is -49.64350988142914\n",
      "Iteration 3499, the loss is 4.526722989254655, parameters k is 11.508797458498758 and b is -49.64347826087578\n",
      "Iteration 3500, the loss is 4.5267224435560225, parameters k is 11.508780158103502 and b is -49.64344664032242\n",
      "Iteration 3501, the loss is 4.526721996730083, parameters k is 11.508812754941447 and b is -49.643407114630726\n",
      "Iteration 3502, the loss is 4.5267213471485555, parameters k is 11.50879545454619 and b is -49.64337549407737\n",
      "Iteration 3503, the loss is 4.5267206975670184, parameters k is 11.508778154150933 and b is -49.64334387352401\n",
      "Iteration 3504, the loss is 4.526720102309849, parameters k is 11.508760853755676 and b is -49.64331225297065\n",
      "Iteration 3505, the loss is 4.526719705042448, parameters k is 11.508793450593622 and b is -49.643272727278955\n",
      "Iteration 3506, the loss is 4.526719055460914, parameters k is 11.508776150198365 and b is -49.6432411067256\n",
      "Iteration 3507, the loss is 4.526718405879379, parameters k is 11.508758849803108 and b is -49.64320948617224\n",
      "Iteration 3508, the loss is 4.526717761063678, parameters k is 11.508741549407851 and b is -49.64317786561888\n",
      "Iteration 3509, the loss is 4.526717413354816, parameters k is 11.508774146245797 and b is -49.643138339927184\n",
      "Iteration 3510, the loss is 4.526716763773281, parameters k is 11.50875684585054 and b is -49.643106719373826\n",
      "Iteration 3511, the loss is 4.526716114191744, parameters k is 11.508739545455283 and b is -49.64307509882047\n",
      "Iteration 3512, the loss is 4.526715464610201, parameters k is 11.508722245060026 and b is -49.64304347826711\n",
      "Iteration 3513, the loss is 4.526715076874477, parameters k is 11.50870494466477 and b is -49.64301185771375\n",
      "Iteration 3514, the loss is 4.526714472085636, parameters k is 11.508737541502715 and b is -49.642972332022055\n",
      "Iteration 3515, the loss is 4.526713822504102, parameters k is 11.508720241107458 and b is -49.6429407114687\n",
      "Iteration 3516, the loss is 4.526713172922566, parameters k is 11.508702940712201 and b is -49.64290909091534\n",
      "Iteration 3517, the loss is 4.5267127356283146, parameters k is 11.508685640316944 and b is -49.64287747036198\n",
      "Iteration 3518, the loss is 4.526712180398007, parameters k is 11.50871823715489 and b is -49.64283794467028\n",
      "Iteration 3519, the loss is 4.526711530816466, parameters k is 11.508700936759633 and b is -49.642806324116926\n",
      "Iteration 3520, the loss is 4.526710881234933, parameters k is 11.508683636364376 and b is -49.64277470356357\n",
      "Iteration 3521, the loss is 4.526710394382142, parameters k is 11.508666335969119 and b is -49.64274308301021\n",
      "Iteration 3522, the loss is 4.5267098887103625, parameters k is 11.508698932807064 and b is -49.64270355731851\n",
      "Iteration 3523, the loss is 4.526709239128826, parameters k is 11.508681632411808 and b is -49.642671936765154\n",
      "Iteration 3524, the loss is 4.526708589547294, parameters k is 11.50866433201655 and b is -49.642640316211796\n",
      "Iteration 3525, the loss is 4.526708053135977, parameters k is 11.508647031621294 and b is -49.64260869565844\n",
      "Iteration 3526, the loss is 4.526707597022726, parameters k is 11.50867962845924 and b is -49.64256916996674\n",
      "Iteration 3527, the loss is 4.526706947441191, parameters k is 11.508662328063982 and b is -49.64253754941338\n",
      "Iteration 3528, the loss is 4.526706297859655, parameters k is 11.508645027668726 and b is -49.642505928860025\n",
      "Iteration 3529, the loss is 4.526705711889802, parameters k is 11.508627727273469 and b is -49.64247430830667\n",
      "Iteration 3530, the loss is 4.5267053053350885, parameters k is 11.508660324111414 and b is -49.64243478261497\n",
      "Iteration 3531, the loss is 4.526704655753556, parameters k is 11.508643023716157 and b is -49.64240316206161\n",
      "Iteration 3532, the loss is 4.526704006172021, parameters k is 11.5086257233209 and b is -49.642371541508254\n",
      "Iteration 3533, the loss is 4.526703370643639, parameters k is 11.508608422925644 and b is -49.642339920954896\n",
      "Iteration 3534, the loss is 4.52670301364745, parameters k is 11.508641019763589 and b is -49.6423003952632\n",
      "Iteration 3535, the loss is 4.5267023640659145, parameters k is 11.508623719368332 and b is -49.64226877470984\n",
      "Iteration 3536, the loss is 4.526701714484379, parameters k is 11.508606418973075 and b is -49.64223715415648\n",
      "Iteration 3537, the loss is 4.526701064902847, parameters k is 11.508589118577818 and b is -49.642205533603125\n",
      "Iteration 3538, the loss is 4.526700686454438, parameters k is 11.508571818182562 and b is -49.64217391304977\n",
      "Iteration 3539, the loss is 4.526700072378278, parameters k is 11.508604415020507 and b is -49.64213438735807\n",
      "Iteration 3540, the loss is 4.526699422796741, parameters k is 11.50858711462525 and b is -49.64210276680471\n",
      "Iteration 3541, the loss is 4.5266987732152115, parameters k is 11.508569814229993 and b is -49.642071146251354\n",
      "Iteration 3542, the loss is 4.526698345208272, parameters k is 11.508552513834736 and b is -49.642039525697996\n",
      "Iteration 3543, the loss is 4.52669778069064, parameters k is 11.508585110672682 and b is -49.6420000000063\n",
      "Iteration 3544, the loss is 4.526697131109103, parameters k is 11.508567810277425 and b is -49.64196837945294\n",
      "Iteration 3545, the loss is 4.526696481527571, parameters k is 11.508550509882168 and b is -49.64193675889958\n",
      "Iteration 3546, the loss is 4.526696003962101, parameters k is 11.508533209486911 and b is -49.641905138346225\n",
      "Iteration 3547, the loss is 4.526695489003001, parameters k is 11.508565806324857 and b is -49.64186561265453\n",
      "Iteration 3548, the loss is 4.526694839421472, parameters k is 11.5085485059296 and b is -49.64183399210117\n",
      "Iteration 3549, the loss is 4.526694189839938, parameters k is 11.508531205534343 and b is -49.64180237154781\n",
      "Iteration 3550, the loss is 4.526693662715934, parameters k is 11.508513905139086 and b is -49.64177075099445\n",
      "Iteration 3551, the loss is 4.526693197315367, parameters k is 11.508546501977031 and b is -49.641731225302756\n",
      "Iteration 3552, the loss is 4.526692547733833, parameters k is 11.508529201581775 and b is -49.6416996047494\n",
      "Iteration 3553, the loss is 4.526691898152296, parameters k is 11.508511901186518 and b is -49.64166798419604\n",
      "Iteration 3554, the loss is 4.526691321469766, parameters k is 11.508494600791261 and b is -49.64163636364268\n",
      "Iteration 3555, the loss is 4.526690905627728, parameters k is 11.508527197629206 and b is -49.641596837950985\n",
      "Iteration 3556, the loss is 4.5266902560461935, parameters k is 11.50850989723395 and b is -49.64156521739763\n",
      "Iteration 3557, the loss is 4.526689606464663, parameters k is 11.508492596838693 and b is -49.64153359684427\n",
      "Iteration 3558, the loss is 4.526688980223594, parameters k is 11.508475296443436 and b is -49.64150197629091\n",
      "Iteration 3559, the loss is 4.526688613940092, parameters k is 11.508507893281381 and b is -49.641462450599214\n",
      "Iteration 3560, the loss is 4.526687964358554, parameters k is 11.508490592886124 and b is -49.641430830045856\n",
      "Iteration 3561, the loss is 4.526687314777022, parameters k is 11.508473292490867 and b is -49.6413992094925\n",
      "Iteration 3562, the loss is 4.526686665195484, parameters k is 11.50845599209561 and b is -49.64136758893914\n",
      "Iteration 3563, the loss is 4.526686296034395, parameters k is 11.508438691700354 and b is -49.64133596838578\n",
      "Iteration 3564, the loss is 4.5266856726709195, parameters k is 11.5084712885383 and b is -49.641296442694085\n",
      "Iteration 3565, the loss is 4.526685023089386, parameters k is 11.508453988143042 and b is -49.64126482214073\n",
      "Iteration 3566, the loss is 4.526684373507846, parameters k is 11.508436687747785 and b is -49.64123320158737\n",
      "Iteration 3567, the loss is 4.526683954788229, parameters k is 11.508419387352529 and b is -49.64120158103401\n",
      "Iteration 3568, the loss is 4.526683380983281, parameters k is 11.508451984190474 and b is -49.64116205534231\n",
      "Iteration 3569, the loss is 4.526682731401746, parameters k is 11.508434683795217 and b is -49.641130434788955\n",
      "Iteration 3570, the loss is 4.526682081820211, parameters k is 11.50841738339996 and b is -49.6410988142356\n",
      "Iteration 3571, the loss is 4.526681613542063, parameters k is 11.508400083004704 and b is -49.64106719368224\n",
      "Iteration 3572, the loss is 4.526681089295649, parameters k is 11.508432679842649 and b is -49.64102766799054\n",
      "Iteration 3573, the loss is 4.526680439714109, parameters k is 11.508415379447392 and b is -49.640996047437184\n",
      "Iteration 3574, the loss is 4.5266797901325715, parameters k is 11.508398079052135 and b is -49.640964426883826\n",
      "Iteration 3575, the loss is 4.526679272295895, parameters k is 11.508380778656878 and b is -49.64093280633047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3576, the loss is 4.526678797608004, parameters k is 11.508413375494824 and b is -49.64089328063877\n",
      "Iteration 3577, the loss is 4.526678148026471, parameters k is 11.508396075099567 and b is -49.64086166008541\n",
      "Iteration 3578, the loss is 4.526677498444937, parameters k is 11.50837877470431 and b is -49.640830039532055\n",
      "Iteration 3579, the loss is 4.526676931049722, parameters k is 11.508361474309053 and b is -49.6407984189787\n",
      "Iteration 3580, the loss is 4.52667650592037, parameters k is 11.508394071146999 and b is -49.640758893287\n",
      "Iteration 3581, the loss is 4.5266758563388345, parameters k is 11.508376770751742 and b is -49.64072727273364\n",
      "Iteration 3582, the loss is 4.5266752067572975, parameters k is 11.508359470356485 and b is -49.640695652180284\n",
      "Iteration 3583, the loss is 4.5266745898035525, parameters k is 11.508342169961228 and b is -49.640664031626926\n",
      "Iteration 3584, the loss is 4.526674214232728, parameters k is 11.508374766799173 and b is -49.64062450593523\n",
      "Iteration 3585, the loss is 4.526673564651194, parameters k is 11.508357466403917 and b is -49.64059288538187\n",
      "Iteration 3586, the loss is 4.5266729150696605, parameters k is 11.50834016600866 and b is -49.64056126482851\n",
      "Iteration 3587, the loss is 4.526672265488123, parameters k is 11.508322865613403 and b is -49.640529644275155\n",
      "Iteration 3588, the loss is 4.526671905614356, parameters k is 11.508305565218146 and b is -49.6404980237218\n",
      "Iteration 3589, the loss is 4.5266712729635525, parameters k is 11.508338162056091 and b is -49.6404584980301\n",
      "Iteration 3590, the loss is 4.526670623382028, parameters k is 11.508320861660835 and b is -49.64042687747674\n",
      "Iteration 3591, the loss is 4.526669973800487, parameters k is 11.508303561265578 and b is -49.640395256923384\n",
      "Iteration 3592, the loss is 4.526669564368189, parameters k is 11.508286260870321 and b is -49.640363636370026\n",
      "Iteration 3593, the loss is 4.526668981275923, parameters k is 11.508318857708266 and b is -49.64032411067833\n",
      "Iteration 3594, the loss is 4.526668331694387, parameters k is 11.50830155731301 and b is -49.64029249012497\n",
      "Iteration 3595, the loss is 4.52666768211285, parameters k is 11.508284256917753 and b is -49.64026086957161\n",
      "Iteration 3596, the loss is 4.526667223122023, parameters k is 11.508266956522496 and b is -49.640229249018255\n",
      "Iteration 3597, the loss is 4.5266666895882794, parameters k is 11.508299553360441 and b is -49.64018972332656\n",
      "Iteration 3598, the loss is 4.526666040006746, parameters k is 11.508282252965184 and b is -49.6401581027732\n",
      "Iteration 3599, the loss is 4.526665390425205, parameters k is 11.508264952569927 and b is -49.64012648221984\n",
      "Iteration 3600, the loss is 4.52666488187585, parameters k is 11.50824765217467 and b is -49.64009486166648\n",
      "Iteration 3601, the loss is 4.5266643979006425, parameters k is 11.508280249012616 and b is -49.640055335974786\n",
      "Iteration 3602, the loss is 4.526663748319109, parameters k is 11.508262948617359 and b is -49.64002371542143\n",
      "Iteration 3603, the loss is 4.5266630987375756, parameters k is 11.508245648222102 and b is -49.63999209486807\n",
      "Iteration 3604, the loss is 4.5266625406296805, parameters k is 11.508228347826845 and b is -49.63996047431471\n",
      "Iteration 3605, the loss is 4.526662106213011, parameters k is 11.50826094466479 and b is -49.639920948623015\n",
      "Iteration 3606, the loss is 4.526661456631474, parameters k is 11.508243644269534 and b is -49.63988932806966\n",
      "Iteration 3607, the loss is 4.526660807049935, parameters k is 11.508226343874277 and b is -49.6398577075163\n",
      "Iteration 3608, the loss is 4.5266601993835085, parameters k is 11.50820904347902 and b is -49.63982608696294\n",
      "Iteration 3609, the loss is 4.526659814525372, parameters k is 11.508241640316966 and b is -49.639786561271244\n",
      "Iteration 3610, the loss is 4.5266591649438315, parameters k is 11.508224339921709 and b is -49.639754940717886\n",
      "Iteration 3611, the loss is 4.526658515362302, parameters k is 11.508207039526452 and b is -49.63972332016453\n",
      "Iteration 3612, the loss is 4.5266578657807655, parameters k is 11.508189739131195 and b is -49.63969169961117\n",
      "Iteration 3613, the loss is 4.526657515194313, parameters k is 11.508172438735938 and b is -49.63966007905781\n",
      "Iteration 3614, the loss is 4.526656873256195, parameters k is 11.508205035573884 and b is -49.639620553366115\n",
      "Iteration 3615, the loss is 4.5266562236746655, parameters k is 11.508187735178627 and b is -49.63958893281276\n",
      "Iteration 3616, the loss is 4.526655574093122, parameters k is 11.50817043478337 and b is -49.6395573122594\n",
      "Iteration 3617, the loss is 4.526655173948147, parameters k is 11.508153134388113 and b is -49.63952569170604\n",
      "Iteration 3618, the loss is 4.526654581568561, parameters k is 11.508185731226058 and b is -49.63948616601434\n",
      "Iteration 3619, the loss is 4.526653931987024, parameters k is 11.508168430830802 and b is -49.639454545460985\n",
      "Iteration 3620, the loss is 4.5266532824054915, parameters k is 11.508151130435545 and b is -49.63942292490763\n",
      "Iteration 3621, the loss is 4.526652832701974, parameters k is 11.508133830040288 and b is -49.63939130435427\n",
      "Iteration 3622, the loss is 4.526652289880919, parameters k is 11.508166426878233 and b is -49.63935177866257\n",
      "Iteration 3623, the loss is 4.526651640299384, parameters k is 11.508149126482976 and b is -49.639320158109214\n",
      "Iteration 3624, the loss is 4.526650990717848, parameters k is 11.50813182608772 and b is -49.639288537555856\n",
      "Iteration 3625, the loss is 4.52665049145581, parameters k is 11.508114525692463 and b is -49.6392569170025\n",
      "Iteration 3626, the loss is 4.526649998193285, parameters k is 11.508147122530408 and b is -49.6392173913108\n",
      "Iteration 3627, the loss is 4.526649348611747, parameters k is 11.508129822135151 and b is -49.63918577075744\n",
      "Iteration 3628, the loss is 4.526648699030213, parameters k is 11.508112521739895 and b is -49.639154150204085\n",
      "Iteration 3629, the loss is 4.52664815020964, parameters k is 11.508095221344638 and b is -49.63912252965073\n",
      "Iteration 3630, the loss is 4.526647706505646, parameters k is 11.508127818182583 and b is -49.63908300395903\n",
      "Iteration 3631, the loss is 4.526647056924111, parameters k is 11.508110517787326 and b is -49.63905138340567\n",
      "Iteration 3632, the loss is 4.526646407342575, parameters k is 11.50809321739207 and b is -49.639019762852314\n",
      "Iteration 3633, the loss is 4.526645808963469, parameters k is 11.508075916996813 and b is -49.638988142298956\n",
      "Iteration 3634, the loss is 4.5266454148180095, parameters k is 11.508108513834758 and b is -49.63894861660726\n",
      "Iteration 3635, the loss is 4.526644765236475, parameters k is 11.508091213439501 and b is -49.6389169960539\n",
      "Iteration 3636, the loss is 4.526644115654939, parameters k is 11.508073913044244 and b is -49.63888537550054\n",
      "Iteration 3637, the loss is 4.526643467717302, parameters k is 11.508056612648987 and b is -49.638853754947185\n",
      "Iteration 3638, the loss is 4.526643123130373, parameters k is 11.508089209486933 and b is -49.63881422925549\n",
      "Iteration 3639, the loss is 4.5266424735488355, parameters k is 11.508071909091676 and b is -49.63878260870213\n",
      "Iteration 3640, the loss is 4.526641823967298, parameters k is 11.508054608696419 and b is -49.63875098814877\n",
      "Iteration 3641, the loss is 4.526641174385761, parameters k is 11.508037308301162 and b is -49.638719367595414\n",
      "Iteration 3642, the loss is 4.526640783528103, parameters k is 11.508020007905905 and b is -49.638687747042056\n",
      "Iteration 3643, the loss is 4.5266401818612, parameters k is 11.50805260474385 and b is -49.63864822135036\n",
      "Iteration 3644, the loss is 4.526639532279662, parameters k is 11.508035304348594 and b is -49.638616600797\n",
      "Iteration 3645, the loss is 4.526638882698128, parameters k is 11.508018003953337 and b is -49.63858498024364\n",
      "Iteration 3646, the loss is 4.526638442281935, parameters k is 11.50800070355808 and b is -49.638553359690285\n",
      "Iteration 3647, the loss is 4.5266378901735616, parameters k is 11.508033300396026 and b is -49.63851383399859\n",
      "Iteration 3648, the loss is 4.526637240592028, parameters k is 11.508016000000769 and b is -49.63848221344523\n",
      "Iteration 3649, the loss is 4.526636591010492, parameters k is 11.507998699605512 and b is -49.63845059289187\n",
      "Iteration 3650, the loss is 4.526636101035765, parameters k is 11.507981399210255 and b is -49.63841897233851\n",
      "Iteration 3651, the loss is 4.52663559848593, parameters k is 11.5080139960482 and b is -49.638379446646816\n",
      "Iteration 3652, the loss is 4.526634948904386, parameters k is 11.507996695652944 and b is -49.63834782609346\n",
      "Iteration 3653, the loss is 4.526634299322851, parameters k is 11.507979395257687 and b is -49.6383162055401\n",
      "Iteration 3654, the loss is 4.5266337597896, parameters k is 11.50796209486243 and b is -49.63828458498674\n",
      "Iteration 3655, the loss is 4.526633306798284, parameters k is 11.507994691700375 and b is -49.638245059295045\n",
      "Iteration 3656, the loss is 4.526632657216748, parameters k is 11.507977391305118 and b is -49.63821343874169\n",
      "Iteration 3657, the loss is 4.526632007635214, parameters k is 11.507960090909862 and b is -49.63818181818833\n",
      "Iteration 3658, the loss is 4.526631418543427, parameters k is 11.507942790514605 and b is -49.63815019763497\n",
      "Iteration 3659, the loss is 4.526631015110654, parameters k is 11.50797538735255 and b is -49.638110671943274\n",
      "Iteration 3660, the loss is 4.526630365529113, parameters k is 11.507958086957293 and b is -49.638079051389916\n",
      "Iteration 3661, the loss is 4.52662971594758, parameters k is 11.507940786562036 and b is -49.63804743083656\n",
      "Iteration 3662, the loss is 4.5266290772972635, parameters k is 11.50792348616678 and b is -49.6380158102832\n",
      "Iteration 3663, the loss is 4.526628723423011, parameters k is 11.507956083004725 and b is -49.6379762845915\n",
      "Iteration 3664, the loss is 4.526628073841478, parameters k is 11.507938782609468 and b is -49.637944664038145\n",
      "Iteration 3665, the loss is 4.526627424259942, parameters k is 11.507921482214211 and b is -49.63791304348479\n",
      "Iteration 3666, the loss is 4.526626774678407, parameters k is 11.507904181818954 and b is -49.63788142293143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3667, the loss is 4.5266263931080655, parameters k is 11.507886881423698 and b is -49.63784980237807\n",
      "Iteration 3668, the loss is 4.526625782153841, parameters k is 11.507919478261643 and b is -49.63781027668637\n",
      "Iteration 3669, the loss is 4.526625132572302, parameters k is 11.507902177866386 and b is -49.637778656133015\n",
      "Iteration 3670, the loss is 4.526624482990768, parameters k is 11.50788487747113 and b is -49.63774703557966\n",
      "Iteration 3671, the loss is 4.526624051861893, parameters k is 11.507867577075872 and b is -49.6377154150263\n",
      "Iteration 3672, the loss is 4.526623490466196, parameters k is 11.507900173913818 and b is -49.6376758893346\n",
      "Iteration 3673, the loss is 4.526622840884664, parameters k is 11.507882873518561 and b is -49.637644268781244\n",
      "Iteration 3674, the loss is 4.526622191303129, parameters k is 11.507865573123304 and b is -49.637612648227886\n",
      "Iteration 3675, the loss is 4.526621710615729, parameters k is 11.507848272728047 and b is -49.63758102767453\n",
      "Iteration 3676, the loss is 4.526621198778562, parameters k is 11.507880869565993 and b is -49.63754150198283\n",
      "Iteration 3677, the loss is 4.52662054919703, parameters k is 11.507863569170736 and b is -49.63750988142947\n",
      "Iteration 3678, the loss is 4.526619899615495, parameters k is 11.507846268775479 and b is -49.637478260876115\n",
      "Iteration 3679, the loss is 4.526619369369556, parameters k is 11.507828968380222 and b is -49.63744664032276\n",
      "Iteration 3680, the loss is 4.526618907090922, parameters k is 11.507861565218167 and b is -49.63740711463106\n",
      "Iteration 3681, the loss is 4.526618257509394, parameters k is 11.50784426482291 and b is -49.6373754940777\n",
      "Iteration 3682, the loss is 4.526617607927855, parameters k is 11.507826964427654 and b is -49.637343873524344\n",
      "Iteration 3683, the loss is 4.526617028123393, parameters k is 11.507809664032397 and b is -49.637312252970986\n",
      "Iteration 3684, the loss is 4.526616615403286, parameters k is 11.507842260870342 and b is -49.63727272727929\n",
      "Iteration 3685, the loss is 4.526615965821748, parameters k is 11.507824960475086 and b is -49.63724110672593\n",
      "Iteration 3686, the loss is 4.5266153162402185, parameters k is 11.507807660079829 and b is -49.63720948617257\n",
      "Iteration 3687, the loss is 4.526614686877221, parameters k is 11.507790359684572 and b is -49.637177865619215\n",
      "Iteration 3688, the loss is 4.526614323715653, parameters k is 11.507822956522517 and b is -49.63713833992752\n",
      "Iteration 3689, the loss is 4.526613674134114, parameters k is 11.50780565612726 and b is -49.63710671937416\n",
      "Iteration 3690, the loss is 4.52661302455258, parameters k is 11.507788355732004 and b is -49.6370750988208\n",
      "Iteration 3691, the loss is 4.526612374971047, parameters k is 11.507771055336747 and b is -49.637043478267444\n",
      "Iteration 3692, the loss is 4.526612002688019, parameters k is 11.50775375494149 and b is -49.637011857714086\n",
      "Iteration 3693, the loss is 4.526611382446477, parameters k is 11.507786351779435 and b is -49.63697233202239\n",
      "Iteration 3694, the loss is 4.526610732864938, parameters k is 11.507769051384178 and b is -49.63694071146903\n",
      "Iteration 3695, the loss is 4.5266100832834075, parameters k is 11.507751750988922 and b is -49.63690909091567\n",
      "Iteration 3696, the loss is 4.526609661441851, parameters k is 11.507734450593665 and b is -49.636877470362315\n",
      "Iteration 3697, the loss is 4.526609090758844, parameters k is 11.50776704743161 and b is -49.63683794467062\n",
      "Iteration 3698, the loss is 4.526608441177308, parameters k is 11.507749747036353 and b is -49.63680632411726\n",
      "Iteration 3699, the loss is 4.526607791595771, parameters k is 11.507732446641096 and b is -49.6367747035639\n",
      "Iteration 3700, the loss is 4.526607320195686, parameters k is 11.50771514624584 and b is -49.63674308301054\n",
      "Iteration 3701, the loss is 4.5266067990712004, parameters k is 11.507747743083785 and b is -49.636703557318846\n",
      "Iteration 3702, the loss is 4.526606149489667, parameters k is 11.507730442688528 and b is -49.63667193676549\n",
      "Iteration 3703, the loss is 4.526605499908132, parameters k is 11.507713142293271 and b is -49.63664031621213\n",
      "Iteration 3704, the loss is 4.526604978949522, parameters k is 11.507695841898014 and b is -49.63660869565877\n",
      "Iteration 3705, the loss is 4.526604507383572, parameters k is 11.50772843873596 and b is -49.636569169967075\n",
      "Iteration 3706, the loss is 4.526603857802032, parameters k is 11.507711138340703 and b is -49.63653754941372\n",
      "Iteration 3707, the loss is 4.526603208220492, parameters k is 11.507693837945446 and b is -49.63650592886036\n",
      "Iteration 3708, the loss is 4.526602637703347, parameters k is 11.50767653755019 and b is -49.636474308307\n",
      "Iteration 3709, the loss is 4.5266022156959265, parameters k is 11.507709134388135 and b is -49.636434782615304\n",
      "Iteration 3710, the loss is 4.526601566114395, parameters k is 11.507691833992878 and b is -49.636403162061946\n",
      "Iteration 3711, the loss is 4.526600916532855, parameters k is 11.507674533597621 and b is -49.63637154150859\n",
      "Iteration 3712, the loss is 4.526600296457178, parameters k is 11.507657233202364 and b is -49.63633992095523\n",
      "Iteration 3713, the loss is 4.526599924008291, parameters k is 11.50768983004031 and b is -49.63630039526353\n",
      "Iteration 3714, the loss is 4.526599274426756, parameters k is 11.507672529645053 and b is -49.636268774710175\n",
      "Iteration 3715, the loss is 4.5265986248452155, parameters k is 11.507655229249796 and b is -49.63623715415682\n",
      "Iteration 3716, the loss is 4.526597975263687, parameters k is 11.507637928854539 and b is -49.63620553360346\n",
      "Iteration 3717, the loss is 4.526597612267977, parameters k is 11.507620628459282 and b is -49.6361739130501\n",
      "Iteration 3718, the loss is 4.526596982739119, parameters k is 11.507653225297227 and b is -49.6361343873584\n",
      "Iteration 3719, the loss is 4.526596333157582, parameters k is 11.50763592490197 and b is -49.636102766805045\n",
      "Iteration 3720, the loss is 4.526595683576049, parameters k is 11.507618624506714 and b is -49.63607114625169\n",
      "Iteration 3721, the loss is 4.526595271021812, parameters k is 11.507601324111457 and b is -49.63603952569833\n",
      "Iteration 3722, the loss is 4.526594691051483, parameters k is 11.507633920949402 and b is -49.63600000000663\n",
      "Iteration 3723, the loss is 4.526594041469946, parameters k is 11.507616620554145 and b is -49.635968379453274\n",
      "Iteration 3724, the loss is 4.526593391888412, parameters k is 11.507599320158889 and b is -49.635936758899916\n",
      "Iteration 3725, the loss is 4.526592929775639, parameters k is 11.507582019763632 and b is -49.63590513834656\n",
      "Iteration 3726, the loss is 4.526592399363836, parameters k is 11.507614616601577 and b is -49.63586561265486\n",
      "Iteration 3727, the loss is 4.5265917497823045, parameters k is 11.50759731620632 and b is -49.6358339921015\n",
      "Iteration 3728, the loss is 4.526591100200774, parameters k is 11.507580015811063 and b is -49.635802371548145\n",
      "Iteration 3729, the loss is 4.526590588529473, parameters k is 11.507562715415807 and b is -49.63577075099479\n",
      "Iteration 3730, the loss is 4.526590107676204, parameters k is 11.507595312253752 and b is -49.63573122530309\n",
      "Iteration 3731, the loss is 4.526589458094668, parameters k is 11.507578011858495 and b is -49.63569960474973\n",
      "Iteration 3732, the loss is 4.526588808513133, parameters k is 11.507560711463238 and b is -49.635667984196374\n",
      "Iteration 3733, the loss is 4.526588247283304, parameters k is 11.507543411067982 and b is -49.635636363643016\n",
      "Iteration 3734, the loss is 4.526587815988562, parameters k is 11.507576007905927 and b is -49.63559683795132\n",
      "Iteration 3735, the loss is 4.526587166407034, parameters k is 11.50755870751067 and b is -49.63556521739796\n",
      "Iteration 3736, the loss is 4.5265865168255, parameters k is 11.507541407115413 and b is -49.6355335968446\n",
      "Iteration 3737, the loss is 4.5265859060371385, parameters k is 11.507524106720156 and b is -49.635501976291245\n",
      "Iteration 3738, the loss is 4.526585524300928, parameters k is 11.507556703558102 and b is -49.63546245059955\n",
      "Iteration 3739, the loss is 4.52658487471939, parameters k is 11.507539403162845 and b is -49.63543083004619\n",
      "Iteration 3740, the loss is 4.526584225137855, parameters k is 11.507522102767588 and b is -49.63539920949283\n",
      "Iteration 3741, the loss is 4.526583575556321, parameters k is 11.507504802372331 and b is -49.635367588939474\n",
      "Iteration 3742, the loss is 4.526583221847936, parameters k is 11.507487501977074 and b is -49.635335968386116\n",
      "Iteration 3743, the loss is 4.526582583031753, parameters k is 11.50752009881502 and b is -49.63529644269442\n",
      "Iteration 3744, the loss is 4.526581933450219, parameters k is 11.507502798419763 and b is -49.63526482214106\n",
      "Iteration 3745, the loss is 4.526581283868685, parameters k is 11.507485498024506 and b is -49.6352332015877\n",
      "Iteration 3746, the loss is 4.526580880601768, parameters k is 11.50746819762925 and b is -49.635201581034345\n",
      "Iteration 3747, the loss is 4.526580291344117, parameters k is 11.507500794467195 and b is -49.63516205534265\n",
      "Iteration 3748, the loss is 4.526579641762579, parameters k is 11.507483494071938 and b is -49.63513043478929\n",
      "Iteration 3749, the loss is 4.526578992181047, parameters k is 11.50746619367668 and b is -49.63509881423593\n",
      "Iteration 3750, the loss is 4.526578539355605, parameters k is 11.507448893281424 and b is -49.63506719368257\n",
      "Iteration 3751, the loss is 4.52657799965648, parameters k is 11.50748149011937 and b is -49.635027667990876\n",
      "Iteration 3752, the loss is 4.526577350074949, parameters k is 11.507464189724113 and b is -49.63499604743752\n",
      "Iteration 3753, the loss is 4.526576700493408, parameters k is 11.507446889328856 and b is -49.63496442688416\n",
      "Iteration 3754, the loss is 4.526576198109433, parameters k is 11.507429588933599 and b is -49.6349328063308\n",
      "Iteration 3755, the loss is 4.526575707968839, parameters k is 11.507462185771544 and b is -49.634893280639105\n",
      "Iteration 3756, the loss is 4.5265750583873094, parameters k is 11.507444885376287 and b is -49.63486166008575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3757, the loss is 4.526574408805773, parameters k is 11.50742758498103 and b is -49.63483003953239\n",
      "Iteration 3758, the loss is 4.526573856863265, parameters k is 11.507410284585774 and b is -49.63479841897903\n",
      "Iteration 3759, the loss is 4.526573416281207, parameters k is 11.507442881423719 and b is -49.634758893287334\n",
      "Iteration 3760, the loss is 4.5265727666996725, parameters k is 11.507425581028462 and b is -49.634727272733976\n",
      "Iteration 3761, the loss is 4.526572117118133, parameters k is 11.507408280633205 and b is -49.63469565218062\n",
      "Iteration 3762, the loss is 4.526571515617095, parameters k is 11.507390980237949 and b is -49.63466403162726\n",
      "Iteration 3763, the loss is 4.526571124593569, parameters k is 11.507423577075894 and b is -49.63462450593556\n",
      "Iteration 3764, the loss is 4.526570475012034, parameters k is 11.507406276680637 and b is -49.634592885382204\n",
      "Iteration 3765, the loss is 4.526569825430499, parameters k is 11.50738897628538 and b is -49.63456126482885\n",
      "Iteration 3766, the loss is 4.526569175848963, parameters k is 11.507371675890123 and b is -49.63452964427549\n",
      "Iteration 3767, the loss is 4.5265688314278965, parameters k is 11.507354375494867 and b is -49.63449802372213\n",
      "Iteration 3768, the loss is 4.526568183324401, parameters k is 11.507386972332812 and b is -49.63445849803043\n",
      "Iteration 3769, the loss is 4.526567533742858, parameters k is 11.507369671937555 and b is -49.634426877477075\n",
      "Iteration 3770, the loss is 4.526566884161325, parameters k is 11.507352371542298 and b is -49.63439525692372\n",
      "Iteration 3771, the loss is 4.526566490181723, parameters k is 11.507335071147041 and b is -49.63436363637036\n",
      "Iteration 3772, the loss is 4.526565891636761, parameters k is 11.507367667984987 and b is -49.63432411067866\n",
      "Iteration 3773, the loss is 4.526565242055226, parameters k is 11.50735036758973 and b is -49.634292490125304\n",
      "Iteration 3774, the loss is 4.526564592473691, parameters k is 11.507333067194473 and b is -49.634260869571946\n",
      "Iteration 3775, the loss is 4.52656414893556, parameters k is 11.507315766799216 and b is -49.63422924901859\n",
      "Iteration 3776, the loss is 4.526563599949124, parameters k is 11.507348363637162 and b is -49.63418972332689\n",
      "Iteration 3777, the loss is 4.526562950367584, parameters k is 11.507331063241905 and b is -49.63415810277353\n",
      "Iteration 3778, the loss is 4.526562300786047, parameters k is 11.507313762846648 and b is -49.634126482220175\n",
      "Iteration 3779, the loss is 4.526561807689388, parameters k is 11.507296462451391 and b is -49.63409486166682\n",
      "Iteration 3780, the loss is 4.526561308261486, parameters k is 11.507329059289336 and b is -49.63405533597512\n",
      "Iteration 3781, the loss is 4.5265606586799505, parameters k is 11.50731175889408 and b is -49.63402371542176\n",
      "Iteration 3782, the loss is 4.526560009098412, parameters k is 11.507294458498823 and b is -49.633992094868404\n",
      "Iteration 3783, the loss is 4.526559466443223, parameters k is 11.507277158103566 and b is -49.633960474315046\n",
      "Iteration 3784, the loss is 4.526559016573844, parameters k is 11.507309754941511 and b is -49.63392094862335\n",
      "Iteration 3785, the loss is 4.526558366992309, parameters k is 11.507292454546254 and b is -49.63388932806999\n",
      "Iteration 3786, the loss is 4.526557717410774, parameters k is 11.507275154150998 and b is -49.63385770751663\n",
      "Iteration 3787, the loss is 4.526557125197047, parameters k is 11.50725785375574 and b is -49.633826086963275\n",
      "Iteration 3788, the loss is 4.52655672488621, parameters k is 11.507290450593686 and b is -49.63378656127158\n",
      "Iteration 3789, the loss is 4.526556075304676, parameters k is 11.50727315019843 and b is -49.63375494071822\n",
      "Iteration 3790, the loss is 4.526555425723135, parameters k is 11.507255849803173 and b is -49.63372332016486\n",
      "Iteration 3791, the loss is 4.526554783950884, parameters k is 11.507238549407916 and b is -49.633691699611504\n",
      "Iteration 3792, the loss is 4.526554433198571, parameters k is 11.507271146245861 and b is -49.633652173919806\n",
      "Iteration 3793, the loss is 4.526553783617037, parameters k is 11.507253845850604 and b is -49.63362055336645\n",
      "Iteration 3794, the loss is 4.526553134035499, parameters k is 11.507236545455347 and b is -49.63358893281309\n",
      "Iteration 3795, the loss is 4.526552484453967, parameters k is 11.50721924506009 and b is -49.63355731225973\n",
      "Iteration 3796, the loss is 4.526552099761689, parameters k is 11.507201944664834 and b is -49.633525691706375\n",
      "Iteration 3797, the loss is 4.5265514919294, parameters k is 11.507234541502779 and b is -49.63348616601468\n",
      "Iteration 3798, the loss is 4.526550842347864, parameters k is 11.507217241107522 and b is -49.63345454546132\n",
      "Iteration 3799, the loss is 4.526550192766323, parameters k is 11.507199940712265 and b is -49.63342292490796\n",
      "Iteration 3800, the loss is 4.526549758515517, parameters k is 11.507182640317009 and b is -49.6333913043546\n",
      "Iteration 3801, the loss is 4.526549200241765, parameters k is 11.507215237154954 and b is -49.633351778662906\n",
      "Iteration 3802, the loss is 4.52654855066022, parameters k is 11.507197936759697 and b is -49.63332015810955\n",
      "Iteration 3803, the loss is 4.52654790107869, parameters k is 11.50718063636444 and b is -49.63328853755619\n",
      "Iteration 3804, the loss is 4.526547417269352, parameters k is 11.507163335969183 and b is -49.63325691700283\n",
      "Iteration 3805, the loss is 4.526546908554127, parameters k is 11.507195932807129 and b is -49.633217391311135\n",
      "Iteration 3806, the loss is 4.526546258972586, parameters k is 11.507178632411872 and b is -49.63318577075778\n",
      "Iteration 3807, the loss is 4.526545609391053, parameters k is 11.507161332016615 and b is -49.63315415020442\n",
      "Iteration 3808, the loss is 4.5265450760231785, parameters k is 11.507144031621358 and b is -49.63312252965106\n",
      "Iteration 3809, the loss is 4.526544616866484, parameters k is 11.507176628459304 and b is -49.633083003959364\n",
      "Iteration 3810, the loss is 4.526543967284951, parameters k is 11.507159328064047 and b is -49.633051383406006\n",
      "Iteration 3811, the loss is 4.526543317703416, parameters k is 11.50714202766879 and b is -49.63301976285265\n",
      "Iteration 3812, the loss is 4.526542734777011, parameters k is 11.507124727273533 and b is -49.63298814229929\n",
      "Iteration 3813, the loss is 4.526542325178848, parameters k is 11.507157324111478 and b is -49.63294861660759\n",
      "Iteration 3814, the loss is 4.52654167559731, parameters k is 11.507140023716222 and b is -49.632916996054234\n",
      "Iteration 3815, the loss is 4.526541026015776, parameters k is 11.507122723320965 and b is -49.63288537550088\n",
      "Iteration 3816, the loss is 4.5265403935308415, parameters k is 11.507105422925708 and b is -49.63285375494752\n",
      "Iteration 3817, the loss is 4.526540033491209, parameters k is 11.507138019763653 and b is -49.63281422925582\n",
      "Iteration 3818, the loss is 4.526539383909672, parameters k is 11.507120719368396 and b is -49.63278260870246\n",
      "Iteration 3819, the loss is 4.526538734328142, parameters k is 11.50710341897314 and b is -49.632750988149105\n",
      "Iteration 3820, the loss is 4.526538084746604, parameters k is 11.507086118577883 and b is -49.63271936759575\n",
      "Iteration 3821, the loss is 4.5265377093416435, parameters k is 11.507068818182626 and b is -49.63268774704239\n",
      "Iteration 3822, the loss is 4.526537092222034, parameters k is 11.507101415020571 and b is -49.63264822135069\n",
      "Iteration 3823, the loss is 4.526536442640505, parameters k is 11.507084114625314 and b is -49.632616600797334\n",
      "Iteration 3824, the loss is 4.526535793058969, parameters k is 11.507066814230058 and b is -49.632584980243976\n",
      "Iteration 3825, the loss is 4.5265353680954785, parameters k is 11.5070495138348 and b is -49.63255335969062\n",
      "Iteration 3826, the loss is 4.526534800534399, parameters k is 11.507082110672746 and b is -49.63251383399892\n",
      "Iteration 3827, the loss is 4.526534150952865, parameters k is 11.50706481027749 and b is -49.63248221344556\n",
      "Iteration 3828, the loss is 4.526533501371328, parameters k is 11.507047509882232 and b is -49.632450592892205\n",
      "Iteration 3829, the loss is 4.526533026849306, parameters k is 11.507030209486976 and b is -49.63241897233885\n",
      "Iteration 3830, the loss is 4.526532508846763, parameters k is 11.507062806324921 and b is -49.63237944664715\n",
      "Iteration 3831, the loss is 4.52653185926523, parameters k is 11.507045505929664 and b is -49.63234782609379\n",
      "Iteration 3832, the loss is 4.526531209683687, parameters k is 11.507028205534407 and b is -49.632316205540434\n",
      "Iteration 3833, the loss is 4.526530685603139, parameters k is 11.50701090513915 and b is -49.632284584987076\n",
      "Iteration 3834, the loss is 4.526530217159125, parameters k is 11.507043501977096 and b is -49.63224505929538\n",
      "Iteration 3835, the loss is 4.52652956757759, parameters k is 11.507026201581839 and b is -49.63221343874202\n",
      "Iteration 3836, the loss is 4.526528917996051, parameters k is 11.507008901186582 and b is -49.63218181818866\n",
      "Iteration 3837, the loss is 4.5265283443569695, parameters k is 11.506991600791325 and b is -49.632150197635305\n",
      "Iteration 3838, the loss is 4.526527925471483, parameters k is 11.50702419762927 and b is -49.63211067194361\n",
      "Iteration 3839, the loss is 4.526527275889947, parameters k is 11.507006897234014 and b is -49.63207905139025\n",
      "Iteration 3840, the loss is 4.526526626308411, parameters k is 11.506989596838757 and b is -49.63204743083689\n",
      "Iteration 3841, the loss is 4.5265260031108046, parameters k is 11.5069722964435 and b is -49.632015810283534\n",
      "Iteration 3842, the loss is 4.5265256337838515, parameters k is 11.507004893281445 and b is -49.631976284591836\n",
      "Iteration 3843, the loss is 4.526524984202311, parameters k is 11.506987592886189 and b is -49.63194466403848\n",
      "Iteration 3844, the loss is 4.526524334620776, parameters k is 11.506970292490932 and b is -49.63191304348512\n",
      "Iteration 3845, the loss is 4.5265236850392405, parameters k is 11.506952992095675 and b is -49.63188142293176\n",
      "Iteration 3846, the loss is 4.526523318921602, parameters k is 11.506935691700418 and b is -49.631849802378404\n",
      "Iteration 3847, the loss is 4.526522692514677, parameters k is 11.506968288538364 and b is -49.63181027668671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3848, the loss is 4.526522042933145, parameters k is 11.506950988143107 and b is -49.63177865613335\n",
      "Iteration 3849, the loss is 4.526521393351607, parameters k is 11.50693368774785 and b is -49.63174703557999\n",
      "Iteration 3850, the loss is 4.526520977675439, parameters k is 11.506916387352593 and b is -49.63171541502663\n",
      "Iteration 3851, the loss is 4.526520400827038, parameters k is 11.506948984190538 and b is -49.631675889334936\n",
      "Iteration 3852, the loss is 4.526519751245505, parameters k is 11.506931683795282 and b is -49.63164426878158\n",
      "Iteration 3853, the loss is 4.526519101663972, parameters k is 11.506914383400025 and b is -49.63161264822822\n",
      "Iteration 3854, the loss is 4.526518636429265, parameters k is 11.506897083004768 and b is -49.63158102767486\n",
      "Iteration 3855, the loss is 4.526518109139401, parameters k is 11.506929679842713 and b is -49.631541501983165\n",
      "Iteration 3856, the loss is 4.52651745955786, parameters k is 11.506912379447456 and b is -49.63150988142981\n",
      "Iteration 3857, the loss is 4.5265168099763295, parameters k is 11.5068950790522 and b is -49.63147826087645\n",
      "Iteration 3858, the loss is 4.526516295183094, parameters k is 11.506877778656943 and b is -49.63144664032309\n",
      "Iteration 3859, the loss is 4.526515817451762, parameters k is 11.506910375494888 and b is -49.63140711463139\n",
      "Iteration 3860, the loss is 4.526515167870224, parameters k is 11.506893075099631 and b is -49.631375494078036\n",
      "Iteration 3861, the loss is 4.526514518288695, parameters k is 11.506875774704374 and b is -49.63134387352468\n",
      "Iteration 3862, the loss is 4.526513953936926, parameters k is 11.506858474309118 and b is -49.63131225297132\n",
      "Iteration 3863, the loss is 4.526513525764126, parameters k is 11.506891071147063 and b is -49.63127272727962\n",
      "Iteration 3864, the loss is 4.526512876182591, parameters k is 11.506873770751806 and b is -49.631241106726264\n",
      "Iteration 3865, the loss is 4.526512226601054, parameters k is 11.50685647035655 and b is -49.63120948617291\n",
      "Iteration 3866, the loss is 4.52651161269076, parameters k is 11.506839169961292 and b is -49.63117786561955\n",
      "Iteration 3867, the loss is 4.526511234076488, parameters k is 11.506871766799238 and b is -49.63113833992785\n",
      "Iteration 3868, the loss is 4.526510584494951, parameters k is 11.506854466403981 and b is -49.63110671937449\n",
      "Iteration 3869, the loss is 4.526509934913419, parameters k is 11.506837166008724 and b is -49.631075098821135\n",
      "Iteration 3870, the loss is 4.526509285331881, parameters k is 11.506819865613467 and b is -49.63104347826778\n",
      "Iteration 3871, the loss is 4.526508928501561, parameters k is 11.50680256521821 and b is -49.63101185771442\n",
      "Iteration 3872, the loss is 4.526508292807313, parameters k is 11.506835162056156 and b is -49.63097233202272\n",
      "Iteration 3873, the loss is 4.52650764322578, parameters k is 11.506817861660899 and b is -49.630940711469364\n",
      "Iteration 3874, the loss is 4.526506993644244, parameters k is 11.506800561265642 and b is -49.630909090916006\n",
      "Iteration 3875, the loss is 4.526506587255395, parameters k is 11.506783260870385 and b is -49.63087747036265\n",
      "Iteration 3876, the loss is 4.526506001119682, parameters k is 11.50681585770833 and b is -49.63083794467095\n",
      "Iteration 3877, the loss is 4.526505351538141, parameters k is 11.506798557313074 and b is -49.63080632411759\n",
      "Iteration 3878, the loss is 4.526504701956609, parameters k is 11.506781256917817 and b is -49.630774703564235\n",
      "Iteration 3879, the loss is 4.526504246009226, parameters k is 11.50676395652256 and b is -49.63074308301088\n",
      "Iteration 3880, the loss is 4.526503709432039, parameters k is 11.506796553360505 and b is -49.63070355731918\n",
      "Iteration 3881, the loss is 4.526503059850506, parameters k is 11.506779252965249 and b is -49.63067193676582\n",
      "Iteration 3882, the loss is 4.526502410268966, parameters k is 11.506761952569992 and b is -49.630640316212464\n",
      "Iteration 3883, the loss is 4.526501904763054, parameters k is 11.506744652174735 and b is -49.630608695659106\n",
      "Iteration 3884, the loss is 4.526501417744406, parameters k is 11.50677724901268 and b is -49.63056916996741\n",
      "Iteration 3885, the loss is 4.526500768162867, parameters k is 11.506759948617423 and b is -49.63053754941405\n",
      "Iteration 3886, the loss is 4.526500118581333, parameters k is 11.506742648222167 and b is -49.63050592886069\n",
      "Iteration 3887, the loss is 4.526499563516889, parameters k is 11.50672534782691 and b is -49.630474308307335\n",
      "Iteration 3888, the loss is 4.526499126056759, parameters k is 11.506757944664855 and b is -49.63043478261564\n",
      "Iteration 3889, the loss is 4.526498476475227, parameters k is 11.506740644269598 and b is -49.63040316206228\n",
      "Iteration 3890, the loss is 4.526497826893695, parameters k is 11.506723343874341 and b is -49.63037154150892\n",
      "Iteration 3891, the loss is 4.5264972222707165, parameters k is 11.506706043479085 and b is -49.630339920955564\n",
      "Iteration 3892, the loss is 4.526496834369128, parameters k is 11.50673864031703 and b is -49.630300395263866\n",
      "Iteration 3893, the loss is 4.526496184787591, parameters k is 11.506721339921773 and b is -49.63026877471051\n",
      "Iteration 3894, the loss is 4.526495535206063, parameters k is 11.506704039526516 and b is -49.63023715415715\n",
      "Iteration 3895, the loss is 4.5264948856245235, parameters k is 11.50668673913126 and b is -49.63020553360379\n",
      "Iteration 3896, the loss is 4.526494538081518, parameters k is 11.506669438736003 and b is -49.630173913050434\n",
      "Iteration 3897, the loss is 4.526493893099953, parameters k is 11.506702035573948 and b is -49.63013438735874\n",
      "Iteration 3898, the loss is 4.526493243518423, parameters k is 11.506684735178691 and b is -49.63010276680538\n",
      "Iteration 3899, the loss is 4.5264925939368865, parameters k is 11.506667434783434 and b is -49.63007114625202\n",
      "Iteration 3900, the loss is 4.526492196835351, parameters k is 11.506650134388178 and b is -49.63003952569866\n",
      "Iteration 3901, the loss is 4.526491601412317, parameters k is 11.506682731226123 and b is -49.630000000006966\n",
      "Iteration 3902, the loss is 4.526490951830788, parameters k is 11.506665430830866 and b is -49.62996837945361\n",
      "Iteration 3903, the loss is 4.526490302249241, parameters k is 11.50664813043561 and b is -49.62993675890025\n",
      "Iteration 3904, the loss is 4.526489855589186, parameters k is 11.506630830040352 and b is -49.62990513834689\n",
      "Iteration 3905, the loss is 4.52648930972468, parameters k is 11.506663426878298 and b is -49.629865612655195\n",
      "Iteration 3906, the loss is 4.5264886601431416, parameters k is 11.50664612648304 and b is -49.62983399210184\n",
      "Iteration 3907, the loss is 4.526488010561611, parameters k is 11.506628826087784 and b is -49.62980237154848\n",
      "Iteration 3908, the loss is 4.526487514343013, parameters k is 11.506611525692527 and b is -49.62977075099512\n",
      "Iteration 3909, the loss is 4.526487018037043, parameters k is 11.506644122530473 and b is -49.62973122530342\n",
      "Iteration 3910, the loss is 4.526486368455504, parameters k is 11.506626822135216 and b is -49.629699604750066\n",
      "Iteration 3911, the loss is 4.526485718873969, parameters k is 11.506609521739959 and b is -49.62966798419671\n",
      "Iteration 3912, the loss is 4.526485173096843, parameters k is 11.506592221344702 and b is -49.62963636364335\n",
      "Iteration 3913, the loss is 4.526484726349406, parameters k is 11.506624818182647 and b is -49.62959683795165\n",
      "Iteration 3914, the loss is 4.5264840767678685, parameters k is 11.50660751778739 and b is -49.629565217398294\n",
      "Iteration 3915, the loss is 4.5264834271863315, parameters k is 11.506590217392134 and b is -49.62953359684494\n",
      "Iteration 3916, the loss is 4.526482831850676, parameters k is 11.506572916996877 and b is -49.62950197629158\n",
      "Iteration 3917, the loss is 4.526482434661771, parameters k is 11.506605513834822 and b is -49.62946245059988\n",
      "Iteration 3918, the loss is 4.526481785080232, parameters k is 11.506588213439565 and b is -49.62943083004652\n",
      "Iteration 3919, the loss is 4.526481135498701, parameters k is 11.506570913044309 and b is -49.629399209493165\n",
      "Iteration 3920, the loss is 4.526480490604506, parameters k is 11.506553612649052 and b is -49.62936758893981\n",
      "Iteration 3921, the loss is 4.526480142974129, parameters k is 11.506586209486997 and b is -49.62932806324811\n",
      "Iteration 3922, the loss is 4.526479493392594, parameters k is 11.50656890909174 and b is -49.62929644269475\n",
      "Iteration 3923, the loss is 4.52647884381106, parameters k is 11.506551608696483 and b is -49.629264822141394\n",
      "Iteration 3924, the loss is 4.526478194229521, parameters k is 11.506534308301227 and b is -49.629233201588036\n",
      "Iteration 3925, the loss is 4.526477806415309, parameters k is 11.50651700790597 and b is -49.62920158103468\n",
      "Iteration 3926, the loss is 4.526477201704951, parameters k is 11.506549604743915 and b is -49.62916205534298\n",
      "Iteration 3927, the loss is 4.5264765521234205, parameters k is 11.506532304348658 and b is -49.62913043478962\n",
      "Iteration 3928, the loss is 4.526475902541885, parameters k is 11.506515003953401 and b is -49.629098814236265\n",
      "Iteration 3929, the loss is 4.5264754651691375, parameters k is 11.506497703558145 and b is -49.62906719368291\n",
      "Iteration 3930, the loss is 4.52647491001732, parameters k is 11.50653030039609 and b is -49.62902766799121\n",
      "Iteration 3931, the loss is 4.526474260435787, parameters k is 11.506513000000833 and b is -49.62899604743785\n",
      "Iteration 3932, the loss is 4.5264736108542465, parameters k is 11.506495699605576 and b is -49.628964426884494\n",
      "Iteration 3933, the loss is 4.526473123922972, parameters k is 11.50647839921032 and b is -49.628932806331136\n",
      "Iteration 3934, the loss is 4.526472618329676, parameters k is 11.506510996048265 and b is -49.62889328063944\n",
      "Iteration 3935, the loss is 4.526471968748149, parameters k is 11.506493695653008 and b is -49.62886166008608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3936, the loss is 4.526471319166605, parameters k is 11.506476395257751 and b is -49.62883003953272\n",
      "Iteration 3937, the loss is 4.526470782676799, parameters k is 11.506459094862494 and b is -49.628798418979365\n",
      "Iteration 3938, the loss is 4.526470326642045, parameters k is 11.50649169170044 and b is -49.62875889328767\n",
      "Iteration 3939, the loss is 4.526469677060508, parameters k is 11.506474391305183 and b is -49.62872727273431\n",
      "Iteration 3940, the loss is 4.526469027478971, parameters k is 11.506457090909926 and b is -49.62869565218095\n",
      "Iteration 3941, the loss is 4.5264684414306355, parameters k is 11.50643979051467 and b is -49.62866403162759\n",
      "Iteration 3942, the loss is 4.526468034954406, parameters k is 11.506472387352614 and b is -49.628624505935896\n",
      "Iteration 3943, the loss is 4.526467385372873, parameters k is 11.506455086957358 and b is -49.62859288538254\n",
      "Iteration 3944, the loss is 4.526466735791336, parameters k is 11.5064377865621 and b is -49.62856126482918\n",
      "Iteration 3945, the loss is 4.526466100184467, parameters k is 11.506420486166844 and b is -49.62852964427582\n",
      "Iteration 3946, the loss is 4.52646574326677, parameters k is 11.50645308300479 and b is -49.628490118584125\n",
      "Iteration 3947, the loss is 4.526465093685234, parameters k is 11.506435782609532 and b is -49.62845849803077\n",
      "Iteration 3948, the loss is 4.526464444103701, parameters k is 11.506418482214276 and b is -49.62842687747741\n",
      "Iteration 3949, the loss is 4.526463794522162, parameters k is 11.506401181819019 and b is -49.62839525692405\n",
      "Iteration 3950, the loss is 4.5264634159952655, parameters k is 11.506383881423762 and b is -49.62836363637069\n",
      "Iteration 3951, the loss is 4.52646280199759, parameters k is 11.506416478261707 and b is -49.628324110678996\n",
      "Iteration 3952, the loss is 4.526462152416059, parameters k is 11.50639917786645 and b is -49.62829249012564\n",
      "Iteration 3953, the loss is 4.526461502834526, parameters k is 11.506381877471194 and b is -49.62826086957228\n",
      "Iteration 3954, the loss is 4.526461074749104, parameters k is 11.506364577075937 and b is -49.62822924901892\n",
      "Iteration 3955, the loss is 4.52646051030996, parameters k is 11.506397173913882 and b is -49.628189723327225\n",
      "Iteration 3956, the loss is 4.526459860728425, parameters k is 11.506379873518625 and b is -49.62815810277387\n",
      "Iteration 3957, the loss is 4.526459211146887, parameters k is 11.506362573123369 and b is -49.62812648222051\n",
      "Iteration 3958, the loss is 4.52645873350293, parameters k is 11.506345272728112 and b is -49.62809486166715\n",
      "Iteration 3959, the loss is 4.526458218622318, parameters k is 11.506377869566057 and b is -49.62805533597545\n",
      "Iteration 3960, the loss is 4.526457569040785, parameters k is 11.5063605691708 and b is -49.628023715422096\n",
      "Iteration 3961, the loss is 4.526456919459252, parameters k is 11.506343268775543 and b is -49.62799209486874\n",
      "Iteration 3962, the loss is 4.526456392256759, parameters k is 11.506325968380287 and b is -49.62796047431538\n",
      "Iteration 3963, the loss is 4.52645592693468, parameters k is 11.506358565218232 and b is -49.62792094862368\n",
      "Iteration 3964, the loss is 4.526455277353147, parameters k is 11.506341264822975 and b is -49.627889328070324\n",
      "Iteration 3965, the loss is 4.526454627771616, parameters k is 11.506323964427718 and b is -49.62785770751697\n",
      "Iteration 3966, the loss is 4.526454051010598, parameters k is 11.506306664032461 and b is -49.62782608696361\n",
      "Iteration 3967, the loss is 4.526453635247044, parameters k is 11.506339260870407 and b is -49.62778656127191\n",
      "Iteration 3968, the loss is 4.526452985665515, parameters k is 11.50632196047515 and b is -49.62775494071855\n",
      "Iteration 3969, the loss is 4.526452336083972, parameters k is 11.506304660079893 and b is -49.627723320165195\n",
      "Iteration 3970, the loss is 4.526451709764427, parameters k is 11.506287359684636 and b is -49.62769169961184\n",
      "Iteration 3971, the loss is 4.52645134355941, parameters k is 11.506319956522582 and b is -49.62765217392014\n",
      "Iteration 3972, the loss is 4.526450693977872, parameters k is 11.506302656127325 and b is -49.62762055336678\n",
      "Iteration 3973, the loss is 4.5264500443963405, parameters k is 11.506285355732068 and b is -49.627588932813424\n",
      "Iteration 3974, the loss is 4.5264493948148035, parameters k is 11.506268055336811 and b is -49.627557312260066\n",
      "Iteration 3975, the loss is 4.526449025575225, parameters k is 11.506250754941554 and b is -49.62752569170671\n",
      "Iteration 3976, the loss is 4.526448402290235, parameters k is 11.5062833517795 and b is -49.62748616601501\n",
      "Iteration 3977, the loss is 4.526447752708696, parameters k is 11.506266051384243 and b is -49.62745454546165\n",
      "Iteration 3978, the loss is 4.526447103127167, parameters k is 11.506248750988986 and b is -49.627422924908295\n",
      "Iteration 3979, the loss is 4.526446684329057, parameters k is 11.506231450593729 and b is -49.62739130435494\n",
      "Iteration 3980, the loss is 4.526446110602594, parameters k is 11.506264047431674 and b is -49.62735177866324\n",
      "Iteration 3981, the loss is 4.526445461021066, parameters k is 11.506246747036418 and b is -49.62732015810988\n",
      "Iteration 3982, the loss is 4.526444811439525, parameters k is 11.50622944664116 and b is -49.627288537556524\n",
      "Iteration 3983, the loss is 4.526444343082888, parameters k is 11.506212146245904 and b is -49.627256917003166\n",
      "Iteration 3984, the loss is 4.526443818914965, parameters k is 11.50624474308385 and b is -49.62721739131147\n",
      "Iteration 3985, the loss is 4.526443169333428, parameters k is 11.506227442688592 and b is -49.62718577075811\n",
      "Iteration 3986, the loss is 4.52644251975189, parameters k is 11.506210142293336 and b is -49.62715415020475\n",
      "Iteration 3987, the loss is 4.526442001836722, parameters k is 11.506192841898079 and b is -49.627122529651395\n",
      "Iteration 3988, the loss is 4.526441527227319, parameters k is 11.506225438736024 and b is -49.6270830039597\n",
      "Iteration 3989, the loss is 4.526440877645789, parameters k is 11.506208138340767 and b is -49.62705138340634\n",
      "Iteration 3990, the loss is 4.526440228064248, parameters k is 11.50619083794551 and b is -49.62701976285298\n",
      "Iteration 3991, the loss is 4.526439660590552, parameters k is 11.506173537550254 and b is -49.62698814229962\n",
      "Iteration 3992, the loss is 4.526439235539685, parameters k is 11.506206134388199 and b is -49.626948616607926\n",
      "Iteration 3993, the loss is 4.526438585958148, parameters k is 11.506188833992942 and b is -49.62691699605457\n",
      "Iteration 3994, the loss is 4.526437936376613, parameters k is 11.506171533597685 and b is -49.62688537550121\n",
      "Iteration 3995, the loss is 4.52643731934438, parameters k is 11.506154233202428 and b is -49.62685375494785\n",
      "Iteration 3996, the loss is 4.526436943852044, parameters k is 11.506186830040374 and b is -49.626814229256155\n",
      "Iteration 3997, the loss is 4.52643629427051, parameters k is 11.506169529645117 and b is -49.6267826087028\n",
      "Iteration 3998, the loss is 4.526435644688974, parameters k is 11.50615222924986 and b is -49.62675098814944\n",
      "Iteration 3999, the loss is 4.526434995107442, parameters k is 11.506134928854603 and b is -49.62671936759608\n",
      "Iteration 4000, the loss is 4.526434635155181, parameters k is 11.506117628459346 and b is -49.62668774704272\n",
      "Iteration 4001, the loss is 4.526434002582876, parameters k is 11.506150225297292 and b is -49.626648221351026\n",
      "Iteration 4002, the loss is 4.526433353001336, parameters k is 11.506132924902035 and b is -49.62661660079767\n",
      "Iteration 4003, the loss is 4.526432703419801, parameters k is 11.506115624506778 and b is -49.62658498024431\n",
      "Iteration 4004, the loss is 4.526432293909014, parameters k is 11.506098324111521 and b is -49.62655335969095\n",
      "Iteration 4005, the loss is 4.526431710895237, parameters k is 11.506130920949467 and b is -49.626513833999255\n",
      "Iteration 4006, the loss is 4.526431061313699, parameters k is 11.50611362055421 and b is -49.6264822134459\n",
      "Iteration 4007, the loss is 4.526430411732168, parameters k is 11.506096320158953 and b is -49.62645059289254\n",
      "Iteration 4008, the loss is 4.5264299526628475, parameters k is 11.506079019763696 and b is -49.62641897233918\n",
      "Iteration 4009, the loss is 4.526429419207599, parameters k is 11.506111616601642 and b is -49.62637944664748\n",
      "Iteration 4010, the loss is 4.526428769626064, parameters k is 11.506094316206385 and b is -49.626347826094126\n",
      "Iteration 4011, the loss is 4.526428120044531, parameters k is 11.506077015811128 and b is -49.62631620554077\n",
      "Iteration 4012, the loss is 4.526427611416677, parameters k is 11.506059715415871 and b is -49.62628458498741\n",
      "Iteration 4013, the loss is 4.526427127519965, parameters k is 11.506092312253816 and b is -49.62624505929571\n",
      "Iteration 4014, the loss is 4.526426477938428, parameters k is 11.50607501185856 and b is -49.626213438742354\n",
      "Iteration 4015, the loss is 4.526425828356892, parameters k is 11.506057711463303 and b is -49.626181818188996\n",
      "Iteration 4016, the loss is 4.52642527017051, parameters k is 11.506040411068046 and b is -49.62615019763564\n",
      "Iteration 4017, the loss is 4.526424835832323, parameters k is 11.506073007905991 and b is -49.62611067194394\n",
      "Iteration 4018, the loss is 4.526424186250786, parameters k is 11.506055707510734 and b is -49.62607905139058\n",
      "Iteration 4019, the loss is 4.526423536669255, parameters k is 11.506038407115478 and b is -49.626047430837225\n",
      "Iteration 4020, the loss is 4.526422928924346, parameters k is 11.50602110672022 and b is -49.62601581028387\n",
      "Iteration 4021, the loss is 4.5264225441446815, parameters k is 11.506053703558166 and b is -49.62597628459217\n",
      "Iteration 4022, the loss is 4.526421894563152, parameters k is 11.50603640316291 and b is -49.62594466403881\n",
      "Iteration 4023, the loss is 4.526421244981618, parameters k is 11.506019102767652 and b is -49.625913043485454\n",
      "Iteration 4024, the loss is 4.526420595400082, parameters k is 11.506001802372396 and b is -49.625881422932096\n",
      "Iteration 4025, the loss is 4.5264202447351405, parameters k is 11.505984501977139 and b is -49.62584980237874\n",
      "Iteration 4026, the loss is 4.526419602875515, parameters k is 11.506017098815084 and b is -49.62581027668704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4027, the loss is 4.526418953293975, parameters k is 11.505999798419827 and b is -49.62577865613368\n",
      "Iteration 4028, the loss is 4.526418303712447, parameters k is 11.50598249802457 and b is -49.625747035580325\n",
      "Iteration 4029, the loss is 4.526417903488972, parameters k is 11.505965197629314 and b is -49.62571541502697\n",
      "Iteration 4030, the loss is 4.526417311187875, parameters k is 11.505997794467259 and b is -49.62567588933527\n",
      "Iteration 4031, the loss is 4.526416661606339, parameters k is 11.505980494072002 and b is -49.62564426878191\n",
      "Iteration 4032, the loss is 4.5264160120248045, parameters k is 11.505963193676745 and b is -49.625612648228554\n",
      "Iteration 4033, the loss is 4.5264155622428035, parameters k is 11.505945893281488 and b is -49.625581027675196\n",
      "Iteration 4034, the loss is 4.5264150195002415, parameters k is 11.505978490119434 and b is -49.6255415019835\n",
      "Iteration 4035, the loss is 4.526414369918704, parameters k is 11.505961189724177 and b is -49.62550988143014\n",
      "Iteration 4036, the loss is 4.526413720337173, parameters k is 11.50594388932892 and b is -49.62547826087678\n",
      "Iteration 4037, the loss is 4.526413220996638, parameters k is 11.505926588933663 and b is -49.625446640323425\n",
      "Iteration 4038, the loss is 4.526412727812602, parameters k is 11.505959185771609 and b is -49.62540711463173\n",
      "Iteration 4039, the loss is 4.526412078231065, parameters k is 11.505941885376352 and b is -49.62537549407837\n",
      "Iteration 4040, the loss is 4.526411428649528, parameters k is 11.505924584981095 and b is -49.62534387352501\n",
      "Iteration 4041, the loss is 4.5264108797504665, parameters k is 11.505907284585838 and b is -49.62531225297165\n",
      "Iteration 4042, the loss is 4.52641043612497, parameters k is 11.505939881423783 and b is -49.625272727279956\n",
      "Iteration 4043, the loss is 4.526409786543427, parameters k is 11.505922581028527 and b is -49.6252411067266\n",
      "Iteration 4044, the loss is 4.526409136961894, parameters k is 11.50590528063327 and b is -49.62520948617324\n",
      "Iteration 4045, the loss is 4.526408538504303, parameters k is 11.505887980238013 and b is -49.62517786561988\n",
      "Iteration 4046, the loss is 4.526408144437325, parameters k is 11.505920577075958 and b is -49.625138339928185\n",
      "Iteration 4047, the loss is 4.526407494855791, parameters k is 11.505903276680701 and b is -49.62510671937483\n",
      "Iteration 4048, the loss is 4.526406845274257, parameters k is 11.505885976285445 and b is -49.62507509882147\n",
      "Iteration 4049, the loss is 4.5264061972581295, parameters k is 11.505868675890188 and b is -49.62504347826811\n",
      "Iteration 4050, the loss is 4.526405852749685, parameters k is 11.505901272728133 and b is -49.625003952576414\n",
      "Iteration 4051, the loss is 4.526405203168152, parameters k is 11.505883972332876 and b is -49.624972332023056\n",
      "Iteration 4052, the loss is 4.526404553586617, parameters k is 11.50586667193762 and b is -49.6249407114697\n",
      "Iteration 4053, the loss is 4.526403904005083, parameters k is 11.505849371542363 and b is -49.62490909091634\n",
      "Iteration 4054, the loss is 4.52640351306893, parameters k is 11.505832071147106 and b is -49.62487747036298\n",
      "Iteration 4055, the loss is 4.52640291148052, parameters k is 11.505864667985051 and b is -49.624837944671285\n",
      "Iteration 4056, the loss is 4.5264022618989825, parameters k is 11.505847367589794 and b is -49.62480632411793\n",
      "Iteration 4057, the loss is 4.526401612317446, parameters k is 11.505830067194537 and b is -49.62477470356457\n",
      "Iteration 4058, the loss is 4.526401171822761, parameters k is 11.50581276679928 and b is -49.62474308301121\n",
      "Iteration 4059, the loss is 4.526400619792881, parameters k is 11.505845363637226 and b is -49.62470355731951\n",
      "Iteration 4060, the loss is 4.5263999702113455, parameters k is 11.50582806324197 and b is -49.624671936766156\n",
      "Iteration 4061, the loss is 4.5263993206298085, parameters k is 11.505810762846712 and b is -49.6246403162128\n",
      "Iteration 4062, the loss is 4.526398830576593, parameters k is 11.505793462451456 and b is -49.62460869565944\n",
      "Iteration 4063, the loss is 4.52639832810524, parameters k is 11.5058260592894 and b is -49.62456916996774\n",
      "Iteration 4064, the loss is 4.526397678523701, parameters k is 11.505808758894144 and b is -49.624537549414384\n",
      "Iteration 4065, the loss is 4.5263970289421716, parameters k is 11.505791458498887 and b is -49.624505928861026\n",
      "Iteration 4066, the loss is 4.526396489330424, parameters k is 11.50577415810363 and b is -49.62447430830767\n",
      "Iteration 4067, the loss is 4.526396036417606, parameters k is 11.505806754941576 and b is -49.62443478261597\n",
      "Iteration 4068, the loss is 4.52639538683607, parameters k is 11.505789454546319 and b is -49.62440316206261\n",
      "Iteration 4069, the loss is 4.526394737254526, parameters k is 11.505772154151062 and b is -49.624371541509255\n",
      "Iteration 4070, the loss is 4.526394148084255, parameters k is 11.505754853755805 and b is -49.6243399209559\n",
      "Iteration 4071, the loss is 4.526393744729965, parameters k is 11.50578745059375 and b is -49.6243003952642\n",
      "Iteration 4072, the loss is 4.526393095148425, parameters k is 11.505770150198494 and b is -49.62426877471084\n",
      "Iteration 4073, the loss is 4.526392445566893, parameters k is 11.505752849803237 and b is -49.624237154157484\n",
      "Iteration 4074, the loss is 4.526391806838093, parameters k is 11.50573554940798 and b is -49.624205533604126\n",
      "Iteration 4075, the loss is 4.52639145304233, parameters k is 11.505768146245925 and b is -49.62416600791243\n",
      "Iteration 4076, the loss is 4.52639080346079, parameters k is 11.505750845850669 and b is -49.62413438735907\n",
      "Iteration 4077, the loss is 4.526390153879254, parameters k is 11.505733545455412 and b is -49.62410276680571\n",
      "Iteration 4078, the loss is 4.5263895042977245, parameters k is 11.505716245060155 and b is -49.624071146252355\n",
      "Iteration 4079, the loss is 4.526389122648889, parameters k is 11.505698944664898 and b is -49.624039525699\n",
      "Iteration 4080, the loss is 4.526388511773154, parameters k is 11.505731541502843 and b is -49.6240000000073\n",
      "Iteration 4081, the loss is 4.526387862191617, parameters k is 11.505714241107587 and b is -49.62396837945394\n",
      "Iteration 4082, the loss is 4.526387212610083, parameters k is 11.50569694071233 and b is -49.623936758900584\n",
      "Iteration 4083, the loss is 4.52638678140272, parameters k is 11.505679640317073 and b is -49.623905138347226\n",
      "Iteration 4084, the loss is 4.526386220085519, parameters k is 11.505712237155018 and b is -49.62386561265553\n",
      "Iteration 4085, the loss is 4.526385570503977, parameters k is 11.505694936759761 and b is -49.62383399210217\n",
      "Iteration 4086, the loss is 4.526384920922448, parameters k is 11.505677636364505 and b is -49.62380237154881\n",
      "Iteration 4087, the loss is 4.526384440156557, parameters k is 11.505660335969248 and b is -49.623770750995455\n",
      "Iteration 4088, the loss is 4.52638392839788, parameters k is 11.505692932807193 and b is -49.62373122530376\n",
      "Iteration 4089, the loss is 4.5263832788163425, parameters k is 11.505675632411936 and b is -49.6236996047504\n",
      "Iteration 4090, the loss is 4.526382629234813, parameters k is 11.50565833201668 and b is -49.62366798419704\n",
      "Iteration 4091, the loss is 4.526382098910383, parameters k is 11.505641031621423 and b is -49.62363636364368\n",
      "Iteration 4092, the loss is 4.526381636710238, parameters k is 11.505673628459368 and b is -49.623596837951986\n",
      "Iteration 4093, the loss is 4.526380987128704, parameters k is 11.505656328064111 and b is -49.62356521739863\n",
      "Iteration 4094, the loss is 4.526380337547174, parameters k is 11.505639027668854 and b is -49.62353359684527\n",
      "Iteration 4095, the loss is 4.526379757664215, parameters k is 11.505621727273597 and b is -49.62350197629191\n",
      "Iteration 4096, the loss is 4.526379345022606, parameters k is 11.505654324111543 and b is -49.623462450600215\n",
      "Iteration 4097, the loss is 4.526378695441067, parameters k is 11.505637023716286 and b is -49.62343083004686\n",
      "Iteration 4098, the loss is 4.526378045859534, parameters k is 11.50561972332103 and b is -49.6233992094935\n",
      "Iteration 4099, the loss is 4.52637741641805, parameters k is 11.505602422925772 and b is -49.62336758894014\n",
      "Iteration 4100, the loss is 4.526377053334964, parameters k is 11.505635019763718 and b is -49.623328063248444\n",
      "Iteration 4101, the loss is 4.526376403753433, parameters k is 11.50561771936846 and b is -49.623296442695086\n",
      "Iteration 4102, the loss is 4.526375754171895, parameters k is 11.505600418973204 and b is -49.62326482214173\n",
      "Iteration 4103, the loss is 4.526375104590365, parameters k is 11.505583118577947 and b is -49.62323320158837\n",
      "Iteration 4104, the loss is 4.526374732228853, parameters k is 11.50556581818269 and b is -49.62320158103501\n",
      "Iteration 4105, the loss is 4.5263741120657945, parameters k is 11.505598415020636 and b is -49.623162055343315\n",
      "Iteration 4106, the loss is 4.526373462484261, parameters k is 11.505581114625379 and b is -49.62313043478996\n",
      "Iteration 4107, the loss is 4.526372812902722, parameters k is 11.505563814230122 and b is -49.6230988142366\n",
      "Iteration 4108, the loss is 4.526372390982679, parameters k is 11.505546513834865 and b is -49.62306719368324\n",
      "Iteration 4109, the loss is 4.526371820378159, parameters k is 11.50557911067281 and b is -49.62302766799154\n",
      "Iteration 4110, the loss is 4.526371170796618, parameters k is 11.505561810277554 and b is -49.622996047438185\n",
      "Iteration 4111, the loss is 4.526370521215084, parameters k is 11.505544509882297 and b is -49.62296442688483\n",
      "Iteration 4112, the loss is 4.526370049736514, parameters k is 11.50552720948704 and b is -49.62293280633147\n",
      "Iteration 4113, the loss is 4.526369528690519, parameters k is 11.505559806324985 and b is -49.62289328063977\n",
      "Iteration 4114, the loss is 4.526368879108984, parameters k is 11.505542505929728 and b is -49.622861660086414\n",
      "Iteration 4115, the loss is 4.526368229527448, parameters k is 11.505525205534472 and b is -49.622830039533056\n",
      "Iteration 4116, the loss is 4.526367708490344, parameters k is 11.505507905139215 and b is -49.6227984189797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4117, the loss is 4.526367237002882, parameters k is 11.50554050197716 and b is -49.622758893288\n",
      "Iteration 4118, the loss is 4.526366587421345, parameters k is 11.505523201581903 and b is -49.62272727273464\n",
      "Iteration 4119, the loss is 4.526365937839812, parameters k is 11.505505901186647 and b is -49.622695652181285\n",
      "Iteration 4120, the loss is 4.526365367244178, parameters k is 11.50548860079139 and b is -49.62266403162793\n",
      "Iteration 4121, the loss is 4.52636494531524, parameters k is 11.505521197629335 and b is -49.62262450593623\n",
      "Iteration 4122, the loss is 4.526364295733708, parameters k is 11.505503897234078 and b is -49.62259288538287\n",
      "Iteration 4123, the loss is 4.526363646152174, parameters k is 11.505486596838821 and b is -49.622561264829514\n",
      "Iteration 4124, the loss is 4.526363025998004, parameters k is 11.505469296443565 and b is -49.622529644276156\n",
      "Iteration 4125, the loss is 4.526362653627608, parameters k is 11.50550189328151 and b is -49.62249011858446\n",
      "Iteration 4126, the loss is 4.526362004046069, parameters k is 11.505484592886253 and b is -49.6224584980311\n",
      "Iteration 4127, the loss is 4.526361354464532, parameters k is 11.505467292490996 and b is -49.62242687747774\n",
      "Iteration 4128, the loss is 4.526360704883002, parameters k is 11.50544999209574 and b is -49.622395256924385\n",
      "Iteration 4129, the loss is 4.5263603418088065, parameters k is 11.505432691700483 and b is -49.62236363637103\n",
      "Iteration 4130, the loss is 4.526359712358433, parameters k is 11.505465288538428 and b is -49.62232411067933\n",
      "Iteration 4131, the loss is 4.526359062776898, parameters k is 11.505447988143171 and b is -49.62229249012597\n",
      "Iteration 4132, the loss is 4.5263584131953625, parameters k is 11.505430687747914 and b is -49.622260869572614\n",
      "Iteration 4133, the loss is 4.526358000562636, parameters k is 11.505413387352657 and b is -49.622229249019256\n",
      "Iteration 4134, the loss is 4.526357420670797, parameters k is 11.505445984190603 and b is -49.62218972332756\n",
      "Iteration 4135, the loss is 4.526356771089259, parameters k is 11.505428683795346 and b is -49.6221581027742\n",
      "Iteration 4136, the loss is 4.526356121507724, parameters k is 11.505411383400089 and b is -49.62212648222084\n",
      "Iteration 4137, the loss is 4.526355659316469, parameters k is 11.505394083004832 and b is -49.622094861667485\n",
      "Iteration 4138, the loss is 4.526355128983157, parameters k is 11.505426679842778 and b is -49.62205533597579\n",
      "Iteration 4139, the loss is 4.526354479401619, parameters k is 11.50540937944752 and b is -49.62202371542243\n",
      "Iteration 4140, the loss is 4.526353829820086, parameters k is 11.505392079052264 and b is -49.62199209486907\n",
      "Iteration 4141, the loss is 4.5263533180703055, parameters k is 11.505374778657007 and b is -49.62196047431571\n",
      "Iteration 4142, the loss is 4.526352837295521, parameters k is 11.505407375494952 and b is -49.621920948624016\n",
      "Iteration 4143, the loss is 4.526352187713983, parameters k is 11.505390075099696 and b is -49.62188932807066\n",
      "Iteration 4144, the loss is 4.526351538132453, parameters k is 11.505372774704439 and b is -49.6218577075173\n",
      "Iteration 4145, the loss is 4.526350976824137, parameters k is 11.505355474309182 and b is -49.62182608696394\n",
      "Iteration 4146, the loss is 4.526350545607881, parameters k is 11.505388071147127 and b is -49.621786561272245\n",
      "Iteration 4147, the loss is 4.526349896026347, parameters k is 11.50537077075187 and b is -49.62175494071889\n",
      "Iteration 4148, the loss is 4.52634924644481, parameters k is 11.505353470356614 and b is -49.62172332016553\n",
      "Iteration 4149, the loss is 4.526348635577968, parameters k is 11.505336169961357 and b is -49.62169169961217\n",
      "Iteration 4150, the loss is 4.526348253920241, parameters k is 11.505368766799302 and b is -49.621652173920474\n",
      "Iteration 4151, the loss is 4.526347604338706, parameters k is 11.505351466404045 and b is -49.621620553367116\n",
      "Iteration 4152, the loss is 4.526346954757175, parameters k is 11.505334166008788 and b is -49.62158893281376\n",
      "Iteration 4153, the loss is 4.526346305175637, parameters k is 11.505316865613532 and b is -49.6215573122604\n",
      "Iteration 4154, the loss is 4.5263459513887625, parameters k is 11.505299565218275 and b is -49.62152569170704\n",
      "Iteration 4155, the loss is 4.526345312651075, parameters k is 11.50533216205622 and b is -49.621486166015345\n",
      "Iteration 4156, the loss is 4.526344663069539, parameters k is 11.505314861660963 and b is -49.62145454546199\n",
      "Iteration 4157, the loss is 4.5263440134880035, parameters k is 11.505297561265706 and b is -49.62142292490863\n",
      "Iteration 4158, the loss is 4.5263436101426, parameters k is 11.50528026087045 and b is -49.62139130435527\n",
      "Iteration 4159, the loss is 4.526343020963436, parameters k is 11.505312857708395 and b is -49.62135177866357\n",
      "Iteration 4160, the loss is 4.526342371381903, parameters k is 11.505295557313138 and b is -49.621320158110215\n",
      "Iteration 4161, the loss is 4.526341721800365, parameters k is 11.505278256917881 and b is -49.62128853755686\n",
      "Iteration 4162, the loss is 4.526341268896427, parameters k is 11.505260956522624 and b is -49.6212569170035\n",
      "Iteration 4163, the loss is 4.526340729275799, parameters k is 11.50529355336057 and b is -49.6212173913118\n",
      "Iteration 4164, the loss is 4.52634007969426, parameters k is 11.505276252965313 and b is -49.621185770758444\n",
      "Iteration 4165, the loss is 4.526339430112724, parameters k is 11.505258952570056 and b is -49.621154150205086\n",
      "Iteration 4166, the loss is 4.526338927650258, parameters k is 11.5052416521748 and b is -49.62112252965173\n",
      "Iteration 4167, the loss is 4.5263384375881595, parameters k is 11.505274249012745 and b is -49.62108300396003\n",
      "Iteration 4168, the loss is 4.526337788006625, parameters k is 11.505256948617488 and b is -49.62105138340667\n",
      "Iteration 4169, the loss is 4.52633713842509, parameters k is 11.505239648222231 and b is -49.621019762853315\n",
      "Iteration 4170, the loss is 4.526336586404092, parameters k is 11.505222347826974 and b is -49.62098814229996\n",
      "Iteration 4171, the loss is 4.5263361459005225, parameters k is 11.50525494466492 and b is -49.62094861660826\n",
      "Iteration 4172, the loss is 4.52633549631899, parameters k is 11.505237644269663 and b is -49.6209169960549\n",
      "Iteration 4173, the loss is 4.526334846737449, parameters k is 11.505220343874406 and b is -49.620885375501544\n",
      "Iteration 4174, the loss is 4.526334245157926, parameters k is 11.505203043479149 and b is -49.620853754948186\n",
      "Iteration 4175, the loss is 4.526333854212883, parameters k is 11.505235640317094 and b is -49.62081422925649\n",
      "Iteration 4176, the loss is 4.526333204631347, parameters k is 11.505218339921838 and b is -49.62078260870313\n",
      "Iteration 4177, the loss is 4.526332555049819, parameters k is 11.50520103952658 and b is -49.62075098814977\n",
      "Iteration 4178, the loss is 4.526331905468279, parameters k is 11.505183739131324 and b is -49.620719367596415\n",
      "Iteration 4179, the loss is 4.5263315609687265, parameters k is 11.505166438736067 and b is -49.62068774704306\n",
      "Iteration 4180, the loss is 4.526330912943709, parameters k is 11.505199035574012 and b is -49.62064822135136\n",
      "Iteration 4181, the loss is 4.526330263362177, parameters k is 11.505181735178756 and b is -49.620616600798\n",
      "Iteration 4182, the loss is 4.526329613780641, parameters k is 11.505164434783499 and b is -49.620584980244644\n",
      "Iteration 4183, the loss is 4.526329219722554, parameters k is 11.505147134388242 and b is -49.620553359691286\n",
      "Iteration 4184, the loss is 4.526328621256079, parameters k is 11.505179731226187 and b is -49.62051383399959\n",
      "Iteration 4185, the loss is 4.526327971674537, parameters k is 11.50516243083093 and b is -49.62048221344623\n",
      "Iteration 4186, the loss is 4.526327322093005, parameters k is 11.505145130435674 and b is -49.62045059289287\n",
      "Iteration 4187, the loss is 4.526326878476388, parameters k is 11.505127830040417 and b is -49.620418972339515\n",
      "Iteration 4188, the loss is 4.526326329568437, parameters k is 11.505160426878362 and b is -49.62037944664782\n",
      "Iteration 4189, the loss is 4.526325679986902, parameters k is 11.505143126483105 and b is -49.62034782609446\n",
      "Iteration 4190, the loss is 4.526325030405365, parameters k is 11.505125826087848 and b is -49.6203162055411\n",
      "Iteration 4191, the loss is 4.526324537230221, parameters k is 11.505108525692592 and b is -49.62028458498774\n",
      "Iteration 4192, the loss is 4.526324037880803, parameters k is 11.505141122530537 and b is -49.620245059296046\n",
      "Iteration 4193, the loss is 4.526323388299261, parameters k is 11.50512382213528 and b is -49.62021343874269\n",
      "Iteration 4194, the loss is 4.52632273871773, parameters k is 11.505106521740023 and b is -49.62018181818933\n",
      "Iteration 4195, the loss is 4.526322195984049, parameters k is 11.505089221344766 and b is -49.62015019763597\n",
      "Iteration 4196, the loss is 4.526321746193165, parameters k is 11.505121818182712 and b is -49.620110671944275\n",
      "Iteration 4197, the loss is 4.52632109661163, parameters k is 11.505104517787455 and b is -49.62007905139092\n",
      "Iteration 4198, the loss is 4.526320447030091, parameters k is 11.505087217392198 and b is -49.62004743083756\n",
      "Iteration 4199, the loss is 4.526319854737883, parameters k is 11.505069916996941 and b is -49.6200158102842\n",
      "Iteration 4200, the loss is 4.526319454505529, parameters k is 11.505102513834887 and b is -49.619976284592504\n",
      "Iteration 4201, the loss is 4.526318804923988, parameters k is 11.50508521343963 and b is -49.619944664039146\n",
      "Iteration 4202, the loss is 4.526318155342453, parameters k is 11.505067913044373 and b is -49.61991304348579\n",
      "Iteration 4203, the loss is 4.52631751349171, parameters k is 11.505050612649116 and b is -49.61988142293243\n",
      "Iteration 4204, the loss is 4.526317162817888, parameters k is 11.505083209487061 and b is -49.61984189724073\n",
      "Iteration 4205, the loss is 4.526316513236348, parameters k is 11.505065909091805 and b is -49.619810276687375\n",
      "Iteration 4206, the loss is 4.5263158636548155, parameters k is 11.505048608696548 and b is -49.61977865613402\n",
      "Iteration 4207, the loss is 4.526315214073281, parameters k is 11.505031308301291 and b is -49.61974703558066\n",
      "Iteration 4208, the loss is 4.526314829302516, parameters k is 11.505014007906034 and b is -49.6197154150273\n",
      "Iteration 4209, the loss is 4.526314221548708, parameters k is 11.50504660474398 and b is -49.6196758893356\n",
      "Iteration 4210, the loss is 4.526313571967175, parameters k is 11.505029304348723 and b is -49.619644268782245\n",
      "Iteration 4211, the loss is 4.526312922385637, parameters k is 11.505012003953466 and b is -49.61961264822889\n",
      "Iteration 4212, the loss is 4.526312488056345, parameters k is 11.504994703558209 and b is -49.61958102767553\n",
      "Iteration 4213, the loss is 4.526311929861072, parameters k is 11.505027300396154 and b is -49.61954150198383\n",
      "Iteration 4214, the loss is 4.526311280279545, parameters k is 11.505010000000897 and b is -49.619509881430474\n",
      "Iteration 4215, the loss is 4.526310630698008, parameters k is 11.50499269960564 and b is -49.619478260877116\n",
      "Iteration 4216, the loss is 4.5263101468101805, parameters k is 11.504975399210384 and b is -49.61944664032376\n",
      "Iteration 4217, the loss is 4.52630963817344, parameters k is 11.50500799604833 and b is -49.61940711463206\n",
      "Iteration 4218, the loss is 4.526308988591907, parameters k is 11.504990695653072 and b is -49.6193754940787\n",
      "Iteration 4219, the loss is 4.5263083390103676, parameters k is 11.504973395257815 and b is -49.619343873525345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4220, the loss is 4.526307805564008, parameters k is 11.504956094862559 and b is -49.61931225297199\n",
      "Iteration 4221, the loss is 4.526307346485797, parameters k is 11.504988691700504 and b is -49.61927272728029\n",
      "Iteration 4222, the loss is 4.526306696904268, parameters k is 11.504971391305247 and b is -49.61924110672693\n",
      "Iteration 4223, the loss is 4.5263060473227315, parameters k is 11.50495409090999 and b is -49.619209486173574\n",
      "Iteration 4224, the loss is 4.52630546431784, parameters k is 11.504936790514734 and b is -49.619177865620216\n",
      "Iteration 4225, the loss is 4.526305054798162, parameters k is 11.504969387352679 and b is -49.61913833992852\n",
      "Iteration 4226, the loss is 4.526304405216631, parameters k is 11.504952086957422 and b is -49.61910671937516\n",
      "Iteration 4227, the loss is 4.5263037556350945, parameters k is 11.504934786562165 and b is -49.6190750988218\n",
      "Iteration 4228, the loss is 4.52630312307167, parameters k is 11.504917486166908 and b is -49.619043478268445\n",
      "Iteration 4229, the loss is 4.526302763110526, parameters k is 11.504950083004854 and b is -49.61900395257675\n",
      "Iteration 4230, the loss is 4.52630211352899, parameters k is 11.504932782609597 and b is -49.61897233202339\n",
      "Iteration 4231, the loss is 4.526301463947454, parameters k is 11.50491548221434 and b is -49.61894071147003\n",
      "Iteration 4232, the loss is 4.52630081436592, parameters k is 11.504898181819083 and b is -49.618909090916674\n",
      "Iteration 4233, the loss is 4.526300438882473, parameters k is 11.504880881423826 and b is -49.618877470363316\n",
      "Iteration 4234, the loss is 4.5262998218413575, parameters k is 11.504913478261772 and b is -49.61883794467162\n",
      "Iteration 4235, the loss is 4.526299172259815, parameters k is 11.504896177866515 and b is -49.61880632411826\n",
      "Iteration 4236, the loss is 4.5262985226782835, parameters k is 11.504878877471258 and b is -49.6187747035649\n",
      "Iteration 4237, the loss is 4.526298097636307, parameters k is 11.504861577076001 and b is -49.618743083011545\n",
      "Iteration 4238, the loss is 4.5262975301537205, parameters k is 11.504894173913947 and b is -49.61870355731985\n",
      "Iteration 4239, the loss is 4.526296880572178, parameters k is 11.50487687351869 and b is -49.61867193676649\n",
      "Iteration 4240, the loss is 4.52629623099064, parameters k is 11.504859573123433 and b is -49.61864031621313\n",
      "Iteration 4241, the loss is 4.526295756390134, parameters k is 11.504842272728176 and b is -49.61860869565977\n",
      "Iteration 4242, the loss is 4.526295238466076, parameters k is 11.504874869566121 and b is -49.618569169968076\n",
      "Iteration 4243, the loss is 4.526294588884542, parameters k is 11.504857569170865 and b is -49.61853754941472\n",
      "Iteration 4244, the loss is 4.526293939303005, parameters k is 11.504840268775608 and b is -49.61850592886136\n",
      "Iteration 4245, the loss is 4.52629341514397, parameters k is 11.504822968380351 and b is -49.618474308308\n",
      "Iteration 4246, the loss is 4.526292946778442, parameters k is 11.504855565218296 and b is -49.618434782616305\n",
      "Iteration 4247, the loss is 4.52629229719691, parameters k is 11.50483826482304 and b is -49.61840316206295\n",
      "Iteration 4248, the loss is 4.526291647615371, parameters k is 11.504820964427783 and b is -49.61837154150959\n",
      "Iteration 4249, the loss is 4.526291073897797, parameters k is 11.504803664032526 and b is -49.61833992095623\n",
      "Iteration 4250, the loss is 4.526290655090802, parameters k is 11.504836260870471 and b is -49.618300395264534\n",
      "Iteration 4251, the loss is 4.526290005509269, parameters k is 11.504818960475214 and b is -49.618268774711176\n",
      "Iteration 4252, the loss is 4.526289355927733, parameters k is 11.504801660079957 and b is -49.61823715415782\n",
      "Iteration 4253, the loss is 4.5262887326516275, parameters k is 11.5047843596847 and b is -49.61820553360446\n",
      "Iteration 4254, the loss is 4.526288363403169, parameters k is 11.504816956522646 and b is -49.61816600791276\n",
      "Iteration 4255, the loss is 4.526287713821635, parameters k is 11.504799656127389 and b is -49.618134387359405\n",
      "Iteration 4256, the loss is 4.526287064240091, parameters k is 11.504782355732132 and b is -49.61810276680605\n",
      "Iteration 4257, the loss is 4.526286414658563, parameters k is 11.504765055336875 and b is -49.61807114625269\n",
      "Iteration 4258, the loss is 4.526286048462429, parameters k is 11.504747754941619 and b is -49.61803952569933\n",
      "Iteration 4259, the loss is 4.526285422133994, parameters k is 11.504780351779564 and b is -49.61800000000763\n",
      "Iteration 4260, the loss is 4.526284772552464, parameters k is 11.504763051384307 and b is -49.617968379454275\n",
      "Iteration 4261, the loss is 4.526284122970922, parameters k is 11.50474575098905 and b is -49.61793675890092\n",
      "Iteration 4262, the loss is 4.526283707216264, parameters k is 11.504728450593793 and b is -49.61790513834756\n",
      "Iteration 4263, the loss is 4.526283130446351, parameters k is 11.504761047431739 and b is -49.61786561265586\n",
      "Iteration 4264, the loss is 4.526282480864816, parameters k is 11.504743747036482 and b is -49.617833992102504\n",
      "Iteration 4265, the loss is 4.526281831283285, parameters k is 11.504726446641225 and b is -49.617802371549146\n",
      "Iteration 4266, the loss is 4.526281365970092, parameters k is 11.504709146245968 and b is -49.61777075099579\n",
      "Iteration 4267, the loss is 4.526280838758718, parameters k is 11.504741743083914 and b is -49.61773122530409\n",
      "Iteration 4268, the loss is 4.5262801891771876, parameters k is 11.504724442688657 and b is -49.61769960475073\n",
      "Iteration 4269, the loss is 4.526279539595649, parameters k is 11.5047071422934 and b is -49.617667984197375\n",
      "Iteration 4270, the loss is 4.526279024723926, parameters k is 11.504689841898143 and b is -49.61763636364402\n",
      "Iteration 4271, the loss is 4.5262785470710805, parameters k is 11.504722438736088 and b is -49.61759683795232\n",
      "Iteration 4272, the loss is 4.526277897489546, parameters k is 11.504705138340832 and b is -49.61756521739896\n",
      "Iteration 4273, the loss is 4.52627724790801, parameters k is 11.504687837945575 and b is -49.617533596845604\n",
      "Iteration 4274, the loss is 4.526276683477756, parameters k is 11.504670537550318 and b is -49.617501976292246\n",
      "Iteration 4275, the loss is 4.526276255383442, parameters k is 11.504703134388263 and b is -49.61746245060055\n",
      "Iteration 4276, the loss is 4.526275605801903, parameters k is 11.504685833993006 and b is -49.61743083004719\n",
      "Iteration 4277, the loss is 4.5262749562203695, parameters k is 11.50466853359775 and b is -49.61739920949383\n",
      "Iteration 4278, the loss is 4.526274342231591, parameters k is 11.504651233202493 and b is -49.617367588940475\n",
      "Iteration 4279, the loss is 4.5262739636958065, parameters k is 11.504683830040438 and b is -49.61732806324878\n",
      "Iteration 4280, the loss is 4.526273314114266, parameters k is 11.504666529645181 and b is -49.61729644269542\n",
      "Iteration 4281, the loss is 4.52627266453273, parameters k is 11.504649229249925 and b is -49.61726482214206\n",
      "Iteration 4282, the loss is 4.526272014951198, parameters k is 11.504631928854668 and b is -49.617233201588704\n",
      "Iteration 4283, the loss is 4.526271658042387, parameters k is 11.50461462845941 and b is -49.617201581035346\n",
      "Iteration 4284, the loss is 4.526271022426636, parameters k is 11.504647225297356 and b is -49.61716205534365\n",
      "Iteration 4285, the loss is 4.5262703728450955, parameters k is 11.5046299249021 and b is -49.61713043479029\n",
      "Iteration 4286, the loss is 4.526269723263559, parameters k is 11.504612624506843 and b is -49.61709881423693\n",
      "Iteration 4287, the loss is 4.526269316796222, parameters k is 11.504595324111586 and b is -49.617067193683575\n",
      "Iteration 4288, the loss is 4.526268730738996, parameters k is 11.504627920949531 and b is -49.61702766799188\n",
      "Iteration 4289, the loss is 4.5262680811574585, parameters k is 11.504610620554274 and b is -49.61699604743852\n",
      "Iteration 4290, the loss is 4.526267431575929, parameters k is 11.504593320159017 and b is -49.61696442688516\n",
      "Iteration 4291, the loss is 4.526266975550056, parameters k is 11.50457601976376 and b is -49.6169328063318\n",
      "Iteration 4292, the loss is 4.526266439051358, parameters k is 11.504608616601706 and b is -49.616893280640106\n",
      "Iteration 4293, the loss is 4.526265789469821, parameters k is 11.504591316206449 and b is -49.61686166008675\n",
      "Iteration 4294, the loss is 4.526265139888286, parameters k is 11.504574015811192 and b is -49.61683003953339\n",
      "Iteration 4295, the loss is 4.526264634303883, parameters k is 11.504556715415935 and b is -49.61679841898003\n",
      "Iteration 4296, the loss is 4.5262641473637135, parameters k is 11.50458931225388 and b is -49.616758893288335\n",
      "Iteration 4297, the loss is 4.526263497782185, parameters k is 11.504572011858624 and b is -49.61672727273498\n",
      "Iteration 4298, the loss is 4.5262628482006475, parameters k is 11.504554711463367 and b is -49.61669565218162\n",
      "Iteration 4299, the loss is 4.526262293057717, parameters k is 11.50453741106811 and b is -49.61666403162826\n",
      "Iteration 4300, the loss is 4.526261855676079, parameters k is 11.504570007906056 and b is -49.616624505936564\n",
      "Iteration 4301, the loss is 4.52626120609455, parameters k is 11.504552707510799 and b is -49.616592885383206\n",
      "Iteration 4302, the loss is 4.526260556513013, parameters k is 11.504535407115542 and b is -49.61656126482985\n",
      "Iteration 4303, the loss is 4.52625995181155, parameters k is 11.504518106720285 and b is -49.61652964427649\n",
      "Iteration 4304, the loss is 4.5262595639884395, parameters k is 11.50455070355823 and b is -49.61649011858479\n",
      "Iteration 4305, the loss is 4.52625891440691, parameters k is 11.504533403162974 and b is -49.616458498031434\n",
      "Iteration 4306, the loss is 4.526258264825371, parameters k is 11.504516102767717 and b is -49.61642687747808\n",
      "Iteration 4307, the loss is 4.526257615243842, parameters k is 11.50449880237246 and b is -49.61639525692472\n",
      "Iteration 4308, the loss is 4.5262572676223485, parameters k is 11.504481501977203 and b is -49.61636363637136\n",
      "Iteration 4309, the loss is 4.526256622719275, parameters k is 11.504514098815148 and b is -49.61632411067966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4310, the loss is 4.526255973137736, parameters k is 11.504496798419892 and b is -49.616292490126305\n",
      "Iteration 4311, the loss is 4.526255323556201, parameters k is 11.504479498024635 and b is -49.61626086957295\n",
      "Iteration 4312, the loss is 4.526254926376174, parameters k is 11.504462197629378 and b is -49.61622924901959\n",
      "Iteration 4313, the loss is 4.526254331031631, parameters k is 11.504494794467323 and b is -49.61618972332789\n",
      "Iteration 4314, the loss is 4.526253681450097, parameters k is 11.504477494072066 and b is -49.616158102774534\n",
      "Iteration 4315, the loss is 4.526253031868567, parameters k is 11.50446019367681 and b is -49.616126482221176\n",
      "Iteration 4316, the loss is 4.526252585130011, parameters k is 11.504442893281553 and b is -49.61609486166782\n",
      "Iteration 4317, the loss is 4.526252039343996, parameters k is 11.504475490119498 and b is -49.61605533597612\n",
      "Iteration 4318, the loss is 4.526251389762462, parameters k is 11.504458189724241 and b is -49.61602371542276\n",
      "Iteration 4319, the loss is 4.5262507401809255, parameters k is 11.504440889328984 and b is -49.615992094869405\n",
      "Iteration 4320, the loss is 4.526250243883841, parameters k is 11.504423588933728 and b is -49.61596047431605\n",
      "Iteration 4321, the loss is 4.526249747656354, parameters k is 11.504456185771673 and b is -49.61592094862435\n",
      "Iteration 4322, the loss is 4.526249098074825, parameters k is 11.504438885376416 and b is -49.61588932807099\n",
      "Iteration 4323, the loss is 4.526248448493289, parameters k is 11.50442158498116 and b is -49.615857707517634\n",
      "Iteration 4324, the loss is 4.526247902637676, parameters k is 11.504404284585902 and b is -49.615826086964276\n",
      "Iteration 4325, the loss is 4.526247455968722, parameters k is 11.504436881423848 and b is -49.61578656127258\n",
      "Iteration 4326, the loss is 4.526246806387184, parameters k is 11.504419581028591 and b is -49.61575494071922\n",
      "Iteration 4327, the loss is 4.526246156805651, parameters k is 11.504402280633334 and b is -49.61572332016586\n",
      "Iteration 4328, the loss is 4.526245561391506, parameters k is 11.504384980238077 and b is -49.615691699612505\n",
      "Iteration 4329, the loss is 4.526245164281082, parameters k is 11.504417577076023 and b is -49.61565217392081\n",
      "Iteration 4330, the loss is 4.526244514699548, parameters k is 11.504400276680766 and b is -49.61562055336745\n",
      "Iteration 4331, the loss is 4.52624386511801, parameters k is 11.504382976285509 and b is -49.61558893281409\n",
      "Iteration 4332, the loss is 4.526243220145332, parameters k is 11.504365675890252 and b is -49.615557312260734\n",
      "Iteration 4333, the loss is 4.5262428725934445, parameters k is 11.504398272728197 and b is -49.615517786569036\n",
      "Iteration 4334, the loss is 4.526242223011914, parameters k is 11.50438097233294 and b is -49.61548616601568\n",
      "Iteration 4335, the loss is 4.526241573430377, parameters k is 11.504363671937684 and b is -49.61545454546232\n",
      "Iteration 4336, the loss is 4.526240923848841, parameters k is 11.504346371542427 and b is -49.61542292490896\n",
      "Iteration 4337, the loss is 4.526240535956137, parameters k is 11.50432907114717 and b is -49.615391304355605\n",
      "Iteration 4338, the loss is 4.526239931324275, parameters k is 11.504361667985116 and b is -49.61535177866391\n",
      "Iteration 4339, the loss is 4.526239281742739, parameters k is 11.504344367589859 and b is -49.61532015811055\n",
      "Iteration 4340, the loss is 4.526238632161204, parameters k is 11.504327067194602 and b is -49.61528853755719\n",
      "Iteration 4341, the loss is 4.526238194709974, parameters k is 11.504309766799345 and b is -49.61525691700383\n",
      "Iteration 4342, the loss is 4.526237639636638, parameters k is 11.50434236363729 and b is -49.615217391312136\n",
      "Iteration 4343, the loss is 4.526236990055099, parameters k is 11.504325063242034 and b is -49.61518577075878\n",
      "Iteration 4344, the loss is 4.526236340473566, parameters k is 11.504307762846777 and b is -49.61515415020542\n",
      "Iteration 4345, the loss is 4.526235853463799, parameters k is 11.50429046245152 and b is -49.61512252965206\n",
      "Iteration 4346, the loss is 4.526235347948996, parameters k is 11.504323059289465 and b is -49.615083003960365\n",
      "Iteration 4347, the loss is 4.526234698367457, parameters k is 11.504305758894208 and b is -49.61505138340701\n",
      "Iteration 4348, the loss is 4.526234048785925, parameters k is 11.504288458498952 and b is -49.61501976285365\n",
      "Iteration 4349, the loss is 4.5262335122176305, parameters k is 11.504271158103695 and b is -49.61498814230029\n",
      "Iteration 4350, the loss is 4.526233056261359, parameters k is 11.50430375494164 and b is -49.614948616608594\n",
      "Iteration 4351, the loss is 4.526232406679823, parameters k is 11.504286454546383 and b is -49.614916996055236\n",
      "Iteration 4352, the loss is 4.526231757098288, parameters k is 11.504269154151126 and b is -49.61488537550188\n",
      "Iteration 4353, the loss is 4.526231170971461, parameters k is 11.50425185375587 and b is -49.61485375494852\n",
      "Iteration 4354, the loss is 4.526230764573722, parameters k is 11.504284450593815 and b is -49.61481422925682\n",
      "Iteration 4355, the loss is 4.526230114992186, parameters k is 11.504267150198558 and b is -49.614782608703464\n",
      "Iteration 4356, the loss is 4.526229465410655, parameters k is 11.504249849803301 and b is -49.61475098815011\n",
      "Iteration 4357, the loss is 4.526228829725295, parameters k is 11.504232549408044 and b is -49.61471936759675\n",
      "Iteration 4358, the loss is 4.526228472886085, parameters k is 11.50426514624599 and b is -49.61467984190505\n",
      "Iteration 4359, the loss is 4.526227823304549, parameters k is 11.504247845850733 and b is -49.61464822135169\n",
      "Iteration 4360, the loss is 4.526227173723015, parameters k is 11.504230545455476 and b is -49.614616600798335\n",
      "Iteration 4361, the loss is 4.526226524141481, parameters k is 11.50421324506022 and b is -49.61458498024498\n",
      "Iteration 4362, the loss is 4.526226145536098, parameters k is 11.504195944664962 and b is -49.61455335969162\n",
      "Iteration 4363, the loss is 4.5262255316169115, parameters k is 11.504228541502908 and b is -49.61451383399992\n",
      "Iteration 4364, the loss is 4.526224882035379, parameters k is 11.504211241107651 and b is -49.614482213446564\n",
      "Iteration 4365, the loss is 4.526224232453838, parameters k is 11.504193940712394 and b is -49.614450592893206\n",
      "Iteration 4366, the loss is 4.526223804289929, parameters k is 11.504176640317137 and b is -49.61441897233985\n",
      "Iteration 4367, the loss is 4.5262232399292746, parameters k is 11.504209237155083 and b is -49.61437944664815\n",
      "Iteration 4368, the loss is 4.5262225903477376, parameters k is 11.504191936759826 and b is -49.61434782609479\n",
      "Iteration 4369, the loss is 4.526221940766203, parameters k is 11.504174636364569 and b is -49.614316205541435\n",
      "Iteration 4370, the loss is 4.5262214630437585, parameters k is 11.504157335969312 and b is -49.61428458498808\n",
      "Iteration 4371, the loss is 4.52622094824164, parameters k is 11.504189932807257 and b is -49.61424505929638\n",
      "Iteration 4372, the loss is 4.526220298660104, parameters k is 11.504172632412 and b is -49.61421343874302\n",
      "Iteration 4373, the loss is 4.5262196490785644, parameters k is 11.504155332016744 and b is -49.614181818189664\n",
      "Iteration 4374, the loss is 4.526219121797592, parameters k is 11.504138031621487 and b is -49.614150197636306\n",
      "Iteration 4375, the loss is 4.526218656554002, parameters k is 11.504170628459432 and b is -49.61411067194461\n",
      "Iteration 4376, the loss is 4.5262180069724645, parameters k is 11.504153328064175 and b is -49.61407905139125\n",
      "Iteration 4377, the loss is 4.52621735739093, parameters k is 11.504136027668919 and b is -49.61404743083789\n",
      "Iteration 4378, the loss is 4.52621678055142, parameters k is 11.504118727273662 and b is -49.614015810284535\n",
      "Iteration 4379, the loss is 4.526216364866364, parameters k is 11.504151324111607 and b is -49.61397628459284\n",
      "Iteration 4380, the loss is 4.526215715284826, parameters k is 11.50413402371635 and b is -49.61394466403948\n",
      "Iteration 4381, the loss is 4.526215065703295, parameters k is 11.504116723321093 and b is -49.61391304348612\n",
      "Iteration 4382, the loss is 4.52621443930525, parameters k is 11.504099422925837 and b is -49.613881422932764\n",
      "Iteration 4383, the loss is 4.5262140731787275, parameters k is 11.504132019763782 and b is -49.613841897241066\n",
      "Iteration 4384, the loss is 4.5262134235971905, parameters k is 11.504114719368525 and b is -49.61381027668771\n",
      "Iteration 4385, the loss is 4.5262127740156535, parameters k is 11.504097418973268 and b is -49.61377865613435\n",
      "Iteration 4386, the loss is 4.5262121244341165, parameters k is 11.504080118578011 and b is -49.61374703558099\n",
      "Iteration 4387, the loss is 4.526211755116048, parameters k is 11.504062818182755 and b is -49.613715415027634\n",
      "Iteration 4388, the loss is 4.526211131909552, parameters k is 11.5040954150207 and b is -49.61367588933594\n",
      "Iteration 4389, the loss is 4.52621048232801, parameters k is 11.504078114625443 and b is -49.61364426878258\n",
      "Iteration 4390, the loss is 4.52620983274648, parameters k is 11.504060814230186 and b is -49.61361264822922\n",
      "Iteration 4391, the loss is 4.526209413869887, parameters k is 11.50404351383493 and b is -49.61358102767586\n",
      "Iteration 4392, the loss is 4.526208840221913, parameters k is 11.504076110672875 and b is -49.613541501984166\n",
      "Iteration 4393, the loss is 4.526208190640376, parameters k is 11.504058810277618 and b is -49.61350988143081\n",
      "Iteration 4394, the loss is 4.526207541058841, parameters k is 11.504041509882361 and b is -49.61347826087745\n",
      "Iteration 4395, the loss is 4.526207072623714, parameters k is 11.504024209487104 and b is -49.61344664032409\n",
      "Iteration 4396, the loss is 4.526206548534278, parameters k is 11.50405680632505 and b is -49.613407114632395\n",
      "Iteration 4397, the loss is 4.526205898952742, parameters k is 11.504039505929793 and b is -49.61337549407904\n",
      "Iteration 4398, the loss is 4.526205249371209, parameters k is 11.504022205534536 and b is -49.61334387352568\n",
      "Iteration 4399, the loss is 4.526204731377544, parameters k is 11.50400490513928 and b is -49.61331225297232\n",
      "Iteration 4400, the loss is 4.526204256846638, parameters k is 11.504037501977225 and b is -49.61327272728062\n",
      "Iteration 4401, the loss is 4.526203607265097, parameters k is 11.504020201581968 and b is -49.613241106727266\n",
      "Iteration 4402, the loss is 4.5262029576835685, parameters k is 11.50400290118671 and b is -49.61320948617391\n",
      "Iteration 4403, the loss is 4.52620239013138, parameters k is 11.503985600791454 and b is -49.61317786562055\n",
      "Iteration 4404, the loss is 4.526201965159001, parameters k is 11.5040181976294 and b is -49.61313833992885\n",
      "Iteration 4405, the loss is 4.526201315577466, parameters k is 11.504000897234143 and b is -49.613106719375494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4406, the loss is 4.526200665995928, parameters k is 11.503983596838886 and b is -49.61307509882214\n",
      "Iteration 4407, the loss is 4.526200048885212, parameters k is 11.503966296443629 and b is -49.61304347826878\n",
      "Iteration 4408, the loss is 4.526199673471365, parameters k is 11.503998893281574 and b is -49.61300395257708\n",
      "Iteration 4409, the loss is 4.526199023889827, parameters k is 11.503981592886317 and b is -49.61297233202372\n",
      "Iteration 4410, the loss is 4.526198374308291, parameters k is 11.50396429249106 and b is -49.612940711470365\n",
      "Iteration 4411, the loss is 4.526197724726755, parameters k is 11.503946992095804 and b is -49.61290909091701\n",
      "Iteration 4412, the loss is 4.526197364696011, parameters k is 11.503929691700547 and b is -49.61287747036365\n",
      "Iteration 4413, the loss is 4.526196732202187, parameters k is 11.503962288538492 and b is -49.61283794467195\n",
      "Iteration 4414, the loss is 4.526196082620654, parameters k is 11.503944988143235 and b is -49.612806324118594\n",
      "Iteration 4415, the loss is 4.5261954330391205, parameters k is 11.503927687747979 and b is -49.612774703565236\n",
      "Iteration 4416, the loss is 4.526195023449842, parameters k is 11.503910387352722 and b is -49.61274308301188\n",
      "Iteration 4417, the loss is 4.526194440514555, parameters k is 11.503942984190667 and b is -49.61270355732018\n",
      "Iteration 4418, the loss is 4.526193790933016, parameters k is 11.50392568379541 and b is -49.61267193676682\n",
      "Iteration 4419, the loss is 4.526193141351483, parameters k is 11.503908383400153 and b is -49.612640316213465\n",
      "Iteration 4420, the loss is 4.526192682203675, parameters k is 11.503891083004897 and b is -49.61260869566011\n",
      "Iteration 4421, the loss is 4.526192148826914, parameters k is 11.503923679842842 and b is -49.61256916996841\n",
      "Iteration 4422, the loss is 4.526191499245379, parameters k is 11.503906379447585 and b is -49.61253754941505\n",
      "Iteration 4423, the loss is 4.526190849663843, parameters k is 11.503889079052328 and b is -49.612505928861694\n",
      "Iteration 4424, the loss is 4.526190340957507, parameters k is 11.503871778657071 and b is -49.612474308308336\n",
      "Iteration 4425, the loss is 4.526189857139279, parameters k is 11.503904375495017 and b is -49.61243478261664\n",
      "Iteration 4426, the loss is 4.526189207557739, parameters k is 11.50388707509976 and b is -49.61240316206328\n",
      "Iteration 4427, the loss is 4.52618855797621, parameters k is 11.503869774704503 and b is -49.61237154150992\n",
      "Iteration 4428, the loss is 4.526187999711341, parameters k is 11.503852474309246 and b is -49.612339920956565\n",
      "Iteration 4429, the loss is 4.526187565451643, parameters k is 11.503885071147192 and b is -49.61230039526487\n",
      "Iteration 4430, the loss is 4.526186915870107, parameters k is 11.503867770751935 and b is -49.61226877471151\n",
      "Iteration 4431, the loss is 4.526186266288572, parameters k is 11.503850470356678 and b is -49.61223715415815\n",
      "Iteration 4432, the loss is 4.526185658465172, parameters k is 11.503833169961421 and b is -49.612205533604794\n",
      "Iteration 4433, the loss is 4.526185273764008, parameters k is 11.503865766799366 and b is -49.612166007913096\n",
      "Iteration 4434, the loss is 4.526184624182464, parameters k is 11.50384846640411 and b is -49.61213438735974\n",
      "Iteration 4435, the loss is 4.526183974600935, parameters k is 11.503831166008853 and b is -49.61210276680638\n",
      "Iteration 4436, the loss is 4.526183325019398, parameters k is 11.503813865613596 and b is -49.61207114625302\n",
      "Iteration 4437, the loss is 4.526182974275971, parameters k is 11.50379656521834 and b is -49.612039525699664\n",
      "Iteration 4438, the loss is 4.526182332494831, parameters k is 11.503829162056284 and b is -49.61200000000797\n",
      "Iteration 4439, the loss is 4.5261816829132915, parameters k is 11.503811861661028 and b is -49.61196837945461\n",
      "Iteration 4440, the loss is 4.5261810333317625, parameters k is 11.50379456126577 and b is -49.61193675890125\n",
      "Iteration 4441, the loss is 4.5261806330298056, parameters k is 11.503777260870514 and b is -49.61190513834789\n",
      "Iteration 4442, the loss is 4.526180040807192, parameters k is 11.50380985770846 and b is -49.611865612656196\n",
      "Iteration 4443, the loss is 4.526179391225659, parameters k is 11.503792557313202 and b is -49.61183399210284\n",
      "Iteration 4444, the loss is 4.526178741644122, parameters k is 11.503775256917946 and b is -49.61180237154948\n",
      "Iteration 4445, the loss is 4.526178291783637, parameters k is 11.503757956522689 and b is -49.61177075099612\n",
      "Iteration 4446, the loss is 4.526177749119552, parameters k is 11.503790553360634 and b is -49.611731225304425\n",
      "Iteration 4447, the loss is 4.526177099538023, parameters k is 11.503773252965377 and b is -49.61169960475107\n",
      "Iteration 4448, the loss is 4.526176449956488, parameters k is 11.50375595257012 and b is -49.61166798419771\n",
      "Iteration 4449, the loss is 4.526175950537466, parameters k is 11.503738652174864 and b is -49.61163636364435\n",
      "Iteration 4450, the loss is 4.526175457431918, parameters k is 11.503771249012809 and b is -49.61159683795265\n",
      "Iteration 4451, the loss is 4.52617480785038, parameters k is 11.503753948617552 and b is -49.611565217399296\n",
      "Iteration 4452, the loss is 4.526174158268847, parameters k is 11.503736648222295 and b is -49.61153359684594\n",
      "Iteration 4453, the loss is 4.526173609291294, parameters k is 11.503719347827039 and b is -49.61150197629258\n",
      "Iteration 4454, the loss is 4.52617316574428, parameters k is 11.503751944664984 and b is -49.61146245060088\n",
      "Iteration 4455, the loss is 4.526172516162745, parameters k is 11.503734644269727 and b is -49.611430830047524\n",
      "Iteration 4456, the loss is 4.52617186658121, parameters k is 11.50371734387447 and b is -49.61139920949417\n",
      "Iteration 4457, the loss is 4.526171268045129, parameters k is 11.503700043479213 and b is -49.61136758894081\n",
      "Iteration 4458, the loss is 4.526170874056642, parameters k is 11.503732640317159 and b is -49.61132806324911\n",
      "Iteration 4459, the loss is 4.5261702244751065, parameters k is 11.503715339921902 and b is -49.61129644269575\n",
      "Iteration 4460, the loss is 4.526169574893566, parameters k is 11.503698039526645 and b is -49.611264822142395\n",
      "Iteration 4461, the loss is 4.526168926798962, parameters k is 11.503680739131388 and b is -49.61123320158904\n",
      "Iteration 4462, the loss is 4.526168582369008, parameters k is 11.503713335969334 and b is -49.61119367589734\n",
      "Iteration 4463, the loss is 4.526167932787464, parameters k is 11.503696035574077 and b is -49.61116205534398\n",
      "Iteration 4464, the loss is 4.5261672832059325, parameters k is 11.50367873517882 and b is -49.611130434790624\n",
      "Iteration 4465, the loss is 4.526166633624398, parameters k is 11.503661434783563 and b is -49.611098814237266\n",
      "Iteration 4466, the loss is 4.5261662426097615, parameters k is 11.503644134388306 and b is -49.61106719368391\n",
      "Iteration 4467, the loss is 4.52616564109983, parameters k is 11.503676731226252 and b is -49.61102766799221\n",
      "Iteration 4468, the loss is 4.526164991518293, parameters k is 11.503659430830995 and b is -49.61099604743885\n",
      "Iteration 4469, the loss is 4.526164341936759, parameters k is 11.503642130435738 and b is -49.610964426885495\n",
      "Iteration 4470, the loss is 4.526163901363595, parameters k is 11.503624830040481 and b is -49.61093280633214\n",
      "Iteration 4471, the loss is 4.5261633494121964, parameters k is 11.503657426878426 and b is -49.61089328064044\n",
      "Iteration 4472, the loss is 4.526162699830664, parameters k is 11.50364012648317 and b is -49.61086166008708\n",
      "Iteration 4473, the loss is 4.526162050249124, parameters k is 11.503622826087913 and b is -49.610830039533724\n",
      "Iteration 4474, the loss is 4.526161560117426, parameters k is 11.503605525692656 and b is -49.610798418980366\n",
      "Iteration 4475, the loss is 4.526161057724558, parameters k is 11.503638122530601 and b is -49.61075889328867\n",
      "Iteration 4476, the loss is 4.526160408143023, parameters k is 11.503620822135344 and b is -49.61072727273531\n",
      "Iteration 4477, the loss is 4.526159758561486, parameters k is 11.503603521740088 and b is -49.61069565218195\n",
      "Iteration 4478, the loss is 4.526159218871261, parameters k is 11.50358622134483 and b is -49.610664031628595\n",
      "Iteration 4479, the loss is 4.526158766036917, parameters k is 11.503618818182776 and b is -49.6106245059369\n",
      "Iteration 4480, the loss is 4.52615811645538, parameters k is 11.50360151778752 and b is -49.61059288538354\n",
      "Iteration 4481, the loss is 4.526157466873848, parameters k is 11.503584217392262 and b is -49.61056126483018\n",
      "Iteration 4482, the loss is 4.5261568776250884, parameters k is 11.503566916997006 and b is -49.61052964427682\n",
      "Iteration 4483, the loss is 4.526156474349281, parameters k is 11.503599513834951 and b is -49.610490118585126\n",
      "Iteration 4484, the loss is 4.5261558247677485, parameters k is 11.503582213439694 and b is -49.61045849803177\n",
      "Iteration 4485, the loss is 4.5261551751862115, parameters k is 11.503564913044437 and b is -49.61042687747841\n",
      "Iteration 4486, the loss is 4.526154536378917, parameters k is 11.50354761264918 and b is -49.61039525692505\n",
      "Iteration 4487, the loss is 4.526154182661644, parameters k is 11.503580209487126 and b is -49.610355731233355\n",
      "Iteration 4488, the loss is 4.526153533080104, parameters k is 11.503562909091869 and b is -49.61032411068\n",
      "Iteration 4489, the loss is 4.526152883498572, parameters k is 11.503545608696612 and b is -49.61029249012664\n",
      "Iteration 4490, the loss is 4.526152233917043, parameters k is 11.503528308301355 and b is -49.61026086957328\n",
      "Iteration 4491, the loss is 4.526151852189715, parameters k is 11.503511007906098 and b is -49.61022924901992\n",
      "Iteration 4492, the loss is 4.526151241392471, parameters k is 11.503543604744044 and b is -49.610189723328226\n",
      "Iteration 4493, the loss is 4.526150591810937, parameters k is 11.503526304348787 and b is -49.61015810277487\n",
      "Iteration 4494, the loss is 4.526149942229398, parameters k is 11.50350900395353 and b is -49.61012648222151\n",
      "Iteration 4495, the loss is 4.526149510943551, parameters k is 11.503491703558273 and b is -49.61009486166815\n",
      "Iteration 4496, the loss is 4.526148949704831, parameters k is 11.503524300396219 and b is -49.610055335976455\n",
      "Iteration 4497, the loss is 4.526148300123299, parameters k is 11.503507000000962 and b is -49.6100237154231\n",
      "Iteration 4498, the loss is 4.526147650541767, parameters k is 11.503489699605705 and b is -49.60999209486974\n",
      "Iteration 4499, the loss is 4.52614716969738, parameters k is 11.503472399210448 and b is -49.60996047431638\n",
      "Iteration 4500, the loss is 4.526146658017194, parameters k is 11.503504996048393 and b is -49.60992094862468\n",
      "Iteration 4501, the loss is 4.52614600843566, parameters k is 11.503487695653137 and b is -49.609889328071326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4502, the loss is 4.526145358854126, parameters k is 11.50347039525788 and b is -49.60985770751797\n",
      "Iteration 4503, the loss is 4.526144828451212, parameters k is 11.503453094862623 and b is -49.60982608696461\n",
      "Iteration 4504, the loss is 4.526144366329559, parameters k is 11.503485691700568 and b is -49.60978656127291\n",
      "Iteration 4505, the loss is 4.526143716748023, parameters k is 11.503468391305312 and b is -49.609754940719554\n",
      "Iteration 4506, the loss is 4.526143067166489, parameters k is 11.503451090910055 and b is -49.6097233201662\n",
      "Iteration 4507, the loss is 4.5261424872050435, parameters k is 11.503433790514798 and b is -49.60969169961284\n",
      "Iteration 4508, the loss is 4.5261420746419185, parameters k is 11.503466387352743 and b is -49.60965217392114\n",
      "Iteration 4509, the loss is 4.526141425060385, parameters k is 11.503449086957486 and b is -49.60962055336778\n",
      "Iteration 4510, the loss is 4.52614077547885, parameters k is 11.50343178656223 and b is -49.609588932814425\n",
      "Iteration 4511, the loss is 4.52614014595888, parameters k is 11.503414486166973 and b is -49.60955731226107\n",
      "Iteration 4512, the loss is 4.526139782954285, parameters k is 11.503447083004918 and b is -49.60951778656937\n",
      "Iteration 4513, the loss is 4.526139133372745, parameters k is 11.503429782609661 and b is -49.60948616601601\n",
      "Iteration 4514, the loss is 4.526138483791214, parameters k is 11.503412482214404 and b is -49.609454545462654\n",
      "Iteration 4515, the loss is 4.52613783420968, parameters k is 11.503395181819148 and b is -49.609422924909296\n",
      "Iteration 4516, the loss is 4.526137461769674, parameters k is 11.50337788142389 and b is -49.60939130435594\n",
      "Iteration 4517, the loss is 4.526136841685113, parameters k is 11.503410478261836 and b is -49.60935177866424\n",
      "Iteration 4518, the loss is 4.526136192103576, parameters k is 11.50339317786658 and b is -49.60932015811088\n",
      "Iteration 4519, the loss is 4.526135542522038, parameters k is 11.503375877471322 and b is -49.609288537557525\n",
      "Iteration 4520, the loss is 4.526135120523507, parameters k is 11.503358577076066 and b is -49.60925691700417\n",
      "Iteration 4521, the loss is 4.526134549997474, parameters k is 11.503391173914011 and b is -49.60921739131247\n",
      "Iteration 4522, the loss is 4.5261339004159415, parameters k is 11.503373873518754 and b is -49.60918577075911\n",
      "Iteration 4523, the loss is 4.526133250834404, parameters k is 11.503356573123497 and b is -49.609154150205754\n",
      "Iteration 4524, the loss is 4.526132779277336, parameters k is 11.50333927272824 and b is -49.609122529652396\n",
      "Iteration 4525, the loss is 4.526132258309837, parameters k is 11.503371869566186 and b is -49.6090830039607\n",
      "Iteration 4526, the loss is 4.526131608728307, parameters k is 11.503354569170929 and b is -49.60905138340734\n",
      "Iteration 4527, the loss is 4.526130959146764, parameters k is 11.503337268775672 and b is -49.60901976285398\n",
      "Iteration 4528, the loss is 4.526130438031174, parameters k is 11.503319968380415 and b is -49.608988142300625\n",
      "Iteration 4529, the loss is 4.526129966622196, parameters k is 11.50335256521836 and b is -49.60894861660893\n",
      "Iteration 4530, the loss is 4.526129317040663, parameters k is 11.503335264823104 and b is -49.60891699605557\n",
      "Iteration 4531, the loss is 4.526128667459127, parameters k is 11.503317964427847 and b is -49.60888537550221\n",
      "Iteration 4532, the loss is 4.526128096785003, parameters k is 11.50330066403259 and b is -49.60885375494885\n",
      "Iteration 4533, the loss is 4.526127674934559, parameters k is 11.503333260870535 and b is -49.608814229257156\n",
      "Iteration 4534, the loss is 4.526127025353025, parameters k is 11.503315960475279 and b is -49.6087826087038\n",
      "Iteration 4535, the loss is 4.526126375771489, parameters k is 11.503298660080022 and b is -49.60875098815044\n",
      "Iteration 4536, the loss is 4.526125755538837, parameters k is 11.503281359684765 and b is -49.60871936759708\n",
      "Iteration 4537, the loss is 4.5261253832469235, parameters k is 11.50331395652271 and b is -49.608679841905385\n",
      "Iteration 4538, the loss is 4.526124733665389, parameters k is 11.503296656127453 and b is -49.60864822135203\n",
      "Iteration 4539, the loss is 4.5261240840838495, parameters k is 11.503279355732197 and b is -49.60861660079867\n",
      "Iteration 4540, the loss is 4.526123434502318, parameters k is 11.50326205533694 and b is -49.60858498024531\n",
      "Iteration 4541, the loss is 4.5261230713496365, parameters k is 11.503244754941683 and b is -49.60855335969195\n",
      "Iteration 4542, the loss is 4.526122441977752, parameters k is 11.503277351779628 and b is -49.608513834000256\n",
      "Iteration 4543, the loss is 4.526121792396209, parameters k is 11.503260051384371 and b is -49.6084822134469\n",
      "Iteration 4544, the loss is 4.526121142814681, parameters k is 11.503242750989115 and b is -49.60845059289354\n",
      "Iteration 4545, the loss is 4.526120730103469, parameters k is 11.503225450593858 and b is -49.60841897234018\n",
      "Iteration 4546, the loss is 4.526120150290116, parameters k is 11.503258047431803 and b is -49.608379446648485\n",
      "Iteration 4547, the loss is 4.526119500708579, parameters k is 11.503240747036546 and b is -49.60834782609513\n",
      "Iteration 4548, the loss is 4.526118851127042, parameters k is 11.50322344664129 and b is -49.60831620554177\n",
      "Iteration 4549, the loss is 4.526118388857297, parameters k is 11.503206146246033 and b is -49.60828458498841\n",
      "Iteration 4550, the loss is 4.526117858602478, parameters k is 11.503238743083978 and b is -49.60824505929671\n",
      "Iteration 4551, the loss is 4.526117209020934, parameters k is 11.503221442688721 and b is -49.608213438743356\n",
      "Iteration 4552, the loss is 4.526116559439402, parameters k is 11.503204142293464 and b is -49.60818181819\n",
      "Iteration 4553, the loss is 4.526116047611133, parameters k is 11.503186841898208 and b is -49.60815019763664\n",
      "Iteration 4554, the loss is 4.526115566914836, parameters k is 11.503219438736153 and b is -49.60811067194494\n",
      "Iteration 4555, the loss is 4.526114917333306, parameters k is 11.503202138340896 and b is -49.608079051391584\n",
      "Iteration 4556, the loss is 4.526114267751767, parameters k is 11.50318483794564 and b is -49.608047430838226\n",
      "Iteration 4557, the loss is 4.526113706364962, parameters k is 11.503167537550382 and b is -49.60801581028487\n",
      "Iteration 4558, the loss is 4.526113275227202, parameters k is 11.503200134388328 and b is -49.60797628459317\n",
      "Iteration 4559, the loss is 4.526112625645665, parameters k is 11.50318283399307 and b is -49.60794466403981\n",
      "Iteration 4560, the loss is 4.526111976064127, parameters k is 11.503165533597814 and b is -49.607913043486455\n",
      "Iteration 4561, the loss is 4.526111365118793, parameters k is 11.503148233202557 and b is -49.6078814229331\n",
      "Iteration 4562, the loss is 4.52611098353956, parameters k is 11.503180830040503 and b is -49.6078418972414\n",
      "Iteration 4563, the loss is 4.526110333958027, parameters k is 11.503163529645246 and b is -49.60781027668804\n",
      "Iteration 4564, the loss is 4.5261096843764905, parameters k is 11.503146229249989 and b is -49.607778656134684\n",
      "Iteration 4565, the loss is 4.526109034794956, parameters k is 11.503128928854732 and b is -49.607747035581326\n",
      "Iteration 4566, the loss is 4.526108680929596, parameters k is 11.503111628459475 and b is -49.60771541502797\n",
      "Iteration 4567, the loss is 4.52610804227039, parameters k is 11.50314422529742 and b is -49.60767588933627\n",
      "Iteration 4568, the loss is 4.5261073926888535, parameters k is 11.503126924902164 and b is -49.60764426878291\n",
      "Iteration 4569, the loss is 4.52610674310732, parameters k is 11.503109624506907 and b is -49.607612648229555\n",
      "Iteration 4570, the loss is 4.526106339683424, parameters k is 11.50309232411165 and b is -49.6075810276762\n",
      "Iteration 4571, the loss is 4.526105750582753, parameters k is 11.503124920949595 and b is -49.6075415019845\n",
      "Iteration 4572, the loss is 4.526105101001223, parameters k is 11.503107620554339 and b is -49.60750988143114\n",
      "Iteration 4573, the loss is 4.526104451419678, parameters k is 11.503090320159082 and b is -49.607478260877784\n",
      "Iteration 4574, the loss is 4.526103998437259, parameters k is 11.503073019763825 and b is -49.607446640324426\n",
      "Iteration 4575, the loss is 4.5261034588951095, parameters k is 11.50310561660177 and b is -49.60740711463273\n",
      "Iteration 4576, the loss is 4.526102809313576, parameters k is 11.503088316206513 and b is -49.60737549407937\n",
      "Iteration 4577, the loss is 4.526102159732048, parameters k is 11.503071015811257 and b is -49.60734387352601\n",
      "Iteration 4578, the loss is 4.526101657191089, parameters k is 11.503053715416 and b is -49.607312252972655\n",
      "Iteration 4579, the loss is 4.52610116720748, parameters k is 11.503086312253945 and b is -49.60727272728096\n",
      "Iteration 4580, the loss is 4.526100517625941, parameters k is 11.503069011858688 and b is -49.6072411067276\n",
      "Iteration 4581, the loss is 4.526099868044406, parameters k is 11.503051711463431 and b is -49.60720948617424\n",
      "Iteration 4582, the loss is 4.526099315944917, parameters k is 11.503034411068175 and b is -49.60717786562088\n",
      "Iteration 4583, the loss is 4.52609887551984, parameters k is 11.50306700790612 and b is -49.607138339929186\n",
      "Iteration 4584, the loss is 4.526098225938301, parameters k is 11.503049707510863 and b is -49.60710671937583\n",
      "Iteration 4585, the loss is 4.526097576356774, parameters k is 11.503032407115606 and b is -49.60707509882247\n",
      "Iteration 4586, the loss is 4.526096974698751, parameters k is 11.50301510672035 and b is -49.60704347826911\n",
      "Iteration 4587, the loss is 4.5260965838322, parameters k is 11.503047703558295 and b is -49.607003952577415\n",
      "Iteration 4588, the loss is 4.526095934250662, parameters k is 11.503030403163038 and b is -49.60697233202406\n",
      "Iteration 4589, the loss is 4.526095284669125, parameters k is 11.503013102767781 and b is -49.6069407114707\n",
      "Iteration 4590, the loss is 4.526094635087593, parameters k is 11.502995802372524 and b is -49.60690909091734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4591, the loss is 4.526094290509551, parameters k is 11.502978501977267 and b is -49.60687747036398\n",
      "Iteration 4592, the loss is 4.526093642563024, parameters k is 11.503011098815213 and b is -49.606837944672286\n",
      "Iteration 4593, the loss is 4.526092992981494, parameters k is 11.502993798419956 and b is -49.60680632411893\n",
      "Iteration 4594, the loss is 4.526092343399957, parameters k is 11.5029764980247 and b is -49.60677470356557\n",
      "Iteration 4595, the loss is 4.526091949263384, parameters k is 11.502959197629442 and b is -49.60674308301221\n",
      "Iteration 4596, the loss is 4.526091350875388, parameters k is 11.502991794467388 and b is -49.606703557320515\n",
      "Iteration 4597, the loss is 4.526090701293852, parameters k is 11.50297449407213 and b is -49.60667193676716\n",
      "Iteration 4598, the loss is 4.526090051712321, parameters k is 11.502957193676874 and b is -49.6066403162138\n",
      "Iteration 4599, the loss is 4.526089608017215, parameters k is 11.502939893281617 and b is -49.60660869566044\n",
      "Iteration 4600, the loss is 4.526089059187749, parameters k is 11.502972490119562 and b is -49.60656916996874\n",
      "Iteration 4601, the loss is 4.526088409606219, parameters k is 11.502955189724306 and b is -49.606537549415386\n",
      "Iteration 4602, the loss is 4.526087760024681, parameters k is 11.502937889329049 and b is -49.60650592886203\n",
      "Iteration 4603, the loss is 4.526087266771046, parameters k is 11.502920588933792 and b is -49.60647430830867\n",
      "Iteration 4604, the loss is 4.526086767500114, parameters k is 11.502953185771737 and b is -49.60643478261697\n",
      "Iteration 4605, the loss is 4.526086117918581, parameters k is 11.50293588537648 and b is -49.606403162063614\n",
      "Iteration 4606, the loss is 4.526085468337042, parameters k is 11.502918584981224 and b is -49.606371541510256\n",
      "Iteration 4607, the loss is 4.526084925524878, parameters k is 11.502901284585967 and b is -49.6063399209569\n",
      "Iteration 4608, the loss is 4.526084475812481, parameters k is 11.502933881423912 and b is -49.6063003952652\n",
      "Iteration 4609, the loss is 4.526083826230944, parameters k is 11.502916581028655 and b is -49.60626877471184\n",
      "Iteration 4610, the loss is 4.5260831766494025, parameters k is 11.502899280633399 and b is -49.606237154158485\n",
      "Iteration 4611, the loss is 4.526082584278713, parameters k is 11.502881980238142 and b is -49.60620553360513\n",
      "Iteration 4612, the loss is 4.526082184124842, parameters k is 11.502914577076087 and b is -49.60616600791343\n",
      "Iteration 4613, the loss is 4.526081534543306, parameters k is 11.50289727668083 and b is -49.60613438736007\n",
      "Iteration 4614, the loss is 4.526080884961771, parameters k is 11.502879976285573 and b is -49.606102766806714\n",
      "Iteration 4615, the loss is 4.526080243032543, parameters k is 11.502862675890317 and b is -49.606071146253356\n",
      "Iteration 4616, the loss is 4.5260798924372025, parameters k is 11.502895272728262 and b is -49.60603162056166\n",
      "Iteration 4617, the loss is 4.526079242855674, parameters k is 11.502877972333005 and b is -49.6060000000083\n",
      "Iteration 4618, the loss is 4.526078593274132, parameters k is 11.502860671937748 and b is -49.60596837945494\n",
      "Iteration 4619, the loss is 4.526077943692595, parameters k is 11.502843371542491 and b is -49.605936758901585\n",
      "Iteration 4620, the loss is 4.5260775588433395, parameters k is 11.502826071147235 and b is -49.60590513834823\n",
      "Iteration 4621, the loss is 4.526076951168032, parameters k is 11.50285866798518 and b is -49.60586561265653\n",
      "Iteration 4622, the loss is 4.526076301586496, parameters k is 11.502841367589923 and b is -49.60583399210317\n",
      "Iteration 4623, the loss is 4.526075652004962, parameters k is 11.502824067194666 and b is -49.605802371549814\n",
      "Iteration 4624, the loss is 4.5260752175971755, parameters k is 11.50280676679941 and b is -49.605770750996456\n",
      "Iteration 4625, the loss is 4.526074659480393, parameters k is 11.502839363637355 and b is -49.60573122530476\n",
      "Iteration 4626, the loss is 4.526074009898856, parameters k is 11.502822063242098 and b is -49.6056996047514\n",
      "Iteration 4627, the loss is 4.526073360317326, parameters k is 11.502804762846841 and b is -49.60566798419804\n",
      "Iteration 4628, the loss is 4.526072876351004, parameters k is 11.502787462451584 and b is -49.605636363644685\n",
      "Iteration 4629, the loss is 4.5260723677927555, parameters k is 11.50282005928953 and b is -49.60559683795299\n",
      "Iteration 4630, the loss is 4.52607171821122, parameters k is 11.502802758894273 and b is -49.60556521739963\n",
      "Iteration 4631, the loss is 4.526071068629683, parameters k is 11.502785458499016 and b is -49.60553359684627\n",
      "Iteration 4632, the loss is 4.526070535104839, parameters k is 11.502768158103759 and b is -49.60550197629291\n",
      "Iteration 4633, the loss is 4.526070076105119, parameters k is 11.502800754941704 and b is -49.605462450601216\n",
      "Iteration 4634, the loss is 4.526069426523582, parameters k is 11.502783454546448 and b is -49.60543083004786\n",
      "Iteration 4635, the loss is 4.5260687769420445, parameters k is 11.50276615415119 and b is -49.6053992094945\n",
      "Iteration 4636, the loss is 4.526068193858666, parameters k is 11.502748853755934 and b is -49.60536758894114\n",
      "Iteration 4637, the loss is 4.52606778441748, parameters k is 11.50278145059388 and b is -49.605328063249445\n",
      "Iteration 4638, the loss is 4.526067134835947, parameters k is 11.502764150198622 and b is -49.60529644269609\n",
      "Iteration 4639, the loss is 4.526066485254406, parameters k is 11.502746849803366 and b is -49.60526482214273\n",
      "Iteration 4640, the loss is 4.526065852612504, parameters k is 11.502729549408109 and b is -49.60523320158937\n",
      "Iteration 4641, the loss is 4.52606549272984, parameters k is 11.502762146246054 and b is -49.605193675897674\n",
      "Iteration 4642, the loss is 4.5260648431483075, parameters k is 11.502744845850797 and b is -49.605162055344316\n",
      "Iteration 4643, the loss is 4.526064193566765, parameters k is 11.50272754545554 and b is -49.60513043479096\n",
      "Iteration 4644, the loss is 4.526063543985241, parameters k is 11.502710245060284 and b is -49.6050988142376\n",
      "Iteration 4645, the loss is 4.526063168423299, parameters k is 11.502692944665027 and b is -49.60506719368424\n",
      "Iteration 4646, the loss is 4.5260625514606705, parameters k is 11.502725541502972 and b is -49.605027667992545\n",
      "Iteration 4647, the loss is 4.526061901879136, parameters k is 11.502708241107715 and b is -49.60499604743919\n",
      "Iteration 4648, the loss is 4.526061252297597, parameters k is 11.502690940712458 and b is -49.60496442688583\n",
      "Iteration 4649, the loss is 4.526060827177133, parameters k is 11.502673640317202 and b is -49.60493280633247\n",
      "Iteration 4650, the loss is 4.526060259773037, parameters k is 11.502706237155147 and b is -49.60489328064077\n",
      "Iteration 4651, the loss is 4.526059610191495, parameters k is 11.50268893675989 and b is -49.604861660087415\n",
      "Iteration 4652, the loss is 4.526058960609962, parameters k is 11.502671636364633 and b is -49.60483003953406\n",
      "Iteration 4653, the loss is 4.526058485930965, parameters k is 11.502654335969376 and b is -49.6047984189807\n",
      "Iteration 4654, the loss is 4.526057968085397, parameters k is 11.502686932807322 and b is -49.604758893289\n",
      "Iteration 4655, the loss is 4.526057318503862, parameters k is 11.502669632412065 and b is -49.604727272735644\n",
      "Iteration 4656, the loss is 4.5260566689223305, parameters k is 11.502652332016808 and b is -49.604695652182286\n",
      "Iteration 4657, the loss is 4.52605614468479, parameters k is 11.502635031621551 and b is -49.60466403162893\n",
      "Iteration 4658, the loss is 4.526055676397753, parameters k is 11.502667628459497 and b is -49.60462450593723\n",
      "Iteration 4659, the loss is 4.526055026816223, parameters k is 11.50265032806424 and b is -49.60459288538387\n",
      "Iteration 4660, the loss is 4.5260543772346855, parameters k is 11.502633027668983 and b is -49.604561264830515\n",
      "Iteration 4661, the loss is 4.5260538034386295, parameters k is 11.502615727273726 and b is -49.60452964427716\n",
      "Iteration 4662, the loss is 4.5260533847101225, parameters k is 11.502648324111671 and b is -49.60449011858546\n",
      "Iteration 4663, the loss is 4.526052735128582, parameters k is 11.502631023716415 and b is -49.6044584980321\n",
      "Iteration 4664, the loss is 4.526052085547048, parameters k is 11.502613723321158 and b is -49.604426877478744\n",
      "Iteration 4665, the loss is 4.526051462192459, parameters k is 11.502596422925901 and b is -49.604395256925386\n",
      "Iteration 4666, the loss is 4.526051093022479, parameters k is 11.502629019763846 and b is -49.60435573123369\n",
      "Iteration 4667, the loss is 4.526050443440941, parameters k is 11.50261171936859 and b is -49.60432411068033\n",
      "Iteration 4668, the loss is 4.526049793859411, parameters k is 11.502594418973333 and b is -49.60429249012697\n",
      "Iteration 4669, the loss is 4.526049144277872, parameters k is 11.502577118578076 and b is -49.604260869573615\n",
      "Iteration 4670, the loss is 4.5260487780032586, parameters k is 11.502559818182819 and b is -49.60422924902026\n",
      "Iteration 4671, the loss is 4.5260481517533115, parameters k is 11.502592415020764 and b is -49.60418972332856\n",
      "Iteration 4672, the loss is 4.526047502171769, parameters k is 11.502575114625508 and b is -49.6041581027752\n",
      "Iteration 4673, the loss is 4.526046852590234, parameters k is 11.50255781423025 and b is -49.604126482221844\n",
      "Iteration 4674, the loss is 4.526046436757088, parameters k is 11.502540513834994 and b is -49.604094861668486\n",
      "Iteration 4675, the loss is 4.52604586006567, parameters k is 11.50257311067294 and b is -49.60405533597679\n",
      "Iteration 4676, the loss is 4.526045210484134, parameters k is 11.502555810277682 and b is -49.60402371542343\n",
      "Iteration 4677, the loss is 4.5260445609026005, parameters k is 11.502538509882426 and b is -49.60399209487007\n",
      "Iteration 4678, the loss is 4.52604409551092, parameters k is 11.502521209487169 and b is -49.603960474316715\n",
      "Iteration 4679, the loss is 4.526043568378034, parameters k is 11.502553806325114 and b is -49.60392094862502\n",
      "Iteration 4680, the loss is 4.5260429187965, parameters k is 11.502536505929857 and b is -49.60388932807166\n",
      "Iteration 4681, the loss is 4.526042269214962, parameters k is 11.5025192055346 and b is -49.6038577075183\n",
      "Iteration 4682, the loss is 4.526041754264754, parameters k is 11.502501905139344 and b is -49.60382608696494\n",
      "Iteration 4683, the loss is 4.5260412766903935, parameters k is 11.502534501977289 and b is -49.603786561273246\n",
      "Iteration 4684, the loss is 4.52604062710886, parameters k is 11.502517201582032 and b is -49.60375494071989\n",
      "Iteration 4685, the loss is 4.526039977527326, parameters k is 11.502499901186775 and b is -49.60372332016653\n",
      "Iteration 4686, the loss is 4.526039413018583, parameters k is 11.502482600791518 and b is -49.60369169961317\n",
      "Iteration 4687, the loss is 4.52603898500276, parameters k is 11.502515197629464 and b is -49.603652173921475\n",
      "Iteration 4688, the loss is 4.526038335421224, parameters k is 11.502497897234207 and b is -49.60362055336812\n",
      "Iteration 4689, the loss is 4.526037685839686, parameters k is 11.50248059683895 and b is -49.60358893281476\n",
      "Iteration 4690, the loss is 4.526037071772419, parameters k is 11.502463296443693 and b is -49.6035573122614\n",
      "Iteration 4691, the loss is 4.526036693315122, parameters k is 11.502495893281639 and b is -49.603517786569704\n",
      "Iteration 4692, the loss is 4.526036043733588, parameters k is 11.502478592886382 and b is -49.603486166016346\n",
      "Iteration 4693, the loss is 4.526035394152055, parameters k is 11.502461292491125 and b is -49.60345454546299\n",
      "Iteration 4694, the loss is 4.526034744570515, parameters k is 11.502443992095868 and b is -49.60342292490963\n",
      "Iteration 4695, the loss is 4.526034387583221, parameters k is 11.502426691700611 and b is -49.60339130435627\n",
      "Iteration 4696, the loss is 4.526033752045947, parameters k is 11.502459288538557 and b is -49.603351778664575\n",
      "Iteration 4697, the loss is 4.526033102464413, parameters k is 11.5024419881433 and b is -49.60332015811122\n",
      "Iteration 4698, the loss is 4.526032452882877, parameters k is 11.502424687748043 and b is -49.60328853755786\n",
      "Iteration 4699, the loss is 4.526032046337049, parameters k is 11.502407387352786 and b is -49.6032569170045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4700, the loss is 4.526031460358308, parameters k is 11.502439984190731 and b is -49.6032173913128\n",
      "Iteration 4701, the loss is 4.526030810776779, parameters k is 11.502422683795475 and b is -49.603185770759445\n",
      "Iteration 4702, the loss is 4.526030161195237, parameters k is 11.502405383400218 and b is -49.60315415020609\n",
      "Iteration 4703, the loss is 4.526029705090879, parameters k is 11.502388083004961 and b is -49.60312252965273\n",
      "Iteration 4704, the loss is 4.526029168670671, parameters k is 11.502420679842906 and b is -49.60308300396103\n",
      "Iteration 4705, the loss is 4.526028519089139, parameters k is 11.50240337944765 and b is -49.603051383407674\n",
      "Iteration 4706, the loss is 4.526027869507598, parameters k is 11.502386079052393 and b is -49.603019762854316\n",
      "Iteration 4707, the loss is 4.52602736384471, parameters k is 11.502368778657136 and b is -49.60298814230096\n",
      "Iteration 4708, the loss is 4.526026876983039, parameters k is 11.502401375495081 and b is -49.60294861660926\n",
      "Iteration 4709, the loss is 4.526026227401502, parameters k is 11.502384075099824 and b is -49.6029169960559\n",
      "Iteration 4710, the loss is 4.526025577819967, parameters k is 11.502366774704567 and b is -49.602885375502545\n",
      "Iteration 4711, the loss is 4.526025022598548, parameters k is 11.50234947430931 and b is -49.60285375494919\n",
      "Iteration 4712, the loss is 4.526024585295399, parameters k is 11.502382071147256 and b is -49.60281422925749\n",
      "Iteration 4713, the loss is 4.526023935713861, parameters k is 11.502364770752 and b is -49.60278260870413\n",
      "Iteration 4714, the loss is 4.5260232861323235, parameters k is 11.502347470356742 and b is -49.602750988150774\n",
      "Iteration 4715, the loss is 4.526022681352378, parameters k is 11.502330169961485 and b is -49.602719367597416\n",
      "Iteration 4716, the loss is 4.526022293607759, parameters k is 11.50236276679943 and b is -49.60267984190572\n",
      "Iteration 4717, the loss is 4.526021644026223, parameters k is 11.502345466404174 and b is -49.60264822135236\n",
      "Iteration 4718, the loss is 4.526020994444691, parameters k is 11.502328166008917 and b is -49.602616600799\n",
      "Iteration 4719, the loss is 4.526020344863152, parameters k is 11.50231086561366 and b is -49.602584980245645\n",
      "Iteration 4720, the loss is 4.526019997163176, parameters k is 11.502293565218404 and b is -49.60255335969229\n",
      "Iteration 4721, the loss is 4.52601935233859, parameters k is 11.502326162056349 and b is -49.60251383400059\n",
      "Iteration 4722, the loss is 4.5260187027570495, parameters k is 11.502308861661092 and b is -49.60248221344723\n",
      "Iteration 4723, the loss is 4.526018053175518, parameters k is 11.502291561265835 and b is -49.602450592893874\n",
      "Iteration 4724, the loss is 4.526017655917009, parameters k is 11.502274260870578 and b is -49.602418972340516\n",
      "Iteration 4725, the loss is 4.52601706065095, parameters k is 11.502306857708524 and b is -49.60237944664882\n",
      "Iteration 4726, the loss is 4.526016411069414, parameters k is 11.502289557313267 and b is -49.60234782609546\n",
      "Iteration 4727, the loss is 4.526015761487881, parameters k is 11.50227225691801 and b is -49.6023162055421\n",
      "Iteration 4728, the loss is 4.526015314670838, parameters k is 11.502254956522753 and b is -49.602284584988745\n",
      "Iteration 4729, the loss is 4.526014768963311, parameters k is 11.502287553360699 and b is -49.60224505929705\n",
      "Iteration 4730, the loss is 4.526014119381771, parameters k is 11.502270252965442 and b is -49.60221343874369\n",
      "Iteration 4731, the loss is 4.52601346980024, parameters k is 11.502252952570185 and b is -49.60218181819033\n",
      "Iteration 4732, the loss is 4.526012973424668, parameters k is 11.502235652174928 and b is -49.60215019763697\n",
      "Iteration 4733, the loss is 4.526012477275678, parameters k is 11.502268249012873 and b is -49.602110671945276\n",
      "Iteration 4734, the loss is 4.526011827694139, parameters k is 11.502250948617617 and b is -49.60207905139192\n",
      "Iteration 4735, the loss is 4.526011178112606, parameters k is 11.50223364822236 and b is -49.60204743083856\n",
      "Iteration 4736, the loss is 4.526010632178499, parameters k is 11.502216347827103 and b is -49.6020158102852\n",
      "Iteration 4737, the loss is 4.526010185588039, parameters k is 11.502248944665048 and b is -49.601976284593505\n",
      "Iteration 4738, the loss is 4.526009536006501, parameters k is 11.502231644269791 and b is -49.60194466404015\n",
      "Iteration 4739, the loss is 4.526008886424963, parameters k is 11.502214343874535 and b is -49.60191304348679\n",
      "Iteration 4740, the loss is 4.526008290932329, parameters k is 11.502197043479278 and b is -49.60188142293343\n",
      "Iteration 4741, the loss is 4.526007893900402, parameters k is 11.502229640317223 and b is -49.601841897241734\n",
      "Iteration 4742, the loss is 4.526007244318865, parameters k is 11.502212339921966 and b is -49.601810276688376\n",
      "Iteration 4743, the loss is 4.526006594737327, parameters k is 11.50219503952671 and b is -49.60177865613502\n",
      "Iteration 4744, the loss is 4.526005949686159, parameters k is 11.502177739131453 and b is -49.60174703558166\n",
      "Iteration 4745, the loss is 4.526005602212761, parameters k is 11.502210335969398 and b is -49.60170750988996\n",
      "Iteration 4746, the loss is 4.526004952631223, parameters k is 11.502193035574141 and b is -49.601675889336605\n",
      "Iteration 4747, the loss is 4.52600430304969, parameters k is 11.502175735178884 and b is -49.60164426878325\n",
      "Iteration 4748, the loss is 4.526003653468157, parameters k is 11.502158434783627 and b is -49.60161264822989\n",
      "Iteration 4749, the loss is 4.526003265496963, parameters k is 11.50214113438837 and b is -49.60158102767653\n",
      "Iteration 4750, the loss is 4.526002660943584, parameters k is 11.502173731226316 and b is -49.60154150198483\n",
      "Iteration 4751, the loss is 4.526002011362059, parameters k is 11.502156430831059 and b is -49.601509881431475\n",
      "Iteration 4752, the loss is 4.5260013617805175, parameters k is 11.502139130435802 and b is -49.60147826087812\n",
      "Iteration 4753, the loss is 4.526000924250798, parameters k is 11.502121830040545 and b is -49.60144664032476\n",
      "Iteration 4754, the loss is 4.526000369255949, parameters k is 11.50215442687849 and b is -49.60140711463306\n",
      "Iteration 4755, the loss is 4.525999719674417, parameters k is 11.502137126483234 and b is -49.601375494079704\n",
      "Iteration 4756, the loss is 4.525999070092881, parameters k is 11.502119826087977 and b is -49.601343873526346\n",
      "Iteration 4757, the loss is 4.525998583004626, parameters k is 11.50210252569272 and b is -49.60131225297299\n",
      "Iteration 4758, the loss is 4.525998077568308, parameters k is 11.502135122530666 and b is -49.60127272728129\n",
      "Iteration 4759, the loss is 4.525997427986778, parameters k is 11.502117822135409 and b is -49.60124110672793\n",
      "Iteration 4760, the loss is 4.525996778405244, parameters k is 11.502100521740152 and b is -49.601209486174575\n",
      "Iteration 4761, the loss is 4.52599624175846, parameters k is 11.502083221344895 and b is -49.60117786562122\n",
      "Iteration 4762, the loss is 4.525995785880681, parameters k is 11.50211581818284 and b is -49.60113833992952\n",
      "Iteration 4763, the loss is 4.525995136299141, parameters k is 11.502098517787584 and b is -49.60110671937616\n",
      "Iteration 4764, the loss is 4.525994486717611, parameters k is 11.502081217392327 and b is -49.601075098822804\n",
      "Iteration 4765, the loss is 4.525993900512295, parameters k is 11.50206391699707 and b is -49.601043478269446\n",
      "Iteration 4766, the loss is 4.5259934941930355, parameters k is 11.502096513835015 and b is -49.60100395257775\n",
      "Iteration 4767, the loss is 4.5259928446115065, parameters k is 11.502079213439758 and b is -49.60097233202439\n",
      "Iteration 4768, the loss is 4.525992195029968, parameters k is 11.502061913044502 and b is -49.60094071147103\n",
      "Iteration 4769, the loss is 4.525991559266123, parameters k is 11.502044612649245 and b is -49.600909090917675\n",
      "Iteration 4770, the loss is 4.525991202505401, parameters k is 11.50207720948719 and b is -49.60086956522598\n",
      "Iteration 4771, the loss is 4.5259905529238695, parameters k is 11.502059909091933 and b is -49.60083794467262\n",
      "Iteration 4772, the loss is 4.525989903342333, parameters k is 11.502042608696676 and b is -49.60080632411926\n",
      "Iteration 4773, the loss is 4.5259892537607955, parameters k is 11.50202530830142 and b is -49.600774703565904\n",
      "Iteration 4774, the loss is 4.525988875076927, parameters k is 11.502008007906163 and b is -49.600743083012546\n",
      "Iteration 4775, the loss is 4.525988261236229, parameters k is 11.502040604744108 and b is -49.60070355732085\n",
      "Iteration 4776, the loss is 4.525987611654693, parameters k is 11.502023304348851 and b is -49.60067193676749\n",
      "Iteration 4777, the loss is 4.52598696207316, parameters k is 11.502006003953595 and b is -49.60064031621413\n",
      "Iteration 4778, the loss is 4.525986533830756, parameters k is 11.501988703558338 and b is -49.600608695660775\n",
      "Iteration 4779, the loss is 4.525985969548592, parameters k is 11.502021300396283 and b is -49.60056916996908\n",
      "Iteration 4780, the loss is 4.52598531996706, parameters k is 11.502004000001026 and b is -49.60053754941572\n",
      "Iteration 4781, the loss is 4.525984670385515, parameters k is 11.50198669960577 and b is -49.60050592886236\n",
      "Iteration 4782, the loss is 4.525984192584585, parameters k is 11.501969399210513 and b is -49.600474308309\n",
      "Iteration 4783, the loss is 4.525983677860954, parameters k is 11.502001996048458 and b is -49.600434782617306\n",
      "Iteration 4784, the loss is 4.525983028279417, parameters k is 11.501984695653201 and b is -49.60040316206395\n",
      "Iteration 4785, the loss is 4.525982378697882, parameters k is 11.501967395257944 and b is -49.60037154151059\n",
      "Iteration 4786, the loss is 4.525981851338418, parameters k is 11.501950094862687 and b is -49.60033992095723\n",
      "Iteration 4787, the loss is 4.525981386173317, parameters k is 11.501982691700633 and b is -49.600300395265535\n",
      "Iteration 4788, the loss is 4.525980736591783, parameters k is 11.501965391305376 and b is -49.60026877471218\n",
      "Iteration 4789, the loss is 4.525980087010245, parameters k is 11.501948090910119 and b is -49.60023715415882\n",
      "Iteration 4790, the loss is 4.525979510092247, parameters k is 11.501930790514862 and b is -49.60020553360546\n",
      "Iteration 4791, the loss is 4.525979094485682, parameters k is 11.501963387352808 and b is -49.600166007913764\n",
      "Iteration 4792, the loss is 4.525978444904146, parameters k is 11.50194608695755 and b is -49.600134387360406\n",
      "Iteration 4793, the loss is 4.525977795322608, parameters k is 11.501928786562294 and b is -49.60010276680705\n",
      "Iteration 4794, the loss is 4.525977168846079, parameters k is 11.501911486167037 and b is -49.60007114625369\n",
      "Iteration 4795, the loss is 4.525976802798044, parameters k is 11.501944083004982 and b is -49.60003162056199\n",
      "Iteration 4796, the loss is 4.525976153216507, parameters k is 11.501926782609726 and b is -49.600000000008635\n",
      "Iteration 4797, the loss is 4.52597550363497, parameters k is 11.501909482214469 and b is -49.59996837945528\n",
      "Iteration 4798, the loss is 4.525974854053436, parameters k is 11.501892181819212 and b is -49.59993675890192\n",
      "Iteration 4799, the loss is 4.525974484656885, parameters k is 11.501874881423955 and b is -49.59990513834856\n",
      "Iteration 4800, the loss is 4.525973861528869, parameters k is 11.5019074782619 and b is -49.59986561265686\n",
      "Iteration 4801, the loss is 4.525973211947333, parameters k is 11.501890177866644 and b is -49.599833992103505\n",
      "Iteration 4802, the loss is 4.525972562365796, parameters k is 11.501872877471387 and b is -49.59980237155015\n",
      "Iteration 4803, the loss is 4.525972143410716, parameters k is 11.50185557707613 and b is -49.59977075099679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4804, the loss is 4.525971569841231, parameters k is 11.501888173914075 and b is -49.59973122530509\n",
      "Iteration 4805, the loss is 4.5259709202597, parameters k is 11.501870873518818 and b is -49.599699604751734\n",
      "Iteration 4806, the loss is 4.525970270678157, parameters k is 11.501853573123562 and b is -49.599667984198376\n",
      "Iteration 4807, the loss is 4.525969802164543, parameters k is 11.501836272728305 and b is -49.59963636364502\n",
      "Iteration 4808, the loss is 4.525969278153597, parameters k is 11.50186886956625 and b is -49.59959683795332\n",
      "Iteration 4809, the loss is 4.525968628572056, parameters k is 11.501851569170993 and b is -49.59956521739996\n",
      "Iteration 4810, the loss is 4.525967978990523, parameters k is 11.501834268775736 and b is -49.599533596846605\n",
      "Iteration 4811, the loss is 4.525967460918379, parameters k is 11.50181696838048 and b is -49.59950197629325\n",
      "Iteration 4812, the loss is 4.5259669864659555, parameters k is 11.501849565218425 and b is -49.59946245060155\n",
      "Iteration 4813, the loss is 4.52596633688442, parameters k is 11.501832264823168 and b is -49.59943083004819\n",
      "Iteration 4814, the loss is 4.525965687302887, parameters k is 11.501814964427911 and b is -49.599399209494834\n",
      "Iteration 4815, the loss is 4.525965119672207, parameters k is 11.501797664032654 and b is -49.599367588941476\n",
      "Iteration 4816, the loss is 4.525964694778316, parameters k is 11.5018302608706 and b is -49.59932806324978\n",
      "Iteration 4817, the loss is 4.525964045196781, parameters k is 11.501812960475343 and b is -49.59929644269642\n",
      "Iteration 4818, the loss is 4.5259633956152445, parameters k is 11.501795660080086 and b is -49.59926482214306\n",
      "Iteration 4819, the loss is 4.52596277842604, parameters k is 11.50177835968483 and b is -49.599233201589705\n",
      "Iteration 4820, the loss is 4.525962403090675, parameters k is 11.501810956522775 and b is -49.59919367589801\n",
      "Iteration 4821, the loss is 4.525961753509148, parameters k is 11.501793656127518 and b is -49.59916205534465\n",
      "Iteration 4822, the loss is 4.525961103927607, parameters k is 11.501776355732261 and b is -49.59913043479129\n",
      "Iteration 4823, the loss is 4.52596045434607, parameters k is 11.501759055337004 and b is -49.599098814237934\n",
      "Iteration 4824, the loss is 4.525960094236842, parameters k is 11.501741754941747 and b is -49.599067193684576\n",
      "Iteration 4825, the loss is 4.525959461821505, parameters k is 11.501774351779693 and b is -49.59902766799288\n",
      "Iteration 4826, the loss is 4.525958812239973, parameters k is 11.501757051384436 and b is -49.59899604743952\n",
      "Iteration 4827, the loss is 4.525958162658436, parameters k is 11.501739750989179 and b is -49.59896442688616\n",
      "Iteration 4828, the loss is 4.525957752990673, parameters k is 11.501722450593922 and b is -49.598932806332805\n",
      "Iteration 4829, the loss is 4.525957170133867, parameters k is 11.501755047431867 and b is -49.59889328064111\n",
      "Iteration 4830, the loss is 4.525956520552334, parameters k is 11.50173774703661 and b is -49.59886166008775\n",
      "Iteration 4831, the loss is 4.525955870970797, parameters k is 11.501720446641354 and b is -49.59883003953439\n",
      "Iteration 4832, the loss is 4.525955411744502, parameters k is 11.501703146246097 and b is -49.59879841898103\n",
      "Iteration 4833, the loss is 4.52595487844623, parameters k is 11.501735743084042 and b is -49.598758893289336\n",
      "Iteration 4834, the loss is 4.525954228864696, parameters k is 11.501718442688786 and b is -49.59872727273598\n",
      "Iteration 4835, the loss is 4.52595357928316, parameters k is 11.501701142293529 and b is -49.59869565218262\n",
      "Iteration 4836, the loss is 4.525953070498333, parameters k is 11.501683841898272 and b is -49.59866403162926\n",
      "Iteration 4837, the loss is 4.52595258675859, parameters k is 11.501716438736217 and b is -49.598624505937565\n",
      "Iteration 4838, the loss is 4.525951937177056, parameters k is 11.50169913834096 and b is -49.59859288538421\n",
      "Iteration 4839, the loss is 4.525951287595524, parameters k is 11.501681837945704 and b is -49.59856126483085\n",
      "Iteration 4840, the loss is 4.525950729252167, parameters k is 11.501664537550447 and b is -49.59852964427749\n",
      "Iteration 4841, the loss is 4.52595029507096, parameters k is 11.501697134388392 and b is -49.598490118585794\n",
      "Iteration 4842, the loss is 4.525949645489425, parameters k is 11.501679833993135 and b is -49.598458498032436\n",
      "Iteration 4843, the loss is 4.525948995907888, parameters k is 11.501662533597878 and b is -49.59842687747908\n",
      "Iteration 4844, the loss is 4.525948388006, parameters k is 11.501645233202622 and b is -49.59839525692572\n",
      "Iteration 4845, the loss is 4.525948003383322, parameters k is 11.501677830040567 and b is -49.59835573123402\n",
      "Iteration 4846, the loss is 4.525947353801785, parameters k is 11.50166052964531 and b is -49.598324110680664\n",
      "Iteration 4847, the loss is 4.525946704220248, parameters k is 11.501643229250053 and b is -49.59829249012731\n",
      "Iteration 4848, the loss is 4.525946054638715, parameters k is 11.501625928854796 and b is -49.59826086957395\n",
      "Iteration 4849, the loss is 4.525945703816797, parameters k is 11.50160862845954 and b is -49.59822924902059\n",
      "Iteration 4850, the loss is 4.525945062114148, parameters k is 11.501641225297485 and b is -49.59818972332889\n",
      "Iteration 4851, the loss is 4.5259444125326125, parameters k is 11.501623924902228 and b is -49.598158102775535\n",
      "Iteration 4852, the loss is 4.525943762951079, parameters k is 11.501606624506971 and b is -49.59812648222218\n",
      "Iteration 4853, the loss is 4.525943362570631, parameters k is 11.501589324111714 and b is -49.59809486166882\n",
      "Iteration 4854, the loss is 4.525942770426512, parameters k is 11.50162192094966 and b is -49.59805533597712\n",
      "Iteration 4855, the loss is 4.525942120844972, parameters k is 11.501604620554403 and b is -49.598023715423764\n",
      "Iteration 4856, the loss is 4.5259414712634385, parameters k is 11.501587320159146 and b is -49.597992094870406\n",
      "Iteration 4857, the loss is 4.525941021324462, parameters k is 11.50157001976389 and b is -49.59796047431705\n",
      "Iteration 4858, the loss is 4.525940478738874, parameters k is 11.501602616601835 and b is -49.59792094862535\n",
      "Iteration 4859, the loss is 4.525939829157335, parameters k is 11.501585316206578 and b is -49.59788932807199\n",
      "Iteration 4860, the loss is 4.525939179575801, parameters k is 11.501568015811321 and b is -49.597857707518635\n",
      "Iteration 4861, the loss is 4.525938680078293, parameters k is 11.501550715416064 and b is -49.59782608696528\n",
      "Iteration 4862, the loss is 4.525938187051236, parameters k is 11.50158331225401 and b is -49.59778656127358\n",
      "Iteration 4863, the loss is 4.525937537469696, parameters k is 11.501566011858753 and b is -49.59775494072022\n",
      "Iteration 4864, the loss is 4.525936887888166, parameters k is 11.501548711463496 and b is -49.597723320166864\n",
      "Iteration 4865, the loss is 4.525936338832124, parameters k is 11.501531411068239 and b is -49.597691699613506\n",
      "Iteration 4866, the loss is 4.525935895363597, parameters k is 11.501564007906184 and b is -49.59765217392181\n",
      "Iteration 4867, the loss is 4.52593524578206, parameters k is 11.501546707510927 and b is -49.59762055336845\n",
      "Iteration 4868, the loss is 4.52593459620053, parameters k is 11.50152940711567 and b is -49.59758893281509\n",
      "Iteration 4869, the loss is 4.5259339975859545, parameters k is 11.501512106720414 and b is -49.597557312261735\n",
      "Iteration 4870, the loss is 4.52593360367596, parameters k is 11.50154470355836 and b is -49.59751778657004\n",
      "Iteration 4871, the loss is 4.525932954094423, parameters k is 11.501527403163102 and b is -49.59748616601668\n",
      "Iteration 4872, the loss is 4.525932304512891, parameters k is 11.501510102767845 and b is -49.59745454546332\n",
      "Iteration 4873, the loss is 4.525931656339788, parameters k is 11.501492802372589 and b is -49.597422924909964\n",
      "Iteration 4874, the loss is 4.525931311988321, parameters k is 11.501525399210534 and b is -49.597383399218266\n",
      "Iteration 4875, the loss is 4.52593066240679, parameters k is 11.501508098815277 and b is -49.59735177866491\n",
      "Iteration 4876, the loss is 4.525930012825249, parameters k is 11.50149079842002 and b is -49.59732015811155\n",
      "Iteration 4877, the loss is 4.525929363243714, parameters k is 11.501473498024763 and b is -49.59728853755819\n",
      "Iteration 4878, the loss is 4.5259289721505915, parameters k is 11.501456197629507 and b is -49.597256917004835\n",
      "Iteration 4879, the loss is 4.52592837071915, parameters k is 11.501488794467452 and b is -49.59721739131314\n",
      "Iteration 4880, the loss is 4.525927721137615, parameters k is 11.501471494072195 and b is -49.59718577075978\n",
      "Iteration 4881, the loss is 4.525927071556079, parameters k is 11.501454193676938 and b is -49.59715415020642\n",
      "Iteration 4882, the loss is 4.525926630904422, parameters k is 11.501436893281682 and b is -49.59712252965306\n",
      "Iteration 4883, the loss is 4.525926079031508, parameters k is 11.501469490119627 and b is -49.597083003961366\n",
      "Iteration 4884, the loss is 4.525925429449974, parameters k is 11.50145218972437 and b is -49.59705138340801\n",
      "Iteration 4885, the loss is 4.525924779868441, parameters k is 11.501434889329113 and b is -49.59701976285465\n",
      "Iteration 4886, the loss is 4.525924289658254, parameters k is 11.501417588933856 and b is -49.59698814230129\n",
      "Iteration 4887, the loss is 4.525923787343876, parameters k is 11.501450185771802 and b is -49.596948616609595\n",
      "Iteration 4888, the loss is 4.525923137762338, parameters k is 11.501432885376545 and b is -49.59691699605624\n",
      "Iteration 4889, the loss is 4.525922488180801, parameters k is 11.501415584981288 and b is -49.59688537550288\n",
      "Iteration 4890, the loss is 4.525921948412083, parameters k is 11.501398284586031 and b is -49.59685375494952\n",
      "Iteration 4891, the loss is 4.525921495656232, parameters k is 11.501430881423977 and b is -49.596814229257824\n",
      "Iteration 4892, the loss is 4.525920846074701, parameters k is 11.50141358102872 and b is -49.596782608704466\n",
      "Iteration 4893, the loss is 4.525920196493164, parameters k is 11.501396280633463 and b is -49.59675098815111\n",
      "Iteration 4894, the loss is 4.5259196071659185, parameters k is 11.501378980238206 and b is -49.59671936759775\n",
      "Iteration 4895, the loss is 4.525919203968601, parameters k is 11.501411577076151 and b is -49.59667984190605\n",
      "Iteration 4896, the loss is 4.525918554387065, parameters k is 11.501394276680895 and b is -49.596648221352694\n",
      "Iteration 4897, the loss is 4.525917904805525, parameters k is 11.501376976285638 and b is -49.59661660079934\n",
      "Iteration 4898, the loss is 4.52591726591975, parameters k is 11.50135967589038 and b is -49.59658498024598\n",
      "Iteration 4899, the loss is 4.525916912280958, parameters k is 11.501392272728326 and b is -49.59654545455428\n",
      "Iteration 4900, the loss is 4.525916262699423, parameters k is 11.50137497233307 and b is -49.59651383400092\n",
      "Iteration 4901, the loss is 4.525915613117888, parameters k is 11.501357671937813 and b is -49.596482213447565\n",
      "Iteration 4902, the loss is 4.525914963536354, parameters k is 11.501340371542556 and b is -49.59645059289421\n",
      "Iteration 4903, the loss is 4.525914581730542, parameters k is 11.501323071147299 and b is -49.59641897234085\n",
      "Iteration 4904, the loss is 4.525913971011786, parameters k is 11.501355667985244 and b is -49.59637944664915\n",
      "Iteration 4905, the loss is 4.525913321430249, parameters k is 11.501338367589987 and b is -49.596347826095794\n",
      "Iteration 4906, the loss is 4.525912671848717, parameters k is 11.50132106719473 and b is -49.596316205542436\n",
      "Iteration 4907, the loss is 4.525912240484376, parameters k is 11.501303766799474 and b is -49.59628458498908\n",
      "Iteration 4908, the loss is 4.525911679324152, parameters k is 11.501336363637419 and b is -49.59624505929738\n",
      "Iteration 4909, the loss is 4.525911029742619, parameters k is 11.501319063242162 and b is -49.59621343874402\n",
      "Iteration 4910, the loss is 4.525910380161079, parameters k is 11.501301762846905 and b is -49.596181818190665\n",
      "Iteration 4911, the loss is 4.525909899238211, parameters k is 11.501284462451649 and b is -49.59615019763731\n",
      "Iteration 4912, the loss is 4.5259093876365135, parameters k is 11.501317059289594 and b is -49.59611067194561\n",
      "Iteration 4913, the loss is 4.525908738054978, parameters k is 11.501299758894337 and b is -49.59607905139225\n",
      "Iteration 4914, the loss is 4.525908088473443, parameters k is 11.50128245849908 and b is -49.596047430838894\n",
      "Iteration 4915, the loss is 4.525907557992042, parameters k is 11.501265158103823 and b is -49.596015810285536\n",
      "Iteration 4916, the loss is 4.525907095948871, parameters k is 11.501297754941769 and b is -49.59597628459384\n",
      "Iteration 4917, the loss is 4.525906446367338, parameters k is 11.501280454546512 and b is -49.59594466404048\n",
      "Iteration 4918, the loss is 4.525905796785807, parameters k is 11.501263154151255 and b is -49.59591304348712\n",
      "Iteration 4919, the loss is 4.525905216745869, parameters k is 11.501245853755998 and b is -49.595881422933765\n",
      "Iteration 4920, the loss is 4.52590480426124, parameters k is 11.501278450593944 and b is -49.59584189724207\n",
      "Iteration 4921, the loss is 4.525904154679708, parameters k is 11.501261150198687 and b is -49.59581027668871\n",
      "Iteration 4922, the loss is 4.525903505098168, parameters k is 11.50124384980343 and b is -49.59577865613535\n",
      "Iteration 4923, the loss is 4.525902875499703, parameters k is 11.501226549408173 and b is -49.595747035581994\n",
      "Iteration 4924, the loss is 4.525902512573597, parameters k is 11.501259146246118 and b is -49.595707509890296\n",
      "Iteration 4925, the loss is 4.525901862992063, parameters k is 11.501241845850862 and b is -49.59567588933694\n",
      "Iteration 4926, the loss is 4.525901213410533, parameters k is 11.501224545455605 and b is -49.59564426878358\n",
      "Iteration 4927, the loss is 4.525900563828996, parameters k is 11.501207245060348 and b is -49.59561264823022\n",
      "Iteration 4928, the loss is 4.525900191310505, parameters k is 11.501189944665091 and b is -49.595581027676864\n",
      "Iteration 4929, the loss is 4.525899571304429, parameters k is 11.501222541503036 and b is -49.59554150198517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4930, the loss is 4.525898921722891, parameters k is 11.50120524110778 and b is -49.59550988143181\n",
      "Iteration 4931, the loss is 4.5258982721413545, parameters k is 11.501187940712523 and b is -49.59547826087845\n",
      "Iteration 4932, the loss is 4.525897850064337, parameters k is 11.501170640317266 and b is -49.59544664032509\n",
      "Iteration 4933, the loss is 4.52589727961679, parameters k is 11.501203237155211 and b is -49.595407114633396\n",
      "Iteration 4934, the loss is 4.525896630035258, parameters k is 11.501185936759954 and b is -49.59537549408004\n",
      "Iteration 4935, the loss is 4.525895980453721, parameters k is 11.501168636364698 and b is -49.59534387352668\n",
      "Iteration 4936, the loss is 4.5258955088181665, parameters k is 11.50115133596944 and b is -49.59531225297332\n",
      "Iteration 4937, the loss is 4.525894987929153, parameters k is 11.501183932807386 and b is -49.595272727281625\n",
      "Iteration 4938, the loss is 4.525894338347615, parameters k is 11.50116663241213 and b is -49.59524110672827\n",
      "Iteration 4939, the loss is 4.5258936887660814, parameters k is 11.501149332016873 and b is -49.59520948617491\n",
      "Iteration 4940, the loss is 4.525893167571998, parameters k is 11.501132031621616 and b is -49.59517786562155\n",
      "Iteration 4941, the loss is 4.5258926962415185, parameters k is 11.501164628459561 and b is -49.59513833992985\n",
      "Iteration 4942, the loss is 4.525892046659981, parameters k is 11.501147328064304 and b is -49.595106719376496\n",
      "Iteration 4943, the loss is 4.525891397078443, parameters k is 11.501130027669047 and b is -49.59507509882314\n",
      "Iteration 4944, the loss is 4.525890826325831, parameters k is 11.50111272727379 and b is -49.59504347826978\n",
      "Iteration 4945, the loss is 4.525890404553875, parameters k is 11.501145324111736 and b is -49.59500395257808\n",
      "Iteration 4946, the loss is 4.525889754972341, parameters k is 11.501128023716479 and b is -49.594972332024724\n",
      "Iteration 4947, the loss is 4.525889105390804, parameters k is 11.501110723321222 and b is -49.59494071147137\n",
      "Iteration 4948, the loss is 4.525888485079667, parameters k is 11.501093422925965 and b is -49.59490909091801\n",
      "Iteration 4949, the loss is 4.52588811286624, parameters k is 11.50112601976391 and b is -49.59486956522631\n",
      "Iteration 4950, the loss is 4.5258874632847, parameters k is 11.501108719368654 and b is -49.59483794467295\n",
      "Iteration 4951, the loss is 4.52588681370317, parameters k is 11.501091418973397 and b is -49.594806324119595\n",
      "Iteration 4952, the loss is 4.525886164121631, parameters k is 11.50107411857814 and b is -49.59477470356624\n",
      "Iteration 4953, the loss is 4.525885800890465, parameters k is 11.501056818182883 and b is -49.59474308301288\n",
      "Iteration 4954, the loss is 4.525885171597067, parameters k is 11.501089415020829 and b is -49.59470355732118\n",
      "Iteration 4955, the loss is 4.525884522015531, parameters k is 11.501072114625572 and b is -49.594671936767824\n",
      "Iteration 4956, the loss is 4.525883872433995, parameters k is 11.501054814230315 and b is -49.594640316214466\n",
      "Iteration 4957, the loss is 4.525883459644291, parameters k is 11.501037513835058 and b is -49.59460869566111\n",
      "Iteration 4958, the loss is 4.525882879909426, parameters k is 11.501070110673004 and b is -49.59456916996941\n",
      "Iteration 4959, the loss is 4.525882230327894, parameters k is 11.501052810277747 and b is -49.59453754941605\n",
      "Iteration 4960, the loss is 4.525881580746358, parameters k is 11.50103550988249 and b is -49.594505928862695\n",
      "Iteration 4961, the loss is 4.525881118398125, parameters k is 11.501018209487233 and b is -49.59447430830934\n",
      "Iteration 4962, the loss is 4.525880588221794, parameters k is 11.501050806325178 and b is -49.59443478261764\n",
      "Iteration 4963, the loss is 4.525879938640253, parameters k is 11.501033505929922 and b is -49.59440316206428\n",
      "Iteration 4964, the loss is 4.525879289058725, parameters k is 11.501016205534665 and b is -49.594371541510924\n",
      "Iteration 4965, the loss is 4.525878777151963, parameters k is 11.500998905139408 and b is -49.594339920957566\n",
      "Iteration 4966, the loss is 4.52587829653416, parameters k is 11.501031501977353 and b is -49.59430039526587\n",
      "Iteration 4967, the loss is 4.525877646952618, parameters k is 11.501014201582096 and b is -49.59426877471251\n",
      "Iteration 4968, the loss is 4.525876997371085, parameters k is 11.50099690118684 and b is -49.59423715415915\n",
      "Iteration 4969, the loss is 4.52587643590579, parameters k is 11.500979600791583 and b is -49.594205533605795\n",
      "Iteration 4970, the loss is 4.525876004846516, parameters k is 11.501012197629528 and b is -49.5941660079141\n",
      "Iteration 4971, the loss is 4.5258753552649775, parameters k is 11.500994897234271 and b is -49.59413438736074\n",
      "Iteration 4972, the loss is 4.525874705683444, parameters k is 11.500977596839014 and b is -49.59410276680738\n",
      "Iteration 4973, the loss is 4.525874094659621, parameters k is 11.500960296443758 and b is -49.594071146254024\n",
      "Iteration 4974, the loss is 4.525873713158878, parameters k is 11.500992893281703 and b is -49.594031620562326\n",
      "Iteration 4975, the loss is 4.52587306357735, parameters k is 11.500975592886446 and b is -49.59400000000897\n",
      "Iteration 4976, the loss is 4.525872413995806, parameters k is 11.50095829249119 and b is -49.59396837945561\n",
      "Iteration 4977, the loss is 4.525871764414274, parameters k is 11.500940992095932 and b is -49.59393675890225\n",
      "Iteration 4978, the loss is 4.525871410470419, parameters k is 11.500923691700676 and b is -49.593905138348894\n",
      "Iteration 4979, the loss is 4.5258707718897035, parameters k is 11.500956288538621 and b is -49.5938656126572\n",
      "Iteration 4980, the loss is 4.525870122308168, parameters k is 11.500938988143364 and b is -49.59383399210384\n",
      "Iteration 4981, the loss is 4.525869472726635, parameters k is 11.500921687748107 and b is -49.59380237155048\n",
      "Iteration 4982, the loss is 4.525869069224253, parameters k is 11.50090438735285 and b is -49.59377075099712\n",
      "Iteration 4983, the loss is 4.525868480202071, parameters k is 11.500936984190796 and b is -49.593731225305426\n",
      "Iteration 4984, the loss is 4.525867830620536, parameters k is 11.500919683795539 and b is -49.59369960475207\n",
      "Iteration 4985, the loss is 4.525867181039002, parameters k is 11.500902383400282 and b is -49.59366798419871\n",
      "Iteration 4986, the loss is 4.525866727978085, parameters k is 11.500885083005025 and b is -49.59363636364535\n",
      "Iteration 4987, the loss is 4.525866188514427, parameters k is 11.50091767984297 and b is -49.593596837953655\n",
      "Iteration 4988, the loss is 4.525865538932892, parameters k is 11.500900379447714 and b is -49.5935652174003\n",
      "Iteration 4989, the loss is 4.52586488935136, parameters k is 11.500883079052457 and b is -49.59353359684694\n",
      "Iteration 4990, the loss is 4.525864386731917, parameters k is 11.5008657786572 and b is -49.59350197629358\n",
      "Iteration 4991, the loss is 4.525863896826793, parameters k is 11.500898375495145 and b is -49.59346245060188\n",
      "Iteration 4992, the loss is 4.525863247245252, parameters k is 11.500881075099889 and b is -49.593430830048526\n",
      "Iteration 4993, the loss is 4.525862597663719, parameters k is 11.500863774704632 and b is -49.59339920949517\n",
      "Iteration 4994, the loss is 4.5258620454857486, parameters k is 11.500846474309375 and b is -49.59336758894181\n",
      "Iteration 4995, the loss is 4.525861605139153, parameters k is 11.50087907114732 and b is -49.59332806325011\n",
      "Iteration 4996, the loss is 4.525860955557622, parameters k is 11.500861770752064 and b is -49.593296442696754\n",
      "Iteration 4997, the loss is 4.525860305976083, parameters k is 11.500844470356807 and b is -49.5932648221434\n",
      "Iteration 4998, the loss is 4.525859704239582, parameters k is 11.50082716996155 and b is -49.59323320159004\n",
      "Iteration 4999, the loss is 4.525859313451519, parameters k is 11.500859766799495 and b is -49.59319367589834\n",
      "Iteration 5000, the loss is 4.525858663869981, parameters k is 11.500842466404238 and b is -49.59316205534498\n",
      "Iteration 5001, the loss is 4.525858014288446, parameters k is 11.500825166008982 and b is -49.593130434791625\n",
      "Iteration 5002, the loss is 4.525857364706912, parameters k is 11.500807865613725 and b is -49.59309881423827\n",
      "Iteration 5003, the loss is 4.525857020050379, parameters k is 11.500790565218468 and b is -49.59306719368491\n",
      "Iteration 5004, the loss is 4.5258563721823455, parameters k is 11.500823162056413 and b is -49.59302766799321\n",
      "Iteration 5005, the loss is 4.525855722600808, parameters k is 11.500805861661156 and b is -49.592996047439854\n",
      "Iteration 5006, the loss is 4.525855073019272, parameters k is 11.5007885612659 and b is -49.592964426886496\n",
      "Iteration 5007, the loss is 4.525854678804213, parameters k is 11.500771260870643 and b is -49.59293280633314\n",
      "Iteration 5008, the loss is 4.52585408049471, parameters k is 11.500803857708588 and b is -49.59289328064144\n",
      "Iteration 5009, the loss is 4.52585343091317, parameters k is 11.500786557313331 and b is -49.59286166008808\n",
      "Iteration 5010, the loss is 4.525852781331633, parameters k is 11.500769256918074 and b is -49.592830039534725\n",
      "Iteration 5011, the loss is 4.525852337558045, parameters k is 11.500751956522818 and b is -49.59279841898137\n",
      "Iteration 5012, the loss is 4.525851788807073, parameters k is 11.500784553360763 and b is -49.59275889328967\n",
      "Iteration 5013, the loss is 4.525851139225532, parameters k is 11.500767252965506 and b is -49.59272727273631\n",
      "Iteration 5014, the loss is 4.5258504896439975, parameters k is 11.50074995257025 and b is -49.592695652182954\n",
      "Iteration 5015, the loss is 4.52584999631187, parameters k is 11.500732652174992 and b is -49.592664031629596\n",
      "Iteration 5016, the loss is 4.525849497119434, parameters k is 11.500765249012938 and b is -49.5926245059379\n",
      "Iteration 5017, the loss is 4.5258488475378975, parameters k is 11.500747948617681 and b is -49.59259288538454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5018, the loss is 4.525848197956361, parameters k is 11.500730648222424 and b is -49.59256126483118\n",
      "Iteration 5019, the loss is 4.525847655065713, parameters k is 11.500713347827167 and b is -49.592529644277825\n",
      "Iteration 5020, the loss is 4.525847205431799, parameters k is 11.500745944665113 and b is -49.59249011858613\n",
      "Iteration 5021, the loss is 4.525846555850262, parameters k is 11.500728644269856 and b is -49.59245849803277\n",
      "Iteration 5022, the loss is 4.5258459062687235, parameters k is 11.500711343874599 and b is -49.59242687747941\n",
      "Iteration 5023, the loss is 4.525845313819541, parameters k is 11.500694043479342 and b is -49.59239525692605\n",
      "Iteration 5024, the loss is 4.52584491374416, parameters k is 11.500726640317287 and b is -49.592355731234356\n",
      "Iteration 5025, the loss is 4.525844264162622, parameters k is 11.50070933992203 and b is -49.592324110681\n",
      "Iteration 5026, the loss is 4.525843614581081, parameters k is 11.500692039526774 and b is -49.59229249012764\n",
      "Iteration 5027, the loss is 4.525842972573372, parameters k is 11.500674739131517 and b is -49.59226086957428\n",
      "Iteration 5028, the loss is 4.525842622056522, parameters k is 11.500707335969462 and b is -49.592221343882585\n",
      "Iteration 5029, the loss is 4.525841972474985, parameters k is 11.500690035574205 and b is -49.59218972332923\n",
      "Iteration 5030, the loss is 4.525841322893449, parameters k is 11.500672735178949 and b is -49.59215810277587\n",
      "Iteration 5031, the loss is 4.525840673311913, parameters k is 11.500655434783692 and b is -49.59212648222251\n",
      "Iteration 5032, the loss is 4.525840288384169, parameters k is 11.500638134388435 and b is -49.59209486166915\n",
      "Iteration 5033, the loss is 4.525839680787349, parameters k is 11.50067073122638 and b is -49.592055335977456\n",
      "Iteration 5034, the loss is 4.525839031205811, parameters k is 11.500653430831123 and b is -49.5920237154241\n",
      "Iteration 5035, the loss is 4.525838381624278, parameters k is 11.500636130435867 and b is -49.59199209487074\n",
      "Iteration 5036, the loss is 4.5258379471380055, parameters k is 11.50061883004061 and b is -49.59196047431738\n",
      "Iteration 5037, the loss is 4.525837389099707, parameters k is 11.500651426878555 and b is -49.591920948625685\n",
      "Iteration 5038, the loss is 4.525836739518171, parameters k is 11.500634126483298 and b is -49.59188932807233\n",
      "Iteration 5039, the loss is 4.525836089936642, parameters k is 11.500616826088041 and b is -49.59185770751897\n",
      "Iteration 5040, the loss is 4.525835605891831, parameters k is 11.500599525692785 and b is -49.59182608696561\n",
      "Iteration 5041, the loss is 4.525835097412071, parameters k is 11.50063212253073 and b is -49.59178656127391\n",
      "Iteration 5042, the loss is 4.525834447830536, parameters k is 11.500614822135473 and b is -49.591754940720556\n",
      "Iteration 5043, the loss is 4.525833798249, parameters k is 11.500597521740216 and b is -49.5917233201672\n",
      "Iteration 5044, the loss is 4.525833264645661, parameters k is 11.50058022134496 and b is -49.59169169961384\n",
      "Iteration 5045, the loss is 4.525832805724431, parameters k is 11.500612818182905 and b is -49.59165217392214\n",
      "Iteration 5046, the loss is 4.5258321561429, parameters k is 11.500595517787648 and b is -49.591620553368784\n",
      "Iteration 5047, the loss is 4.525831506561362, parameters k is 11.500578217392391 and b is -49.59158893281543\n",
      "Iteration 5048, the loss is 4.525830923399498, parameters k is 11.500560916997134 and b is -49.59155731226207\n",
      "Iteration 5049, the loss is 4.5258305140367945, parameters k is 11.50059351383508 and b is -49.59151778657037\n",
      "Iteration 5050, the loss is 4.525829864455262, parameters k is 11.500576213439823 and b is -49.59148616601701\n",
      "Iteration 5051, the loss is 4.525829214873726, parameters k is 11.500558913044566 and b is -49.591454545463655\n",
      "Iteration 5052, the loss is 4.525828582153325, parameters k is 11.50054161264931 and b is -49.5914229249103\n",
      "Iteration 5053, the loss is 4.525828222349159, parameters k is 11.500574209487255 and b is -49.5913833992186\n",
      "Iteration 5054, the loss is 4.5258275727676285, parameters k is 11.500556909091998 and b is -49.59135177866524\n",
      "Iteration 5055, the loss is 4.525826923186087, parameters k is 11.50053960869674 and b is -49.591320158111884\n",
      "Iteration 5056, the loss is 4.525826273604555, parameters k is 11.500522308301484 and b is -49.591288537558526\n",
      "Iteration 5057, the loss is 4.525825897964133, parameters k is 11.500505007906227 and b is -49.59125691700517\n",
      "Iteration 5058, the loss is 4.525825281079987, parameters k is 11.500537604744173 and b is -49.59121739131347\n",
      "Iteration 5059, the loss is 4.525824631498447, parameters k is 11.500520304348916 and b is -49.59118577076011\n",
      "Iteration 5060, the loss is 4.525823981916911, parameters k is 11.500503003953659 and b is -49.591154150206755\n",
      "Iteration 5061, the loss is 4.525823556717953, parameters k is 11.500485703558402 and b is -49.5911225296534\n",
      "Iteration 5062, the loss is 4.5258229893923465, parameters k is 11.500518300396347 and b is -49.5910830039617\n",
      "Iteration 5063, the loss is 4.52582233981081, parameters k is 11.50050100000109 and b is -49.59105138340834\n",
      "Iteration 5064, the loss is 4.5258216902292805, parameters k is 11.500483699605834 and b is -49.591019762854984\n",
      "Iteration 5065, the loss is 4.52582121547179, parameters k is 11.500466399210577 and b is -49.590988142301626\n",
      "Iteration 5066, the loss is 4.5258206977047095, parameters k is 11.500498996048522 and b is -49.59094861660993\n",
      "Iteration 5067, the loss is 4.525820048123173, parameters k is 11.500481695653265 and b is -49.59091699605657\n",
      "Iteration 5068, the loss is 4.52581939854164, parameters k is 11.500464395258009 and b is -49.59088537550321\n",
      "Iteration 5069, the loss is 4.525818874225622, parameters k is 11.500447094862752 and b is -49.590853754949855\n",
      "Iteration 5070, the loss is 4.525818406017076, parameters k is 11.500479691700697 and b is -49.59081422925816\n",
      "Iteration 5071, the loss is 4.525817756435537, parameters k is 11.50046239130544 and b is -49.5907826087048\n",
      "Iteration 5072, the loss is 4.525817106854006, parameters k is 11.500445090910183 and b is -49.59075098815144\n",
      "Iteration 5073, the loss is 4.525816532979456, parameters k is 11.500427790514927 and b is -49.59071936759808\n",
      "Iteration 5074, the loss is 4.525816114329436, parameters k is 11.500460387352872 and b is -49.590679841906386\n",
      "Iteration 5075, the loss is 4.525815464747901, parameters k is 11.500443086957615 and b is -49.59064822135303\n",
      "Iteration 5076, the loss is 4.525814815166368, parameters k is 11.500425786562358 and b is -49.59061660079967\n",
      "Iteration 5077, the loss is 4.525814191733287, parameters k is 11.500408486167101 and b is -49.59058498024631\n",
      "Iteration 5078, the loss is 4.525813822641797, parameters k is 11.500441083005047 and b is -49.590545454554615\n",
      "Iteration 5079, the loss is 4.525813173060261, parameters k is 11.50042378260979 and b is -49.59051383400126\n",
      "Iteration 5080, the loss is 4.525812523478732, parameters k is 11.500406482214533 and b is -49.5904822134479\n",
      "Iteration 5081, the loss is 4.525811873897194, parameters k is 11.500389181819276 and b is -49.59045059289454\n",
      "Iteration 5082, the loss is 4.5258115075440895, parameters k is 11.50037188142402 and b is -49.59041897234118\n",
      "Iteration 5083, the loss is 4.525810881372619, parameters k is 11.500404478261965 and b is -49.590379446649486\n",
      "Iteration 5084, the loss is 4.525810231791088, parameters k is 11.500387177866708 and b is -49.59034782609613\n",
      "Iteration 5085, the loss is 4.525809582209554, parameters k is 11.500369877471451 and b is -49.59031620554277\n",
      "Iteration 5086, the loss is 4.525809166297919, parameters k is 11.500352577076194 and b is -49.59028458498941\n",
      "Iteration 5087, the loss is 4.525808589684985, parameters k is 11.50038517391414 and b is -49.590245059297715\n",
      "Iteration 5088, the loss is 4.525807940103451, parameters k is 11.500367873518883 and b is -49.59021343874436\n",
      "Iteration 5089, the loss is 4.525807290521917, parameters k is 11.500350573123626 and b is -49.590181818191\n",
      "Iteration 5090, the loss is 4.525806825051752, parameters k is 11.50033327272837 and b is -49.59015019763764\n",
      "Iteration 5091, the loss is 4.525806297997354, parameters k is 11.500365869566314 and b is -49.59011067194594\n",
      "Iteration 5092, the loss is 4.525805648415813, parameters k is 11.500348569171058 and b is -49.590079051392586\n",
      "Iteration 5093, the loss is 4.525804998834279, parameters k is 11.5003312687758 and b is -49.59004743083923\n",
      "Iteration 5094, the loss is 4.525804483805585, parameters k is 11.500313968380544 and b is -49.59001581028587\n",
      "Iteration 5095, the loss is 4.525804006309712, parameters k is 11.50034656521849 and b is -49.58997628459417\n",
      "Iteration 5096, the loss is 4.52580335672818, parameters k is 11.500329264823232 and b is -49.589944664040814\n",
      "Iteration 5097, the loss is 4.52580270714664, parameters k is 11.500311964427976 and b is -49.589913043487456\n",
      "Iteration 5098, the loss is 4.525802142559419, parameters k is 11.500294664032719 and b is -49.5898814229341\n",
      "Iteration 5099, the loss is 4.525801714622074, parameters k is 11.500327260870664 and b is -49.5898418972424\n",
      "Iteration 5100, the loss is 4.525801065040536, parameters k is 11.500309960475407 and b is -49.58981027668904\n",
      "Iteration 5101, the loss is 4.525800415459007, parameters k is 11.50029266008015 and b is -49.589778656135685\n",
      "Iteration 5102, the loss is 4.52579980131325, parameters k is 11.500275359684894 and b is -49.58974703558233\n",
      "Iteration 5103, the loss is 4.525799422934438, parameters k is 11.500307956522839 and b is -49.58970750989063\n",
      "Iteration 5104, the loss is 4.525798773352911, parameters k is 11.500290656127582 and b is -49.58967588933727\n",
      "Iteration 5105, the loss is 4.525798123771373, parameters k is 11.500273355732325 and b is -49.589644268783914\n",
      "Iteration 5106, the loss is 4.525797474189828, parameters k is 11.500256055337069 and b is -49.589612648230556\n",
      "Iteration 5107, the loss is 4.525797117124045, parameters k is 11.500238754941812 and b is -49.5895810276772\n",
      "Iteration 5108, the loss is 4.525796481665267, parameters k is 11.500271351779757 and b is -49.5895415019855\n",
      "Iteration 5109, the loss is 4.525795832083734, parameters k is 11.5002540513845 and b is -49.58950988143214\n",
      "Iteration 5110, the loss is 4.525795182502197, parameters k is 11.500236750989243 and b is -49.589478260878785\n",
      "Iteration 5111, the loss is 4.525794775877876, parameters k is 11.500219450593987 and b is -49.58944664032543\n",
      "Iteration 5112, the loss is 4.525794189977627, parameters k is 11.500252047431932 and b is -49.58940711463373\n",
      "Iteration 5113, the loss is 4.525793540396093, parameters k is 11.500234747036675 and b is -49.58937549408037\n",
      "Iteration 5114, the loss is 4.525792890814555, parameters k is 11.500217446641418 and b is -49.589343873527014\n",
      "Iteration 5115, the loss is 4.525792434631709, parameters k is 11.500200146246161 and b is -49.589312252973656\n",
      "Iteration 5116, the loss is 4.525791898289987, parameters k is 11.500232743084107 and b is -49.58927272728196\n",
      "Iteration 5117, the loss is 4.525791248708462, parameters k is 11.50021544268885 and b is -49.5892411067286\n",
      "Iteration 5118, the loss is 4.525790599126919, parameters k is 11.500198142293593 and b is -49.58920948617524\n",
      "Iteration 5119, the loss is 4.525790093385538, parameters k is 11.500180841898336 and b is -49.589177865621885\n",
      "Iteration 5120, the loss is 4.525789606602352, parameters k is 11.500213438736282 and b is -49.58913833993019\n",
      "Iteration 5121, the loss is 4.525788957020815, parameters k is 11.500196138341025 and b is -49.58910671937683\n",
      "Iteration 5122, the loss is 4.525788307439285, parameters k is 11.500178837945768 and b is -49.58907509882347\n",
      "Iteration 5123, the loss is 4.5257877521393715, parameters k is 11.500161537550511 and b is -49.58904347827011\n",
      "Iteration 5124, the loss is 4.525787314914714, parameters k is 11.500194134388456 and b is -49.589003952578416\n",
      "Iteration 5125, the loss is 4.52578666533318, parameters k is 11.5001768339932 and b is -49.58897233202506\n",
      "Iteration 5126, the loss is 4.525786015751642, parameters k is 11.500159533597943 and b is -49.5889407114717\n",
      "Iteration 5127, the loss is 4.525785410893206, parameters k is 11.500142233202686 and b is -49.58890909091834\n",
      "Iteration 5128, the loss is 4.525785023227078, parameters k is 11.500174830040631 and b is -49.588869565226645\n",
      "Iteration 5129, the loss is 4.525784373645543, parameters k is 11.500157529645374 and b is -49.58883794467329\n",
      "Iteration 5130, the loss is 4.525783724064007, parameters k is 11.500140229250118 and b is -49.58880632411993\n",
      "Iteration 5131, the loss is 4.525783074482469, parameters k is 11.50012292885486 and b is -49.58877470356657\n",
      "Iteration 5132, the loss is 4.525782726704005, parameters k is 11.500105628459604 and b is -49.58874308301321\n",
      "Iteration 5133, the loss is 4.525782081957905, parameters k is 11.50013822529755 and b is -49.588703557321516\n",
      "Iteration 5134, the loss is 4.52578143237637, parameters k is 11.500120924902292 and b is -49.58867193676816\n",
      "Iteration 5135, the loss is 4.52578078279483, parameters k is 11.500103624507036 and b is -49.5886403162148\n",
      "Iteration 5136, the loss is 4.525780385457829, parameters k is 11.500086324111779 and b is -49.58860869566144\n",
      "Iteration 5137, the loss is 4.525779790270265, parameters k is 11.500118920949724 and b is -49.588569169969745\n",
      "Iteration 5138, the loss is 4.525779140688727, parameters k is 11.500101620554467 and b is -49.58853754941639\n",
      "Iteration 5139, the loss is 4.525778491107192, parameters k is 11.50008432015921 and b is -49.58850592886303\n",
      "Iteration 5140, the loss is 4.525778044211671, parameters k is 11.500067019763954 and b is -49.58847430830967\n",
      "Iteration 5141, the loss is 4.52577749858263, parameters k is 11.500099616601899 and b is -49.58843478261797\n",
      "Iteration 5142, the loss is 4.525776849001095, parameters k is 11.500082316206642 and b is -49.588403162064616\n",
      "Iteration 5143, the loss is 4.525776199419558, parameters k is 11.500065015811385 and b is -49.58837154151126\n",
      "Iteration 5144, the loss is 4.525775702965498, parameters k is 11.500047715416128 and b is -49.5883399209579\n",
      "Iteration 5145, the loss is 4.525775206894997, parameters k is 11.500080312254074 and b is -49.5883003952662\n",
      "Iteration 5146, the loss is 4.5257745573134605, parameters k is 11.500063011858817 and b is -49.588268774712844\n",
      "Iteration 5147, the loss is 4.525773907731919, parameters k is 11.50004571146356 and b is -49.588237154159486\n",
      "Iteration 5148, the loss is 4.525773361719334, parameters k is 11.500028411068303 and b is -49.58820553360613\n",
      "Iteration 5149, the loss is 4.525772915207354, parameters k is 11.500061007906249 and b is -49.58816600791443\n",
      "Iteration 5150, the loss is 4.525772265625823, parameters k is 11.500043707510992 and b is -49.58813438736107\n",
      "Iteration 5151, the loss is 4.525771616044286, parameters k is 11.500026407115735 and b is -49.588102766807715\n",
      "Iteration 5152, the loss is 4.52577102047316, parameters k is 11.500009106720478 and b is -49.58807114625436\n",
      "Iteration 5153, the loss is 4.525770623519715, parameters k is 11.500041703558423 and b is -49.58803162056266\n",
      "Iteration 5154, the loss is 4.52576997393818, parameters k is 11.500024403163167 and b is -49.5880000000093\n",
      "Iteration 5155, the loss is 4.525769324356644, parameters k is 11.50000710276791 and b is -49.587968379455944\n",
      "Iteration 5156, the loss is 4.525768679226987, parameters k is 11.499989802372653 and b is -49.587936758902586\n",
      "Iteration 5157, the loss is 4.525768331832081, parameters k is 11.500022399210598 and b is -49.58789723321089\n",
      "Iteration 5158, the loss is 4.525767682250545, parameters k is 11.500005098815341 and b is -49.58786561265753\n",
      "Iteration 5159, the loss is 4.52576703266901, parameters k is 11.499987798420085 and b is -49.58783399210417\n",
      "Iteration 5160, the loss is 4.52576638308747, parameters k is 11.499970498024828 and b is -49.587802371550815\n",
      "Iteration 5161, the loss is 4.52576599503779, parameters k is 11.499953197629571 and b is -49.58777075099746\n",
      "Iteration 5162, the loss is 4.525765390562908, parameters k is 11.499985794467516 and b is -49.58773122530576\n",
      "Iteration 5163, the loss is 4.525764740981374, parameters k is 11.49996849407226 and b is -49.5876996047524\n",
      "Iteration 5164, the loss is 4.525764091399837, parameters k is 11.499951193677003 and b is -49.587667984199044\n",
      "Iteration 5165, the loss is 4.525763653791622, parameters k is 11.499933893281746 and b is -49.587636363645686\n",
      "Iteration 5166, the loss is 4.525763098875266, parameters k is 11.499966490119691 and b is -49.58759683795399\n",
      "Iteration 5167, the loss is 4.525762449293733, parameters k is 11.499949189724434 and b is -49.58756521740063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5168, the loss is 4.525761799712199, parameters k is 11.499931889329178 and b is -49.58753359684727\n",
      "Iteration 5169, the loss is 4.525761312545455, parameters k is 11.49991458893392 and b is -49.587501976293915\n",
      "Iteration 5170, the loss is 4.525760807187628, parameters k is 11.499947185771866 and b is -49.58746245060222\n",
      "Iteration 5171, the loss is 4.525760157606091, parameters k is 11.49992988537661 and b is -49.58743083004886\n",
      "Iteration 5172, the loss is 4.525759508024557, parameters k is 11.499912584981352 and b is -49.5873992094955\n",
      "Iteration 5173, the loss is 4.52575897129929, parameters k is 11.499895284586096 and b is -49.58736758894214\n",
      "Iteration 5174, the loss is 4.525758515499992, parameters k is 11.49992788142404 and b is -49.587328063250446\n",
      "Iteration 5175, the loss is 4.525757865918458, parameters k is 11.499910581028784 and b is -49.58729644269709\n",
      "Iteration 5176, the loss is 4.525757216336921, parameters k is 11.499893280633527 and b is -49.58726482214373\n",
      "Iteration 5177, the loss is 4.5257566300531185, parameters k is 11.49987598023827 and b is -49.58723320159037\n",
      "Iteration 5178, the loss is 4.525756223812354, parameters k is 11.499908577076216 and b is -49.587193675898675\n",
      "Iteration 5179, the loss is 4.525755574230821, parameters k is 11.499891276680959 and b is -49.58716205534532\n",
      "Iteration 5180, the loss is 4.525754924649288, parameters k is 11.499873976285702 and b is -49.58713043479196\n",
      "Iteration 5181, the loss is 4.525754288806957, parameters k is 11.499856675890445 and b is -49.5870988142386\n",
      "Iteration 5182, the loss is 4.5257539321247195, parameters k is 11.49988927272839 and b is -49.587059288546904\n",
      "Iteration 5183, the loss is 4.525753282543184, parameters k is 11.499871972333134 and b is -49.587027667993546\n",
      "Iteration 5184, the loss is 4.525752632961648, parameters k is 11.499854671937877 and b is -49.58699604744019\n",
      "Iteration 5185, the loss is 4.525751983380108, parameters k is 11.49983737154262 and b is -49.58696442688683\n",
      "Iteration 5186, the loss is 4.525751604617755, parameters k is 11.499820071147363 and b is -49.58693280633347\n",
      "Iteration 5187, the loss is 4.525750990855542, parameters k is 11.499852667985309 and b is -49.586893280641775\n",
      "Iteration 5188, the loss is 4.525750341274011, parameters k is 11.499835367590052 and b is -49.58686166008842\n",
      "Iteration 5189, the loss is 4.525749691692476, parameters k is 11.499818067194795 and b is -49.58683003953506\n",
      "Iteration 5190, the loss is 4.525749263371583, parameters k is 11.499800766799538 and b is -49.5867984189817\n",
      "Iteration 5191, the loss is 4.5257486991679095, parameters k is 11.499833363637483 and b is -49.58675889329\n",
      "Iteration 5192, the loss is 4.525748049586371, parameters k is 11.499816063242227 and b is -49.586727272736645\n",
      "Iteration 5193, the loss is 4.5257474000048346, parameters k is 11.49979876284697 and b is -49.58669565218329\n",
      "Iteration 5194, the loss is 4.525746922125416, parameters k is 11.499781462451713 and b is -49.58666403162993\n",
      "Iteration 5195, the loss is 4.525746407480272, parameters k is 11.499814059289658 and b is -49.58662450593823\n",
      "Iteration 5196, the loss is 4.525745757898734, parameters k is 11.499796758894401 and b is -49.586592885384874\n",
      "Iteration 5197, the loss is 4.525745108317199, parameters k is 11.499779458499145 and b is -49.586561264831516\n",
      "Iteration 5198, the loss is 4.5257445808792465, parameters k is 11.499762158103888 and b is -49.58652964427816\n",
      "Iteration 5199, the loss is 4.5257441157926355, parameters k is 11.499794754941833 and b is -49.58649011858646\n",
      "Iteration 5200, the loss is 4.525743466211097, parameters k is 11.499777454546576 and b is -49.5864584980331\n",
      "Iteration 5201, the loss is 4.525742816629562, parameters k is 11.49976015415132 and b is -49.586426877479745\n",
      "Iteration 5202, the loss is 4.5257422396330735, parameters k is 11.499742853756063 and b is -49.58639525692639\n",
      "Iteration 5203, the loss is 4.525741824104994, parameters k is 11.499775450594008 and b is -49.58635573123469\n",
      "Iteration 5204, the loss is 4.525741174523462, parameters k is 11.499758150198751 and b is -49.58632411068133\n",
      "Iteration 5205, the loss is 4.525740524941926, parameters k is 11.499740849803494 and b is -49.586292490127974\n",
      "Iteration 5206, the loss is 4.525739898386907, parameters k is 11.499723549408237 and b is -49.586260869574616\n",
      "Iteration 5207, the loss is 4.5257395324173535, parameters k is 11.499756146246183 and b is -49.58622134388292\n",
      "Iteration 5208, the loss is 4.525738882835817, parameters k is 11.499738845850926 and b is -49.58618972332956\n",
      "Iteration 5209, the loss is 4.5257382332542875, parameters k is 11.49972154545567 and b is -49.5861581027762\n",
      "Iteration 5210, the loss is 4.52573758367275, parameters k is 11.499704245060412 and b is -49.586126482222845\n",
      "Iteration 5211, the loss is 4.525737214197712, parameters k is 11.499686944665156 and b is -49.58609486166949\n",
      "Iteration 5212, the loss is 4.525736591148183, parameters k is 11.4997195415031 and b is -49.58605533597779\n",
      "Iteration 5213, the loss is 4.525735941566645, parameters k is 11.499702241107844 and b is -49.58602371542443\n",
      "Iteration 5214, the loss is 4.525735291985115, parameters k is 11.499684940712587 and b is -49.585992094871074\n",
      "Iteration 5215, the loss is 4.525734872951541, parameters k is 11.49966764031733 and b is -49.585960474317716\n",
      "Iteration 5216, the loss is 4.525734299460546, parameters k is 11.499700237155276 and b is -49.58592094862602\n",
      "Iteration 5217, the loss is 4.52573364987901, parameters k is 11.499682936760019 and b is -49.58588932807266\n",
      "Iteration 5218, the loss is 4.525733000297475, parameters k is 11.499665636364762 and b is -49.5858577075193\n",
      "Iteration 5219, the loss is 4.52573253170537, parameters k is 11.499648335969505 and b is -49.585826086965945\n",
      "Iteration 5220, the loss is 4.525732007772909, parameters k is 11.49968093280745 and b is -49.58578656127425\n",
      "Iteration 5221, the loss is 4.525731358191375, parameters k is 11.499663632412194 and b is -49.58575494072089\n",
      "Iteration 5222, the loss is 4.525730708609841, parameters k is 11.499646332016937 and b is -49.58572332016753\n",
      "Iteration 5223, the loss is 4.525730190459206, parameters k is 11.49962903162168 and b is -49.58569169961417\n",
      "Iteration 5224, the loss is 4.52572971608527, parameters k is 11.499661628459625 and b is -49.585652173922476\n",
      "Iteration 5225, the loss is 4.525729066503736, parameters k is 11.499644328064369 and b is -49.58562055336912\n",
      "Iteration 5226, the loss is 4.525728416922201, parameters k is 11.499627027669112 and b is -49.58558893281576\n",
      "Iteration 5227, the loss is 4.525727849213039, parameters k is 11.499609727273855 and b is -49.5855573122624\n",
      "Iteration 5228, the loss is 4.52572742439763, parameters k is 11.4996423241118 and b is -49.585517786570705\n",
      "Iteration 5229, the loss is 4.525726774816096, parameters k is 11.499625023716543 and b is -49.58548616601735\n",
      "Iteration 5230, the loss is 4.52572612523456, parameters k is 11.499607723321287 and b is -49.58545454546399\n",
      "Iteration 5231, the loss is 4.525725507966867, parameters k is 11.49959042292603 and b is -49.58542292491063\n",
      "Iteration 5232, the loss is 4.525725132709999, parameters k is 11.499623019763975 and b is -49.585383399218934\n",
      "Iteration 5233, the loss is 4.525724483128465, parameters k is 11.499605719368718 and b is -49.585351778665576\n",
      "Iteration 5234, the loss is 4.5257238335469285, parameters k is 11.499588418973461 and b is -49.58532015811222\n",
      "Iteration 5235, the loss is 4.525723183965393, parameters k is 11.499571118578205 and b is -49.58528853755886\n",
      "Iteration 5236, the loss is 4.5257228237776665, parameters k is 11.499553818182948 and b is -49.5852569170055\n",
      "Iteration 5237, the loss is 4.525722191440822, parameters k is 11.499586415020893 and b is -49.585217391313805\n",
      "Iteration 5238, the loss is 4.525721541859285, parameters k is 11.499569114625636 and b is -49.58518577076045\n",
      "Iteration 5239, the loss is 4.525720892277747, parameters k is 11.49955181423038 and b is -49.58515415020709\n",
      "Iteration 5240, the loss is 4.525720482531499, parameters k is 11.499534513835123 and b is -49.58512252965373\n",
      "Iteration 5241, the loss is 4.525719899753186, parameters k is 11.499567110673068 and b is -49.58508300396203\n",
      "Iteration 5242, the loss is 4.525719250171653, parameters k is 11.499549810277811 and b is -49.585051383408675\n",
      "Iteration 5243, the loss is 4.525718600590111, parameters k is 11.499532509882554 and b is -49.58501976285532\n",
      "Iteration 5244, the loss is 4.525718141285334, parameters k is 11.499515209487297 and b is -49.58498814230196\n",
      "Iteration 5245, the loss is 4.525717608065551, parameters k is 11.499547806325243 and b is -49.58494861661026\n",
      "Iteration 5246, the loss is 4.525716958484013, parameters k is 11.499530505929986 and b is -49.584916996056904\n",
      "Iteration 5247, the loss is 4.525716308902479, parameters k is 11.499513205534729 and b is -49.584885375503546\n",
      "Iteration 5248, the loss is 4.525715800039164, parameters k is 11.499495905139472 and b is -49.58485375495019\n",
      "Iteration 5249, the loss is 4.525715316377903, parameters k is 11.499528501977418 and b is -49.58481422925849\n",
      "Iteration 5250, the loss is 4.525714666796374, parameters k is 11.49951120158216 and b is -49.58478260870513\n",
      "Iteration 5251, the loss is 4.525714017214839, parameters k is 11.499493901186904 and b is -49.584750988151775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5252, the loss is 4.5257134587929935, parameters k is 11.499476600791647 and b is -49.58471936759842\n",
      "Iteration 5253, the loss is 4.525713024690272, parameters k is 11.499509197629592 and b is -49.58467984190672\n",
      "Iteration 5254, the loss is 4.5257123751087365, parameters k is 11.499491897234336 and b is -49.58464822135336\n",
      "Iteration 5255, the loss is 4.525711725527202, parameters k is 11.499474596839079 and b is -49.584616600800004\n",
      "Iteration 5256, the loss is 4.525711117546826, parameters k is 11.499457296443822 and b is -49.584584980246646\n",
      "Iteration 5257, the loss is 4.525710733002635, parameters k is 11.499489893281767 and b is -49.58454545455495\n",
      "Iteration 5258, the loss is 4.5257100834211, parameters k is 11.49947259288651 and b is -49.58451383400159\n",
      "Iteration 5259, the loss is 4.5257094338395625, parameters k is 11.499455292491254 and b is -49.58448221344823\n",
      "Iteration 5260, the loss is 4.5257087842580335, parameters k is 11.499437992095997 and b is -49.584450592894875\n",
      "Iteration 5261, the loss is 4.525708433357624, parameters k is 11.49942069170074 and b is -49.58441897234152\n",
      "Iteration 5262, the loss is 4.52570779173346, parameters k is 11.499453288538685 and b is -49.58437944664982\n",
      "Iteration 5263, the loss is 4.525707142151927, parameters k is 11.499435988143428 and b is -49.58434782609646\n",
      "Iteration 5264, the loss is 4.525706492570397, parameters k is 11.499418687748172 and b is -49.584316205543104\n",
      "Iteration 5265, the loss is 4.5257060921114585, parameters k is 11.499401387352915 and b is -49.584284584989746\n",
      "Iteration 5266, the loss is 4.525705500045825, parameters k is 11.49943398419086 and b is -49.58424505929805\n",
      "Iteration 5267, the loss is 4.52570485046429, parameters k is 11.499416683795603 and b is -49.58421343874469\n",
      "Iteration 5268, the loss is 4.525704200882756, parameters k is 11.499399383400347 and b is -49.58418181819133\n",
      "Iteration 5269, the loss is 4.525703750865287, parameters k is 11.49938208300509 and b is -49.584150197637975\n",
      "Iteration 5270, the loss is 4.525703208358188, parameters k is 11.499414679843035 and b is -49.58411067194628\n",
      "Iteration 5271, the loss is 4.5257025587766515, parameters k is 11.499397379447778 and b is -49.58407905139292\n",
      "Iteration 5272, the loss is 4.525701909195117, parameters k is 11.499380079052521 and b is -49.58404743083956\n",
      "Iteration 5273, the loss is 4.525701409619119, parameters k is 11.499362778657265 and b is -49.5840158102862\n",
      "Iteration 5274, the loss is 4.525700916670546, parameters k is 11.49939537549521 and b is -49.583976284594506\n",
      "Iteration 5275, the loss is 4.525700267089015, parameters k is 11.499378075099953 and b is -49.58394466404115\n",
      "Iteration 5276, the loss is 4.5256996175074775, parameters k is 11.499360774704696 and b is -49.58391304348779\n",
      "Iteration 5277, the loss is 4.525699068372949, parameters k is 11.49934347430944 and b is -49.58388142293443\n",
      "Iteration 5278, the loss is 4.525698624982915, parameters k is 11.499376071147385 and b is -49.583841897242735\n",
      "Iteration 5279, the loss is 4.5256979754013775, parameters k is 11.499358770752128 and b is -49.58381027668938\n",
      "Iteration 5280, the loss is 4.525697325819842, parameters k is 11.499341470356871 and b is -49.58377865613602\n",
      "Iteration 5281, the loss is 4.525696727126781, parameters k is 11.499324169961614 and b is -49.58374703558266\n",
      "Iteration 5282, the loss is 4.5256963332952775, parameters k is 11.49935676679956 and b is -49.583707509890964\n",
      "Iteration 5283, the loss is 4.525695683713741, parameters k is 11.499339466404303 and b is -49.583675889337606\n",
      "Iteration 5284, the loss is 4.525695034132205, parameters k is 11.499322166009046 and b is -49.58364426878425\n",
      "Iteration 5285, the loss is 4.525694385880611, parameters k is 11.499304865613789 and b is -49.58361264823089\n",
      "Iteration 5286, the loss is 4.525694041607641, parameters k is 11.499337462451734 and b is -49.58357312253919\n",
      "Iteration 5287, the loss is 4.525693392026101, parameters k is 11.499320162056478 and b is -49.583541501985835\n",
      "Iteration 5288, the loss is 4.525692742444568, parameters k is 11.49930286166122 and b is -49.58350988143248\n",
      "Iteration 5289, the loss is 4.525692092863031, parameters k is 11.499285561265964 and b is -49.58347826087912\n",
      "Iteration 5290, the loss is 4.525691701691414, parameters k is 11.499268260870707 and b is -49.58344664032576\n",
      "Iteration 5291, the loss is 4.5256911003384666, parameters k is 11.499300857708652 and b is -49.58340711463406\n",
      "Iteration 5292, the loss is 4.5256904507569296, parameters k is 11.499283557313396 and b is -49.583375494080705\n",
      "Iteration 5293, the loss is 4.525689801175395, parameters k is 11.499266256918139 and b is -49.58334387352735\n",
      "Iteration 5294, the loss is 4.525689360445248, parameters k is 11.499248956522882 and b is -49.58331225297399\n",
      "Iteration 5295, the loss is 4.525688808650825, parameters k is 11.499281553360827 and b is -49.58327272728229\n",
      "Iteration 5296, the loss is 4.525688159069293, parameters k is 11.49926425296557 and b is -49.583241106728934\n",
      "Iteration 5297, the loss is 4.5256875094877556, parameters k is 11.499246952570314 and b is -49.583209486175576\n",
      "Iteration 5298, the loss is 4.52568701919908, parameters k is 11.499229652175057 and b is -49.58317786562222\n",
      "Iteration 5299, the loss is 4.525686516963193, parameters k is 11.499262249013002 and b is -49.58313833993052\n",
      "Iteration 5300, the loss is 4.525685867381652, parameters k is 11.499244948617745 and b is -49.58310671937716\n",
      "Iteration 5301, the loss is 4.52568521780012, parameters k is 11.499227648222488 and b is -49.583075098823805\n",
      "Iteration 5302, the loss is 4.525684677952915, parameters k is 11.499210347827232 and b is -49.58304347827045\n",
      "Iteration 5303, the loss is 4.525684225275552, parameters k is 11.499242944665177 and b is -49.58300395257875\n",
      "Iteration 5304, the loss is 4.525683575694016, parameters k is 11.49922564426992 and b is -49.58297233202539\n",
      "Iteration 5305, the loss is 4.525682926112487, parameters k is 11.499208343874663 and b is -49.582940711472034\n",
      "Iteration 5306, the loss is 4.525682336706744, parameters k is 11.499191043479406 and b is -49.582909090918676\n",
      "Iteration 5307, the loss is 4.525681933587915, parameters k is 11.499223640317352 and b is -49.58286956522698\n",
      "Iteration 5308, the loss is 4.525681284006383, parameters k is 11.499206339922095 and b is -49.58283794467362\n",
      "Iteration 5309, the loss is 4.525680634424842, parameters k is 11.499189039526838 and b is -49.58280632412026\n",
      "Iteration 5310, the loss is 4.525679995460572, parameters k is 11.499171739131581 and b is -49.582774703566905\n",
      "Iteration 5311, the loss is 4.525679641900274, parameters k is 11.499204335969527 and b is -49.58273517787521\n",
      "Iteration 5312, the loss is 4.525678992318742, parameters k is 11.49918703557427 and b is -49.58270355732185\n",
      "Iteration 5313, the loss is 4.525678342737206, parameters k is 11.499169735179013 and b is -49.58267193676849\n",
      "Iteration 5314, the loss is 4.525677693155673, parameters k is 11.499152434783756 and b is -49.582640316215134\n",
      "Iteration 5315, the loss is 4.525677311271375, parameters k is 11.4991351343885 and b is -49.582608695661776\n",
      "Iteration 5316, the loss is 4.525676700631108, parameters k is 11.499167731226445 and b is -49.58256916997008\n",
      "Iteration 5317, the loss is 4.525676051049569, parameters k is 11.499150430831188 and b is -49.58253754941672\n",
      "Iteration 5318, the loss is 4.525675401468034, parameters k is 11.499133130435931 and b is -49.58250592886336\n",
      "Iteration 5319, the loss is 4.525674970025206, parameters k is 11.499115830040674 and b is -49.582474308310005\n",
      "Iteration 5320, the loss is 4.525674408943464, parameters k is 11.49914842687862 and b is -49.58243478261831\n",
      "Iteration 5321, the loss is 4.525673759361929, parameters k is 11.499131126483363 and b is -49.58240316206495\n",
      "Iteration 5322, the loss is 4.525673109780399, parameters k is 11.499113826088106 and b is -49.58237154151159\n",
      "Iteration 5323, the loss is 4.52567262877904, parameters k is 11.499096525692849 and b is -49.58233992095823\n",
      "Iteration 5324, the loss is 4.525672117255828, parameters k is 11.499129122530794 and b is -49.582300395266536\n",
      "Iteration 5325, the loss is 4.525671467674289, parameters k is 11.499111822135538 and b is -49.58226877471318\n",
      "Iteration 5326, the loss is 4.525670818092758, parameters k is 11.49909452174028 and b is -49.58223715415982\n",
      "Iteration 5327, the loss is 4.5256702875328605, parameters k is 11.499077221345024 and b is -49.58220553360646\n",
      "Iteration 5328, the loss is 4.5256698255681895, parameters k is 11.49910981818297 and b is -49.582166007914765\n",
      "Iteration 5329, the loss is 4.52566917598666, parameters k is 11.499092517787712 and b is -49.58213438736141\n",
      "Iteration 5330, the loss is 4.525668526405119, parameters k is 11.499075217392456 and b is -49.58210276680805\n",
      "Iteration 5331, the loss is 4.525667946286702, parameters k is 11.499057916997199 and b is -49.58207114625469\n",
      "Iteration 5332, the loss is 4.525667533880558, parameters k is 11.499090513835144 and b is -49.582031620562994\n",
      "Iteration 5333, the loss is 4.525666884299016, parameters k is 11.499073213439887 and b is -49.582000000009636\n",
      "Iteration 5334, the loss is 4.525666234717484, parameters k is 11.49905591304463 and b is -49.58196837945628\n",
      "Iteration 5335, the loss is 4.525665605040534, parameters k is 11.499038612649374 and b is -49.58193675890292\n",
      "Iteration 5336, the loss is 4.525665242192914, parameters k is 11.499071209487319 and b is -49.58189723321122\n",
      "Iteration 5337, the loss is 4.525664592611379, parameters k is 11.499053909092062 and b is -49.581865612657865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5338, the loss is 4.525663943029847, parameters k is 11.499036608696805 and b is -49.58183399210451\n",
      "Iteration 5339, the loss is 4.525663293448312, parameters k is 11.499019308301548 and b is -49.58180237155115\n",
      "Iteration 5340, the loss is 4.525662920851331, parameters k is 11.499002007906292 and b is -49.58177075099779\n",
      "Iteration 5341, the loss is 4.525662300923739, parameters k is 11.499034604744237 and b is -49.58173122530609\n",
      "Iteration 5342, the loss is 4.5256616513422046, parameters k is 11.49901730434898 and b is -49.581699604752735\n",
      "Iteration 5343, the loss is 4.525661001760673, parameters k is 11.499000003953723 and b is -49.58166798419938\n",
      "Iteration 5344, the loss is 4.525660579605162, parameters k is 11.498982703558466 and b is -49.58163636364602\n",
      "Iteration 5345, the loss is 4.525660009236107, parameters k is 11.499015300396412 and b is -49.58159683795432\n",
      "Iteration 5346, the loss is 4.525659359654568, parameters k is 11.498998000001155 and b is -49.581565217400964\n",
      "Iteration 5347, the loss is 4.525658710073035, parameters k is 11.498980699605898 and b is -49.581533596847606\n",
      "Iteration 5348, the loss is 4.525658238358998, parameters k is 11.498963399210641 and b is -49.58150197629425\n",
      "Iteration 5349, the loss is 4.5256577175484685, parameters k is 11.498995996048587 and b is -49.58146245060255\n",
      "Iteration 5350, the loss is 4.525657067966929, parameters k is 11.49897869565333 and b is -49.58143083004919\n",
      "Iteration 5351, the loss is 4.525656418385399, parameters k is 11.498961395258073 and b is -49.581399209495835\n",
      "Iteration 5352, the loss is 4.525655897112827, parameters k is 11.498944094862816 and b is -49.58136758894248\n",
      "Iteration 5353, the loss is 4.525655425860831, parameters k is 11.498976691700761 and b is -49.58132806325078\n",
      "Iteration 5354, the loss is 4.525654776279298, parameters k is 11.498959391305505 and b is -49.58129644269742\n",
      "Iteration 5355, the loss is 4.525654126697764, parameters k is 11.498942090910248 and b is -49.581264822144064\n",
      "Iteration 5356, the loss is 4.525653555866658, parameters k is 11.498924790514991 and b is -49.581233201590706\n",
      "Iteration 5357, the loss is 4.525653134173193, parameters k is 11.498957387352936 and b is -49.58119367589901\n",
      "Iteration 5358, the loss is 4.525652484591661, parameters k is 11.49894008695768 and b is -49.58116205534565\n",
      "Iteration 5359, the loss is 4.525651835010121, parameters k is 11.498922786562423 and b is -49.58113043479229\n",
      "Iteration 5360, the loss is 4.5256512146204875, parameters k is 11.498905486167166 and b is -49.581098814238935\n",
      "Iteration 5361, the loss is 4.525650842485555, parameters k is 11.498938083005111 and b is -49.58105928854724\n",
      "Iteration 5362, the loss is 4.5256501929040205, parameters k is 11.498920782609854 and b is -49.58102766799388\n",
      "Iteration 5363, the loss is 4.525649543322483, parameters k is 11.498903482214597 and b is -49.58099604744052\n",
      "Iteration 5364, the loss is 4.525648893740955, parameters k is 11.49888618181934 and b is -49.580964426887164\n",
      "Iteration 5365, the loss is 4.525648530431293, parameters k is 11.498868881424084 and b is -49.580932806333806\n",
      "Iteration 5366, the loss is 4.525647901216383, parameters k is 11.49890147826203 and b is -49.58089328064211\n",
      "Iteration 5367, the loss is 4.525647251634847, parameters k is 11.498884177866772 and b is -49.58086166008875\n",
      "Iteration 5368, the loss is 4.525646602053312, parameters k is 11.498866877471515 and b is -49.58083003953539\n",
      "Iteration 5369, the loss is 4.525646189185124, parameters k is 11.498849577076259 and b is -49.580798418982035\n",
      "Iteration 5370, the loss is 4.525645609528748, parameters k is 11.498882173914204 and b is -49.58075889329034\n",
      "Iteration 5371, the loss is 4.525644959947208, parameters k is 11.498864873518947 and b is -49.58072727273698\n",
      "Iteration 5372, the loss is 4.525644310365673, parameters k is 11.49884757312369 and b is -49.58069565218362\n",
      "Iteration 5373, the loss is 4.525643847938955, parameters k is 11.498830272728433 and b is -49.58066403163026\n",
      "Iteration 5374, the loss is 4.5256433178411095, parameters k is 11.498862869566379 and b is -49.580624505938566\n",
      "Iteration 5375, the loss is 4.525642668259574, parameters k is 11.498845569171122 and b is -49.58059288538521\n",
      "Iteration 5376, the loss is 4.525642018678036, parameters k is 11.498828268775865 and b is -49.58056126483185\n",
      "Iteration 5377, the loss is 4.525641506692786, parameters k is 11.498810968380608 and b is -49.58052964427849\n",
      "Iteration 5378, the loss is 4.525641026153471, parameters k is 11.498843565218554 and b is -49.580490118586795\n",
      "Iteration 5379, the loss is 4.525640376571934, parameters k is 11.498826264823297 and b is -49.58045849803344\n",
      "Iteration 5380, the loss is 4.525639726990396, parameters k is 11.49880896442804 and b is -49.58042687748008\n",
      "Iteration 5381, the loss is 4.525639165446616, parameters k is 11.498791664032783 and b is -49.58039525692672\n",
      "Iteration 5382, the loss is 4.525638734465834, parameters k is 11.498824260870729 and b is -49.580355731235024\n",
      "Iteration 5383, the loss is 4.525638084884297, parameters k is 11.498806960475472 and b is -49.580324110681666\n",
      "Iteration 5384, the loss is 4.525637435302768, parameters k is 11.498789660080215 and b is -49.58029249012831\n",
      "Iteration 5385, the loss is 4.525636824200446, parameters k is 11.498772359684958 and b is -49.58026086957495\n",
      "Iteration 5386, the loss is 4.525636442778195, parameters k is 11.498804956522903 and b is -49.58022134388325\n",
      "Iteration 5387, the loss is 4.525635793196655, parameters k is 11.498787656127647 and b is -49.580189723329894\n",
      "Iteration 5388, the loss is 4.525635143615122, parameters k is 11.49877035573239 and b is -49.58015810277654\n",
      "Iteration 5389, the loss is 4.52563449403359, parameters k is 11.498753055337133 and b is -49.58012648222318\n",
      "Iteration 5390, the loss is 4.525634140011249, parameters k is 11.498735754941876 and b is -49.58009486166982\n",
      "Iteration 5391, the loss is 4.525633501509021, parameters k is 11.498768351779821 and b is -49.58005533597812\n",
      "Iteration 5392, the loss is 4.525632851927492, parameters k is 11.498751051384565 and b is -49.580023715424765\n",
      "Iteration 5393, the loss is 4.5256322023459505, parameters k is 11.498733750989308 and b is -49.57999209487141\n",
      "Iteration 5394, the loss is 4.525631798765084, parameters k is 11.498716450594051 and b is -49.57996047431805\n",
      "Iteration 5395, the loss is 4.525631209821388, parameters k is 11.498749047431996 and b is -49.57992094862635\n",
      "Iteration 5396, the loss is 4.525630560239845, parameters k is 11.49873174703674 and b is -49.579889328072994\n",
      "Iteration 5397, the loss is 4.525629910658312, parameters k is 11.498714446641483 and b is -49.579857707519636\n",
      "Iteration 5398, the loss is 4.52562945751891, parameters k is 11.498697146246226 and b is -49.57982608696628\n",
      "Iteration 5399, the loss is 4.52562891813375, parameters k is 11.498729743084171 and b is -49.57978656127458\n",
      "Iteration 5400, the loss is 4.525628268552213, parameters k is 11.498712442688914 and b is -49.57975494072122\n",
      "Iteration 5401, the loss is 4.525627618970673, parameters k is 11.498695142293657 and b is -49.579723320167865\n",
      "Iteration 5402, the loss is 4.525627116272749, parameters k is 11.4986778418984 and b is -49.57969169961451\n",
      "Iteration 5403, the loss is 4.525626626446114, parameters k is 11.498710438736346 and b is -49.57965217392281\n",
      "Iteration 5404, the loss is 4.525625976864576, parameters k is 11.498693138341089 and b is -49.57962055336945\n",
      "Iteration 5405, the loss is 4.525625327283038, parameters k is 11.498675837945832 and b is -49.579588932816094\n",
      "Iteration 5406, the loss is 4.525624775026576, parameters k is 11.498658537550575 and b is -49.579557312262736\n",
      "Iteration 5407, the loss is 4.525624334758477, parameters k is 11.49869113438852 and b is -49.57951778657104\n",
      "Iteration 5408, the loss is 4.525623685176941, parameters k is 11.498673833993264 and b is -49.57948616601768\n",
      "Iteration 5409, the loss is 4.5256230355954035, parameters k is 11.498656533598007 and b is -49.57945454546432\n",
      "Iteration 5410, the loss is 4.525622433780412, parameters k is 11.49863923320275 and b is -49.579422924910965\n",
      "Iteration 5411, the loss is 4.525622043070834, parameters k is 11.498671830040696 and b is -49.57938339921927\n",
      "Iteration 5412, the loss is 4.525621393489299, parameters k is 11.498654529645439 and b is -49.57935177866591\n",
      "Iteration 5413, the loss is 4.52562074390776, parameters k is 11.498637229250182 and b is -49.57932015811255\n",
      "Iteration 5414, the loss is 4.525620094326228, parameters k is 11.498619928854925 and b is -49.579288537559194\n",
      "Iteration 5415, the loss is 4.525619749591207, parameters k is 11.498602628459668 and b is -49.579256917005836\n",
      "Iteration 5416, the loss is 4.525619101801661, parameters k is 11.498635225297614 and b is -49.57921739131414\n",
      "Iteration 5417, the loss is 4.525618452220126, parameters k is 11.498617924902357 and b is -49.57918577076078\n",
      "Iteration 5418, the loss is 4.525617802638589, parameters k is 11.4986006245071 and b is -49.57915415020742\n",
      "Iteration 5419, the loss is 4.525617408345043, parameters k is 11.498583324111843 and b is -49.579122529654065\n",
      "Iteration 5420, the loss is 4.525616810114024, parameters k is 11.498615920949788 and b is -49.57908300396237\n",
      "Iteration 5421, the loss is 4.525616160532485, parameters k is 11.498598620554532 and b is -49.57905138340901\n",
      "Iteration 5422, the loss is 4.525615510950955, parameters k is 11.498581320159275 and b is -49.57901976285565\n",
      "Iteration 5423, the loss is 4.5256150670988715, parameters k is 11.498564019764018 and b is -49.57898814230229\n",
      "Iteration 5424, the loss is 4.525614518426387, parameters k is 11.498596616601963 and b is -49.578948616610596\n",
      "Iteration 5425, the loss is 4.525613868844855, parameters k is 11.498579316206706 and b is -49.57891699605724\n",
      "Iteration 5426, the loss is 4.5256132192633185, parameters k is 11.49856201581145 and b is -49.57888537550388\n",
      "Iteration 5427, the loss is 4.5256127258527, parameters k is 11.498544715416193 and b is -49.57885375495052\n",
      "Iteration 5428, the loss is 4.52561222673875, parameters k is 11.498577312254138 and b is -49.578814229258825\n",
      "Iteration 5429, the loss is 4.52561157715721, parameters k is 11.498560011858881 and b is -49.57878260870547\n",
      "Iteration 5430, the loss is 4.525610927575679, parameters k is 11.498542711463624 and b is -49.57875098815211\n",
      "Iteration 5431, the loss is 4.5256103846065345, parameters k is 11.498525411068368 and b is -49.57871936759875\n",
      "Iteration 5432, the loss is 4.52560993505111, parameters k is 11.498558007906313 and b is -49.578679841907054\n",
      "Iteration 5433, the loss is 4.525609285469576, parameters k is 11.498540707511056 and b is -49.578648221353696\n",
      "Iteration 5434, the loss is 4.525608635888038, parameters k is 11.4985234071158 and b is -49.57861660080034\n",
      "Iteration 5435, the loss is 4.525608043360371, parameters k is 11.498506106720543 and b is -49.57858498024698\n",
      "Iteration 5436, the loss is 4.525607643363471, parameters k is 11.498538703558488 and b is -49.57854545455528\n",
      "Iteration 5437, the loss is 4.525606993781941, parameters k is 11.498521403163231 and b is -49.578513834001924\n",
      "Iteration 5438, the loss is 4.525606344200407, parameters k is 11.498504102767974 and b is -49.57848221344857\n",
      "Iteration 5439, the loss is 4.525605702114204, parameters k is 11.498486802372717 and b is -49.57845059289521\n",
      "Iteration 5440, the loss is 4.525605351675835, parameters k is 11.498519399210663 and b is -49.57841106720351\n",
      "Iteration 5441, the loss is 4.525604702094302, parameters k is 11.498502098815406 and b is -49.57837944665015\n",
      "Iteration 5442, the loss is 4.525604052512762, parameters k is 11.498484798420149 and b is -49.578347826096795\n",
      "Iteration 5443, the loss is 4.525603402931229, parameters k is 11.498467498024892 and b is -49.57831620554344\n",
      "Iteration 5444, the loss is 4.525603017924999, parameters k is 11.498450197629635 and b is -49.57828458499008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5445, the loss is 4.525602410406669, parameters k is 11.49848279446758 and b is -49.57824505929838\n",
      "Iteration 5446, the loss is 4.525601760825129, parameters k is 11.498465494072324 and b is -49.578213438745024\n",
      "Iteration 5447, the loss is 4.525601111243596, parameters k is 11.498448193677067 and b is -49.578181818191666\n",
      "Iteration 5448, the loss is 4.525600676678831, parameters k is 11.49843089328181 and b is -49.57815019763831\n",
      "Iteration 5449, the loss is 4.525600118719026, parameters k is 11.498463490119756 and b is -49.57811067194661\n",
      "Iteration 5450, the loss is 4.525599469137486, parameters k is 11.498446189724499 and b is -49.57807905139325\n",
      "Iteration 5451, the loss is 4.525598819555954, parameters k is 11.498428889329242 and b is -49.578047430839895\n",
      "Iteration 5452, the loss is 4.525598335432662, parameters k is 11.498411588933985 and b is -49.57801581028654\n",
      "Iteration 5453, the loss is 4.525597827031386, parameters k is 11.49844418577193 and b is -49.57797628459484\n",
      "Iteration 5454, the loss is 4.525597177449848, parameters k is 11.498426885376674 and b is -49.57794466404148\n",
      "Iteration 5455, the loss is 4.5255965278683155, parameters k is 11.498409584981417 and b is -49.577913043488124\n",
      "Iteration 5456, the loss is 4.5255959941864905, parameters k is 11.49839228458616 and b is -49.577881422934766\n",
      "Iteration 5457, the loss is 4.525595535343751, parameters k is 11.498424881424105 and b is -49.57784189724307\n",
      "Iteration 5458, the loss is 4.525594885762218, parameters k is 11.498407581028848 and b is -49.57781027668971\n",
      "Iteration 5459, the loss is 4.525594236180678, parameters k is 11.498390280633592 and b is -49.57777865613635\n",
      "Iteration 5460, the loss is 4.525593652940324, parameters k is 11.498372980238335 and b is -49.577747035582995\n",
      "Iteration 5461, the loss is 4.525593243656118, parameters k is 11.49840557707628 and b is -49.5777075098913\n",
      "Iteration 5462, the loss is 4.525592594074577, parameters k is 11.498388276681023 and b is -49.57767588933794\n",
      "Iteration 5463, the loss is 4.525591944493042, parameters k is 11.498370976285766 and b is -49.57764426878458\n",
      "Iteration 5464, the loss is 4.5255913116941535, parameters k is 11.49835367589051 and b is -49.577612648231224\n",
      "Iteration 5465, the loss is 4.525590951968474, parameters k is 11.498386272728455 and b is -49.577573122539526\n",
      "Iteration 5466, the loss is 4.525590302386941, parameters k is 11.498368972333198 and b is -49.57754150198617\n",
      "Iteration 5467, the loss is 4.5255896528054045, parameters k is 11.498351671937941 and b is -49.57750988143281\n",
      "Iteration 5468, the loss is 4.525589003223869, parameters k is 11.498334371542684 and b is -49.57747826087945\n",
      "Iteration 5469, the loss is 4.525588627504955, parameters k is 11.498317071147428 and b is -49.577446640326094\n",
      "Iteration 5470, the loss is 4.525588010699299, parameters k is 11.498349667985373 and b is -49.5774071146344\n",
      "Iteration 5471, the loss is 4.525587361117765, parameters k is 11.498332367590116 and b is -49.57737549408104\n",
      "Iteration 5472, the loss is 4.5255867115362305, parameters k is 11.49831506719486 and b is -49.57734387352768\n",
      "Iteration 5473, the loss is 4.525586286258789, parameters k is 11.498297766799602 and b is -49.57731225297432\n",
      "Iteration 5474, the loss is 4.52558571901166, parameters k is 11.498330363637548 and b is -49.577272727282626\n",
      "Iteration 5475, the loss is 4.5255850694301305, parameters k is 11.498313063242291 and b is -49.57724110672927\n",
      "Iteration 5476, the loss is 4.525584419848595, parameters k is 11.498295762847034 and b is -49.57720948617591\n",
      "Iteration 5477, the loss is 4.525583945012626, parameters k is 11.498278462451777 and b is -49.57717786562255\n",
      "Iteration 5478, the loss is 4.5255834273240305, parameters k is 11.498311059289723 and b is -49.577138339930855\n",
      "Iteration 5479, the loss is 4.525582777742495, parameters k is 11.498293758894466 and b is -49.5771067193775\n",
      "Iteration 5480, the loss is 4.525582128160953, parameters k is 11.498276458499209 and b is -49.57707509882414\n",
      "Iteration 5481, the loss is 4.525581603766452, parameters k is 11.498259158103952 and b is -49.57704347827078\n",
      "Iteration 5482, the loss is 4.52558113563639, parameters k is 11.498291754941897 and b is -49.57700395257908\n",
      "Iteration 5483, the loss is 4.52558048605486, parameters k is 11.49827445454664 and b is -49.576972332025726\n",
      "Iteration 5484, the loss is 4.525579836473318, parameters k is 11.498257154151384 and b is -49.57694071147237\n",
      "Iteration 5485, the loss is 4.525579262520282, parameters k is 11.498239853756127 and b is -49.57690909091901\n",
      "Iteration 5486, the loss is 4.525578843948754, parameters k is 11.498272450594072 and b is -49.57686956522731\n",
      "Iteration 5487, the loss is 4.5255781943672195, parameters k is 11.498255150198815 and b is -49.576837944673954\n",
      "Iteration 5488, the loss is 4.5255775447856825, parameters k is 11.498237849803559 and b is -49.5768063241206\n",
      "Iteration 5489, the loss is 4.5255769212741175, parameters k is 11.498220549408302 and b is -49.57677470356724\n",
      "Iteration 5490, the loss is 4.525576552261108, parameters k is 11.498253146246247 and b is -49.57673517787554\n",
      "Iteration 5491, the loss is 4.525575902679576, parameters k is 11.49823584585099 and b is -49.57670355732218\n",
      "Iteration 5492, the loss is 4.5255752530980455, parameters k is 11.498218545455734 and b is -49.576671936768825\n",
      "Iteration 5493, the loss is 4.5255746035165085, parameters k is 11.498201245060477 and b is -49.57664031621547\n",
      "Iteration 5494, the loss is 4.525574237084913, parameters k is 11.49818394466522 and b is -49.57660869566211\n",
      "Iteration 5495, the loss is 4.525573610991934, parameters k is 11.498216541503165 and b is -49.57656916997041\n",
      "Iteration 5496, the loss is 4.525572961410403, parameters k is 11.498199241107908 and b is -49.576537549417054\n",
      "Iteration 5497, the loss is 4.525572311828874, parameters k is 11.498181940712652 and b is -49.576505928863696\n",
      "Iteration 5498, the loss is 4.525571895838748, parameters k is 11.498164640317395 and b is -49.57647430831034\n",
      "Iteration 5499, the loss is 4.525571319304305, parameters k is 11.49819723715534 and b is -49.57643478261864\n",
      "Iteration 5500, the loss is 4.525570669722771, parameters k is 11.498179936760083 and b is -49.57640316206528\n",
      "Iteration 5501, the loss is 4.525570020141232, parameters k is 11.498162636364826 and b is -49.576371541511925\n",
      "Iteration 5502, the loss is 4.525569554592575, parameters k is 11.49814533596957 and b is -49.57633992095857\n",
      "Iteration 5503, the loss is 4.5255690276166645, parameters k is 11.498177932807515 and b is -49.57630039526687\n",
      "Iteration 5504, the loss is 4.525568378035129, parameters k is 11.498160632412258 and b is -49.57626877471351\n",
      "Iteration 5505, the loss is 4.525567728453597, parameters k is 11.498143332017001 and b is -49.576237154160154\n",
      "Iteration 5506, the loss is 4.525567213346408, parameters k is 11.498126031621744 and b is -49.576205533606796\n",
      "Iteration 5507, the loss is 4.525566735929024, parameters k is 11.49815862845969 and b is -49.5761660079151\n",
      "Iteration 5508, the loss is 4.525566086347493, parameters k is 11.498141328064433 and b is -49.57613438736174\n",
      "Iteration 5509, the loss is 4.525565436765956, parameters k is 11.498124027669176 and b is -49.57610276680838\n",
      "Iteration 5510, the loss is 4.525564872100241, parameters k is 11.49810672727392 and b is -49.576071146255025\n",
      "Iteration 5511, the loss is 4.525564444241389, parameters k is 11.498139324111865 and b is -49.57603162056333\n",
      "Iteration 5512, the loss is 4.525563794659856, parameters k is 11.498122023716608 and b is -49.57600000000997\n",
      "Iteration 5513, the loss is 4.525563145078322, parameters k is 11.498104723321351 and b is -49.57596837945661\n",
      "Iteration 5514, the loss is 4.525562530854075, parameters k is 11.498087422926094 and b is -49.575936758903254\n",
      "Iteration 5515, the loss is 4.525562152553754, parameters k is 11.49812001976404 and b is -49.575897233211556\n",
      "Iteration 5516, the loss is 4.525561502972219, parameters k is 11.498102719368783 and b is -49.5758656126582\n",
      "Iteration 5517, the loss is 4.5255608533906875, parameters k is 11.498085418973526 and b is -49.57583399210484\n",
      "Iteration 5518, the loss is 4.525560203809145, parameters k is 11.498068118578269 and b is -49.57580237155148\n",
      "Iteration 5519, the loss is 4.525559846664872, parameters k is 11.498050818183012 and b is -49.575770750998124\n",
      "Iteration 5520, the loss is 4.5255592112845875, parameters k is 11.498083415020957 and b is -49.57573122530643\n",
      "Iteration 5521, the loss is 4.5255585617030505, parameters k is 11.4980661146257 and b is -49.57569960475307\n",
      "Iteration 5522, the loss is 4.52555791212151, parameters k is 11.498048814230444 and b is -49.57566798419971\n",
      "Iteration 5523, the loss is 4.525557505418705, parameters k is 11.498031513835187 and b is -49.57563636364635\n",
      "Iteration 5524, the loss is 4.525556919596944, parameters k is 11.498064110673132 and b is -49.575596837954656\n",
      "Iteration 5525, the loss is 4.525556270015407, parameters k is 11.498046810277875 and b is -49.5755652174013\n",
      "Iteration 5526, the loss is 4.525555620433876, parameters k is 11.498029509882619 and b is -49.57553359684794\n",
      "Iteration 5527, the loss is 4.525555164172535, parameters k is 11.498012209487362 and b is -49.57550197629458\n",
      "Iteration 5528, the loss is 4.525554627909311, parameters k is 11.498044806325307 and b is -49.575462450602885\n",
      "Iteration 5529, the loss is 4.525553978327773, parameters k is 11.49802750593005 and b is -49.57543083004953\n",
      "Iteration 5530, the loss is 4.525553328746236, parameters k is 11.498010205534793 and b is -49.57539920949617\n",
      "Iteration 5531, the loss is 4.525552822926368, parameters k is 11.497992905139537 and b is -49.57536758894281\n",
      "Iteration 5532, the loss is 4.525552336221675, parameters k is 11.498025501977482 and b is -49.57532806325111\n",
      "Iteration 5533, the loss is 4.525551686640136, parameters k is 11.498008201582225 and b is -49.575296442697756\n",
      "Iteration 5534, the loss is 4.5255510370586, parameters k is 11.497990901186968 and b is -49.5752648221444\n",
      "Iteration 5535, the loss is 4.525550481680201, parameters k is 11.497973600791711 and b is -49.57523320159104\n",
      "Iteration 5536, the loss is 4.525550044534033, parameters k is 11.498006197629657 and b is -49.57519367589934\n",
      "Iteration 5537, the loss is 4.525549394952495, parameters k is 11.4979888972344 and b is -49.575162055345984\n",
      "Iteration 5538, the loss is 4.52554874537096, parameters k is 11.497971596839143 and b is -49.57513043479263\n",
      "Iteration 5539, the loss is 4.525548140434033, parameters k is 11.497954296443886 and b is -49.57509881423927\n",
      "Iteration 5540, the loss is 4.525547752846393, parameters k is 11.497986893281832 and b is -49.57505928854757\n",
      "Iteration 5541, the loss is 4.525547103264857, parameters k is 11.497969592886575 and b is -49.57502766799421\n",
      "Iteration 5542, the loss is 4.525546453683322, parameters k is 11.497952292491318 and b is -49.574996047440855\n",
      "Iteration 5543, the loss is 4.52554580410179, parameters k is 11.497934992096061 and b is -49.5749644268875\n",
      "Iteration 5544, the loss is 4.525545456244833, parameters k is 11.497917691700804 and b is -49.57493280633414\n",
      "Iteration 5545, the loss is 4.5255448115772205, parameters k is 11.49795028853875 and b is -49.57489328064244\n",
      "Iteration 5546, the loss is 4.525544161995685, parameters k is 11.497932988143493 and b is -49.574861660089084\n",
      "Iteration 5547, the loss is 4.525543512414152, parameters k is 11.497915687748236 and b is -49.574830039535726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5548, the loss is 4.52554311499866, parameters k is 11.49789838735298 and b is -49.57479841898237\n",
      "Iteration 5549, the loss is 4.525542519889582, parameters k is 11.497930984190925 and b is -49.57475889329067\n",
      "Iteration 5550, the loss is 4.525541870308048, parameters k is 11.497913683795668 and b is -49.57472727273731\n",
      "Iteration 5551, the loss is 4.525541220726516, parameters k is 11.49789638340041 and b is -49.574695652183955\n",
      "Iteration 5552, the loss is 4.525540773752494, parameters k is 11.497879083005154 and b is -49.5746640316306\n",
      "Iteration 5553, the loss is 4.525540228201942, parameters k is 11.4979116798431 and b is -49.5746245059389\n",
      "Iteration 5554, the loss is 4.525539578620408, parameters k is 11.497894379447843 and b is -49.57459288538554\n",
      "Iteration 5555, the loss is 4.52553892903887, parameters k is 11.497877079052586 and b is -49.574561264832184\n",
      "Iteration 5556, the loss is 4.525538432506321, parameters k is 11.497859778657329 and b is -49.574529644278826\n",
      "Iteration 5557, the loss is 4.525537936514307, parameters k is 11.497892375495274 and b is -49.57449011858713\n",
      "Iteration 5558, the loss is 4.525537286932777, parameters k is 11.497875075100017 and b is -49.57445849803377\n",
      "Iteration 5559, the loss is 4.525536637351241, parameters k is 11.49785777470476 and b is -49.57442687748041\n",
      "Iteration 5560, the loss is 4.5255360912601565, parameters k is 11.497840474309504 and b is -49.574395256927055\n",
      "Iteration 5561, the loss is 4.525535644826666, parameters k is 11.497873071147449 and b is -49.57435573123536\n",
      "Iteration 5562, the loss is 4.525534995245134, parameters k is 11.497855770752192 and b is -49.574324110682\n",
      "Iteration 5563, the loss is 4.525534345663599, parameters k is 11.497838470356935 and b is -49.57429249012864\n",
      "Iteration 5564, the loss is 4.525533750013989, parameters k is 11.497821169961679 and b is -49.57426086957528\n",
      "Iteration 5565, the loss is 4.525533353139037, parameters k is 11.497853766799624 and b is -49.574221343883586\n",
      "Iteration 5566, the loss is 4.525532703557502, parameters k is 11.497836466404367 and b is -49.57418972333023\n",
      "Iteration 5567, the loss is 4.5255320539759625, parameters k is 11.49781916600911 and b is -49.57415810277687\n",
      "Iteration 5568, the loss is 4.525531408767826, parameters k is 11.497801865613853 and b is -49.57412648222351\n",
      "Iteration 5569, the loss is 4.525531061451395, parameters k is 11.497834462451799 and b is -49.574086956531815\n",
      "Iteration 5570, the loss is 4.525530411869865, parameters k is 11.497817162056542 and b is -49.57405533597846\n",
      "Iteration 5571, the loss is 4.525529762288327, parameters k is 11.497799861661285 and b is -49.5740237154251\n",
      "Iteration 5572, the loss is 4.525529112706789, parameters k is 11.497782561266028 and b is -49.57399209487174\n",
      "Iteration 5573, the loss is 4.525528724578621, parameters k is 11.497765260870771 and b is -49.57396047431838\n",
      "Iteration 5574, the loss is 4.525528120182223, parameters k is 11.497797857708717 and b is -49.573920948626686\n",
      "Iteration 5575, the loss is 4.525527470600687, parameters k is 11.49778055731346 and b is -49.57388932807333\n",
      "Iteration 5576, the loss is 4.5255268210191515, parameters k is 11.497763256918203 and b is -49.57385770751997\n",
      "Iteration 5577, the loss is 4.525526383332453, parameters k is 11.497745956522946 and b is -49.57382608696661\n",
      "Iteration 5578, the loss is 4.525525828494582, parameters k is 11.497778553360892 and b is -49.573786561274915\n",
      "Iteration 5579, the loss is 4.52552517891305, parameters k is 11.497761252965635 and b is -49.57375494072156\n",
      "Iteration 5580, the loss is 4.525524529331511, parameters k is 11.497743952570378 and b is -49.5737233201682\n",
      "Iteration 5581, the loss is 4.525524042086287, parameters k is 11.497726652175121 and b is -49.57369169961484\n",
      "Iteration 5582, the loss is 4.5255235368069515, parameters k is 11.497759249013066 and b is -49.57365217392314\n",
      "Iteration 5583, the loss is 4.52552288722541, parameters k is 11.49774194861781 and b is -49.573620553369786\n",
      "Iteration 5584, the loss is 4.525522237643878, parameters k is 11.497724648222553 and b is -49.57358893281643\n",
      "Iteration 5585, the loss is 4.525521700840114, parameters k is 11.497707347827296 and b is -49.57355731226307\n",
      "Iteration 5586, the loss is 4.525521245119308, parameters k is 11.497739944665241 and b is -49.57351778657137\n",
      "Iteration 5587, the loss is 4.525520595537777, parameters k is 11.497722644269984 and b is -49.573486166018014\n",
      "Iteration 5588, the loss is 4.525519945956239, parameters k is 11.497705343874728 and b is -49.57345454546466\n",
      "Iteration 5589, the loss is 4.525519359593948, parameters k is 11.49768804347947 and b is -49.5734229249113\n",
      "Iteration 5590, the loss is 4.525518953431675, parameters k is 11.497720640317416 and b is -49.5733833992196\n",
      "Iteration 5591, the loss is 4.525518303850135, parameters k is 11.49770333992216 and b is -49.57335177866624\n",
      "Iteration 5592, the loss is 4.525517654268601, parameters k is 11.497686039526902 and b is -49.573320158112885\n",
      "Iteration 5593, the loss is 4.525517018347776, parameters k is 11.497668739131646 and b is -49.57328853755953\n",
      "Iteration 5594, the loss is 4.525516661744034, parameters k is 11.497701335969591 and b is -49.57324901186783\n",
      "Iteration 5595, the loss is 4.525516012162499, parameters k is 11.497684035574334 and b is -49.57321739131447\n",
      "Iteration 5596, the loss is 4.525515362580966, parameters k is 11.497666735179077 and b is -49.573185770761114\n",
      "Iteration 5597, the loss is 4.525514712999428, parameters k is 11.49764943478382 and b is -49.573154150207756\n",
      "Iteration 5598, the loss is 4.52551433415858, parameters k is 11.497632134388564 and b is -49.5731225296544\n",
      "Iteration 5599, the loss is 4.5255137204748666, parameters k is 11.497664731226509 and b is -49.5730830039627\n",
      "Iteration 5600, the loss is 4.525513070893325, parameters k is 11.497647430831252 and b is -49.57305138340934\n",
      "Iteration 5601, the loss is 4.525512421311789, parameters k is 11.497630130435995 and b is -49.573019762855985\n",
      "Iteration 5602, the loss is 4.525511992912409, parameters k is 11.497612830040739 and b is -49.57298814230263\n",
      "Iteration 5603, the loss is 4.525511428787223, parameters k is 11.497645426878684 and b is -49.57294861661093\n",
      "Iteration 5604, the loss is 4.5255107792056855, parameters k is 11.497628126483427 and b is -49.57291699605757\n",
      "Iteration 5605, the loss is 4.525510129624153, parameters k is 11.49761082608817 and b is -49.572885375504214\n",
      "Iteration 5606, the loss is 4.525509651666243, parameters k is 11.497593525692913 and b is -49.572853754950856\n",
      "Iteration 5607, the loss is 4.525509137099588, parameters k is 11.497626122530859 and b is -49.57281422925916\n",
      "Iteration 5608, the loss is 4.525508487518049, parameters k is 11.497608822135602 and b is -49.5727826087058\n",
      "Iteration 5609, the loss is 4.5255078379365115, parameters k is 11.497591521740345 and b is -49.57275098815244\n",
      "Iteration 5610, the loss is 4.525507310420075, parameters k is 11.497574221345088 and b is -49.572719367599085\n",
      "Iteration 5611, the loss is 4.5255068454119485, parameters k is 11.497606818183034 and b is -49.57267984190739\n",
      "Iteration 5612, the loss is 4.525506195830411, parameters k is 11.497589517787777 and b is -49.57264822135403\n",
      "Iteration 5613, the loss is 4.525505546248883, parameters k is 11.49757221739252 and b is -49.57261660080067\n",
      "Iteration 5614, the loss is 4.525504969173906, parameters k is 11.497554916997263 and b is -49.57258498024731\n",
      "Iteration 5615, the loss is 4.52550455372431, parameters k is 11.497587513835208 and b is -49.572545454555616\n",
      "Iteration 5616, the loss is 4.5255039041427745, parameters k is 11.497570213439952 and b is -49.57251383400226\n",
      "Iteration 5617, the loss is 4.525503254561239, parameters k is 11.497552913044695 and b is -49.5724822134489\n",
      "Iteration 5618, the loss is 4.525502627927739, parameters k is 11.497535612649438 and b is -49.57245059289554\n",
      "Iteration 5619, the loss is 4.525502262036673, parameters k is 11.497568209487383 and b is -49.572411067203845\n",
      "Iteration 5620, the loss is 4.5255016124551375, parameters k is 11.497550909092126 and b is -49.57237944665049\n",
      "Iteration 5621, the loss is 4.525500962873605, parameters k is 11.49753360869687 and b is -49.57234782609713\n",
      "Iteration 5622, the loss is 4.525500313292066, parameters k is 11.497516308301613 and b is -49.57231620554377\n",
      "Iteration 5623, the loss is 4.525499943738542, parameters k is 11.497499007906356 and b is -49.57228458499041\n",
      "Iteration 5624, the loss is 4.525499320767501, parameters k is 11.497531604744301 and b is -49.572245059298716\n",
      "Iteration 5625, the loss is 4.525498671185969, parameters k is 11.497514304349044 and b is -49.57221343874536\n",
      "Iteration 5626, the loss is 4.525498021604432, parameters k is 11.497497003953788 and b is -49.572181818192\n",
      "Iteration 5627, the loss is 4.525497602492369, parameters k is 11.49747970355853 and b is -49.57215019763864\n",
      "Iteration 5628, the loss is 4.525497029079863, parameters k is 11.497512300396476 and b is -49.572110671946945\n",
      "Iteration 5629, the loss is 4.525496379498327, parameters k is 11.49749500000122 and b is -49.57207905139359\n",
      "Iteration 5630, the loss is 4.5254957299167895, parameters k is 11.497477699605962 and b is -49.57204743084023\n",
      "Iteration 5631, the loss is 4.525495261246199, parameters k is 11.497460399210706 and b is -49.57201581028687\n",
      "Iteration 5632, the loss is 4.5254947373922265, parameters k is 11.497492996048651 and b is -49.57197628459517\n",
      "Iteration 5633, the loss is 4.525494087810688, parameters k is 11.497475695653394 and b is -49.571944664041816\n",
      "Iteration 5634, the loss is 4.525493438229154, parameters k is 11.497458395258137 and b is -49.57191304348846\n",
      "Iteration 5635, the loss is 4.525492920000034, parameters k is 11.49744109486288 and b is -49.5718814229351\n",
      "Iteration 5636, the loss is 4.52549244570459, parameters k is 11.497473691700826 and b is -49.5718418972434\n",
      "Iteration 5637, the loss is 4.525491796123052, parameters k is 11.497456391305569 and b is -49.571810276690044\n",
      "Iteration 5638, the loss is 4.525491146541519, parameters k is 11.497439090910312 and b is -49.571778656136686\n",
      "Iteration 5639, the loss is 4.525490578753861, parameters k is 11.497421790515055 and b is -49.57174703558333\n",
      "Iteration 5640, the loss is 4.525490154016949, parameters k is 11.497454387353 and b is -49.57170750989163\n",
      "Iteration 5641, the loss is 4.525489504435416, parameters k is 11.497437086957744 and b is -49.57167588933827\n",
      "Iteration 5642, the loss is 4.525488854853878, parameters k is 11.497419786562487 and b is -49.571644268784915\n",
      "Iteration 5643, the loss is 4.525488237507694, parameters k is 11.49740248616723 and b is -49.57161264823156\n",
      "Iteration 5644, the loss is 4.525487862329315, parameters k is 11.497435083005175 and b is -49.57157312253986\n",
      "Iteration 5645, the loss is 4.525487212747778, parameters k is 11.497417782609919 and b is -49.5715415019865\n",
      "Iteration 5646, the loss is 4.525486563166243, parameters k is 11.497400482214662 and b is -49.571509881433144\n",
      "Iteration 5647, the loss is 4.525485913584705, parameters k is 11.497383181819405 and b is -49.571478260879786\n",
      "Iteration 5648, the loss is 4.525485553318495, parameters k is 11.497365881424148 and b is -49.57144664032643\n",
      "Iteration 5649, the loss is 4.525484921060138, parameters k is 11.497398478262093 and b is -49.57140711463473\n",
      "Iteration 5650, the loss is 4.525484271478602, parameters k is 11.497381177866837 and b is -49.57137549408137\n",
      "Iteration 5651, the loss is 4.525483621897069, parameters k is 11.49736387747158 and b is -49.571343873528015\n",
      "Iteration 5652, the loss is 4.525483212072329, parameters k is 11.497346577076323 and b is -49.57131225297466\n",
      "Iteration 5653, the loss is 4.525482629372504, parameters k is 11.497379173914268 and b is -49.57127272728296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5654, the loss is 4.525481979790968, parameters k is 11.497361873519012 and b is -49.5712411067296\n",
      "Iteration 5655, the loss is 4.525481330209433, parameters k is 11.497344573123755 and b is -49.571209486176244\n",
      "Iteration 5656, the loss is 4.5254808708261605, parameters k is 11.497327272728498 and b is -49.571177865622886\n",
      "Iteration 5657, the loss is 4.525480337684862, parameters k is 11.497359869566443 and b is -49.57113833993119\n",
      "Iteration 5658, the loss is 4.525479688103335, parameters k is 11.497342569171186 and b is -49.57110671937783\n",
      "Iteration 5659, the loss is 4.525479038521798, parameters k is 11.49732526877593 and b is -49.57107509882447\n",
      "Iteration 5660, the loss is 4.525478529579995, parameters k is 11.497307968380673 and b is -49.571043478271115\n",
      "Iteration 5661, the loss is 4.525478045997231, parameters k is 11.497340565218618 and b is -49.57100395257942\n",
      "Iteration 5662, the loss is 4.525477396415693, parameters k is 11.497323264823361 and b is -49.57097233202606\n",
      "Iteration 5663, the loss is 4.525476746834157, parameters k is 11.497305964428104 and b is -49.5709407114727\n",
      "Iteration 5664, the loss is 4.525476188333823, parameters k is 11.497288664032848 and b is -49.57090909091934\n",
      "Iteration 5665, the loss is 4.52547575430959, parameters k is 11.497321260870793 and b is -49.570869565227646\n",
      "Iteration 5666, the loss is 4.525475104728052, parameters k is 11.497303960475536 and b is -49.57083794467429\n",
      "Iteration 5667, the loss is 4.525474455146519, parameters k is 11.49728666008028 and b is -49.57080632412093\n",
      "Iteration 5668, the loss is 4.525473847087651, parameters k is 11.497269359685022 and b is -49.57077470356757\n",
      "Iteration 5669, the loss is 4.525473462621951, parameters k is 11.497301956522968 and b is -49.570735177875875\n",
      "Iteration 5670, the loss is 4.525472813040418, parameters k is 11.497284656127711 and b is -49.57070355732252\n",
      "Iteration 5671, the loss is 4.525472163458884, parameters k is 11.497267355732454 and b is -49.57067193676916\n",
      "Iteration 5672, the loss is 4.525471513877349, parameters k is 11.497250055337197 and b is -49.5706403162158\n",
      "Iteration 5673, the loss is 4.525471162898459, parameters k is 11.49723275494194 and b is -49.57060869566244\n",
      "Iteration 5674, the loss is 4.5254705213527755, parameters k is 11.497265351779886 and b is -49.570569169970746\n",
      "Iteration 5675, the loss is 4.525469871771245, parameters k is 11.497248051384629 and b is -49.57053754941739\n",
      "Iteration 5676, the loss is 4.525469222189707, parameters k is 11.497230750989372 and b is -49.57050592886403\n",
      "Iteration 5677, the loss is 4.525468821652284, parameters k is 11.497213450594115 and b is -49.57047430831067\n",
      "Iteration 5678, the loss is 4.525468229665143, parameters k is 11.49724604743206 and b is -49.570434782618975\n",
      "Iteration 5679, the loss is 4.525467580083609, parameters k is 11.497228747036804 and b is -49.57040316206562\n",
      "Iteration 5680, the loss is 4.52546693050207, parameters k is 11.497211446641547 and b is -49.57037154151226\n",
      "Iteration 5681, the loss is 4.525466480406119, parameters k is 11.49719414624629 and b is -49.5703399209589\n",
      "Iteration 5682, the loss is 4.525465937977504, parameters k is 11.497226743084235 and b is -49.5703003952672\n",
      "Iteration 5683, the loss is 4.525465288395969, parameters k is 11.497209442688979 and b is -49.570268774713846\n",
      "Iteration 5684, the loss is 4.525464638814434, parameters k is 11.497192142293722 and b is -49.57023715416049\n",
      "Iteration 5685, the loss is 4.525464139159944, parameters k is 11.497174841898465 and b is -49.57020553360713\n",
      "Iteration 5686, the loss is 4.5254636462898645, parameters k is 11.49720743873641 and b is -49.57016600791543\n",
      "Iteration 5687, the loss is 4.52546299670833, parameters k is 11.497190138341153 and b is -49.570134387362074\n",
      "Iteration 5688, the loss is 4.5254623471267985, parameters k is 11.497172837945897 and b is -49.570102766808716\n",
      "Iteration 5689, the loss is 4.525461797913784, parameters k is 11.49715553755064 and b is -49.57007114625536\n",
      "Iteration 5690, the loss is 4.525461354602229, parameters k is 11.497188134388585 and b is -49.57003162056366\n",
      "Iteration 5691, the loss is 4.525460705020694, parameters k is 11.497170833993328 and b is -49.5700000000103\n",
      "Iteration 5692, the loss is 4.525460055439159, parameters k is 11.497153533598071 and b is -49.569968379456945\n",
      "Iteration 5693, the loss is 4.525459456667612, parameters k is 11.497136233202815 and b is -49.56993675890359\n",
      "Iteration 5694, the loss is 4.525459062914596, parameters k is 11.49716883004076 and b is -49.56989723321189\n",
      "Iteration 5695, the loss is 4.525458413333054, parameters k is 11.497151529645503 and b is -49.56986561265853\n",
      "Iteration 5696, the loss is 4.525457763751519, parameters k is 11.497134229250246 and b is -49.569833992105174\n",
      "Iteration 5697, the loss is 4.525457115421447, parameters k is 11.49711692885499 and b is -49.569802371551816\n",
      "Iteration 5698, the loss is 4.525456771226953, parameters k is 11.497149525692935 and b is -49.56976284586012\n",
      "Iteration 5699, the loss is 4.525456121645418, parameters k is 11.497132225297678 and b is -49.56973122530676\n",
      "Iteration 5700, the loss is 4.525455472063886, parameters k is 11.497114924902421 and b is -49.5696996047534\n",
      "Iteration 5701, the loss is 4.525454822482346, parameters k is 11.497097624507164 and b is -49.569667984200045\n",
      "Iteration 5702, the loss is 4.525454431232245, parameters k is 11.497080324111908 and b is -49.56963636364669\n",
      "Iteration 5703, the loss is 4.52545382995778, parameters k is 11.497112920949853 and b is -49.56959683795499\n",
      "Iteration 5704, the loss is 4.525453180376245, parameters k is 11.497095620554596 and b is -49.56956521740163\n",
      "Iteration 5705, the loss is 4.525452530794714, parameters k is 11.49707832015934 and b is -49.569533596848274\n",
      "Iteration 5706, the loss is 4.525452089986079, parameters k is 11.497061019764082 and b is -49.569501976294916\n",
      "Iteration 5707, the loss is 4.525451538270146, parameters k is 11.497093616602028 and b is -49.56946245060322\n",
      "Iteration 5708, the loss is 4.525450888688608, parameters k is 11.49707631620677 and b is -49.56943083004986\n",
      "Iteration 5709, the loss is 4.525450239107074, parameters k is 11.497059015811514 and b is -49.5693992094965\n",
      "Iteration 5710, the loss is 4.52544974873991, parameters k is 11.497041715416257 and b is -49.569367588943145\n",
      "Iteration 5711, the loss is 4.525449246582501, parameters k is 11.497074312254203 and b is -49.56932806325145\n",
      "Iteration 5712, the loss is 4.525448597000969, parameters k is 11.497057011858946 and b is -49.56929644269809\n",
      "Iteration 5713, the loss is 4.525447947419436, parameters k is 11.497039711463689 and b is -49.56926482214473\n",
      "Iteration 5714, the loss is 4.525447407493739, parameters k is 11.497022411068432 and b is -49.56923320159137\n",
      "Iteration 5715, the loss is 4.525446954894872, parameters k is 11.497055007906377 and b is -49.569193675899676\n",
      "Iteration 5716, the loss is 4.52544630531333, parameters k is 11.49703770751112 and b is -49.56916205534632\n",
      "Iteration 5717, the loss is 4.525445655731796, parameters k is 11.497020407115864 and b is -49.56913043479296\n",
      "Iteration 5718, the loss is 4.525445066247574, parameters k is 11.497003106720607 and b is -49.5690988142396\n",
      "Iteration 5719, the loss is 4.525444663207232, parameters k is 11.497035703558552 and b is -49.569059288547905\n",
      "Iteration 5720, the loss is 4.5254440136256955, parameters k is 11.497018403163295 and b is -49.56902766799455\n",
      "Iteration 5721, the loss is 4.525443364044165, parameters k is 11.497001102768039 and b is -49.56899604744119\n",
      "Iteration 5722, the loss is 4.525442725001403, parameters k is 11.496983802372782 and b is -49.56896442688783\n",
      "Iteration 5723, the loss is 4.525442371519589, parameters k is 11.497016399210727 and b is -49.568924901196134\n",
      "Iteration 5724, the loss is 4.525441721938056, parameters k is 11.49699909881547 and b is -49.568893280642776\n",
      "Iteration 5725, the loss is 4.525441072356529, parameters k is 11.496981798420213 and b is -49.56886166008942\n",
      "Iteration 5726, the loss is 4.525440422774992, parameters k is 11.496964498024957 and b is -49.56883003953606\n",
      "Iteration 5727, the loss is 4.525440040812202, parameters k is 11.4969471976297 and b is -49.5687984189827\n",
      "Iteration 5728, the loss is 4.525439430250421, parameters k is 11.496979794467645 and b is -49.568758893291005\n",
      "Iteration 5729, the loss is 4.525438780668887, parameters k is 11.496962494072388 and b is -49.56872727273765\n",
      "Iteration 5730, the loss is 4.525438131087349, parameters k is 11.496945193677131 and b is -49.56869565218429\n",
      "Iteration 5731, the loss is 4.525437699566036, parameters k is 11.496927893281875 and b is -49.56866403163093\n",
      "Iteration 5732, the loss is 4.5254371385627845, parameters k is 11.49696049011982 and b is -49.56862450593923\n",
      "Iteration 5733, the loss is 4.525436488981246, parameters k is 11.496943189724563 and b is -49.568592885385875\n",
      "Iteration 5734, the loss is 4.525435839399711, parameters k is 11.496925889329306 and b is -49.56856126483252\n",
      "Iteration 5735, the loss is 4.525435358319865, parameters k is 11.49690858893405 and b is -49.56852964427916\n",
      "Iteration 5736, the loss is 4.525434846875146, parameters k is 11.496941185771995 and b is -49.56849011858746\n",
      "Iteration 5737, the loss is 4.525434197293609, parameters k is 11.496923885376738 and b is -49.568458498034104\n",
      "Iteration 5738, the loss is 4.5254335477120735, parameters k is 11.496906584981481 and b is -49.568426877480746\n",
      "Iteration 5739, the loss is 4.525433017073697, parameters k is 11.496889284586224 and b is -49.56839525692739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5740, the loss is 4.525432555187508, parameters k is 11.49692188142417 and b is -49.56835573123569\n",
      "Iteration 5741, the loss is 4.525431905605972, parameters k is 11.496904581028913 and b is -49.56832411068233\n",
      "Iteration 5742, the loss is 4.525431256024437, parameters k is 11.496887280633656 and b is -49.568292490128975\n",
      "Iteration 5743, the loss is 4.5254306758275264, parameters k is 11.4968699802384 and b is -49.56826086957562\n",
      "Iteration 5744, the loss is 4.525430263499868, parameters k is 11.496902577076344 and b is -49.56822134388392\n",
      "Iteration 5745, the loss is 4.525429613918334, parameters k is 11.496885276681088 and b is -49.56818972333056\n",
      "Iteration 5746, the loss is 4.5254289643367995, parameters k is 11.49686797628583 and b is -49.568158102777204\n",
      "Iteration 5747, the loss is 4.525428334581362, parameters k is 11.496850675890574 and b is -49.568126482223846\n",
      "Iteration 5748, the loss is 4.525427971812235, parameters k is 11.49688327272852 and b is -49.56808695653215\n",
      "Iteration 5749, the loss is 4.525427322230695, parameters k is 11.496865972333262 and b is -49.56805533597879\n",
      "Iteration 5750, the loss is 4.525426672649165, parameters k is 11.496848671938006 and b is -49.56802371542543\n",
      "Iteration 5751, the loss is 4.525426023067629, parameters k is 11.496831371542749 and b is -49.567992094872075\n",
      "Iteration 5752, the loss is 4.525425650392159, parameters k is 11.496814071147492 and b is -49.56796047431872\n",
      "Iteration 5753, the loss is 4.525425030543059, parameters k is 11.496846667985437 and b is -49.56792094862702\n",
      "Iteration 5754, the loss is 4.525424380961526, parameters k is 11.49682936759018 and b is -49.56788932807366\n",
      "Iteration 5755, the loss is 4.525423731379995, parameters k is 11.496812067194924 and b is -49.567857707520304\n",
      "Iteration 5756, the loss is 4.525423309145994, parameters k is 11.496794766799667 and b is -49.567826086966946\n",
      "Iteration 5757, the loss is 4.525422738855421, parameters k is 11.496827363637612 and b is -49.56778656127525\n",
      "Iteration 5758, the loss is 4.525422089273886, parameters k is 11.496810063242355 and b is -49.56775494072189\n",
      "Iteration 5759, the loss is 4.52542143969235, parameters k is 11.496792762847099 and b is -49.56772332016853\n",
      "Iteration 5760, the loss is 4.525420967899825, parameters k is 11.496775462451842 and b is -49.567691699615175\n",
      "Iteration 5761, the loss is 4.525420447167789, parameters k is 11.496808059289787 and b is -49.56765217392348\n",
      "Iteration 5762, the loss is 4.525419797586252, parameters k is 11.49679075889453 and b is -49.56762055337012\n",
      "Iteration 5763, the loss is 4.525419148004716, parameters k is 11.496773458499273 and b is -49.56758893281676\n",
      "Iteration 5764, the loss is 4.525418626653653, parameters k is 11.496756158104017 and b is -49.5675573122634\n",
      "Iteration 5765, the loss is 4.5254181554801445, parameters k is 11.496788754941962 and b is -49.567517786571706\n",
      "Iteration 5766, the loss is 4.525417505898611, parameters k is 11.496771454546705 and b is -49.56748616601835\n",
      "Iteration 5767, the loss is 4.525416856317072, parameters k is 11.496754154151448 and b is -49.56745454546499\n",
      "Iteration 5768, the loss is 4.525416285407491, parameters k is 11.496736853756191 and b is -49.56742292491163\n",
      "Iteration 5769, the loss is 4.525415863792509, parameters k is 11.496769450594137 and b is -49.567383399219935\n",
      "Iteration 5770, the loss is 4.525415214210974, parameters k is 11.49675215019888 and b is -49.56735177866658\n",
      "Iteration 5771, the loss is 4.525414564629442, parameters k is 11.496734849803623 and b is -49.56732015811322\n",
      "Iteration 5772, the loss is 4.525413944161323, parameters k is 11.496717549408366 and b is -49.56728853755986\n",
      "Iteration 5773, the loss is 4.525413572104872, parameters k is 11.496750146246312 and b is -49.567249011868164\n",
      "Iteration 5774, the loss is 4.525412922523338, parameters k is 11.496732845851055 and b is -49.567217391314806\n",
      "Iteration 5775, the loss is 4.525412272941805, parameters k is 11.496715545455798 and b is -49.56718577076145\n",
      "Iteration 5776, the loss is 4.525411623360268, parameters k is 11.496698245060541 and b is -49.56715415020809\n",
      "Iteration 5777, the loss is 4.525411259972118, parameters k is 11.496680944665284 and b is -49.56712252965473\n",
      "Iteration 5778, the loss is 4.525410630835703, parameters k is 11.49671354150323 and b is -49.567083003963035\n",
      "Iteration 5779, the loss is 4.525409981254165, parameters k is 11.496696241107973 and b is -49.56705138340968\n",
      "Iteration 5780, the loss is 4.525409331672625, parameters k is 11.496678940712716 and b is -49.56701976285632\n",
      "Iteration 5781, the loss is 4.525408918725949, parameters k is 11.496661640317459 and b is -49.56698814230296\n",
      "Iteration 5782, the loss is 4.525408339148065, parameters k is 11.496694237155404 and b is -49.56694861661126\n",
      "Iteration 5783, the loss is 4.525407689566527, parameters k is 11.496676936760148 and b is -49.566916996057905\n",
      "Iteration 5784, the loss is 4.525407039984993, parameters k is 11.49665963636489 and b is -49.56688537550455\n",
      "Iteration 5785, the loss is 4.5254065774797825, parameters k is 11.496642335969634 and b is -49.56685375495119\n",
      "Iteration 5786, the loss is 4.525406047460426, parameters k is 11.49667493280758 and b is -49.56681422925949\n",
      "Iteration 5787, the loss is 4.52540539787889, parameters k is 11.496657632412322 and b is -49.566782608706134\n",
      "Iteration 5788, the loss is 4.525404748297352, parameters k is 11.496640332017066 and b is -49.566750988152776\n",
      "Iteration 5789, the loss is 4.525404236233614, parameters k is 11.496623031621809 and b is -49.56671936759942\n",
      "Iteration 5790, the loss is 4.525403755772783, parameters k is 11.496655628459754 and b is -49.56667984190772\n",
      "Iteration 5791, the loss is 4.525403106191253, parameters k is 11.496638328064497 and b is -49.56664822135436\n",
      "Iteration 5792, the loss is 4.525402456609715, parameters k is 11.49662102766924 and b is -49.566616600801005\n",
      "Iteration 5793, the loss is 4.525401894987448, parameters k is 11.496603727273984 and b is -49.56658498024765\n",
      "Iteration 5794, the loss is 4.525401464085151, parameters k is 11.496636324111929 and b is -49.56654545455595\n",
      "Iteration 5795, the loss is 4.525400814503614, parameters k is 11.496619023716672 and b is -49.56651383400259\n",
      "Iteration 5796, the loss is 4.525400164922075, parameters k is 11.496601723321415 and b is -49.566482213449234\n",
      "Iteration 5797, the loss is 4.525399553741275, parameters k is 11.496584422926158 and b is -49.566450592895876\n",
      "Iteration 5798, the loss is 4.5253991723975115, parameters k is 11.496617019764104 and b is -49.56641106720418\n",
      "Iteration 5799, the loss is 4.525398522815975, parameters k is 11.496599719368847 and b is -49.56637944665082\n",
      "Iteration 5800, the loss is 4.525397873234442, parameters k is 11.49658241897359 and b is -49.56634782609746\n",
      "Iteration 5801, the loss is 4.5253972236529085, parameters k is 11.496565118578333 and b is -49.566316205544105\n",
      "Iteration 5802, the loss is 4.525396869552084, parameters k is 11.496547818183076 and b is -49.56628458499075\n",
      "Iteration 5803, the loss is 4.525396231128341, parameters k is 11.496580415021022 and b is -49.56624505929905\n",
      "Iteration 5804, the loss is 4.525395581546804, parameters k is 11.496563114625765 and b is -49.56621343874569\n",
      "Iteration 5805, the loss is 4.525394931965268, parameters k is 11.496545814230508 and b is -49.566181818192334\n",
      "Iteration 5806, the loss is 4.525394528305912, parameters k is 11.496528513835251 and b is -49.566150197638976\n",
      "Iteration 5807, the loss is 4.525393939440701, parameters k is 11.496561110673197 and b is -49.56611067194728\n",
      "Iteration 5808, the loss is 4.525393289859163, parameters k is 11.49654381027794 and b is -49.56607905139392\n",
      "Iteration 5809, the loss is 4.52539264027763, parameters k is 11.496526509882683 and b is -49.56604743084056\n",
      "Iteration 5810, the loss is 4.525392187059742, parameters k is 11.496509209487426 and b is -49.566015810287205\n",
      "Iteration 5811, the loss is 4.525391647753061, parameters k is 11.496541806325371 and b is -49.56597628459551\n",
      "Iteration 5812, the loss is 4.52539099817153, parameters k is 11.496524505930115 and b is -49.56594466404215\n",
      "Iteration 5813, the loss is 4.525390348589994, parameters k is 11.496507205534858 and b is -49.56591304348879\n",
      "Iteration 5814, the loss is 4.525389845813576, parameters k is 11.496489905139601 and b is -49.56588142293543\n",
      "Iteration 5815, the loss is 4.525389356065422, parameters k is 11.496522501977546 and b is -49.565841897243736\n",
      "Iteration 5816, the loss is 4.525388706483892, parameters k is 11.49650520158229 and b is -49.56581027669038\n",
      "Iteration 5817, the loss is 4.525388056902354, parameters k is 11.496487901187033 and b is -49.56577865613702\n",
      "Iteration 5818, the loss is 4.525387504567406, parameters k is 11.496470600791776 and b is -49.56574703558366\n",
      "Iteration 5819, the loss is 4.525387064377784, parameters k is 11.496503197629721 and b is -49.565707509891965\n",
      "Iteration 5820, the loss is 4.525386414796254, parameters k is 11.496485897234464 and b is -49.56567588933861\n",
      "Iteration 5821, the loss is 4.525385765214717, parameters k is 11.496468596839208 and b is -49.56564426878525\n",
      "Iteration 5822, the loss is 4.525385163321236, parameters k is 11.49645129644395 and b is -49.56561264823189\n",
      "Iteration 5823, the loss is 4.525384772690149, parameters k is 11.496483893281896 and b is -49.565573122540194\n",
      "Iteration 5824, the loss is 4.525384123108618, parameters k is 11.49646659288664 and b is -49.565541501986836\n",
      "Iteration 5825, the loss is 4.525383473527078, parameters k is 11.496449292491382 and b is -49.56550988143348\n",
      "Iteration 5826, the loss is 4.525382823945549, parameters k is 11.496431992096126 and b is -49.56547826088012\n",
      "Iteration 5827, the loss is 4.525382479132039, parameters k is 11.496414691700869 and b is -49.56544664032676\n",
      "Iteration 5828, the loss is 4.525381831420979, parameters k is 11.496447288538814 and b is -49.565407114635065\n",
      "Iteration 5829, the loss is 4.52538118183944, parameters k is 11.496429988143557 and b is -49.56537549408171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5830, the loss is 4.52538053225791, parameters k is 11.4964126877483 and b is -49.56534387352835\n",
      "Iteration 5831, the loss is 4.5253801378858665, parameters k is 11.496395387353044 and b is -49.56531225297499\n",
      "Iteration 5832, the loss is 4.525379539733341, parameters k is 11.496427984190989 and b is -49.56527272728329\n",
      "Iteration 5833, the loss is 4.5253788901518055, parameters k is 11.496410683795732 and b is -49.565241106729935\n",
      "Iteration 5834, the loss is 4.525378240570269, parameters k is 11.496393383400475 and b is -49.56520948617658\n",
      "Iteration 5835, the loss is 4.525377796639701, parameters k is 11.496376083005218 and b is -49.56517786562322\n",
      "Iteration 5836, the loss is 4.5253772480457055, parameters k is 11.496408679843164 and b is -49.56513833993152\n",
      "Iteration 5837, the loss is 4.525376598464164, parameters k is 11.496391379447907 and b is -49.565106719378164\n",
      "Iteration 5838, the loss is 4.525375948882635, parameters k is 11.49637407905265 and b is -49.565075098824806\n",
      "Iteration 5839, the loss is 4.52537545539353, parameters k is 11.496356778657393 and b is -49.56504347827145\n",
      "Iteration 5840, the loss is 4.52537495635807, parameters k is 11.496389375495339 and b is -49.56500395257975\n",
      "Iteration 5841, the loss is 4.525374306776529, parameters k is 11.496372075100082 and b is -49.56497233202639\n",
      "Iteration 5842, the loss is 4.525373657194998, parameters k is 11.496354774704825 and b is -49.564940711473035\n",
      "Iteration 5843, the loss is 4.525373114147363, parameters k is 11.496337474309568 and b is -49.56490909091968\n",
      "Iteration 5844, the loss is 4.525372664670427, parameters k is 11.496370071147513 and b is -49.56486956522798\n",
      "Iteration 5845, the loss is 4.52537201508889, parameters k is 11.496352770752257 and b is -49.56483794467462\n",
      "Iteration 5846, the loss is 4.525371365507356, parameters k is 11.496335470357 and b is -49.564806324121264\n",
      "Iteration 5847, the loss is 4.5253707729012, parameters k is 11.496318169961743 and b is -49.564774703567906\n",
      "Iteration 5848, the loss is 4.525370372982788, parameters k is 11.496350766799688 and b is -49.56473517787621\n",
      "Iteration 5849, the loss is 4.525369723401253, parameters k is 11.496333466404431 and b is -49.56470355732285\n",
      "Iteration 5850, the loss is 4.525369073819718, parameters k is 11.496316166009175 and b is -49.56467193676949\n",
      "Iteration 5851, the loss is 4.525368431655028, parameters k is 11.496298865613918 and b is -49.564640316216135\n",
      "Iteration 5852, the loss is 4.525368081295153, parameters k is 11.496331462451863 and b is -49.56460079052444\n",
      "Iteration 5853, the loss is 4.525367431713616, parameters k is 11.496314162056606 and b is -49.56456916997108\n",
      "Iteration 5854, the loss is 4.525366782132082, parameters k is 11.49629686166135 and b is -49.56453754941772\n",
      "Iteration 5855, the loss is 4.5253661325505465, parameters k is 11.496279561266093 and b is -49.564505928864364\n",
      "Iteration 5856, the loss is 4.525365747465826, parameters k is 11.496262260870836 and b is -49.564474308311006\n",
      "Iteration 5857, the loss is 4.525365140025984, parameters k is 11.496294857708781 and b is -49.56443478261931\n",
      "Iteration 5858, the loss is 4.525364490444441, parameters k is 11.496277557313524 and b is -49.56440316206595\n",
      "Iteration 5859, the loss is 4.525363840862912, parameters k is 11.496260256918267 and b is -49.56437154151259\n",
      "Iteration 5860, the loss is 4.5253634062196575, parameters k is 11.49624295652301 and b is -49.564339920959235\n",
      "Iteration 5861, the loss is 4.525362848338341, parameters k is 11.496275553360956 and b is -49.56430039526754\n",
      "Iteration 5862, the loss is 4.525362198756806, parameters k is 11.4962582529657 and b is -49.56426877471418\n",
      "Iteration 5863, the loss is 4.525361549175271, parameters k is 11.496240952570442 and b is -49.56423715416082\n",
      "Iteration 5864, the loss is 4.525361064973492, parameters k is 11.496223652175185 and b is -49.56420553360746\n",
      "Iteration 5865, the loss is 4.525360556650704, parameters k is 11.49625624901313 and b is -49.564166007915766\n",
      "Iteration 5866, the loss is 4.525359907069163, parameters k is 11.496238948617874 and b is -49.56413438736241\n",
      "Iteration 5867, the loss is 4.525359257487634, parameters k is 11.496221648222617 and b is -49.56410276680905\n",
      "Iteration 5868, the loss is 4.525358723727323, parameters k is 11.49620434782736 and b is -49.56407114625569\n",
      "Iteration 5869, the loss is 4.525358264963066, parameters k is 11.496236944665306 and b is -49.564031620563995\n",
      "Iteration 5870, the loss is 4.525357615381534, parameters k is 11.496219644270049 and b is -49.56400000001064\n",
      "Iteration 5871, the loss is 4.525356965799999, parameters k is 11.496202343874792 and b is -49.56396837945728\n",
      "Iteration 5872, the loss is 4.5253563824811485, parameters k is 11.496185043479535 and b is -49.56393675890392\n",
      "Iteration 5873, the loss is 4.525355973275429, parameters k is 11.49621764031748 and b is -49.563897233212224\n",
      "Iteration 5874, the loss is 4.525355323693896, parameters k is 11.496200339922224 and b is -49.563865612658866\n",
      "Iteration 5875, the loss is 4.525354674112362, parameters k is 11.496183039526967 and b is -49.56383399210551\n",
      "Iteration 5876, the loss is 4.5253540412349835, parameters k is 11.49616573913171 and b is -49.56380237155215\n",
      "Iteration 5877, the loss is 4.525353681587794, parameters k is 11.496198335969655 and b is -49.56376284586045\n",
      "Iteration 5878, the loss is 4.525353032006257, parameters k is 11.496181035574399 and b is -49.563731225307095\n",
      "Iteration 5879, the loss is 4.525352382424723, parameters k is 11.496163735179142 and b is -49.56369960475374\n",
      "Iteration 5880, the loss is 4.525351732843184, parameters k is 11.496146434783885 and b is -49.56366798420038\n",
      "Iteration 5881, the loss is 4.525351357045785, parameters k is 11.496129134388628 and b is -49.56363636364702\n",
      "Iteration 5882, the loss is 4.525350740318621, parameters k is 11.496161731226573 and b is -49.56359683795532\n",
      "Iteration 5883, the loss is 4.525350090737085, parameters k is 11.496144430831317 and b is -49.563565217401965\n",
      "Iteration 5884, the loss is 4.525349441155551, parameters k is 11.49612713043606 and b is -49.56353359684861\n",
      "Iteration 5885, the loss is 4.525349015799615, parameters k is 11.496109830040803 and b is -49.56350197629525\n",
      "Iteration 5886, the loss is 4.525348448630983, parameters k is 11.496142426878748 and b is -49.56346245060355\n",
      "Iteration 5887, the loss is 4.525347799049448, parameters k is 11.496125126483491 and b is -49.563430830050194\n",
      "Iteration 5888, the loss is 4.525347149467912, parameters k is 11.496107826088235 and b is -49.563399209496836\n",
      "Iteration 5889, the loss is 4.525346674553449, parameters k is 11.496090525692978 and b is -49.56336758894348\n",
      "Iteration 5890, the loss is 4.525346156943338, parameters k is 11.496123122530923 and b is -49.56332806325178\n",
      "Iteration 5891, the loss is 4.525345507361804, parameters k is 11.496105822135666 and b is -49.56329644269842\n",
      "Iteration 5892, the loss is 4.52534485778027, parameters k is 11.49608852174041 and b is -49.563264822145065\n",
      "Iteration 5893, the loss is 4.525344333307279, parameters k is 11.496071221345153 and b is -49.56323320159171\n",
      "Iteration 5894, the loss is 4.525343865255708, parameters k is 11.496103818183098 and b is -49.56319367590001\n",
      "Iteration 5895, the loss is 4.525343215674175, parameters k is 11.496086517787841 and b is -49.56316205534665\n",
      "Iteration 5896, the loss is 4.525342566092639, parameters k is 11.496069217392584 and b is -49.563130434793294\n",
      "Iteration 5897, the loss is 4.525341992061107, parameters k is 11.496051916997327 and b is -49.563098814239936\n",
      "Iteration 5898, the loss is 4.525341573568067, parameters k is 11.496084513835273 and b is -49.56305928854824\n",
      "Iteration 5899, the loss is 4.52534092398653, parameters k is 11.496067213440016 and b is -49.56302766799488\n",
      "Iteration 5900, the loss is 4.5253402744050035, parameters k is 11.496049913044759 and b is -49.56299604744152\n",
      "Iteration 5901, the loss is 4.5253396508149395, parameters k is 11.496032612649502 and b is -49.562964426888165\n",
      "Iteration 5902, the loss is 4.525339281880433, parameters k is 11.496065209487448 and b is -49.56292490119647\n",
      "Iteration 5903, the loss is 4.525338632298901, parameters k is 11.49604790909219 and b is -49.56289328064311\n",
      "Iteration 5904, the loss is 4.5253379827173585, parameters k is 11.496030608696934 and b is -49.56286166008975\n",
      "Iteration 5905, the loss is 4.525337333135824, parameters k is 11.496013308301677 and b is -49.562830039536394\n",
      "Iteration 5906, the loss is 4.525336966625746, parameters k is 11.49599600790642 and b is -49.562798418983036\n",
      "Iteration 5907, the loss is 4.52533634061126, parameters k is 11.496028604744366 and b is -49.56275889329134\n",
      "Iteration 5908, the loss is 4.525335691029726, parameters k is 11.496011304349109 and b is -49.56272727273798\n",
      "Iteration 5909, the loss is 4.525335041448186, parameters k is 11.495994003953852 and b is -49.56269565218462\n",
      "Iteration 5910, the loss is 4.525334625379576, parameters k is 11.495976703558595 and b is -49.562664031631265\n",
      "Iteration 5911, the loss is 4.525334048923625, parameters k is 11.49600930039654 and b is -49.56262450593957\n",
      "Iteration 5912, the loss is 4.525333399342087, parameters k is 11.495992000001284 and b is -49.56259288538621\n",
      "Iteration 5913, the loss is 4.52533274976055, parameters k is 11.495974699606027 and b is -49.56256126483285\n",
      "Iteration 5914, the loss is 4.525332284133405, parameters k is 11.49595739921077 and b is -49.56252964427949\n",
      "Iteration 5915, the loss is 4.525331757235982, parameters k is 11.495989996048715 and b is -49.562490118587796\n",
      "Iteration 5916, the loss is 4.52533110765445, parameters k is 11.495972695653458 and b is -49.56245849803444\n",
      "Iteration 5917, the loss is 4.525330458072913, parameters k is 11.495955395258202 and b is -49.56242687748108\n",
      "Iteration 5918, the loss is 4.525329942887235, parameters k is 11.495938094862945 and b is -49.56239525692772\n",
      "Iteration 5919, the loss is 4.525329465548347, parameters k is 11.49597069170089 and b is -49.562355731236025\n",
      "Iteration 5920, the loss is 4.5253288159668115, parameters k is 11.495953391305633 and b is -49.56232411068267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5921, the loss is 4.525328166385276, parameters k is 11.495936090910376 and b is -49.56229249012931\n",
      "Iteration 5922, the loss is 4.525327601641069, parameters k is 11.49591879051512 and b is -49.56226086957595\n",
      "Iteration 5923, the loss is 4.525327173860706, parameters k is 11.495951387353065 and b is -49.562221343884254\n",
      "Iteration 5924, the loss is 4.525326524279172, parameters k is 11.495934086957808 and b is -49.562189723330896\n",
      "Iteration 5925, the loss is 4.525325874697637, parameters k is 11.495916786562551 and b is -49.56215810277754\n",
      "Iteration 5926, the loss is 4.5253252603949035, parameters k is 11.495899486167295 and b is -49.56212648222418\n",
      "Iteration 5927, the loss is 4.525324882173071, parameters k is 11.49593208300524 and b is -49.56208695653248\n",
      "Iteration 5928, the loss is 4.525324232591534, parameters k is 11.495914782609983 and b is -49.562055335979124\n",
      "Iteration 5929, the loss is 4.52532358301, parameters k is 11.495897482214726 and b is -49.56202371542577\n",
      "Iteration 5930, the loss is 4.525322933428463, parameters k is 11.49588018181947 and b is -49.56199209487241\n",
      "Iteration 5931, the loss is 4.525322576205702, parameters k is 11.495862881424213 and b is -49.56196047431905\n",
      "Iteration 5932, the loss is 4.525321940903894, parameters k is 11.495895478262158 and b is -49.56192094862735\n",
      "Iteration 5933, the loss is 4.525321291322361, parameters k is 11.495878177866901 and b is -49.561889328073995\n",
      "Iteration 5934, the loss is 4.525320641740832, parameters k is 11.495860877471644 and b is -49.56185770752064\n",
      "Iteration 5935, the loss is 4.525320234959537, parameters k is 11.495843577076387 and b is -49.56182608696728\n",
      "Iteration 5936, the loss is 4.52531964921626, parameters k is 11.495876173914333 and b is -49.56178656127558\n",
      "Iteration 5937, the loss is 4.525318999634724, parameters k is 11.495858873519076 and b is -49.561754940722224\n",
      "Iteration 5938, the loss is 4.5253183500531895, parameters k is 11.495841573123819 and b is -49.561723320168866\n",
      "Iteration 5939, the loss is 4.5253178937133685, parameters k is 11.495824272728562 and b is -49.56169169961551\n",
      "Iteration 5940, the loss is 4.525317357528626, parameters k is 11.495856869566508 and b is -49.56165217392381\n",
      "Iteration 5941, the loss is 4.52531670794709, parameters k is 11.49583956917125 and b is -49.56162055337045\n",
      "Iteration 5942, the loss is 4.525316058365551, parameters k is 11.495822268775994 and b is -49.561588932817095\n",
      "Iteration 5943, the loss is 4.525315552467196, parameters k is 11.495804968380737 and b is -49.56155731226374\n",
      "Iteration 5944, the loss is 4.525315065840981, parameters k is 11.495837565218682 and b is -49.56151778657204\n",
      "Iteration 5945, the loss is 4.525314416259449, parameters k is 11.495820264823426 and b is -49.56148616601868\n",
      "Iteration 5946, the loss is 4.525313766677914, parameters k is 11.495802964428169 and b is -49.561454545465324\n",
      "Iteration 5947, the loss is 4.525313211221025, parameters k is 11.495785664032912 and b is -49.561422924911966\n",
      "Iteration 5948, the loss is 4.525312774153345, parameters k is 11.495818260870857 and b is -49.56138339922027\n",
      "Iteration 5949, the loss is 4.525312124571813, parameters k is 11.4958009604756 and b is -49.56135177866691\n",
      "Iteration 5950, the loss is 4.525311474990277, parameters k is 11.495783660080344 and b is -49.56132015811355\n",
      "Iteration 5951, the loss is 4.525310869974858, parameters k is 11.495766359685087 and b is -49.561288537560195\n",
      "Iteration 5952, the loss is 4.525310482465715, parameters k is 11.495798956523032 and b is -49.5612490118685\n",
      "Iteration 5953, the loss is 4.525309832884174, parameters k is 11.495781656127775 and b is -49.56121739131514\n",
      "Iteration 5954, the loss is 4.5253091833026415, parameters k is 11.495764355732518 and b is -49.56118577076178\n",
      "Iteration 5955, the loss is 4.525308533721103, parameters k is 11.495747055337262 and b is -49.561154150208424\n",
      "Iteration 5956, the loss is 4.52530818578566, parameters k is 11.495729754942005 and b is -49.561122529655066\n",
      "Iteration 5957, the loss is 4.525307541196538, parameters k is 11.49576235177995 and b is -49.56108300396337\n",
      "Iteration 5958, the loss is 4.525306891615002, parameters k is 11.495745051384693 and b is -49.56105138341001\n",
      "Iteration 5959, the loss is 4.525306242033463, parameters k is 11.495727750989436 and b is -49.56101976285665\n",
      "Iteration 5960, the loss is 4.525305844539492, parameters k is 11.49571045059418 and b is -49.560988142303295\n",
      "Iteration 5961, the loss is 4.525305249508901, parameters k is 11.495743047432125 and b is -49.5609486166116\n",
      "Iteration 5962, the loss is 4.525304599927366, parameters k is 11.495725747036868 and b is -49.56091699605824\n",
      "Iteration 5963, the loss is 4.525303950345832, parameters k is 11.495708446641611 and b is -49.56088537550488\n",
      "Iteration 5964, the loss is 4.525303503293323, parameters k is 11.495691146246354 and b is -49.56085375495152\n",
      "Iteration 5965, the loss is 4.525302957821261, parameters k is 11.4957237430843 and b is -49.560814229259826\n",
      "Iteration 5966, the loss is 4.525302308239726, parameters k is 11.495706442689043 and b is -49.56078260870647\n",
      "Iteration 5967, the loss is 4.5253016586581865, parameters k is 11.495689142293786 and b is -49.56075098815311\n",
      "Iteration 5968, the loss is 4.52530116204716, parameters k is 11.49567184189853 and b is -49.56071936759975\n",
      "Iteration 5969, the loss is 4.525300666133629, parameters k is 11.495704438736475 and b is -49.560679841908055\n",
      "Iteration 5970, the loss is 4.525300016552094, parameters k is 11.495687138341218 and b is -49.5606482213547\n",
      "Iteration 5971, the loss is 4.525299366970559, parameters k is 11.495669837945961 and b is -49.56061660080134\n",
      "Iteration 5972, the loss is 4.52529882080099, parameters k is 11.495652537550704 and b is -49.56058498024798\n",
      "Iteration 5973, the loss is 4.5252983744459865, parameters k is 11.49568513438865 and b is -49.560545454556284\n",
      "Iteration 5974, the loss is 4.525297724864451, parameters k is 11.495667833993393 and b is -49.560513834002926\n",
      "Iteration 5975, the loss is 4.525297075282915, parameters k is 11.495650533598136 and b is -49.56048221344957\n",
      "Iteration 5976, the loss is 4.525296479554822, parameters k is 11.495633233202879 and b is -49.56045059289621\n",
      "Iteration 5977, the loss is 4.52529608275835, parameters k is 11.495665830040824 and b is -49.56041106720451\n",
      "Iteration 5978, the loss is 4.525295433176812, parameters k is 11.495648529645567 and b is -49.560379446651154\n",
      "Iteration 5979, the loss is 4.525294783595283, parameters k is 11.49563122925031 and b is -49.5603478260978\n",
      "Iteration 5980, the loss is 4.525294138308652, parameters k is 11.495613928855054 and b is -49.56031620554444\n",
      "Iteration 5981, the loss is 4.525293791070713, parameters k is 11.495646525693 and b is -49.56027667985274\n",
      "Iteration 5982, the loss is 4.5252931414891755, parameters k is 11.495629225297742 and b is -49.56024505929938\n",
      "Iteration 5983, the loss is 4.525292491907643, parameters k is 11.495611924902486 and b is -49.560213438746025\n",
      "Iteration 5984, the loss is 4.525291842326109, parameters k is 11.495594624507229 and b is -49.56018181819267\n",
      "Iteration 5985, the loss is 4.52529145411945, parameters k is 11.495577324111972 and b is -49.56015019763931\n",
      "Iteration 5986, the loss is 4.525290849801539, parameters k is 11.495609920949917 and b is -49.56011067194761\n",
      "Iteration 5987, the loss is 4.525290200220004, parameters k is 11.49559262055466 and b is -49.560079051394254\n",
      "Iteration 5988, the loss is 4.52528955063847, parameters k is 11.495575320159404 and b is -49.560047430840896\n",
      "Iteration 5989, the loss is 4.525289112873285, parameters k is 11.495558019764147 and b is -49.56001581028754\n",
      "Iteration 5990, the loss is 4.5252885581139015, parameters k is 11.495590616602092 and b is -49.55997628459584\n",
      "Iteration 5991, the loss is 4.525287908532367, parameters k is 11.495573316206835 and b is -49.55994466404248\n",
      "Iteration 5992, the loss is 4.525287258950829, parameters k is 11.495556015811578 and b is -49.559913043489125\n",
      "Iteration 5993, the loss is 4.525286771627116, parameters k is 11.495538715416322 and b is -49.55988142293577\n",
      "Iteration 5994, the loss is 4.5252862664262645, parameters k is 11.495571312254267 and b is -49.55984189724407\n",
      "Iteration 5995, the loss is 4.525285616844731, parameters k is 11.49555401185901 and b is -49.55981027669071\n",
      "Iteration 5996, the loss is 4.5252849672631905, parameters k is 11.495536711463753 and b is -49.559778656137354\n",
      "Iteration 5997, the loss is 4.525284430380942, parameters k is 11.495519411068496 and b is -49.559747035583996\n",
      "Iteration 5998, the loss is 4.525283974738625, parameters k is 11.495552007906442 and b is -49.5597075098923\n",
      "Iteration 5999, the loss is 4.525283325157092, parameters k is 11.495534707511185 and b is -49.55967588933894\n",
      "Iteration 6000, the loss is 4.525282675575552, parameters k is 11.495517407115928 and b is -49.55964426878558\n",
      "Iteration 6001, the loss is 4.525282089134778, parameters k is 11.495500106720671 and b is -49.559612648232225\n",
      "Iteration 6002, the loss is 4.5252816830509905, parameters k is 11.495532703558617 and b is -49.55957312254053\n",
      "Iteration 6003, the loss is 4.525281033469449, parameters k is 11.49551540316336 and b is -49.55954150198717\n",
      "Iteration 6004, the loss is 4.5252803838879165, parameters k is 11.495498102768103 and b is -49.55950988143381\n",
      "Iteration 6005, the loss is 4.525279747888602, parameters k is 11.495480802372846 and b is -49.559478260880454\n",
      "Iteration 6006, the loss is 4.525279391363347, parameters k is 11.495513399210791 and b is -49.559438735188756\n",
      "Iteration 6007, the loss is 4.525278741781817, parameters k is 11.495496098815535 and b is -49.5594071146354\n",
      "Iteration 6008, the loss is 4.525278092200283, parameters k is 11.495478798420278 and b is -49.55937549408204\n",
      "Iteration 6009, the loss is 4.525277442618744, parameters k is 11.495461498025021 and b is -49.55934387352868\n",
      "Iteration 6010, the loss is 4.525277063699408, parameters k is 11.495444197629764 and b is -49.559312252975324\n",
      "Iteration 6011, the loss is 4.525276450094174, parameters k is 11.49547679446771 and b is -49.55927272728363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6012, the loss is 4.5252758005126426, parameters k is 11.495459494072453 and b is -49.55924110673027\n",
      "Iteration 6013, the loss is 4.525275150931107, parameters k is 11.495442193677196 and b is -49.55920948617691\n",
      "Iteration 6014, the loss is 4.525274722453236, parameters k is 11.495424893281939 and b is -49.55917786562355\n",
      "Iteration 6015, the loss is 4.525274158406538, parameters k is 11.495457490119884 and b is -49.559138339931856\n",
      "Iteration 6016, the loss is 4.525273508825007, parameters k is 11.495440189724627 and b is -49.5591067193785\n",
      "Iteration 6017, the loss is 4.525272859243468, parameters k is 11.49542288932937 and b is -49.55907509882514\n",
      "Iteration 6018, the loss is 4.5252723812070705, parameters k is 11.495405588934114 and b is -49.55904347827178\n",
      "Iteration 6019, the loss is 4.525271866718902, parameters k is 11.49543818577206 and b is -49.559003952580085\n",
      "Iteration 6020, the loss is 4.525271217137365, parameters k is 11.495420885376802 and b is -49.55897233202673\n",
      "Iteration 6021, the loss is 4.525270567555831, parameters k is 11.495403584981545 and b is -49.55894071147337\n",
      "Iteration 6022, the loss is 4.525270039960905, parameters k is 11.495386284586289 and b is -49.55890909092001\n",
      "Iteration 6023, the loss is 4.525269575031263, parameters k is 11.495418881424234 and b is -49.55886956522831\n",
      "Iteration 6024, the loss is 4.525268925449733, parameters k is 11.495401581028977 and b is -49.558837944674956\n",
      "Iteration 6025, the loss is 4.525268275868196, parameters k is 11.49538428063372 and b is -49.5588063241216\n",
      "Iteration 6026, the loss is 4.525267698714735, parameters k is 11.495366980238463 and b is -49.55877470356824\n",
      "Iteration 6027, the loss is 4.525267283343629, parameters k is 11.495399577076409 and b is -49.55873517787654\n",
      "Iteration 6028, the loss is 4.525266633762093, parameters k is 11.495382276681152 and b is -49.558703557323184\n",
      "Iteration 6029, the loss is 4.525265984180561, parameters k is 11.495364976285895 and b is -49.55867193676983\n",
      "Iteration 6030, the loss is 4.525265357468567, parameters k is 11.495347675890638 and b is -49.55864031621647\n",
      "Iteration 6031, the loss is 4.5252649916559955, parameters k is 11.495380272728584 and b is -49.55860079052477\n",
      "Iteration 6032, the loss is 4.525264342074457, parameters k is 11.495362972333327 and b is -49.55856916997141\n",
      "Iteration 6033, the loss is 4.52526369249292, parameters k is 11.49534567193807 and b is -49.558537549418055\n",
      "Iteration 6034, the loss is 4.525263042911385, parameters k is 11.495328371542813 and b is -49.5585059288647\n",
      "Iteration 6035, the loss is 4.525262673279366, parameters k is 11.495311071147556 and b is -49.55847430831134\n",
      "Iteration 6036, the loss is 4.525262050386813, parameters k is 11.495343667985502 and b is -49.55843478261964\n",
      "Iteration 6037, the loss is 4.525261400805281, parameters k is 11.495326367590245 and b is -49.558403162066284\n",
      "Iteration 6038, the loss is 4.525260751223745, parameters k is 11.495309067194988 and b is -49.558371541512926\n",
      "Iteration 6039, the loss is 4.525260332033201, parameters k is 11.495291766799731 and b is -49.55833992095957\n",
      "Iteration 6040, the loss is 4.525259758699179, parameters k is 11.495324363637677 and b is -49.55830039526787\n",
      "Iteration 6041, the loss is 4.525259109117643, parameters k is 11.49530706324242 and b is -49.55826877471451\n",
      "Iteration 6042, the loss is 4.525258459536108, parameters k is 11.495289762847163 and b is -49.558237154161155\n",
      "Iteration 6043, the loss is 4.525257990787027, parameters k is 11.495272462451906 and b is -49.5582055336078\n",
      "Iteration 6044, the loss is 4.525257467011542, parameters k is 11.495305059289851 and b is -49.5581660079161\n",
      "Iteration 6045, the loss is 4.52525681743001, parameters k is 11.495287758894595 and b is -49.55813438736274\n",
      "Iteration 6046, the loss is 4.525256167848471, parameters k is 11.495270458499338 and b is -49.558102766809384\n",
      "Iteration 6047, the loss is 4.525255649540858, parameters k is 11.49525315810408 and b is -49.558071146256026\n",
      "Iteration 6048, the loss is 4.5252551753239025, parameters k is 11.495285754942026 and b is -49.55803162056433\n",
      "Iteration 6049, the loss is 4.52525452574237, parameters k is 11.49526845454677 and b is -49.55800000001097\n",
      "Iteration 6050, the loss is 4.5252538761608365, parameters k is 11.495251154151513 and b is -49.55796837945761\n",
      "Iteration 6051, the loss is 4.525253308294693, parameters k is 11.495233853756256 and b is -49.557936758904255\n",
      "Iteration 6052, the loss is 4.525252883636265, parameters k is 11.495266450594201 and b is -49.55789723321256\n",
      "Iteration 6053, the loss is 4.5252522340547285, parameters k is 11.495249150198944 and b is -49.5578656126592\n",
      "Iteration 6054, the loss is 4.525251584473202, parameters k is 11.495231849803687 and b is -49.55783399210584\n",
      "Iteration 6055, the loss is 4.525250967048528, parameters k is 11.49521454940843 and b is -49.557802371552484\n",
      "Iteration 6056, the loss is 4.525250591948628, parameters k is 11.495247146246376 and b is -49.557762845860786\n",
      "Iteration 6057, the loss is 4.525249942367096, parameters k is 11.495229845851119 and b is -49.55773122530743\n",
      "Iteration 6058, the loss is 4.525249292785559, parameters k is 11.495212545455862 and b is -49.55769960475407\n",
      "Iteration 6059, the loss is 4.525248643204022, parameters k is 11.495195245060605 and b is -49.55766798420071\n",
      "Iteration 6060, the loss is 4.525248282859325, parameters k is 11.495177944665349 and b is -49.557636363647354\n",
      "Iteration 6061, the loss is 4.525247650679457, parameters k is 11.495210541503294 and b is -49.55759683795566\n",
      "Iteration 6062, the loss is 4.525247001097926, parameters k is 11.495193241108037 and b is -49.5575652174023\n",
      "Iteration 6063, the loss is 4.525246351516391, parameters k is 11.49517594071278 and b is -49.55753359684894\n",
      "Iteration 6064, the loss is 4.525245941613156, parameters k is 11.495158640317523 and b is -49.55750197629558\n",
      "Iteration 6065, the loss is 4.525245358991821, parameters k is 11.495191237155469 and b is -49.557462450603886\n",
      "Iteration 6066, the loss is 4.525244709410282, parameters k is 11.495173936760212 and b is -49.55743083005053\n",
      "Iteration 6067, the loss is 4.525244059828749, parameters k is 11.495156636364955 and b is -49.55739920949717\n",
      "Iteration 6068, the loss is 4.525243600366993, parameters k is 11.495139335969698 and b is -49.55736758894381\n",
      "Iteration 6069, the loss is 4.525243067304184, parameters k is 11.495171932807644 and b is -49.557328063252115\n",
      "Iteration 6070, the loss is 4.525242417722649, parameters k is 11.495154632412387 and b is -49.55729644269876\n",
      "Iteration 6071, the loss is 4.525241768141111, parameters k is 11.49513733201713 and b is -49.5572648221454\n",
      "Iteration 6072, the loss is 4.525241259120822, parameters k is 11.495120031621873 and b is -49.55723320159204\n",
      "Iteration 6073, the loss is 4.525240775616542, parameters k is 11.495152628459818 and b is -49.55719367590034\n",
      "Iteration 6074, the loss is 4.525240126035011, parameters k is 11.495135328064562 and b is -49.557162055346986\n",
      "Iteration 6075, the loss is 4.525239476453478, parameters k is 11.495118027669305 and b is -49.55713043479363\n",
      "Iteration 6076, the loss is 4.5252389178746535, parameters k is 11.495100727274048 and b is -49.55709881424027\n",
      "Iteration 6077, the loss is 4.525238483928907, parameters k is 11.495133324111993 and b is -49.55705928854857\n",
      "Iteration 6078, the loss is 4.525237834347371, parameters k is 11.495116023716736 and b is -49.557027667995214\n",
      "Iteration 6079, the loss is 4.525237184765831, parameters k is 11.49509872332148 and b is -49.55699604744186\n",
      "Iteration 6080, the loss is 4.525236576628482, parameters k is 11.495081422926223 and b is -49.5569644268885\n",
      "Iteration 6081, the loss is 4.525236192241271, parameters k is 11.495114019764168 and b is -49.5569249011968\n",
      "Iteration 6082, the loss is 4.5252355426597335, parameters k is 11.495096719368911 and b is -49.55689328064344\n",
      "Iteration 6083, the loss is 4.525234893078198, parameters k is 11.495079418973654 and b is -49.556861660090085\n",
      "Iteration 6084, the loss is 4.525234243496664, parameters k is 11.495062118578398 and b is -49.55683003953673\n",
      "Iteration 6085, the loss is 4.525233892439285, parameters k is 11.49504481818314 and b is -49.55679841898337\n",
      "Iteration 6086, the loss is 4.525233250972094, parameters k is 11.495077415021086 and b is -49.55675889329167\n",
      "Iteration 6087, the loss is 4.525232601390558, parameters k is 11.49506011462583 and b is -49.556727272738314\n",
      "Iteration 6088, the loss is 4.525231951809025, parameters k is 11.495042814230573 and b is -49.556695652184956\n",
      "Iteration 6089, the loss is 4.525231551193112, parameters k is 11.495025513835316 and b is -49.5566640316316\n",
      "Iteration 6090, the loss is 4.525230959284459, parameters k is 11.495058110673261 and b is -49.5566245059399\n",
      "Iteration 6091, the loss is 4.525230309702924, parameters k is 11.495040810278004 and b is -49.55659288538654\n",
      "Iteration 6092, the loss is 4.52522966012139, parameters k is 11.495023509882747 and b is -49.556561264833185\n",
      "Iteration 6093, the loss is 4.525229209946946, parameters k is 11.49500620948749 and b is -49.55652964427983\n",
      "Iteration 6094, the loss is 4.525228667596815, parameters k is 11.495038806325436 and b is -49.55649011858813\n",
      "Iteration 6095, the loss is 4.525228018015283, parameters k is 11.495021505930179 and b is -49.55645849803477\n",
      "Iteration 6096, the loss is 4.5252273684337485, parameters k is 11.495004205534922 and b is -49.556426877481414\n",
      "Iteration 6097, the loss is 4.525226868700779, parameters k is 11.494986905139665 and b is -49.556395256928056\n",
      "Iteration 6098, the loss is 4.525226375909184, parameters k is 11.49501950197761 and b is -49.55635573123636\n",
      "Iteration 6099, the loss is 4.525225726327648, parameters k is 11.495002201582354 and b is -49.556324110683\n",
      "Iteration 6100, the loss is 4.525225076746115, parameters k is 11.494984901187097 and b is -49.55629249012964\n",
      "Iteration 6101, the loss is 4.525224527454611, parameters k is 11.49496760079184 and b is -49.556260869576285\n",
      "Iteration 6102, the loss is 4.525224084221543, parameters k is 11.495000197629786 and b is -49.55622134388459\n",
      "Iteration 6103, the loss is 4.525223434640014, parameters k is 11.494982897234529 and b is -49.55618972333123\n",
      "Iteration 6104, the loss is 4.525222785058475, parameters k is 11.494965596839272 and b is -49.55615810277787\n",
      "Iteration 6105, the loss is 4.525222186208436, parameters k is 11.494948296444015 and b is -49.55612648222451\n",
      "Iteration 6106, the loss is 4.52522179253391, parameters k is 11.49498089328196 and b is -49.556086956532816\n",
      "Iteration 6107, the loss is 4.525221142952375, parameters k is 11.494963592886704 and b is -49.55605533597946\n",
      "Iteration 6108, the loss is 4.5252204933708375, parameters k is 11.494946292491447 and b is -49.5560237154261\n",
      "Iteration 6109, the loss is 4.525219844962274, parameters k is 11.49492899209619 and b is -49.55599209487274\n",
      "Iteration 6110, the loss is 4.525219500846268, parameters k is 11.494961588934135 and b is -49.555952569181045\n",
      "Iteration 6111, the loss is 4.5252188512647376, parameters k is 11.494944288538878 and b is -49.55592094862769\n",
      "Iteration 6112, the loss is 4.525218201683196, parameters k is 11.494926988143622 and b is -49.55588932807433\n",
      "Iteration 6113, the loss is 4.525217552101666, parameters k is 11.494909687748365 and b is -49.55585770752097\n",
      "Iteration 6114, the loss is 4.525217160773075, parameters k is 11.494892387353108 and b is -49.55582608696761\n",
      "Iteration 6115, the loss is 4.525216559577101, parameters k is 11.494924984191053 and b is -49.555786561275916\n",
      "Iteration 6116, the loss is 4.5252159099955644, parameters k is 11.494907683795796 and b is -49.55575494072256\n",
      "Iteration 6117, the loss is 4.525215260414026, parameters k is 11.49489038340054 and b is -49.5557233201692\n",
      "Iteration 6118, the loss is 4.525214819526906, parameters k is 11.494873083005283 and b is -49.55569169961584\n",
      "Iteration 6119, the loss is 4.525214267889462, parameters k is 11.494905679843228 and b is -49.555652173924145\n",
      "Iteration 6120, the loss is 4.525213618307923, parameters k is 11.494888379447971 and b is -49.55562055337079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6121, the loss is 4.525212968726393, parameters k is 11.494871079052714 and b is -49.55558893281743\n",
      "Iteration 6122, the loss is 4.525212478280735, parameters k is 11.494853778657458 and b is -49.55555731226407\n",
      "Iteration 6123, the loss is 4.525211976201824, parameters k is 11.494886375495403 and b is -49.55551778657237\n",
      "Iteration 6124, the loss is 4.525211326620289, parameters k is 11.494869075100146 and b is -49.555486166019016\n",
      "Iteration 6125, the loss is 4.525210677038753, parameters k is 11.49485177470489 and b is -49.55545454546566\n",
      "Iteration 6126, the loss is 4.5252101370345645, parameters k is 11.494834474309632 and b is -49.5554229249123\n",
      "Iteration 6127, the loss is 4.525209684514187, parameters k is 11.494867071147578 and b is -49.5553833992206\n",
      "Iteration 6128, the loss is 4.525209034932646, parameters k is 11.494849770752321 and b is -49.555351778667244\n",
      "Iteration 6129, the loss is 4.5252083853511165, parameters k is 11.494832470357064 and b is -49.55532015811389\n",
      "Iteration 6130, the loss is 4.525207795788396, parameters k is 11.494815169961807 and b is -49.55528853756053\n",
      "Iteration 6131, the loss is 4.5252073928265455, parameters k is 11.494847766799753 and b is -49.55524901186883\n",
      "Iteration 6132, the loss is 4.525206743245009, parameters k is 11.494830466404496 and b is -49.55521739131547\n",
      "Iteration 6133, the loss is 4.525206093663475, parameters k is 11.494813166009239 and b is -49.555185770762115\n",
      "Iteration 6134, the loss is 4.525205454542229, parameters k is 11.494795865613982 and b is -49.55515415020876\n",
      "Iteration 6135, the loss is 4.52520510113891, parameters k is 11.494828462451927 and b is -49.55511462451706\n",
      "Iteration 6136, the loss is 4.525204451557375, parameters k is 11.49481116205667 and b is -49.5550830039637\n",
      "Iteration 6137, the loss is 4.525203801975838, parameters k is 11.494793861661414 and b is -49.555051383410344\n",
      "Iteration 6138, the loss is 4.5252031523943055, parameters k is 11.494776561266157 and b is -49.555019762856986\n",
      "Iteration 6139, the loss is 4.52520277035303, parameters k is 11.4947592608709 and b is -49.55498814230363\n",
      "Iteration 6140, the loss is 4.525202159869734, parameters k is 11.494791857708845 and b is -49.55494861661193\n",
      "Iteration 6141, the loss is 4.525201510288202, parameters k is 11.494774557313589 and b is -49.55491699605857\n",
      "Iteration 6142, the loss is 4.525200860706666, parameters k is 11.494757256918332 and b is -49.554885375505215\n",
      "Iteration 6143, the loss is 4.525200429106862, parameters k is 11.494739956523075 and b is -49.55485375495186\n",
      "Iteration 6144, the loss is 4.525199868182102, parameters k is 11.49477255336102 and b is -49.55481422926016\n",
      "Iteration 6145, the loss is 4.525199218600561, parameters k is 11.494755252965764 and b is -49.5547826087068\n",
      "Iteration 6146, the loss is 4.5251985690190315, parameters k is 11.494737952570507 and b is -49.554750988153444\n",
      "Iteration 6147, the loss is 4.525198087860693, parameters k is 11.49472065217525 and b is -49.554719367600086\n",
      "Iteration 6148, the loss is 4.525197576494461, parameters k is 11.494753249013195 and b is -49.55467984190839\n",
      "Iteration 6149, the loss is 4.525196926912928, parameters k is 11.494735948617938 and b is -49.55464822135503\n",
      "Iteration 6150, the loss is 4.52519627733139, parameters k is 11.494718648222682 and b is -49.55461660080167\n",
      "Iteration 6151, the loss is 4.525195746614525, parameters k is 11.494701347827425 and b is -49.554584980248315\n",
      "Iteration 6152, the loss is 4.525195284806832, parameters k is 11.49473394466537 and b is -49.55454545455662\n",
      "Iteration 6153, the loss is 4.525194635225285, parameters k is 11.494716644270113 and b is -49.55451383400326\n",
      "Iteration 6154, the loss is 4.525193985643757, parameters k is 11.494699343874856 and b is -49.5544822134499\n",
      "Iteration 6155, the loss is 4.525193405368353, parameters k is 11.4946820434796 and b is -49.55445059289654\n",
      "Iteration 6156, the loss is 4.52519299311919, parameters k is 11.494714640317545 and b is -49.554411067204846\n",
      "Iteration 6157, the loss is 4.525192343537651, parameters k is 11.494697339922288 and b is -49.55437944665149\n",
      "Iteration 6158, the loss is 4.525191693956116, parameters k is 11.494680039527031 and b is -49.55434782609813\n",
      "Iteration 6159, the loss is 4.525191064122187, parameters k is 11.494662739131774 and b is -49.55431620554477\n",
      "Iteration 6160, the loss is 4.525190701431553, parameters k is 11.49469533596972 and b is -49.554276679853075\n",
      "Iteration 6161, the loss is 4.5251900518500054, parameters k is 11.494678035574463 and b is -49.55424505929972\n",
      "Iteration 6162, the loss is 4.525189402268479, parameters k is 11.494660735179206 and b is -49.55421343874636\n",
      "Iteration 6163, the loss is 4.52518875268695, parameters k is 11.49464343478395 and b is -49.554181818193\n",
      "Iteration 6164, the loss is 4.525188379932991, parameters k is 11.494626134388692 and b is -49.55415019763964\n",
      "Iteration 6165, the loss is 4.525187760162375, parameters k is 11.494658731226638 and b is -49.554110671947946\n",
      "Iteration 6166, the loss is 4.525187110580846, parameters k is 11.494641430831381 and b is -49.55407905139459\n",
      "Iteration 6167, the loss is 4.525186460999301, parameters k is 11.494624130436124 and b is -49.55404743084123\n",
      "Iteration 6168, the loss is 4.525186038686821, parameters k is 11.494606830040867 and b is -49.55401581028787\n",
      "Iteration 6169, the loss is 4.525185468474738, parameters k is 11.494639426878813 and b is -49.553976284596175\n",
      "Iteration 6170, the loss is 4.5251848188932025, parameters k is 11.494622126483556 and b is -49.55394466404282\n",
      "Iteration 6171, the loss is 4.525184169311671, parameters k is 11.494604826088299 and b is -49.55391304348946\n",
      "Iteration 6172, the loss is 4.525183697440654, parameters k is 11.494587525693042 and b is -49.5538814229361\n",
      "Iteration 6173, the loss is 4.5251831767871025, parameters k is 11.494620122530987 and b is -49.5538418972444\n",
      "Iteration 6174, the loss is 4.525182527205573, parameters k is 11.49460282213573 and b is -49.553810276691046\n",
      "Iteration 6175, the loss is 4.52518187762403, parameters k is 11.494585521740474 and b is -49.55377865613769\n",
      "Iteration 6176, the loss is 4.525181356194482, parameters k is 11.494568221345217 and b is -49.55374703558433\n",
      "Iteration 6177, the loss is 4.525180885099463, parameters k is 11.494600818183162 and b is -49.55370750989263\n",
      "Iteration 6178, the loss is 4.525180235517929, parameters k is 11.494583517787905 and b is -49.553675889339274\n",
      "Iteration 6179, the loss is 4.525179585936392, parameters k is 11.494566217392649 and b is -49.553644268785916\n",
      "Iteration 6180, the loss is 4.525179014948309, parameters k is 11.494548916997392 and b is -49.55361264823256\n",
      "Iteration 6181, the loss is 4.525178593411828, parameters k is 11.494581513835337 and b is -49.55357312254086\n",
      "Iteration 6182, the loss is 4.5251779438302915, parameters k is 11.49456421344008 and b is -49.5535415019875\n",
      "Iteration 6183, the loss is 4.525177294248756, parameters k is 11.494546913044823 and b is -49.553509881434145\n",
      "Iteration 6184, the loss is 4.5251766737021475, parameters k is 11.494529612649567 and b is -49.55347826088079\n",
      "Iteration 6185, the loss is 4.525176301724186, parameters k is 11.494562209487512 and b is -49.55343873518909\n",
      "Iteration 6186, the loss is 4.52517565214265, parameters k is 11.494544909092255 and b is -49.55340711463573\n",
      "Iteration 6187, the loss is 4.525175002561118, parameters k is 11.494527608696998 and b is -49.553375494082374\n",
      "Iteration 6188, the loss is 4.525174352979581, parameters k is 11.494510308301741 and b is -49.553343873529016\n",
      "Iteration 6189, the loss is 4.525173989512945, parameters k is 11.494493007906485 and b is -49.55331225297566\n",
      "Iteration 6190, the loss is 4.525173360455018, parameters k is 11.49452560474443 and b is -49.55327272728396\n",
      "Iteration 6191, the loss is 4.525172710873481, parameters k is 11.494508304349173 and b is -49.5532411067306\n",
      "Iteration 6192, the loss is 4.525172061291945, parameters k is 11.494491003953916 and b is -49.553209486177245\n",
      "Iteration 6193, the loss is 4.525171648266783, parameters k is 11.49447370355866 and b is -49.55317786562389\n",
      "Iteration 6194, the loss is 4.525171068767383, parameters k is 11.494506300396605 and b is -49.55313833993219\n",
      "Iteration 6195, the loss is 4.525170419185839, parameters k is 11.494489000001348 and b is -49.55310671937883\n",
      "Iteration 6196, the loss is 4.5251697696043065, parameters k is 11.494471699606091 and b is -49.553075098825474\n",
      "Iteration 6197, the loss is 4.525169307020617, parameters k is 11.494454399210834 and b is -49.553043478272116\n",
      "Iteration 6198, the loss is 4.525168777079737, parameters k is 11.49448699604878 and b is -49.55300395258042\n",
      "Iteration 6199, the loss is 4.525168127498203, parameters k is 11.494469695653523 and b is -49.55297233202706\n",
      "Iteration 6200, the loss is 4.525167477916672, parameters k is 11.494452395258266 and b is -49.5529407114737\n",
      "Iteration 6201, the loss is 4.525166965774442, parameters k is 11.49443509486301 and b is -49.552909090920345\n",
      "Iteration 6202, the loss is 4.5251664853921065, parameters k is 11.494467691700955 and b is -49.55286956522865\n",
      "Iteration 6203, the loss is 4.525165835810566, parameters k is 11.494450391305698 and b is -49.55283794467529\n",
      "Iteration 6204, the loss is 4.52516518622903, parameters k is 11.49443309091044 and b is -49.55280632412193\n",
      "Iteration 6205, the loss is 4.525164624528274, parameters k is 11.494415790515184 and b is -49.55277470356857\n",
      "Iteration 6206, the loss is 4.525164193704469, parameters k is 11.49444838735313 and b is -49.552735177876876\n",
      "Iteration 6207, the loss is 4.5251635441229325, parameters k is 11.494431086957873 and b is -49.55270355732352\n",
      "Iteration 6208, the loss is 4.525162894541394, parameters k is 11.494413786562616 and b is -49.55267193677016\n",
      "Iteration 6209, the loss is 4.525162283282109, parameters k is 11.494396486167359 and b is -49.5526403162168\n",
      "Iteration 6210, the loss is 4.52516190201683, parameters k is 11.494429083005304 and b is -49.552600790525105\n",
      "Iteration 6211, the loss is 4.525161252435289, parameters k is 11.494411782610047 and b is -49.55256916997175\n",
      "Iteration 6212, the loss is 4.5251606028537585, parameters k is 11.49439448221479 and b is -49.55253754941839\n",
      "Iteration 6213, the loss is 4.525159953272228, parameters k is 11.494377181819534 and b is -49.55250592886503\n",
      "Iteration 6214, the loss is 4.525159599092904, parameters k is 11.494359881424277 and b is -49.55247430831167\n",
      "Iteration 6215, the loss is 4.525158960747656, parameters k is 11.494392478262222 and b is -49.552434782619976\n",
      "Iteration 6216, the loss is 4.525158311166117, parameters k is 11.494375177866965 and b is -49.55240316206662\n",
      "Iteration 6217, the loss is 4.5251576615845845, parameters k is 11.494357877471709 and b is -49.55237154151326\n",
      "Iteration 6218, the loss is 4.52515725784674, parameters k is 11.494340577076452 and b is -49.5523399209599\n",
      "Iteration 6219, the loss is 4.525156669060015, parameters k is 11.494373173914397 and b is -49.552300395268205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6220, the loss is 4.525156019478479, parameters k is 11.49435587351914 and b is -49.55226877471485\n",
      "Iteration 6221, the loss is 4.525155369896943, parameters k is 11.494338573123883 and b is -49.55223715416149\n",
      "Iteration 6222, the loss is 4.525154916600569, parameters k is 11.494321272728627 and b is -49.55220553360813\n",
      "Iteration 6223, the loss is 4.525154377372382, parameters k is 11.494353869566572 and b is -49.55216600791643\n",
      "Iteration 6224, the loss is 4.525153727790846, parameters k is 11.494336569171315 and b is -49.552134387363076\n",
      "Iteration 6225, the loss is 4.525153078209309, parameters k is 11.494319268776058 and b is -49.55210276680972\n",
      "Iteration 6226, the loss is 4.525152575354398, parameters k is 11.494301968380801 and b is -49.55207114625636\n",
      "Iteration 6227, the loss is 4.525152085684743, parameters k is 11.494334565218747 and b is -49.55203162056466\n",
      "Iteration 6228, the loss is 4.525151436103207, parameters k is 11.49431726482349 and b is -49.552000000011304\n",
      "Iteration 6229, the loss is 4.525150786521672, parameters k is 11.494299964428233 and b is -49.551968379457946\n",
      "Iteration 6230, the loss is 4.525150234108231, parameters k is 11.494282664032976 and b is -49.55193675890459\n",
      "Iteration 6231, the loss is 4.525149793997108, parameters k is 11.494315260870922 and b is -49.55189723321289\n",
      "Iteration 6232, the loss is 4.52514914441557, parameters k is 11.494297960475665 and b is -49.55186561265953\n",
      "Iteration 6233, the loss is 4.525148494834038, parameters k is 11.494280660080408 and b is -49.551833992106175\n",
      "Iteration 6234, the loss is 4.525147892862065, parameters k is 11.494263359685151 and b is -49.55180237155282\n",
      "Iteration 6235, the loss is 4.525147502309468, parameters k is 11.494295956523096 and b is -49.55176284586112\n",
      "Iteration 6236, the loss is 4.525146852727931, parameters k is 11.49427865612784 and b is -49.55173122530776\n",
      "Iteration 6237, the loss is 4.525146203146393, parameters k is 11.494261355732583 and b is -49.551699604754404\n",
      "Iteration 6238, the loss is 4.5251455535648555, parameters k is 11.494244055337326 and b is -49.551667984201046\n",
      "Iteration 6239, the loss is 4.525145208672867, parameters k is 11.49422675494207 and b is -49.55163636364769\n",
      "Iteration 6240, the loss is 4.525144561040298, parameters k is 11.494259351780014 and b is -49.55159683795599\n",
      "Iteration 6241, the loss is 4.525143911458756, parameters k is 11.494242051384758 and b is -49.55156521740263\n",
      "Iteration 6242, the loss is 4.525143261877223, parameters k is 11.4942247509895 and b is -49.551533596849275\n",
      "Iteration 6243, the loss is 4.525142867426703, parameters k is 11.494207450594244 and b is -49.55150197629592\n",
      "Iteration 6244, the loss is 4.525142269352661, parameters k is 11.49424004743219 and b is -49.55146245060422\n",
      "Iteration 6245, the loss is 4.525141619771121, parameters k is 11.494222747036932 and b is -49.55143083005086\n",
      "Iteration 6246, the loss is 4.525140970189586, parameters k is 11.494205446641676 and b is -49.551399209497504\n",
      "Iteration 6247, the loss is 4.52514052618053, parameters k is 11.494188146246419 and b is -49.551367588944146\n",
      "Iteration 6248, the loss is 4.525139977665018, parameters k is 11.494220743084364 and b is -49.55132806325245\n",
      "Iteration 6249, the loss is 4.5251393280834895, parameters k is 11.494203442689107 and b is -49.55129644269909\n",
      "Iteration 6250, the loss is 4.525138678501945, parameters k is 11.49418614229385 and b is -49.55126482214573\n",
      "Iteration 6251, the loss is 4.525138184934363, parameters k is 11.494168841898594 and b is -49.551233201592375\n",
      "Iteration 6252, the loss is 4.525137685977383, parameters k is 11.494201438736539 and b is -49.55119367590068\n",
      "Iteration 6253, the loss is 4.525137036395845, parameters k is 11.494184138341282 and b is -49.55116205534732\n",
      "Iteration 6254, the loss is 4.52513638681431, parameters k is 11.494166837946025 and b is -49.55113043479396\n",
      "Iteration 6255, the loss is 4.525135843688188, parameters k is 11.494149537550769 and b is -49.5510988142406\n",
      "Iteration 6256, the loss is 4.525135394289746, parameters k is 11.494182134388714 and b is -49.551059288548906\n",
      "Iteration 6257, the loss is 4.5251347447082075, parameters k is 11.494164833993457 and b is -49.55102766799555\n",
      "Iteration 6258, the loss is 4.525134095126676, parameters k is 11.4941475335982 and b is -49.55099604744219\n",
      "Iteration 6259, the loss is 4.525133502442022, parameters k is 11.494130233202943 and b is -49.55096442688883\n",
      "Iteration 6260, the loss is 4.525133102602108, parameters k is 11.494162830040889 and b is -49.550924901197135\n",
      "Iteration 6261, the loss is 4.525132453020566, parameters k is 11.494145529645632 and b is -49.55089328064378\n",
      "Iteration 6262, the loss is 4.525131803439034, parameters k is 11.494128229250375 and b is -49.55086166009042\n",
      "Iteration 6263, the loss is 4.525131161195856, parameters k is 11.494110928855118 and b is -49.55083003953706\n",
      "Iteration 6264, the loss is 4.525130810914475, parameters k is 11.494143525693064 and b is -49.550790513845364\n",
      "Iteration 6265, the loss is 4.5251301613329336, parameters k is 11.494126225297807 and b is -49.550758893292006\n",
      "Iteration 6266, the loss is 4.525129511751404, parameters k is 11.49410892490255 and b is -49.55072727273865\n",
      "Iteration 6267, the loss is 4.525128862169862, parameters k is 11.494091624507293 and b is -49.55069565218529\n",
      "Iteration 6268, the loss is 4.525128477006655, parameters k is 11.494074324112036 and b is -49.55066403163193\n",
      "Iteration 6269, the loss is 4.525127869645294, parameters k is 11.494106920949982 and b is -49.550624505940235\n",
      "Iteration 6270, the loss is 4.525127220063762, parameters k is 11.494089620554725 and b is -49.55059288538688\n",
      "Iteration 6271, the loss is 4.525126570482223, parameters k is 11.494072320159468 and b is -49.55056126483352\n",
      "Iteration 6272, the loss is 4.525126135760489, parameters k is 11.494055019764211 and b is -49.55052964428016\n",
      "Iteration 6273, the loss is 4.525125577957657, parameters k is 11.494087616602156 and b is -49.55049011858846\n",
      "Iteration 6274, the loss is 4.525124928376123, parameters k is 11.4940703162069 and b is -49.550458498035105\n",
      "Iteration 6275, the loss is 4.525124278794589, parameters k is 11.494053015811643 and b is -49.55042687748175\n",
      "Iteration 6276, the loss is 4.525123794514316, parameters k is 11.494035715416386 and b is -49.55039525692839\n",
      "Iteration 6277, the loss is 4.525123286270017, parameters k is 11.494068312254331 and b is -49.55035573123669\n",
      "Iteration 6278, the loss is 4.525122636688486, parameters k is 11.494051011859074 and b is -49.550324110683334\n",
      "Iteration 6279, the loss is 4.525121987106951, parameters k is 11.494033711463818 and b is -49.550292490129976\n",
      "Iteration 6280, the loss is 4.525121453268151, parameters k is 11.49401641106856 and b is -49.55026086957662\n",
      "Iteration 6281, the loss is 4.525120994582386, parameters k is 11.494049007906506 and b is -49.55022134388492\n",
      "Iteration 6282, the loss is 4.525120345000849, parameters k is 11.49403170751125 and b is -49.55018972333156\n",
      "Iteration 6283, the loss is 4.525119695419309, parameters k is 11.494014407115992 and b is -49.550158102778205\n",
      "Iteration 6284, the loss is 4.52511911202198, parameters k is 11.493997106720736 and b is -49.55012648222485\n",
      "Iteration 6285, the loss is 4.52511870289475, parameters k is 11.494029703558681 and b is -49.55008695653315\n",
      "Iteration 6286, the loss is 4.525118053313211, parameters k is 11.494012403163424 and b is -49.55005533597979\n",
      "Iteration 6287, the loss is 4.525117403731676, parameters k is 11.493995102768167 and b is -49.550023715426434\n",
      "Iteration 6288, the loss is 4.525116770775813, parameters k is 11.49397780237291 and b is -49.549992094873076\n",
      "Iteration 6289, the loss is 4.525116411207106, parameters k is 11.494010399210856 and b is -49.54995256918138\n",
      "Iteration 6290, the loss is 4.525115761625573, parameters k is 11.493993098815599 and b is -49.54992094862802\n",
      "Iteration 6291, the loss is 4.525115112044034, parameters k is 11.493975798420342 and b is -49.54988932807466\n",
      "Iteration 6292, the loss is 4.525114462462498, parameters k is 11.493958498025085 and b is -49.549857707521305\n",
      "Iteration 6293, the loss is 4.52511408658661, parameters k is 11.493941197629828 and b is -49.54982608696795\n",
      "Iteration 6294, the loss is 4.525113469937935, parameters k is 11.493973794467774 and b is -49.54978656127625\n",
      "Iteration 6295, the loss is 4.525112820356401, parameters k is 11.493956494072517 and b is -49.54975494072289\n",
      "Iteration 6296, the loss is 4.525112170774871, parameters k is 11.49393919367726 and b is -49.549723320169534\n",
      "Iteration 6297, the loss is 4.525111745340447, parameters k is 11.493921893282003 and b is -49.549691699616176\n",
      "Iteration 6298, the loss is 4.5251111782502935, parameters k is 11.493954490119949 and b is -49.54965217392448\n",
      "Iteration 6299, the loss is 4.525110528668766, parameters k is 11.493937189724692 and b is -49.54962055337112\n",
      "Iteration 6300, the loss is 4.525109879087223, parameters k is 11.493919889329435 and b is -49.54958893281776\n",
      "Iteration 6301, the loss is 4.5251094040942785, parameters k is 11.493902588934178 and b is -49.549557312264405\n",
      "Iteration 6302, the loss is 4.525108886562661, parameters k is 11.493935185772123 and b is -49.54951778657271\n",
      "Iteration 6303, the loss is 4.525108236981126, parameters k is 11.493917885376867 and b is -49.54948616601935\n",
      "Iteration 6304, the loss is 4.52510758739959, parameters k is 11.49390058498161 and b is -49.54945454546599\n",
      "Iteration 6305, the loss is 4.5251070628481065, parameters k is 11.493883284586353 and b is -49.54942292491263\n",
      "Iteration 6306, the loss is 4.52510659487502, parameters k is 11.493915881424298 and b is -49.549383399220936\n",
      "Iteration 6307, the loss is 4.525105945293488, parameters k is 11.493898581029041 and b is -49.54935177866758\n",
      "Iteration 6308, the loss is 4.525105295711949, parameters k is 11.493881280633785 and b is -49.54932015811422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6309, the loss is 4.525104721601939, parameters k is 11.493863980238528 and b is -49.54928853756086\n",
      "Iteration 6310, the loss is 4.525104303187385, parameters k is 11.493896577076473 and b is -49.549249011869165\n",
      "Iteration 6311, the loss is 4.525103653605856, parameters k is 11.493879276681216 and b is -49.54921739131581\n",
      "Iteration 6312, the loss is 4.525103004024309, parameters k is 11.49386197628596 and b is -49.54918577076245\n",
      "Iteration 6313, the loss is 4.525102380355773, parameters k is 11.493844675890703 and b is -49.54915415020909\n",
      "Iteration 6314, the loss is 4.52510201149974, parameters k is 11.493877272728648 and b is -49.549114624517394\n",
      "Iteration 6315, the loss is 4.525101361918209, parameters k is 11.493859972333391 and b is -49.549083003964036\n",
      "Iteration 6316, the loss is 4.5251007123366715, parameters k is 11.493842671938134 and b is -49.54905138341068\n",
      "Iteration 6317, the loss is 4.525100062755141, parameters k is 11.493825371542878 and b is -49.54901976285732\n",
      "Iteration 6318, the loss is 4.525099696166574, parameters k is 11.49380807114762 and b is -49.54898814230396\n",
      "Iteration 6319, the loss is 4.525099070230576, parameters k is 11.493840667985566 and b is -49.548948616612265\n",
      "Iteration 6320, the loss is 4.525098420649042, parameters k is 11.49382336759031 and b is -49.54891699605891\n",
      "Iteration 6321, the loss is 4.5250977710675055, parameters k is 11.493806067195052 and b is -49.54888537550555\n",
      "Iteration 6322, the loss is 4.525097354920402, parameters k is 11.493788766799796 and b is -49.54885375495219\n",
      "Iteration 6323, the loss is 4.525096778542936, parameters k is 11.49382136363774 and b is -49.54881422926049\n",
      "Iteration 6324, the loss is 4.525096128961401, parameters k is 11.493804063242484 and b is -49.548782608707135\n",
      "Iteration 6325, the loss is 4.525095479379869, parameters k is 11.493786762847227 and b is -49.54875098815378\n",
      "Iteration 6326, the loss is 4.525095013674234, parameters k is 11.49376946245197 and b is -49.54871936760042\n",
      "Iteration 6327, the loss is 4.525094486855299, parameters k is 11.493802059289916 and b is -49.54867984190872\n",
      "Iteration 6328, the loss is 4.525093837273764, parameters k is 11.493784758894659 and b is -49.548648221355364\n",
      "Iteration 6329, the loss is 4.52509318769223, parameters k is 11.493767458499402 and b is -49.548616600802006\n",
      "Iteration 6330, the loss is 4.525092672428069, parameters k is 11.493750158104145 and b is -49.54858498024865\n",
      "Iteration 6331, the loss is 4.525092195167663, parameters k is 11.49378275494209 and b is -49.54854545455695\n",
      "Iteration 6332, the loss is 4.525091545586128, parameters k is 11.493765454546834 and b is -49.54851383400359\n",
      "Iteration 6333, the loss is 4.525090896004594, parameters k is 11.493748154151577 and b is -49.548482213450235\n",
      "Iteration 6334, the loss is 4.525090331181896, parameters k is 11.49373085375632 and b is -49.54845059289688\n",
      "Iteration 6335, the loss is 4.5250899034800245, parameters k is 11.493763450594265 and b is -49.54841106720518\n",
      "Iteration 6336, the loss is 4.525089253898492, parameters k is 11.493746150199009 and b is -49.54837944665182\n",
      "Iteration 6337, the loss is 4.525088604316955, parameters k is 11.493728849803752 and b is -49.548347826098464\n",
      "Iteration 6338, the loss is 4.525087989935729, parameters k is 11.493711549408495 and b is -49.548316205545106\n",
      "Iteration 6339, the loss is 4.525087611792386, parameters k is 11.49374414624644 and b is -49.54827667985341\n",
      "Iteration 6340, the loss is 4.525086962210852, parameters k is 11.493726845851183 and b is -49.54824505930005\n",
      "Iteration 6341, the loss is 4.5250863126293135, parameters k is 11.493709545455927 and b is -49.54821343874669\n",
      "Iteration 6342, the loss is 4.525085663047782, parameters k is 11.49369224506067 and b is -49.548181818193335\n",
      "Iteration 6343, the loss is 4.5250853057465275, parameters k is 11.493674944665413 and b is -49.54815019763998\n",
      "Iteration 6344, the loss is 4.5250846705232135, parameters k is 11.493707541503358 and b is -49.54811067194828\n",
      "Iteration 6345, the loss is 4.5250840209416765, parameters k is 11.493690241108101 and b is -49.54807905139492\n",
      "Iteration 6346, the loss is 4.525083371360142, parameters k is 11.493672940712845 and b is -49.548047430841564\n",
      "Iteration 6347, the loss is 4.525082964500361, parameters k is 11.493655640317588 and b is -49.548015810288206\n",
      "Iteration 6348, the loss is 4.525082378835578, parameters k is 11.493688237155533 and b is -49.54797628459651\n",
      "Iteration 6349, the loss is 4.525081729254043, parameters k is 11.493670936760276 and b is -49.54794466404315\n",
      "Iteration 6350, the loss is 4.525081079672503, parameters k is 11.49365363636502 and b is -49.54791304348979\n",
      "Iteration 6351, the loss is 4.525080623254193, parameters k is 11.493636335969763 and b is -49.547881422936435\n",
      "Iteration 6352, the loss is 4.525080087147938, parameters k is 11.493668932807708 and b is -49.54784189724474\n",
      "Iteration 6353, the loss is 4.525079437566405, parameters k is 11.493651632412451 and b is -49.54781027669138\n",
      "Iteration 6354, the loss is 4.52507878798486, parameters k is 11.493634332017194 and b is -49.54777865613802\n",
      "Iteration 6355, the loss is 4.525078282008022, parameters k is 11.493617031621937 and b is -49.54774703558466\n",
      "Iteration 6356, the loss is 4.525077795460297, parameters k is 11.493649628459883 and b is -49.547707509892966\n",
      "Iteration 6357, the loss is 4.525077145878769, parameters k is 11.493632328064626 and b is -49.54767588933961\n",
      "Iteration 6358, the loss is 4.52507649629723, parameters k is 11.49361502766937 and b is -49.54764426878625\n",
      "Iteration 6359, the loss is 4.525075940761855, parameters k is 11.493597727274112 and b is -49.54761264823289\n",
      "Iteration 6360, the loss is 4.525075503772664, parameters k is 11.493630324112058 and b is -49.547573122541195\n",
      "Iteration 6361, the loss is 4.525074854191125, parameters k is 11.4936130237168 and b is -49.54754150198784\n",
      "Iteration 6362, the loss is 4.52507420460959, parameters k is 11.493595723321544 and b is -49.54750988143448\n",
      "Iteration 6363, the loss is 4.525073599515687, parameters k is 11.493578422926287 and b is -49.54747826088112\n",
      "Iteration 6364, the loss is 4.5250732120850214, parameters k is 11.493611019764232 and b is -49.547438735189424\n",
      "Iteration 6365, the loss is 4.525072562503495, parameters k is 11.493593719368976 and b is -49.547407114636066\n",
      "Iteration 6366, the loss is 4.525071912921955, parameters k is 11.493576418973719 and b is -49.54737549408271\n",
      "Iteration 6367, the loss is 4.525071263340419, parameters k is 11.493559118578462 and b is -49.54734387352935\n",
      "Iteration 6368, the loss is 4.5250709153264905, parameters k is 11.493541818183205 and b is -49.54731225297599\n",
      "Iteration 6369, the loss is 4.525070270815852, parameters k is 11.49357441502115 and b is -49.547272727284295\n",
      "Iteration 6370, the loss is 4.5250696212343176, parameters k is 11.493557114625894 and b is -49.54724110673094\n",
      "Iteration 6371, the loss is 4.525068971652781, parameters k is 11.493539814230637 and b is -49.54720948617758\n",
      "Iteration 6372, the loss is 4.525068574080327, parameters k is 11.49352251383538 and b is -49.54717786562422\n",
      "Iteration 6373, the loss is 4.525067979128222, parameters k is 11.493555110673325 and b is -49.54713833993252\n",
      "Iteration 6374, the loss is 4.525067329546676, parameters k is 11.493537810278069 and b is -49.547106719379165\n",
      "Iteration 6375, the loss is 4.5250666799651444, parameters k is 11.493520509882812 and b is -49.54707509882581\n",
      "Iteration 6376, the loss is 4.525066232834153, parameters k is 11.493503209487555 and b is -49.54704347827245\n",
      "Iteration 6377, the loss is 4.525065687440581, parameters k is 11.4935358063255 and b is -49.54700395258075\n",
      "Iteration 6378, the loss is 4.525065037859046, parameters k is 11.493518505930243 and b is -49.546972332027394\n",
      "Iteration 6379, the loss is 4.5250643882775075, parameters k is 11.493501205534987 and b is -49.546940711474036\n",
      "Iteration 6380, the loss is 4.525063891587982, parameters k is 11.49348390513973 and b is -49.54690909092068\n",
      "Iteration 6381, the loss is 4.525063395752943, parameters k is 11.493516501977675 and b is -49.54686956522898\n",
      "Iteration 6382, the loss is 4.525062746171407, parameters k is 11.493499201582418 and b is -49.54683794467562\n",
      "Iteration 6383, the loss is 4.525062096589869, parameters k is 11.493481901187161 and b is -49.546806324122265\n",
      "Iteration 6384, the loss is 4.525061550341814, parameters k is 11.493464600791905 and b is -49.54677470356891\n",
      "Iteration 6385, the loss is 4.525061104065304, parameters k is 11.49349719762985 and b is -49.54673517787721\n",
      "Iteration 6386, the loss is 4.5250604544837625, parameters k is 11.493479897234593 and b is -49.54670355732385\n",
      "Iteration 6387, the loss is 4.525059804902233, parameters k is 11.493462596839336 and b is -49.546671936770494\n",
      "Iteration 6388, the loss is 4.5250592090956445, parameters k is 11.49344529644408 and b is -49.546640316217136\n",
      "Iteration 6389, the loss is 4.52505881237767, parameters k is 11.493477893282025 and b is -49.54660079052544\n",
      "Iteration 6390, the loss is 4.525058162796133, parameters k is 11.493460592886768 and b is -49.54656916997208\n",
      "Iteration 6391, the loss is 4.525057513214593, parameters k is 11.493443292491511 and b is -49.54653754941872\n",
      "Iteration 6392, the loss is 4.5250568678494725, parameters k is 11.493425992096254 and b is -49.546505928865365\n",
      "Iteration 6393, the loss is 4.525056520690029, parameters k is 11.4934585889342 and b is -49.54646640317367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6394, the loss is 4.525055871108491, parameters k is 11.493441288538943 and b is -49.54643478262031\n",
      "Iteration 6395, the loss is 4.525055221526952, parameters k is 11.493423988143686 and b is -49.54640316206695\n",
      "Iteration 6396, the loss is 4.52505457194542, parameters k is 11.493406687748429 and b is -49.546371541513594\n",
      "Iteration 6397, the loss is 4.525054183660279, parameters k is 11.493389387353172 and b is -49.546339920960236\n",
      "Iteration 6398, the loss is 4.525053579420857, parameters k is 11.493421984191118 and b is -49.54630039526854\n",
      "Iteration 6399, the loss is 4.525052929839319, parameters k is 11.49340468379586 and b is -49.54626877471518\n",
      "Iteration 6400, the loss is 4.525052280257784, parameters k is 11.493387383400604 and b is -49.54623715416182\n",
      "Iteration 6401, the loss is 4.525051842414112, parameters k is 11.493370083005347 and b is -49.546205533608465\n",
      "Iteration 6402, the loss is 4.525051287733216, parameters k is 11.493402679843292 and b is -49.54616600791677\n",
      "Iteration 6403, the loss is 4.525050638151681, parameters k is 11.493385379448036 and b is -49.54613438736341\n",
      "Iteration 6404, the loss is 4.5250499885701485, parameters k is 11.493368079052779 and b is -49.54610276681005\n",
      "Iteration 6405, the loss is 4.525049501167938, parameters k is 11.493350778657522 and b is -49.54607114625669\n",
      "Iteration 6406, the loss is 4.5250489960455775, parameters k is 11.493383375495467 and b is -49.546031620564996\n",
      "Iteration 6407, the loss is 4.525048346464046, parameters k is 11.49336607510021 and b is -49.54600000001164\n",
      "Iteration 6408, the loss is 4.5250476968825115, parameters k is 11.493348774704954 and b is -49.54596837945828\n",
      "Iteration 6409, the loss is 4.525047159921772, parameters k is 11.493331474309697 and b is -49.54593675890492\n",
      "Iteration 6410, the loss is 4.525046704357942, parameters k is 11.493364071147642 and b is -49.545897233213225\n",
      "Iteration 6411, the loss is 4.525046054776405, parameters k is 11.493346770752385 and b is -49.54586561265987\n",
      "Iteration 6412, the loss is 4.52504540519487, parameters k is 11.493329470357128 and b is -49.54583399210651\n",
      "Iteration 6413, the loss is 4.525044818675605, parameters k is 11.493312169961872 and b is -49.54580237155315\n",
      "Iteration 6414, the loss is 4.5250444126703036, parameters k is 11.493344766799817 and b is -49.545762845861454\n",
      "Iteration 6415, the loss is 4.525043763088768, parameters k is 11.49332746640456 and b is -49.545731225308096\n",
      "Iteration 6416, the loss is 4.525043113507232, parameters k is 11.493310166009303 and b is -49.54569960475474\n",
      "Iteration 6417, the loss is 4.525042477429435, parameters k is 11.493292865614047 and b is -49.54566798420138\n",
      "Iteration 6418, the loss is 4.525042120982664, parameters k is 11.493325462451992 and b is -49.54562845850968\n",
      "Iteration 6419, the loss is 4.52504147140113, parameters k is 11.493308162056735 and b is -49.545596837956325\n",
      "Iteration 6420, the loss is 4.525040821819598, parameters k is 11.493290861661478 and b is -49.54556521740297\n",
      "Iteration 6421, the loss is 4.525040172238061, parameters k is 11.493273561266221 and b is -49.54553359684961\n",
      "Iteration 6422, the loss is 4.525039793240236, parameters k is 11.493256260870965 and b is -49.54550197629625\n",
      "Iteration 6423, the loss is 4.525039179713496, parameters k is 11.49328885770891 and b is -49.54546245060455\n",
      "Iteration 6424, the loss is 4.525038530131959, parameters k is 11.493271557313653 and b is -49.545430830051195\n",
      "Iteration 6425, the loss is 4.525037880550422, parameters k is 11.493254256918396 and b is -49.54539920949784\n",
      "Iteration 6426, the loss is 4.5250374519940655, parameters k is 11.49323695652314 and b is -49.54536758894448\n",
      "Iteration 6427, the loss is 4.525036888025858, parameters k is 11.493269553361085 and b is -49.54532806325278\n",
      "Iteration 6428, the loss is 4.525036238444323, parameters k is 11.493252252965828 and b is -49.545296442699424\n",
      "Iteration 6429, the loss is 4.52503558886279, parameters k is 11.493234952570571 and b is -49.545264822146066\n",
      "Iteration 6430, the loss is 4.525035110747902, parameters k is 11.493217652175314 and b is -49.54523320159271\n",
      "Iteration 6431, the loss is 4.525034596338217, parameters k is 11.49325024901326 and b is -49.54519367590101\n",
      "Iteration 6432, the loss is 4.5250339467566825, parameters k is 11.493232948618003 and b is -49.54516205534765\n",
      "Iteration 6433, the loss is 4.5250332971751455, parameters k is 11.493215648222746 and b is -49.545130434794295\n",
      "Iteration 6434, the loss is 4.525032769501725, parameters k is 11.493198347827489 and b is -49.54509881424094\n",
      "Iteration 6435, the loss is 4.525032304650579, parameters k is 11.493230944665434 and b is -49.54505928854924\n",
      "Iteration 6436, the loss is 4.525031655069047, parameters k is 11.493213644270178 and b is -49.54502766799588\n",
      "Iteration 6437, the loss is 4.525031005487514, parameters k is 11.49319634387492 and b is -49.544996047442524\n",
      "Iteration 6438, the loss is 4.525030428255564, parameters k is 11.493179043479664 and b is -49.544964426889166\n",
      "Iteration 6439, the loss is 4.5250300129629455, parameters k is 11.49321164031761 and b is -49.54492490119747\n",
      "Iteration 6440, the loss is 4.525029363381405, parameters k is 11.493194339922352 and b is -49.54489328064411\n",
      "Iteration 6441, the loss is 4.525028713799872, parameters k is 11.493177039527096 and b is -49.54486166009075\n",
      "Iteration 6442, the loss is 4.525028087009396, parameters k is 11.493159739131839 and b is -49.544830039537395\n",
      "Iteration 6443, the loss is 4.525027721275305, parameters k is 11.493192335969784 and b is -49.5447905138457\n",
      "Iteration 6444, the loss is 4.525027071693778, parameters k is 11.493175035574527 and b is -49.54475889329234\n",
      "Iteration 6445, the loss is 4.525026422112236, parameters k is 11.49315773517927 and b is -49.54472727273898\n",
      "Iteration 6446, the loss is 4.525025772530703, parameters k is 11.493140434784014 and b is -49.544695652185624\n",
      "Iteration 6447, the loss is 4.525025402820193, parameters k is 11.493123134388757 and b is -49.544664031632266\n",
      "Iteration 6448, the loss is 4.525024780006134, parameters k is 11.493155731226702 and b is -49.54462450594057\n",
      "Iteration 6449, the loss is 4.525024130424603, parameters k is 11.493138430831445 and b is -49.54459288538721\n",
      "Iteration 6450, the loss is 4.525023480843067, parameters k is 11.493121130436188 and b is -49.54456126483385\n",
      "Iteration 6451, the loss is 4.5250230615740294, parameters k is 11.493103830040932 and b is -49.544529644280495\n",
      "Iteration 6452, the loss is 4.525022488318497, parameters k is 11.493136426878877 and b is -49.5444901185888\n",
      "Iteration 6453, the loss is 4.525021838736958, parameters k is 11.49311912648362 and b is -49.54445849803544\n",
      "Iteration 6454, the loss is 4.525021189155426, parameters k is 11.493101826088363 and b is -49.54442687748208\n",
      "Iteration 6455, the loss is 4.5250207203278565, parameters k is 11.493084525693106 and b is -49.54439525692872\n",
      "Iteration 6456, the loss is 4.525020196630856, parameters k is 11.493117122531052 and b is -49.544355731237026\n",
      "Iteration 6457, the loss is 4.525019547049324, parameters k is 11.493099822135795 and b is -49.54432411068367\n",
      "Iteration 6458, the loss is 4.5250188974677865, parameters k is 11.493082521740538 and b is -49.54429249013031\n",
      "Iteration 6459, the loss is 4.52501837908169, parameters k is 11.493065221345281 and b is -49.54426086957695\n",
      "Iteration 6460, the loss is 4.525017904943223, parameters k is 11.493097818183227 and b is -49.544221343885255\n",
      "Iteration 6461, the loss is 4.525017255361685, parameters k is 11.49308051778797 and b is -49.5441897233319\n",
      "Iteration 6462, the loss is 4.525016605780148, parameters k is 11.493063217392713 and b is -49.54415810277854\n",
      "Iteration 6463, the loss is 4.52501603783552, parameters k is 11.493045916997456 and b is -49.54412648222518\n",
      "Iteration 6464, the loss is 4.525015613255583, parameters k is 11.493078513835401 and b is -49.544086956533484\n",
      "Iteration 6465, the loss is 4.525014963674049, parameters k is 11.493061213440145 and b is -49.544055335980126\n",
      "Iteration 6466, the loss is 4.525014314092515, parameters k is 11.493043913044888 and b is -49.54402371542677\n",
      "Iteration 6467, the loss is 4.525013696589353, parameters k is 11.493026612649631 and b is -49.54399209487341\n",
      "Iteration 6468, the loss is 4.525013321567948, parameters k is 11.493059209487576 and b is -49.54395256918171\n",
      "Iteration 6469, the loss is 4.525012671986406, parameters k is 11.49304190909232 and b is -49.543920948628354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6470, the loss is 4.5250120224048755, parameters k is 11.493024608697063 and b is -49.543889328075\n",
      "Iteration 6471, the loss is 4.525011372823339, parameters k is 11.493007308301806 and b is -49.54385770752164\n",
      "Iteration 6472, the loss is 4.525011012400157, parameters k is 11.492990007906549 and b is -49.54382608696828\n",
      "Iteration 6473, the loss is 4.525010380298772, parameters k is 11.493022604744494 and b is -49.54378656127658\n",
      "Iteration 6474, the loss is 4.5250097307172386, parameters k is 11.493005304349238 and b is -49.543754940723225\n",
      "Iteration 6475, the loss is 4.525009081135698, parameters k is 11.49298800395398 and b is -49.54372332016987\n",
      "Iteration 6476, the loss is 4.5250086711539845, parameters k is 11.492970703558724 and b is -49.54369169961651\n",
      "Iteration 6477, the loss is 4.525008088611133, parameters k is 11.49300330039667 and b is -49.54365217392481\n",
      "Iteration 6478, the loss is 4.525007439029601, parameters k is 11.492986000001412 and b is -49.543620553371454\n",
      "Iteration 6479, the loss is 4.525006789448065, parameters k is 11.492968699606156 and b is -49.543588932818096\n",
      "Iteration 6480, the loss is 4.525006329907818, parameters k is 11.492951399210899 and b is -49.54355731226474\n",
      "Iteration 6481, the loss is 4.525005796923497, parameters k is 11.492983996048844 and b is -49.54351778657304\n",
      "Iteration 6482, the loss is 4.525005147341962, parameters k is 11.492966695653587 and b is -49.54348616601968\n",
      "Iteration 6483, the loss is 4.525004497760428, parameters k is 11.49294939525833 and b is -49.543454545466325\n",
      "Iteration 6484, the loss is 4.525003988661649, parameters k is 11.492932094863074 and b is -49.54342292491297\n",
      "Iteration 6485, the loss is 4.525003505235863, parameters k is 11.492964691701019 and b is -49.54338339922127\n",
      "Iteration 6486, the loss is 4.525002855654327, parameters k is 11.492947391305762 and b is -49.54335177866791\n",
      "Iteration 6487, the loss is 4.525002206072796, parameters k is 11.492930090910505 and b is -49.543320158114554\n",
      "Iteration 6488, the loss is 4.525001647415481, parameters k is 11.492912790515248 and b is -49.543288537561196\n",
      "Iteration 6489, the loss is 4.525001213548226, parameters k is 11.492945387353194 and b is -49.5432490118695\n",
      "Iteration 6490, the loss is 4.525000563966685, parameters k is 11.492928086957937 and b is -49.54321739131614\n",
      "Iteration 6491, the loss is 4.524999914385157, parameters k is 11.49291078656268 and b is -49.54318577076278\n",
      "Iteration 6492, the loss is 4.524999306169312, parameters k is 11.492893486167423 and b is -49.543154150209425\n",
      "Iteration 6493, the loss is 4.524998921860586, parameters k is 11.492926083005369 and b is -49.54311462451773\n",
      "Iteration 6494, the loss is 4.524998272279052, parameters k is 11.492908782610112 and b is -49.54308300396437\n",
      "Iteration 6495, the loss is 4.524997622697519, parameters k is 11.492891482214855 and b is -49.54305138341101\n",
      "Iteration 6496, the loss is 4.5249969731159805, parameters k is 11.492874181819598 and b is -49.543019762857654\n",
      "Iteration 6497, the loss is 4.524996621980109, parameters k is 11.492856881424341 and b is -49.542988142304296\n",
      "Iteration 6498, the loss is 4.524995980591416, parameters k is 11.492889478262287 and b is -49.5429486166126\n",
      "Iteration 6499, the loss is 4.524995331009882, parameters k is 11.49287217786703 and b is -49.54291699605924\n",
      "Iteration 6500, the loss is 4.524994681428339, parameters k is 11.492854877471773 and b is -49.54288537550588\n",
      "Iteration 6501, the loss is 4.524994280733941, parameters k is 11.492837577076516 and b is -49.542853754952525\n",
      "Iteration 6502, the loss is 4.524993688903776, parameters k is 11.492870173914461 and b is -49.54281422926083\n",
      "Iteration 6503, the loss is 4.524993039322241, parameters k is 11.492852873519205 and b is -49.54278260870747\n",
      "Iteration 6504, the loss is 4.524992389740701, parameters k is 11.492835573123948 and b is -49.54275098815411\n",
      "Iteration 6505, the loss is 4.52499193948777, parameters k is 11.492818272728691 and b is -49.54271936760075\n",
      "Iteration 6506, the loss is 4.52499139721614, parameters k is 11.492850869566636 and b is -49.542679841909056\n",
      "Iteration 6507, the loss is 4.524990747634602, parameters k is 11.49283356917138 and b is -49.5426482213557\n",
      "Iteration 6508, the loss is 4.524990098053065, parameters k is 11.492816268776123 and b is -49.54261660080234\n",
      "Iteration 6509, the loss is 4.524989598241607, parameters k is 11.492798968380866 and b is -49.54258498024898\n",
      "Iteration 6510, the loss is 4.524989105528501, parameters k is 11.492831565218811 and b is -49.542545454557285\n",
      "Iteration 6511, the loss is 4.524988455946965, parameters k is 11.492814264823554 and b is -49.54251383400393\n",
      "Iteration 6512, the loss is 4.524987806365432, parameters k is 11.492796964428297 and b is -49.54248221345057\n",
      "Iteration 6513, the loss is 4.524987256995436, parameters k is 11.49277966403304 and b is -49.54245059289721\n",
      "Iteration 6514, the loss is 4.5249868138408615, parameters k is 11.492812260870986 and b is -49.542411067205514\n",
      "Iteration 6515, the loss is 4.524986164259328, parameters k is 11.49279496047573 and b is -49.542379446652156\n",
      "Iteration 6516, the loss is 4.524985514677791, parameters k is 11.492777660080472 and b is -49.5423478260988\n",
      "Iteration 6517, the loss is 4.524984915749273, parameters k is 11.492760359685215 and b is -49.54231620554544\n",
      "Iteration 6518, the loss is 4.524984522153225, parameters k is 11.49279295652316 and b is -49.54227667985374\n",
      "Iteration 6519, the loss is 4.524983872571685, parameters k is 11.492775656127904 and b is -49.542245059300384\n",
      "Iteration 6520, the loss is 4.524983222990157, parameters k is 11.492758355732647 and b is -49.54221343874703\n",
      "Iteration 6521, the loss is 4.524982574503103, parameters k is 11.49274105533739 and b is -49.54218181819367\n",
      "Iteration 6522, the loss is 4.524982230465591, parameters k is 11.492773652175336 and b is -49.54214229250197\n",
      "Iteration 6523, the loss is 4.524981580884053, parameters k is 11.492756351780079 and b is -49.54211067194861\n",
      "Iteration 6524, the loss is 4.524980931302515, parameters k is 11.492739051384822 and b is -49.542079051395255\n",
      "Iteration 6525, the loss is 4.52498028172098, parameters k is 11.492721750989565 and b is -49.5420474308419\n",
      "Iteration 6526, the loss is 4.5249798903139, parameters k is 11.492704450594308 and b is -49.54201581028854\n",
      "Iteration 6527, the loss is 4.524979289196415, parameters k is 11.492737047432254 and b is -49.54197628459684\n",
      "Iteration 6528, the loss is 4.524978639614878, parameters k is 11.492719747036997 and b is -49.541944664043484\n",
      "Iteration 6529, the loss is 4.524977990033344, parameters k is 11.49270244664174 and b is -49.541913043490126\n",
      "Iteration 6530, the loss is 4.52497754906773, parameters k is 11.492685146246483 and b is -49.54188142293677\n",
      "Iteration 6531, the loss is 4.5249769975087775, parameters k is 11.492717743084429 and b is -49.54184189724507\n",
      "Iteration 6532, the loss is 4.524976347927243, parameters k is 11.492700442689172 and b is -49.54181027669171\n",
      "Iteration 6533, the loss is 4.524975698345706, parameters k is 11.492683142293915 and b is -49.541778656138355\n",
      "Iteration 6534, the loss is 4.524975207821565, parameters k is 11.492665841898658 and b is -49.541747035585\n",
      "Iteration 6535, the loss is 4.5249747058211405, parameters k is 11.492698438736603 and b is -49.5417075098933\n",
      "Iteration 6536, the loss is 4.524974056239601, parameters k is 11.492681138341347 and b is -49.54167588933994\n",
      "Iteration 6537, the loss is 4.524973406658069, parameters k is 11.49266383794609 and b is -49.541644268786584\n",
      "Iteration 6538, the loss is 4.524972866575395, parameters k is 11.492646537550833 and b is -49.541612648233226\n",
      "Iteration 6539, the loss is 4.524972414133502, parameters k is 11.492679134388778 and b is -49.54157312254153\n",
      "Iteration 6540, the loss is 4.52497176455197, parameters k is 11.492661833993521 and b is -49.54154150198817\n",
      "Iteration 6541, the loss is 4.52497111497043, parameters k is 11.492644533598265 and b is -49.54150988143481\n",
      "Iteration 6542, the loss is 4.524970525329225, parameters k is 11.492627233203008 and b is -49.541478260881455\n",
      "Iteration 6543, the loss is 4.524970122445864, parameters k is 11.492659830040953 and b is -49.54143873518976\n",
      "Iteration 6544, the loss is 4.524969472864332, parameters k is 11.492642529645696 and b is -49.5414071146364\n",
      "Iteration 6545, the loss is 4.524968823282793, parameters k is 11.49262522925044 and b is -49.54137549408304\n",
      "Iteration 6546, the loss is 4.52496818408306, parameters k is 11.492607928855183 and b is -49.541343873529684\n",
      "Iteration 6547, the loss is 4.524967830758226, parameters k is 11.492640525693128 and b is -49.541304347837986\n",
      "Iteration 6548, the loss is 4.524967181176695, parameters k is 11.492623225297871 and b is -49.54127272728463\n",
      "Iteration 6549, the loss is 4.524966531595154, parameters k is 11.492605924902614 and b is -49.54124110673127\n",
      "Iteration 6550, the loss is 4.524965882013621, parameters k is 11.492588624507357 and b is -49.54120948617791\n",
      "Iteration 6551, the loss is 4.524965499893854, parameters k is 11.4925713241121 and b is -49.541177865624554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6552, the loss is 4.524964889489055, parameters k is 11.492603920950046 and b is -49.54113833993286\n",
      "Iteration 6553, the loss is 4.524964239907516, parameters k is 11.492586620554789 and b is -49.5411067193795\n",
      "Iteration 6554, the loss is 4.524963590325981, parameters k is 11.492569320159532 and b is -49.54107509882614\n",
      "Iteration 6555, the loss is 4.524963158647689, parameters k is 11.492552019764275 and b is -49.54104347827278\n",
      "Iteration 6556, the loss is 4.5249625978014185, parameters k is 11.49258461660222 and b is -49.541003952581086\n",
      "Iteration 6557, the loss is 4.524961948219879, parameters k is 11.492567316206964 and b is -49.54097233202773\n",
      "Iteration 6558, the loss is 4.524961298638345, parameters k is 11.492550015811707 and b is -49.54094071147437\n",
      "Iteration 6559, the loss is 4.524960817401522, parameters k is 11.49253271541645 and b is -49.54090909092101\n",
      "Iteration 6560, the loss is 4.524960306113778, parameters k is 11.492565312254396 and b is -49.540869565229315\n",
      "Iteration 6561, the loss is 4.524959656532244, parameters k is 11.492548011859139 and b is -49.54083794467596\n",
      "Iteration 6562, the loss is 4.524959006950711, parameters k is 11.492530711463882 and b is -49.5408063241226\n",
      "Iteration 6563, the loss is 4.524958476155356, parameters k is 11.492513411068625 and b is -49.54077470356924\n",
      "Iteration 6564, the loss is 4.524958014426137, parameters k is 11.49254600790657 and b is -49.54073517787754\n",
      "Iteration 6565, the loss is 4.524957364844603, parameters k is 11.492528707511314 and b is -49.540703557324186\n",
      "Iteration 6566, the loss is 4.524956715263068, parameters k is 11.492511407116057 and b is -49.54067193677083\n",
      "Iteration 6567, the loss is 4.524956134909187, parameters k is 11.4924941067208 and b is -49.54064031621747\n",
      "Iteration 6568, the loss is 4.524955722738505, parameters k is 11.492526703558745 and b is -49.54060079052577\n",
      "Iteration 6569, the loss is 4.524955073156967, parameters k is 11.492509403163488 and b is -49.540569169972414\n",
      "Iteration 6570, the loss is 4.524954423575435, parameters k is 11.492492102768232 and b is -49.54053754941906\n",
      "Iteration 6571, the loss is 4.524953793663013, parameters k is 11.492474802372975 and b is -49.5405059288657\n",
      "Iteration 6572, the loss is 4.524953431050864, parameters k is 11.49250739921092 and b is -49.540466403174\n",
      "Iteration 6573, the loss is 4.524952781469332, parameters k is 11.492490098815663 and b is -49.54043478262064\n",
      "Iteration 6574, the loss is 4.5249521318877965, parameters k is 11.492472798420406 and b is -49.540403162067285\n",
      "Iteration 6575, the loss is 4.524951482306258, parameters k is 11.49245549802515 and b is -49.54037154151393\n",
      "Iteration 6576, the loss is 4.524951109473821, parameters k is 11.492438197629893 and b is -49.54033992096057\n",
      "Iteration 6577, the loss is 4.524950489781692, parameters k is 11.492470794467838 and b is -49.54030039526887\n",
      "Iteration 6578, the loss is 4.524949840200159, parameters k is 11.492453494072581 and b is -49.540268774715514\n",
      "Iteration 6579, the loss is 4.524949190618622, parameters k is 11.492436193677324 and b is -49.540237154162156\n",
      "Iteration 6580, the loss is 4.524948768227656, parameters k is 11.492418893282068 and b is -49.5402055336088\n",
      "Iteration 6581, the loss is 4.524948198094054, parameters k is 11.492451490120013 and b is -49.5401660079171\n",
      "Iteration 6582, the loss is 4.524947548512519, parameters k is 11.492434189724756 and b is -49.54013438736374\n",
      "Iteration 6583, the loss is 4.524946898930986, parameters k is 11.4924168893295 and b is -49.540102766810385\n",
      "Iteration 6584, the loss is 4.524946426981481, parameters k is 11.492399588934243 and b is -49.54007114625703\n",
      "Iteration 6585, the loss is 4.524945906406419, parameters k is 11.492432185772188 and b is -49.54003162056533\n",
      "Iteration 6586, the loss is 4.524945256824886, parameters k is 11.492414885376931 and b is -49.54000000001197\n",
      "Iteration 6587, the loss is 4.524944607243346, parameters k is 11.492397584981674 and b is -49.539968379458614\n",
      "Iteration 6588, the loss is 4.524944085735319, parameters k is 11.492380284586417 and b is -49.539936758905256\n",
      "Iteration 6589, the loss is 4.524943614718776, parameters k is 11.492412881424363 and b is -49.53989723321356\n",
      "Iteration 6590, the loss is 4.52494296513724, parameters k is 11.492395581029106 and b is -49.5398656126602\n",
      "Iteration 6591, the loss is 4.524942315555706, parameters k is 11.492378280633849 and b is -49.53983399210684\n",
      "Iteration 6592, the loss is 4.524941744489143, parameters k is 11.492360980238592 and b is -49.539802371553485\n",
      "Iteration 6593, the loss is 4.524941323031145, parameters k is 11.492393577076538 and b is -49.53976284586179\n",
      "Iteration 6594, the loss is 4.52494067344961, parameters k is 11.49237627668128 and b is -49.53973122530843\n",
      "Iteration 6595, the loss is 4.524940023868071, parameters k is 11.492358976286024 and b is -49.53969960475507\n",
      "Iteration 6596, the loss is 4.524939403242979, parameters k is 11.492341675890767 and b is -49.539667984201714\n",
      "Iteration 6597, the loss is 4.524939031343501, parameters k is 11.492374272728712 and b is -49.539628458510016\n",
      "Iteration 6598, the loss is 4.524938381761967, parameters k is 11.492356972333456 and b is -49.53959683795666\n",
      "Iteration 6599, the loss is 4.524937732180432, parameters k is 11.492339671938199 and b is -49.5395652174033\n",
      "Iteration 6600, the loss is 4.5249370825989015, parameters k is 11.492322371542942 and b is -49.53953359684994\n",
      "Iteration 6601, the loss is 4.524936719053781, parameters k is 11.492305071147685 and b is -49.539501976296584\n",
      "Iteration 6602, the loss is 4.524936090074331, parameters k is 11.49233766798563 and b is -49.53946245060489\n",
      "Iteration 6603, the loss is 4.524935440492799, parameters k is 11.492320367590374 and b is -49.53943083005153\n",
      "Iteration 6604, the loss is 4.52493479091126, parameters k is 11.492303067195117 and b is -49.53939920949817\n",
      "Iteration 6605, the loss is 4.524934377807611, parameters k is 11.49228576679986 and b is -49.53936758894481\n",
      "Iteration 6606, the loss is 4.52493379838669, parameters k is 11.492318363637805 and b is -49.539328063253116\n",
      "Iteration 6607, the loss is 4.52493314880516, parameters k is 11.492301063242548 and b is -49.53929644269976\n",
      "Iteration 6608, the loss is 4.524932499223627, parameters k is 11.492283762847292 and b is -49.5392648221464\n",
      "Iteration 6609, the loss is 4.52493203656144, parameters k is 11.492266462452035 and b is -49.53923320159304\n",
      "Iteration 6610, the loss is 4.524931506699058, parameters k is 11.49229905928998 and b is -49.539193675901345\n",
      "Iteration 6611, the loss is 4.524930857117521, parameters k is 11.492281758894723 and b is -49.53916205534799\n",
      "Iteration 6612, the loss is 4.5249302075359905, parameters k is 11.492264458499466 and b is -49.53913043479463\n",
      "Iteration 6613, the loss is 4.524929695315272, parameters k is 11.49224715810421 and b is -49.53909881424127\n",
      "Iteration 6614, the loss is 4.524929215011424, parameters k is 11.492279754942155 and b is -49.53905928854957\n",
      "Iteration 6615, the loss is 4.524928565429886, parameters k is 11.492262454546898 and b is -49.539027667996216\n",
      "Iteration 6616, the loss is 4.524927915848349, parameters k is 11.492245154151641 and b is -49.53899604744286\n",
      "Iteration 6617, the loss is 4.5249273540691, parameters k is 11.492227853756384 and b is -49.5389644268895\n",
      "Iteration 6618, the loss is 4.524926923323782, parameters k is 11.49226045059433 and b is -49.5389249011978\n",
      "Iteration 6619, the loss is 4.524926273742246, parameters k is 11.492243150199073 and b is -49.538893280644444\n",
      "Iteration 6620, the loss is 4.524925624160709, parameters k is 11.492225849803816 and b is -49.53886166009109\n",
      "Iteration 6621, the loss is 4.524925012822936, parameters k is 11.49220854940856 and b is -49.53883003953773\n",
      "Iteration 6622, the loss is 4.524924631636145, parameters k is 11.492241146246505 and b is -49.53879051384603\n",
      "Iteration 6623, the loss is 4.524923982054607, parameters k is 11.492223845851248 and b is -49.53875889329267\n",
      "Iteration 6624, the loss is 4.524923332473074, parameters k is 11.492206545455991 and b is -49.538727272739315\n",
      "Iteration 6625, the loss is 4.524922682891542, parameters k is 11.492189245060734 and b is -49.53869565218596\n",
      "Iteration 6626, the loss is 4.524922328633736, parameters k is 11.492171944665477 and b is -49.5386640316326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6627, the loss is 4.524921690366975, parameters k is 11.492204541503423 and b is -49.5386245059409\n",
      "Iteration 6628, the loss is 4.524921040785435, parameters k is 11.492187241108166 and b is -49.538592885387544\n",
      "Iteration 6629, the loss is 4.524920391203901, parameters k is 11.492169940712909 and b is -49.538561264834186\n",
      "Iteration 6630, the loss is 4.524919987387561, parameters k is 11.492152640317652 and b is -49.53852964428083\n",
      "Iteration 6631, the loss is 4.524919398679338, parameters k is 11.492185237155597 and b is -49.53849011858913\n",
      "Iteration 6632, the loss is 4.524918749097797, parameters k is 11.49216793676034 and b is -49.53845849803577\n",
      "Iteration 6633, the loss is 4.524918099516267, parameters k is 11.492150636365084 and b is -49.538426877482415\n",
      "Iteration 6634, the loss is 4.5249176461414, parameters k is 11.492133335969827 and b is -49.53839525692906\n",
      "Iteration 6635, the loss is 4.524917106991703, parameters k is 11.492165932807772 and b is -49.53835573123736\n",
      "Iteration 6636, the loss is 4.524916457410162, parameters k is 11.492148632412515 and b is -49.538324110684\n",
      "Iteration 6637, the loss is 4.524915807828626, parameters k is 11.492131332017259 and b is -49.538292490130644\n",
      "Iteration 6638, the loss is 4.524915304895228, parameters k is 11.492114031622002 and b is -49.538260869577286\n",
      "Iteration 6639, the loss is 4.524914815304057, parameters k is 11.492146628459947 and b is -49.53822134388559\n",
      "Iteration 6640, the loss is 4.524914165722524, parameters k is 11.49212932806469 and b is -49.53818972333223\n",
      "Iteration 6641, the loss is 4.524913516140989, parameters k is 11.492112027669434 and b is -49.53815810277887\n",
      "Iteration 6642, the loss is 4.5249129636490615, parameters k is 11.492094727274177 and b is -49.538126482225515\n",
      "Iteration 6643, the loss is 4.524912523616424, parameters k is 11.492127324112122 and b is -49.53808695653382\n",
      "Iteration 6644, the loss is 4.524911874034881, parameters k is 11.492110023716865 and b is -49.53805533598046\n",
      "Iteration 6645, the loss is 4.524911224453347, parameters k is 11.492092723321608 and b is -49.5380237154271\n",
      "Iteration 6646, the loss is 4.524910622402891, parameters k is 11.492075422926352 and b is -49.537992094873744\n",
      "Iteration 6647, the loss is 4.524910231928787, parameters k is 11.492108019764297 and b is -49.537952569182046\n",
      "Iteration 6648, the loss is 4.524909582347252, parameters k is 11.49209071936904 and b is -49.53792094862869\n",
      "Iteration 6649, the loss is 4.524908932765715, parameters k is 11.492073418973783 and b is -49.53788932807533\n",
      "Iteration 6650, the loss is 4.524908283184182, parameters k is 11.492056118578526 and b is -49.53785770752197\n",
      "Iteration 6651, the loss is 4.524907938213693, parameters k is 11.49203881818327 and b is -49.537826086968614\n",
      "Iteration 6652, the loss is 4.524907290659612, parameters k is 11.492071415021215 and b is -49.53778656127692\n",
      "Iteration 6653, the loss is 4.524906641078077, parameters k is 11.492054114625958 and b is -49.53775494072356\n",
      "Iteration 6654, the loss is 4.5249059914965395, parameters k is 11.492036814230701 and b is -49.5377233201702\n",
      "Iteration 6655, the loss is 4.524905596967524, parameters k is 11.492019513835444 and b is -49.53769169961684\n",
      "Iteration 6656, the loss is 4.524904998971974, parameters k is 11.49205211067339 and b is -49.537652173925146\n",
      "Iteration 6657, the loss is 4.524904349390442, parameters k is 11.492034810278133 and b is -49.53762055337179\n",
      "Iteration 6658, the loss is 4.5249036998089025, parameters k is 11.492017509882876 and b is -49.53758893281843\n",
      "Iteration 6659, the loss is 4.524903255721354, parameters k is 11.49200020948762 and b is -49.53755731226507\n",
      "Iteration 6660, the loss is 4.524902707284341, parameters k is 11.492032806325565 and b is -49.537517786573375\n",
      "Iteration 6661, the loss is 4.524902057702797, parameters k is 11.492015505930308 and b is -49.53748616602002\n",
      "Iteration 6662, the loss is 4.524901408121263, parameters k is 11.491998205535051 and b is -49.53745454546666\n",
      "Iteration 6663, the loss is 4.524900914475189, parameters k is 11.491980905139794 and b is -49.5374229249133\n",
      "Iteration 6664, the loss is 4.524900415596698, parameters k is 11.49201350197774 and b is -49.5373833992216\n",
      "Iteration 6665, the loss is 4.524899766015163, parameters k is 11.491996201582483 and b is -49.537351778668246\n",
      "Iteration 6666, the loss is 4.524899116433627, parameters k is 11.491978901187226 and b is -49.53732015811489\n",
      "Iteration 6667, the loss is 4.524898573229023, parameters k is 11.491961600791969 and b is -49.53728853756153\n",
      "Iteration 6668, the loss is 4.524898123909058, parameters k is 11.491994197629914 and b is -49.53724901186983\n",
      "Iteration 6669, the loss is 4.524897474327525, parameters k is 11.491976897234657 and b is -49.537217391316474\n",
      "Iteration 6670, the loss is 4.524896824745989, parameters k is 11.4919595968394 and b is -49.53718577076312\n",
      "Iteration 6671, the loss is 4.524896231982854, parameters k is 11.491942296444144 and b is -49.53715415020976\n",
      "Iteration 6672, the loss is 4.52489583222142, parameters k is 11.491974893282089 and b is -49.53711462451806\n",
      "Iteration 6673, the loss is 4.524895182639891, parameters k is 11.491957592886832 and b is -49.5370830039647\n",
      "Iteration 6674, the loss is 4.524894533058353, parameters k is 11.491940292491575 and b is -49.537051383411345\n",
      "Iteration 6675, the loss is 4.524893890736682, parameters k is 11.491922992096319 and b is -49.53701976285799\n",
      "Iteration 6676, the loss is 4.524893540533785, parameters k is 11.491955588934264 and b is -49.53698023716629\n",
      "Iteration 6677, the loss is 4.524892890952251, parameters k is 11.491938288539007 and b is -49.53694861661293\n",
      "Iteration 6678, the loss is 4.524892241370716, parameters k is 11.49192098814375 and b is -49.536916996059574\n",
      "Iteration 6679, the loss is 4.524891591789179, parameters k is 11.491903687748493 and b is -49.536885375506216\n",
      "Iteration 6680, the loss is 4.5248912065474824, parameters k is 11.491886387353237 and b is -49.53685375495286\n",
      "Iteration 6681, the loss is 4.524890599264612, parameters k is 11.491918984191182 and b is -49.53681422926116\n",
      "Iteration 6682, the loss is 4.524889949683081, parameters k is 11.491901683795925 and b is -49.5367826087078\n",
      "Iteration 6683, the loss is 4.524889300101539, parameters k is 11.491884383400668 and b is -49.536750988154445\n",
      "Iteration 6684, the loss is 4.5248888653013095, parameters k is 11.491867083005411 and b is -49.53671936760109\n",
      "Iteration 6685, the loss is 4.524888307576972, parameters k is 11.491899679843357 and b is -49.53667984190939\n",
      "Iteration 6686, the loss is 4.524887657995442, parameters k is 11.4918823794481 and b is -49.53664822135603\n",
      "Iteration 6687, the loss is 4.524887008413908, parameters k is 11.491865079052843 and b is -49.536616600802674\n",
      "Iteration 6688, the loss is 4.524886524055151, parameters k is 11.491847778657586 and b is -49.536584980249316\n",
      "Iteration 6689, the loss is 4.524886015889336, parameters k is 11.491880375495532 and b is -49.53654545455762\n",
      "Iteration 6690, the loss is 4.5248853663078, parameters k is 11.491863075100275 and b is -49.53651383400426\n",
      "Iteration 6691, the loss is 4.524884716726272, parameters k is 11.491845774705018 and b is -49.5364822134509\n",
      "Iteration 6692, the loss is 4.524884182808979, parameters k is 11.491828474309761 and b is -49.536450592897545\n",
      "Iteration 6693, the loss is 4.524883724201701, parameters k is 11.491861071147706 and b is -49.53641106720585\n",
      "Iteration 6694, the loss is 4.524883074620166, parameters k is 11.49184377075245 and b is -49.53637944665249\n",
      "Iteration 6695, the loss is 4.524882425038626, parameters k is 11.491826470357193 and b is -49.53634782609913\n",
      "Iteration 6696, the loss is 4.524881841562803, parameters k is 11.491809169961936 and b is -49.53631620554577\n",
      "Iteration 6697, the loss is 4.524881432514057, parameters k is 11.491841766799881 and b is -49.536276679854076\n",
      "Iteration 6698, the loss is 4.524880782932527, parameters k is 11.491824466404625 and b is -49.53624505930072\n",
      "Iteration 6699, the loss is 4.5248801333509885, parameters k is 11.491807166009368 and b is -49.53621343874736\n",
      "Iteration 6700, the loss is 4.524879500316644, parameters k is 11.49178986561411 and b is -49.536181818194\n",
      "Iteration 6701, the loss is 4.524879140826427, parameters k is 11.491822462452056 and b is -49.536142292502305\n",
      "Iteration 6702, the loss is 4.524878491244895, parameters k is 11.4918051620568 and b is -49.53611067194895\n",
      "Iteration 6703, the loss is 4.524877841663354, parameters k is 11.491787861661543 and b is -49.53607905139559\n",
      "Iteration 6704, the loss is 4.524877192081818, parameters k is 11.491770561266286 and b is -49.53604743084223\n",
      "Iteration 6705, the loss is 4.52487681612744, parameters k is 11.491753260871029 and b is -49.53601581028887\n",
      "Iteration 6706, the loss is 4.524876199557255, parameters k is 11.491785857708974 and b is -49.535976284597176\n",
      "Iteration 6707, the loss is 4.524875549975719, parameters k is 11.491768557313717 and b is -49.53594466404382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6708, the loss is 4.524874900394182, parameters k is 11.49175125691846 and b is -49.53591304349046\n",
      "Iteration 6709, the loss is 4.524874474881274, parameters k is 11.491733956523204 and b is -49.5358814229371\n",
      "Iteration 6710, the loss is 4.5248739078696145, parameters k is 11.491766553361149 and b is -49.535841897245405\n",
      "Iteration 6711, the loss is 4.5248732582880775, parameters k is 11.491749252965892 and b is -49.53581027669205\n",
      "Iteration 6712, the loss is 4.524872608706544, parameters k is 11.491731952570635 and b is -49.53577865613869\n",
      "Iteration 6713, the loss is 4.524872133635104, parameters k is 11.491714652175379 and b is -49.53574703558533\n",
      "Iteration 6714, the loss is 4.52487161618198, parameters k is 11.491747249013324 and b is -49.53570750989363\n",
      "Iteration 6715, the loss is 4.524870966600443, parameters k is 11.491729948618067 and b is -49.535675889340276\n",
      "Iteration 6716, the loss is 4.524870317018904, parameters k is 11.49171264822281 and b is -49.53564426878692\n",
      "Iteration 6717, the loss is 4.524869792388941, parameters k is 11.491695347827553 and b is -49.53561264823356\n",
      "Iteration 6718, the loss is 4.524869324494341, parameters k is 11.491727944665499 and b is -49.53557312254186\n",
      "Iteration 6719, the loss is 4.5248686749128035, parameters k is 11.491710644270242 and b is -49.535541501988504\n",
      "Iteration 6720, the loss is 4.524868025331269, parameters k is 11.491693343874985 and b is -49.535509881435146\n",
      "Iteration 6721, the loss is 4.524867451142766, parameters k is 11.491676043479728 and b is -49.53547826088179\n",
      "Iteration 6722, the loss is 4.524867032806703, parameters k is 11.491708640317674 and b is -49.53543873519009\n",
      "Iteration 6723, the loss is 4.524866383225168, parameters k is 11.491691339922417 and b is -49.53540711463673\n",
      "Iteration 6724, the loss is 4.524865733643631, parameters k is 11.49167403952716 and b is -49.535375494083375\n",
      "Iteration 6725, the loss is 4.524865109896601, parameters k is 11.491656739131903 and b is -49.53534387353002\n",
      "Iteration 6726, the loss is 4.524864741119065, parameters k is 11.491689335969848 and b is -49.53530434783832\n",
      "Iteration 6727, the loss is 4.5248640915375296, parameters k is 11.491672035574592 and b is -49.53527272728496\n",
      "Iteration 6728, the loss is 4.524863441955995, parameters k is 11.491654735179335 and b is -49.535241106731604\n",
      "Iteration 6729, the loss is 4.524862792374456, parameters k is 11.491637434784078 and b is -49.535209486178246\n",
      "Iteration 6730, the loss is 4.524862425707399, parameters k is 11.491620134388821 and b is -49.53517786562489\n",
      "Iteration 6731, the loss is 4.5248617998498935, parameters k is 11.491652731226766 and b is -49.53513833993319\n",
      "Iteration 6732, the loss is 4.5248611502683485, parameters k is 11.49163543083151 and b is -49.53510671937983\n",
      "Iteration 6733, the loss is 4.524860500686821, parameters k is 11.491618130436253 and b is -49.535075098826475\n",
      "Iteration 6734, the loss is 4.524860084461227, parameters k is 11.491600830040996 and b is -49.53504347827312\n",
      "Iteration 6735, the loss is 4.524859508162251, parameters k is 11.491633426878941 and b is -49.53500395258142\n",
      "Iteration 6736, the loss is 4.524858858580721, parameters k is 11.491616126483684 and b is -49.53497233202806\n",
      "Iteration 6737, the loss is 4.524858208999185, parameters k is 11.491598826088428 and b is -49.534940711474704\n",
      "Iteration 6738, the loss is 4.524857743215069, parameters k is 11.49158152569317 and b is -49.534909090921346\n",
      "Iteration 6739, the loss is 4.524857216474619, parameters k is 11.491614122531116 and b is -49.53486956522965\n",
      "Iteration 6740, the loss is 4.52485656689308, parameters k is 11.49159682213586 and b is -49.53483794467629\n",
      "Iteration 6741, the loss is 4.524855917311545, parameters k is 11.491579521740602 and b is -49.53480632412293\n",
      "Iteration 6742, the loss is 4.524855401968895, parameters k is 11.491562221345346 and b is -49.534774703569575\n",
      "Iteration 6743, the loss is 4.524854924786981, parameters k is 11.491594818183291 and b is -49.53473517787788\n",
      "Iteration 6744, the loss is 4.524854275205447, parameters k is 11.491577517788034 and b is -49.53470355732452\n",
      "Iteration 6745, the loss is 4.52485362562391, parameters k is 11.491560217392777 and b is -49.53467193677116\n",
      "Iteration 6746, the loss is 4.5248530607227275, parameters k is 11.49154291699752 and b is -49.5346403162178\n",
      "Iteration 6747, the loss is 4.524852633099344, parameters k is 11.491575513835466 and b is -49.534600790526106\n",
      "Iteration 6748, the loss is 4.524851983517807, parameters k is 11.491558213440209 and b is -49.53456916997275\n",
      "Iteration 6749, the loss is 4.524851333936269, parameters k is 11.491540913044952 and b is -49.53453754941939\n",
      "Iteration 6750, the loss is 4.524850719476562, parameters k is 11.491523612649695 and b is -49.53450592886603\n",
      "Iteration 6751, the loss is 4.524850341411705, parameters k is 11.49155620948764 and b is -49.534466403174335\n",
      "Iteration 6752, the loss is 4.524849691830167, parameters k is 11.491538909092384 and b is -49.53443478262098\n",
      "Iteration 6753, the loss is 4.524849042248632, parameters k is 11.491521608697127 and b is -49.53440316206762\n",
      "Iteration 6754, the loss is 4.524848392667097, parameters k is 11.49150430830187 and b is -49.53437154151426\n",
      "Iteration 6755, the loss is 4.52484803528736, parameters k is 11.491487007906613 and b is -49.5343399209609\n",
      "Iteration 6756, the loss is 4.524847400142529, parameters k is 11.491519604744559 and b is -49.534300395269206\n",
      "Iteration 6757, the loss is 4.524846750560994, parameters k is 11.491502304349302 and b is -49.53426877471585\n",
      "Iteration 6758, the loss is 4.524846100979464, parameters k is 11.491485003954045 and b is -49.53423715416249\n",
      "Iteration 6759, the loss is 4.524845694041189, parameters k is 11.491467703558788 and b is -49.53420553360913\n",
      "Iteration 6760, the loss is 4.524845108454891, parameters k is 11.491500300396734 and b is -49.534166007917435\n",
      "Iteration 6761, the loss is 4.524844458873363, parameters k is 11.491483000001477 and b is -49.53413438736408\n",
      "Iteration 6762, the loss is 4.524843809291822, parameters k is 11.49146569960622 and b is -49.53410276681072\n",
      "Iteration 6763, the loss is 4.5248433527950205, parameters k is 11.491448399210963 and b is -49.53407114625736\n",
      "Iteration 6764, the loss is 4.524842816767255, parameters k is 11.491480996048908 and b is -49.53403162056566\n",
      "Iteration 6765, the loss is 4.524842167185719, parameters k is 11.491463695653652 and b is -49.534000000012306\n",
      "Iteration 6766, the loss is 4.524841517604186, parameters k is 11.491446395258395 and b is -49.53396837945895\n",
      "Iteration 6767, the loss is 4.524841011548856, parameters k is 11.491429094863138 and b is -49.53393675890559\n",
      "Iteration 6768, the loss is 4.524840525079621, parameters k is 11.491461691701083 and b is -49.53389723321389\n",
      "Iteration 6769, the loss is 4.524839875498085, parameters k is 11.491444391305826 and b is -49.533865612660534\n",
      "Iteration 6770, the loss is 4.524839225916552, parameters k is 11.49142709091057 and b is -49.533833992107176\n",
      "Iteration 6771, the loss is 4.5248386703026835, parameters k is 11.491409790515313 and b is -49.53380237155382\n",
      "Iteration 6772, the loss is 4.524838233391976, parameters k is 11.491442387353258 and b is -49.53376284586212\n",
      "Iteration 6773, the loss is 4.524837583810445, parameters k is 11.491425086958001 and b is -49.53373122530876\n",
      "Iteration 6774, the loss is 4.524836934228909, parameters k is 11.491407786562744 and b is -49.533699604755405\n",
      "Iteration 6775, the loss is 4.524836329056515, parameters k is 11.491390486167488 and b is -49.53366798420205\n",
      "Iteration 6776, the loss is 4.524835941704344, parameters k is 11.491423083005433 and b is -49.53362845851035\n",
      "Iteration 6777, the loss is 4.524835292122812, parameters k is 11.491405782610176 and b is -49.53359683795699\n",
      "Iteration 6778, the loss is 4.524834642541273, parameters k is 11.49138848221492 and b is -49.533565217403634\n",
      "Iteration 6779, the loss is 4.524833992959732, parameters k is 11.491371181819662 and b is -49.533533596850276\n",
      "Iteration 6780, the loss is 4.524833644867318, parameters k is 11.491353881424406 and b is -49.53350197629692\n",
      "Iteration 6781, the loss is 4.52483300043517, parameters k is 11.491386478262351 and b is -49.53346245060522\n",
      "Iteration 6782, the loss is 4.524832350853634, parameters k is 11.491369177867094 and b is -49.53343083005186\n",
      "Iteration 6783, the loss is 4.524831701272098, parameters k is 11.491351877471837 and b is -49.533399209498505\n",
      "Iteration 6784, the loss is 4.524831303621149, parameters k is 11.49133457707658 and b is -49.53336758894515\n",
      "Iteration 6785, the loss is 4.5248307087475315, parameters k is 11.491367173914526 and b is -49.53332806325345\n",
      "Iteration 6786, the loss is 4.524830059165995, parameters k is 11.491349873519269 and b is -49.53329644270009\n",
      "Iteration 6787, the loss is 4.524829409584459, parameters k is 11.491332573124012 and b is -49.533264822146734\n",
      "Iteration 6788, the loss is 4.524828962374977, parameters k is 11.491315272728755 and b is -49.533233201593376\n",
      "Iteration 6789, the loss is 4.5248284170598945, parameters k is 11.4913478695667 and b is -49.53319367590168\n",
      "Iteration 6790, the loss is 4.52482776747836, parameters k is 11.491330569171444 and b is -49.53316205534832\n",
      "Iteration 6791, the loss is 4.5248271178968205, parameters k is 11.491313268776187 and b is -49.53313043479496\n",
      "Iteration 6792, the loss is 4.5248266211288115, parameters k is 11.49129596838093 and b is -49.533098814241605\n",
      "Iteration 6793, the loss is 4.5248261253722575, parameters k is 11.491328565218875 and b is -49.53305928854991\n",
      "Iteration 6794, the loss is 4.52482547579072, parameters k is 11.491311264823619 and b is -49.53302766799655\n",
      "Iteration 6795, the loss is 4.5248248262091835, parameters k is 11.491293964428362 and b is -49.53299604744319\n",
      "Iteration 6796, the loss is 4.524824279882648, parameters k is 11.491276664033105 and b is -49.53296442688983\n",
      "Iteration 6797, the loss is 4.524823833684625, parameters k is 11.49130926087105 and b is -49.532924901198136\n",
      "Iteration 6798, the loss is 4.524823184103087, parameters k is 11.491291960475793 and b is -49.53289328064478\n",
      "Iteration 6799, the loss is 4.524822534521552, parameters k is 11.491274660080537 and b is -49.53286166009142\n",
      "Iteration 6800, the loss is 4.5248219386364745, parameters k is 11.49125735968528 and b is -49.53283003953806\n",
      "Iteration 6801, the loss is 4.524821541996981, parameters k is 11.491289956523225 and b is -49.532790513846365\n",
      "Iteration 6802, the loss is 4.524820892415446, parameters k is 11.491272656127968 and b is -49.53275889329301\n",
      "Iteration 6803, the loss is 4.524820242833912, parameters k is 11.491255355732712 and b is -49.53272727273965\n",
      "Iteration 6804, the loss is 4.524819597390304, parameters k is 11.491238055337455 and b is -49.53269565218629\n",
      "Iteration 6805, the loss is 4.52481925030934, parameters k is 11.4912706521754 and b is -49.532656126494594\n",
      "Iteration 6806, the loss is 4.524818600727808, parameters k is 11.491253351780143 and b is -49.532624505941236\n",
      "Iteration 6807, the loss is 4.524817951146277, parameters k is 11.491236051384886 and b is -49.53259288538788\n",
      "Iteration 6808, the loss is 4.5248173015647355, parameters k is 11.49121875098963 and b is -49.53256126483452\n",
      "Iteration 6809, the loss is 4.524816913201109, parameters k is 11.491201450594373 and b is -49.53252964428116\n",
      "Iteration 6810, the loss is 4.524816309040166, parameters k is 11.491234047432318 and b is -49.532490118589465\n",
      "Iteration 6811, the loss is 4.524815659458638, parameters k is 11.491216747037061 and b is -49.53245849803611\n",
      "Iteration 6812, the loss is 4.5248150098770985, parameters k is 11.491199446641804 and b is -49.53242687748275\n",
      "Iteration 6813, the loss is 4.524814571954936, parameters k is 11.491182146246548 and b is -49.53239525692939\n",
      "Iteration 6814, the loss is 4.524814017352532, parameters k is 11.491214743084493 and b is -49.53235573123769\n",
      "Iteration 6815, the loss is 4.524813367771001, parameters k is 11.491197442689236 and b is -49.532324110684335\n",
      "Iteration 6816, the loss is 4.524812718189466, parameters k is 11.49118014229398 and b is -49.53229249013098\n",
      "Iteration 6817, the loss is 4.524812230708772, parameters k is 11.491162841898722 and b is -49.53226086957762\n",
      "Iteration 6818, the loss is 4.524811725664895, parameters k is 11.491195438736668 and b is -49.53222134388592\n",
      "Iteration 6819, the loss is 4.524811076083358, parameters k is 11.49117813834141 and b is -49.532189723332564\n",
      "Iteration 6820, the loss is 4.524810426501831, parameters k is 11.491160837946154 and b is -49.532158102779206\n",
      "Iteration 6821, the loss is 4.524809889462606, parameters k is 11.491143537550897 and b is -49.53212648222585\n",
      "Iteration 6822, the loss is 4.524809433977258, parameters k is 11.491176134388843 and b is -49.53208695653415\n",
      "Iteration 6823, the loss is 4.524808784395725, parameters k is 11.491158833993586 and b is -49.53205533598079\n",
      "Iteration 6824, the loss is 4.524808134814189, parameters k is 11.491141533598329 and b is -49.532023715427435\n",
      "Iteration 6825, the loss is 4.5248075482164305, parameters k is 11.491124233203072 and b is -49.53199209487408\n",
      "Iteration 6826, the loss is 4.524807142289618, parameters k is 11.491156830041017 and b is -49.53195256918238\n",
      "Iteration 6827, the loss is 4.524806492708086, parameters k is 11.49113952964576 and b is -49.53192094862902\n",
      "Iteration 6828, the loss is 4.524805843126553, parameters k is 11.491122229250504 and b is -49.531889328075664\n",
      "Iteration 6829, the loss is 4.524805206970265, parameters k is 11.491104928855247 and b is -49.531857707522306\n",
      "Iteration 6830, the loss is 4.524804850601987, parameters k is 11.491137525693192 and b is -49.53181818183061\n",
      "Iteration 6831, the loss is 4.524804201020454, parameters k is 11.491120225297935 and b is -49.53178656127725\n",
      "Iteration 6832, the loss is 4.524803551438909, parameters k is 11.491102924902679 and b is -49.53175494072389\n",
      "Iteration 6833, the loss is 4.524802901857377, parameters k is 11.491085624507422 and b is -49.531723320170535\n",
      "Iteration 6834, the loss is 4.52480252278106, parameters k is 11.491068324112165 and b is -49.53169169961718\n",
      "Iteration 6835, the loss is 4.524801909332816, parameters k is 11.49110092095011 and b is -49.53165217392548\n",
      "Iteration 6836, the loss is 4.5248012597512774, parameters k is 11.491083620554853 and b is -49.53162055337212\n",
      "Iteration 6837, the loss is 4.524800610169742, parameters k is 11.491066320159597 and b is -49.531588932818764\n",
      "Iteration 6838, the loss is 4.524800181534898, parameters k is 11.49104901976434 and b is -49.531557312265406\n",
      "Iteration 6839, the loss is 4.524799617645174, parameters k is 11.491081616602285 and b is -49.53151778657371\n",
      "Iteration 6840, the loss is 4.52479896806364, parameters k is 11.491064316207028 and b is -49.53148616602035\n",
      "Iteration 6841, the loss is 4.524798318482103, parameters k is 11.491047015811771 and b is -49.53145454546699\n",
      "Iteration 6842, the loss is 4.524797840288725, parameters k is 11.491029715416515 and b is -49.531422924913635\n",
      "Iteration 6843, the loss is 4.524797325957534, parameters k is 11.49106231225446 and b is -49.53138339922194\n",
      "Iteration 6844, the loss is 4.524796676375999, parameters k is 11.491045011859203 and b is -49.53135177866858\n",
      "Iteration 6845, the loss is 4.524796026794464, parameters k is 11.491027711463946 and b is -49.53132015811522\n",
      "Iteration 6846, the loss is 4.524795499042562, parameters k is 11.49101041106869 and b is -49.53128853756186\n",
      "Iteration 6847, the loss is 4.524795034269897, parameters k is 11.491043007906635 and b is -49.531249011870166\n",
      "Iteration 6848, the loss is 4.524794384688363, parameters k is 11.491025707511378 and b is -49.53121739131681\n",
      "Iteration 6849, the loss is 4.524793735106831, parameters k is 11.491008407116121 and b is -49.53118577076345\n",
      "Iteration 6850, the loss is 4.524793157796391, parameters k is 11.490991106720864 and b is -49.53115415021009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6851, the loss is 4.524792742582262, parameters k is 11.49102370355881 and b is -49.531114624518395\n",
      "Iteration 6852, the loss is 4.5247920930007295, parameters k is 11.491006403163553 and b is -49.53108300396504\n",
      "Iteration 6853, the loss is 4.52479144341919, parameters k is 11.490989102768296 and b is -49.53105138341168\n",
      "Iteration 6854, the loss is 4.524790816550219, parameters k is 11.49097180237304 and b is -49.53101976285832\n",
      "Iteration 6855, the loss is 4.524790450894621, parameters k is 11.491004399210984 and b is -49.530980237166624\n",
      "Iteration 6856, the loss is 4.524789801313084, parameters k is 11.490987098815728 and b is -49.530948616613266\n",
      "Iteration 6857, the loss is 4.524789151731552, parameters k is 11.49096979842047 and b is -49.53091699605991\n",
      "Iteration 6858, the loss is 4.524788502150015, parameters k is 11.490952498025214 and b is -49.53088537550655\n",
      "Iteration 6859, the loss is 4.524788132361025, parameters k is 11.490935197629957 and b is -49.53085375495319\n",
      "Iteration 6860, the loss is 4.5247875096254475, parameters k is 11.490967794467903 and b is -49.530814229261495\n",
      "Iteration 6861, the loss is 4.524786860043913, parameters k is 11.490950494072646 and b is -49.53078260870814\n",
      "Iteration 6862, the loss is 4.524786210462382, parameters k is 11.490933193677389 and b is -49.53075098815478\n",
      "Iteration 6863, the loss is 4.524785791114852, parameters k is 11.490915893282132 and b is -49.53071936760142\n",
      "Iteration 6864, the loss is 4.524785217937815, parameters k is 11.490948490120077 and b is -49.53067984190972\n",
      "Iteration 6865, the loss is 4.524784568356271, parameters k is 11.49093118972482 and b is -49.530648221356365\n",
      "Iteration 6866, the loss is 4.524783918774746, parameters k is 11.490913889329564 and b is -49.53061660080301\n",
      "Iteration 6867, the loss is 4.524783449868687, parameters k is 11.490896588934307 and b is -49.53058498024965\n",
      "Iteration 6868, the loss is 4.5247829262501815, parameters k is 11.490929185772252 and b is -49.53054545455795\n",
      "Iteration 6869, the loss is 4.524782276668641, parameters k is 11.490911885376995 and b is -49.530513834004594\n",
      "Iteration 6870, the loss is 4.524781627087106, parameters k is 11.490894584981739 and b is -49.530482213451236\n",
      "Iteration 6871, the loss is 4.5247811086225145, parameters k is 11.490877284586482 and b is -49.53045059289788\n",
      "Iteration 6872, the loss is 4.524780634562534, parameters k is 11.490909881424427 and b is -49.53041106720618\n",
      "Iteration 6873, the loss is 4.524779984981004, parameters k is 11.49089258102917 and b is -49.53037944665282\n",
      "Iteration 6874, the loss is 4.524779335399468, parameters k is 11.490875280633913 and b is -49.530347826099465\n",
      "Iteration 6875, the loss is 4.524778767376351, parameters k is 11.490857980238657 and b is -49.53031620554611\n",
      "Iteration 6876, the loss is 4.524778342874906, parameters k is 11.490890577076602 and b is -49.53027667985441\n",
      "Iteration 6877, the loss is 4.524777693293369, parameters k is 11.490873276681345 and b is -49.53024505930105\n",
      "Iteration 6878, the loss is 4.524777043711829, parameters k is 11.490855976286088 and b is -49.530213438747694\n",
      "Iteration 6879, the loss is 4.524776426130178, parameters k is 11.490838675890831 and b is -49.530181818194336\n",
      "Iteration 6880, the loss is 4.524776051187258, parameters k is 11.490871272728777 and b is -49.53014229250264\n",
      "Iteration 6881, the loss is 4.524775401605728, parameters k is 11.49085397233352 and b is -49.53011067194928\n",
      "Iteration 6882, the loss is 4.524774752024189, parameters k is 11.490836671938263 and b is -49.53007905139592\n",
      "Iteration 6883, the loss is 4.524774102442655, parameters k is 11.490819371543006 and b is -49.530047430842565\n",
      "Iteration 6884, the loss is 4.524773741940984, parameters k is 11.49080207114775 and b is -49.53001581028921\n",
      "Iteration 6885, the loss is 4.524773109918091, parameters k is 11.490834667985695 and b is -49.52997628459751\n",
      "Iteration 6886, the loss is 4.52477246033656, parameters k is 11.490817367590438 and b is -49.52994466404415\n",
      "Iteration 6887, the loss is 4.524771810755022, parameters k is 11.490800067195181 and b is -49.529913043490794\n",
      "Iteration 6888, the loss is 4.524771400694812, parameters k is 11.490782766799924 and b is -49.529881422937436\n",
      "Iteration 6889, the loss is 4.524770818230453, parameters k is 11.49081536363787 and b is -49.52984189724574\n",
      "Iteration 6890, the loss is 4.524770168648916, parameters k is 11.490798063242613 and b is -49.52981027669238\n",
      "Iteration 6891, the loss is 4.524769519067382, parameters k is 11.490780762847356 and b is -49.52977865613902\n",
      "Iteration 6892, the loss is 4.524769059448642, parameters k is 11.4907634624521 and b is -49.529747035585665\n",
      "Iteration 6893, the loss is 4.524768526542812, parameters k is 11.490796059290044 and b is -49.52970750989397\n",
      "Iteration 6894, the loss is 4.524767876961279, parameters k is 11.490778758894788 and b is -49.52967588934061\n",
      "Iteration 6895, the loss is 4.524767227379744, parameters k is 11.49076145849953 and b is -49.52964426878725\n",
      "Iteration 6896, the loss is 4.524766718202475, parameters k is 11.490744158104274 and b is -49.52961264823389\n",
      "Iteration 6897, the loss is 4.524766234855176, parameters k is 11.49077675494222 and b is -49.529573122542196\n",
      "Iteration 6898, the loss is 4.524765585273644, parameters k is 11.490759454546962 and b is -49.52954150198884\n",
      "Iteration 6899, the loss is 4.5247649356921045, parameters k is 11.490742154151706 and b is -49.52950988143548\n",
      "Iteration 6900, the loss is 4.524764376956308, parameters k is 11.490724853756449 and b is -49.52947826088212\n",
      "Iteration 6901, the loss is 4.524763943167537, parameters k is 11.490757450594394 and b is -49.529438735190425\n",
      "Iteration 6902, the loss is 4.524763293586006, parameters k is 11.490740150199137 and b is -49.52940711463707\n",
      "Iteration 6903, the loss is 4.524762644004466, parameters k is 11.49072284980388 and b is -49.52937549408371\n",
      "Iteration 6904, the loss is 4.524762035710138, parameters k is 11.490705549408624 and b is -49.52934387353035\n",
      "Iteration 6905, the loss is 4.5247616514799045, parameters k is 11.490738146246569 and b is -49.529304347838654\n",
      "Iteration 6906, the loss is 4.524761001898372, parameters k is 11.490720845851312 and b is -49.529272727285296\n",
      "Iteration 6907, the loss is 4.524760352316832, parameters k is 11.490703545456055 and b is -49.52924110673194\n",
      "Iteration 6908, the loss is 4.524759702735295, parameters k is 11.490686245060798 and b is -49.52920948617858\n",
      "Iteration 6909, the loss is 4.52475935152094, parameters k is 11.490668944665542 and b is -49.52917786562522\n",
      "Iteration 6910, the loss is 4.524758710210729, parameters k is 11.490701541503487 and b is -49.529138339933525\n",
      "Iteration 6911, the loss is 4.5247580606291935, parameters k is 11.49068424110823 and b is -49.52910671938017\n",
      "Iteration 6912, the loss is 4.524757411047661, parameters k is 11.490666940712973 and b is -49.52907509882681\n",
      "Iteration 6913, the loss is 4.524757010274773, parameters k is 11.490649640317717 and b is -49.52904347827345\n",
      "Iteration 6914, the loss is 4.524756418523093, parameters k is 11.490682237155662 and b is -49.52900395258175\n",
      "Iteration 6915, the loss is 4.524755768941555, parameters k is 11.490664936760405 and b is -49.528972332028395\n",
      "Iteration 6916, the loss is 4.524755119360018, parameters k is 11.490647636365148 and b is -49.52894071147504\n",
      "Iteration 6917, the loss is 4.524754669028604, parameters k is 11.490630335969891 and b is -49.52890909092168\n",
      "Iteration 6918, the loss is 4.524754126835458, parameters k is 11.490662932807837 and b is -49.52886956522998\n",
      "Iteration 6919, the loss is 4.5247534772539195, parameters k is 11.49064563241258 and b is -49.528837944676624\n",
      "Iteration 6920, the loss is 4.524752827672384, parameters k is 11.490628332017323 and b is -49.528806324123266\n",
      "Iteration 6921, the loss is 4.524752327782438, parameters k is 11.490611031622066 and b is -49.52877470356991\n",
      "Iteration 6922, the loss is 4.524751835147815, parameters k is 11.490643628460012 and b is -49.52873517787821\n",
      "Iteration 6923, the loss is 4.524751185566282, parameters k is 11.490626328064755 and b is -49.52870355732485\n",
      "Iteration 6924, the loss is 4.524750535984747, parameters k is 11.490609027669498 and b is -49.528671936771495\n",
      "Iteration 6925, the loss is 4.524749986536268, parameters k is 11.490591727274241 and b is -49.52864031621814\n",
      "Iteration 6926, the loss is 4.524749543460178, parameters k is 11.490624324112186 and b is -49.52860079052644\n",
      "Iteration 6927, the loss is 4.524748893878643, parameters k is 11.49060702371693 and b is -49.52856916997308\n",
      "Iteration 6928, the loss is 4.524748244297111, parameters k is 11.490589723321673 and b is -49.528537549419724\n",
      "Iteration 6929, the loss is 4.524747645290096, parameters k is 11.490572422926416 and b is -49.528505928866366\n",
      "Iteration 6930, the loss is 4.524747251772542, parameters k is 11.490605019764361 and b is -49.52846640317467\n",
      "Iteration 6931, the loss is 4.5247466021910085, parameters k is 11.490587719369104 and b is -49.52843478262131\n",
      "Iteration 6932, the loss is 4.524745952609471, parameters k is 11.490570418973848 and b is -49.52840316206795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6933, the loss is 4.524745304043929, parameters k is 11.49055311857859 and b is -49.528371541514595\n",
      "Iteration 6934, the loss is 4.5247449600849015, parameters k is 11.490585715416536 and b is -49.5283320158229\n",
      "Iteration 6935, the loss is 4.524744310503364, parameters k is 11.49056841502128 and b is -49.52830039526954\n",
      "Iteration 6936, the loss is 4.524743660921834, parameters k is 11.490551114626022 and b is -49.52826877471618\n",
      "Iteration 6937, the loss is 4.524743011340297, parameters k is 11.490533814230766 and b is -49.528237154162824\n",
      "Iteration 6938, the loss is 4.524742619854731, parameters k is 11.490516513835509 and b is -49.528205533609466\n",
      "Iteration 6939, the loss is 4.524742018815729, parameters k is 11.490549110673454 and b is -49.52816600791777\n",
      "Iteration 6940, the loss is 4.524741369234198, parameters k is 11.490531810278197 and b is -49.52813438736441\n",
      "Iteration 6941, the loss is 4.52474071965266, parameters k is 11.49051450988294 and b is -49.52810276681105\n",
      "Iteration 6942, the loss is 4.524740278608562, parameters k is 11.490497209487684 and b is -49.528071146257695\n",
      "Iteration 6943, the loss is 4.524739727128088, parameters k is 11.490529806325629 and b is -49.528031620566\n",
      "Iteration 6944, the loss is 4.524739077546556, parameters k is 11.490512505930372 and b is -49.52800000001264\n",
      "Iteration 6945, the loss is 4.52473842796502, parameters k is 11.490495205535115 and b is -49.52796837945928\n",
      "Iteration 6946, the loss is 4.524737937362384, parameters k is 11.490477905139858 and b is -49.52793675890592\n",
      "Iteration 6947, the loss is 4.5247374354404535, parameters k is 11.490510501977804 and b is -49.527897233214226\n",
      "Iteration 6948, the loss is 4.524736785858922, parameters k is 11.490493201582547 and b is -49.52786561266087\n",
      "Iteration 6949, the loss is 4.52473613627739, parameters k is 11.49047590118729 and b is -49.52783399210751\n",
      "Iteration 6950, the loss is 4.524735596116228, parameters k is 11.490458600792033 and b is -49.52780237155415\n",
      "Iteration 6951, the loss is 4.524735143752818, parameters k is 11.490491197629979 and b is -49.527762845862455\n",
      "Iteration 6952, the loss is 4.524734494171279, parameters k is 11.490473897234722 and b is -49.5277312253091\n",
      "Iteration 6953, the loss is 4.524733844589754, parameters k is 11.490456596839465 and b is -49.52769960475574\n",
      "Iteration 6954, the loss is 4.524733254870053, parameters k is 11.490439296444208 and b is -49.52766798420238\n",
      "Iteration 6955, the loss is 4.52473285206518, parameters k is 11.490471893282153 and b is -49.527628458510684\n",
      "Iteration 6956, the loss is 4.524732202483641, parameters k is 11.490454592886897 and b is -49.527596837957326\n",
      "Iteration 6957, the loss is 4.524731552902107, parameters k is 11.49043729249164 and b is -49.52756521740397\n",
      "Iteration 6958, the loss is 4.524730913623885, parameters k is 11.490419992096383 and b is -49.52753359685061\n",
      "Iteration 6959, the loss is 4.524730560377544, parameters k is 11.490452588934328 and b is -49.52749407115891\n",
      "Iteration 6960, the loss is 4.5247299107960055, parameters k is 11.490435288539071 and b is -49.527462450605555\n",
      "Iteration 6961, the loss is 4.524729261214474, parameters k is 11.490417988143815 and b is -49.5274308300522\n",
      "Iteration 6962, the loss is 4.524728611632935, parameters k is 11.490400687748558 and b is -49.52739920949884\n",
      "Iteration 6963, the loss is 4.524728229434685, parameters k is 11.490383387353301 and b is -49.52736758894548\n",
      "Iteration 6964, the loss is 4.52472761910837, parameters k is 11.490415984191246 and b is -49.52732806325378\n",
      "Iteration 6965, the loss is 4.524726969526833, parameters k is 11.49039868379599 and b is -49.527296442700425\n",
      "Iteration 6966, the loss is 4.524726319945297, parameters k is 11.490381383400733 and b is -49.52726482214707\n",
      "Iteration 6967, the loss is 4.5247258881885175, parameters k is 11.490364083005476 and b is -49.52723320159371\n",
      "Iteration 6968, the loss is 4.524725327420732, parameters k is 11.490396679843421 and b is -49.52719367590201\n",
      "Iteration 6969, the loss is 4.524724677839195, parameters k is 11.490379379448164 and b is -49.527162055348654\n",
      "Iteration 6970, the loss is 4.524724028257663, parameters k is 11.490362079052908 and b is -49.527130434795296\n",
      "Iteration 6971, the loss is 4.524723546942353, parameters k is 11.49034477865765 and b is -49.52709881424194\n",
      "Iteration 6972, the loss is 4.524723035733095, parameters k is 11.490377375495596 and b is -49.52705928855024\n",
      "Iteration 6973, the loss is 4.52472238615156, parameters k is 11.49036007510034 and b is -49.52702766799688\n",
      "Iteration 6974, the loss is 4.524721736570025, parameters k is 11.490342774705082 and b is -49.526996047443525\n",
      "Iteration 6975, the loss is 4.524721205696182, parameters k is 11.490325474309826 and b is -49.52696442689017\n",
      "Iteration 6976, the loss is 4.5247207440454575, parameters k is 11.49035807114777 and b is -49.52692490119847\n",
      "Iteration 6977, the loss is 4.5247200944639205, parameters k is 11.490340770752514 and b is -49.52689328064511\n",
      "Iteration 6978, the loss is 4.5247194448823835, parameters k is 11.490323470357257 and b is -49.526861660091754\n",
      "Iteration 6979, the loss is 4.5247188644500165, parameters k is 11.490306169962 and b is -49.526830039538396\n",
      "Iteration 6980, the loss is 4.5247184523578206, parameters k is 11.490338766799946 and b is -49.5267905138467\n",
      "Iteration 6981, the loss is 4.524717802776291, parameters k is 11.490321466404689 and b is -49.52675889329334\n",
      "Iteration 6982, the loss is 4.524717153194748, parameters k is 11.490304166009432 and b is -49.52672727273998\n",
      "Iteration 6983, the loss is 4.524716523203845, parameters k is 11.490286865614175 and b is -49.526695652186625\n",
      "Iteration 6984, the loss is 4.5247161606701845, parameters k is 11.49031946245212 and b is -49.52665612649493\n",
      "Iteration 6985, the loss is 4.5247155110886474, parameters k is 11.490302162056864 and b is -49.52662450594157\n",
      "Iteration 6986, the loss is 4.524714861507111, parameters k is 11.490284861661607 and b is -49.52659288538821\n",
      "Iteration 6987, the loss is 4.524714211925578, parameters k is 11.49026756126635 and b is -49.526561264834854\n",
      "Iteration 6988, the loss is 4.524713839014646, parameters k is 11.490250260871093 and b is -49.526529644281496\n",
      "Iteration 6989, the loss is 4.524713219401005, parameters k is 11.490282857709039 and b is -49.5264901185898\n",
      "Iteration 6990, the loss is 4.524712569819471, parameters k is 11.490265557313782 and b is -49.52645849803644\n",
      "Iteration 6991, the loss is 4.524711920237938, parameters k is 11.490248256918525 and b is -49.52642687748308\n",
      "Iteration 6992, the loss is 4.5247114977684735, parameters k is 11.490230956523268 and b is -49.526395256929725\n",
      "Iteration 6993, the loss is 4.524710927713371, parameters k is 11.490263553361213 and b is -49.52635573123803\n",
      "Iteration 6994, the loss is 4.524710278131836, parameters k is 11.490246252965957 and b is -49.52632411068467\n",
      "Iteration 6995, the loss is 4.524709628550301, parameters k is 11.4902289525707 and b is -49.52629249013131\n",
      "Iteration 6996, the loss is 4.524709156522313, parameters k is 11.490211652175443 and b is -49.52626086957795\n",
      "Iteration 6997, the loss is 4.524708636025738, parameters k is 11.490244249013388 and b is -49.526221343886256\n",
      "Iteration 6998, the loss is 4.524707986444197, parameters k is 11.490226948618131 and b is -49.5261897233329\n",
      "Iteration 6999, the loss is 4.524707336862663, parameters k is 11.490209648222875 and b is -49.52615810277954\n",
      "Iteration 7000, the loss is 4.52470681527614, parameters k is 11.490192347827618 and b is -49.52612648222618\n",
      "Iteration 7001, the loss is 4.524706344338098, parameters k is 11.490224944665563 and b is -49.526086956534485\n",
      "Iteration 7002, the loss is 4.524705694756563, parameters k is 11.490207644270306 and b is -49.52605533598113\n",
      "Iteration 7003, the loss is 4.5247050451750255, parameters k is 11.49019034387505 and b is -49.52602371542777\n",
      "Iteration 7004, the loss is 4.524704474029973, parameters k is 11.490173043479793 and b is -49.52599209487441\n",
      "Iteration 7005, the loss is 4.524704052650461, parameters k is 11.490205640317738 and b is -49.525952569182714\n",
      "Iteration 7006, the loss is 4.5247034030689255, parameters k is 11.490188339922481 and b is -49.525920948629356\n",
      "Iteration 7007, the loss is 4.524702753487386, parameters k is 11.490171039527224 and b is -49.525889328076\n",
      "Iteration 7008, the loss is 4.524702132783806, parameters k is 11.490153739131967 and b is -49.52585770752264\n",
      "Iteration 7009, the loss is 4.52470176096282, parameters k is 11.490186335969913 and b is -49.52581818183094\n",
      "Iteration 7010, the loss is 4.524701111381288, parameters k is 11.490169035574656 and b is -49.525786561277584\n",
      "Iteration 7011, the loss is 4.52470046179975, parameters k is 11.4901517351794 and b is -49.52575494072423\n",
      "Iteration 7012, the loss is 4.524699812218216, parameters k is 11.490134434784142 and b is -49.52572332017087\n",
      "Iteration 7013, the loss is 4.524699448594607, parameters k is 11.490117134388885 and b is -49.52569169961751\n",
      "Iteration 7014, the loss is 4.524698819693644, parameters k is 11.49014973122683 and b is -49.52565217392581\n",
      "Iteration 7015, the loss is 4.524698170112112, parameters k is 11.490132430831574 and b is -49.525620553372455\n",
      "Iteration 7016, the loss is 4.524697520530577, parameters k is 11.490115130436317 and b is -49.5255889328191\n",
      "Iteration 7017, the loss is 4.524697107348438, parameters k is 11.49009783004106 and b is -49.52555731226574\n",
      "Iteration 7018, the loss is 4.524696528006013, parameters k is 11.490130426879006 and b is -49.52551778657404\n",
      "Iteration 7019, the loss is 4.524695878424471, parameters k is 11.490113126483749 and b is -49.525486166020684\n",
      "Iteration 7020, the loss is 4.524695228842942, parameters k is 11.490095826088492 and b is -49.525454545467326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7021, the loss is 4.524694766102271, parameters k is 11.490078525693235 and b is -49.52542292491397\n",
      "Iteration 7022, the loss is 4.524694236318373, parameters k is 11.49011112253118 and b is -49.52538339922227\n",
      "Iteration 7023, the loss is 4.52469358673684, parameters k is 11.490093822135924 and b is -49.52535177866891\n",
      "Iteration 7024, the loss is 4.524692937155309, parameters k is 11.490076521740667 and b is -49.525320158115555\n",
      "Iteration 7025, the loss is 4.5246924248561005, parameters k is 11.49005922134541 and b is -49.5252885375622\n",
      "Iteration 7026, the loss is 4.524691944630734, parameters k is 11.490091818183355 and b is -49.5252490118705\n",
      "Iteration 7027, the loss is 4.524691295049196, parameters k is 11.490074517788099 and b is -49.52521739131714\n",
      "Iteration 7028, the loss is 4.524690645467664, parameters k is 11.490057217392842 and b is -49.525185770763784\n",
      "Iteration 7029, the loss is 4.524690083609931, parameters k is 11.490039916997585 and b is -49.525154150210426\n",
      "Iteration 7030, the loss is 4.524689652943102, parameters k is 11.49007251383553 and b is -49.52511462451873\n",
      "Iteration 7031, the loss is 4.524689003361564, parameters k is 11.490055213440273 and b is -49.52508300396537\n",
      "Iteration 7032, the loss is 4.52468835378003, parameters k is 11.490037913045017 and b is -49.52505138341201\n",
      "Iteration 7033, the loss is 4.524687742363763, parameters k is 11.49002061264976 and b is -49.525019762858655\n",
      "Iteration 7034, the loss is 4.52468736125546, parameters k is 11.490053209487705 and b is -49.52498023716696\n",
      "Iteration 7035, the loss is 4.524686711673925, parameters k is 11.490035909092448 and b is -49.5249486166136\n",
      "Iteration 7036, the loss is 4.524686062092393, parameters k is 11.490018608697191 and b is -49.52491699606024\n",
      "Iteration 7037, the loss is 4.52468541251086, parameters k is 11.490001308301935 and b is -49.524885375506884\n",
      "Iteration 7038, the loss is 4.524685058174561, parameters k is 11.489984007906678 and b is -49.524853754953526\n",
      "Iteration 7039, the loss is 4.524684419986287, parameters k is 11.490016604744623 and b is -49.52481422926183\n",
      "Iteration 7040, the loss is 4.52468377040475, parameters k is 11.489999304349366 and b is -49.52478260870847\n",
      "Iteration 7041, the loss is 4.524683120823217, parameters k is 11.48998200395411 and b is -49.52475098815511\n",
      "Iteration 7042, the loss is 4.524682716928391, parameters k is 11.489964703558853 and b is -49.524719367601755\n",
      "Iteration 7043, the loss is 4.524682128298651, parameters k is 11.489997300396798 and b is -49.52467984191006\n",
      "Iteration 7044, the loss is 4.524681478717115, parameters k is 11.489980000001541 and b is -49.5246482213567\n",
      "Iteration 7045, the loss is 4.524680829135578, parameters k is 11.489962699606284 and b is -49.52461660080334\n",
      "Iteration 7046, the loss is 4.524680375682227, parameters k is 11.489945399211027 and b is -49.52458498024998\n",
      "Iteration 7047, the loss is 4.52467983661101, parameters k is 11.489977996048973 and b is -49.524545454558286\n",
      "Iteration 7048, the loss is 4.52467918702948, parameters k is 11.489960695653716 and b is -49.52451383400493\n",
      "Iteration 7049, the loss is 4.524678537447943, parameters k is 11.489943395258459 and b is -49.52448221345157\n",
      "Iteration 7050, the loss is 4.524678034436054, parameters k is 11.489926094863202 and b is -49.52445059289821\n",
      "Iteration 7051, the loss is 4.524677544923375, parameters k is 11.489958691701148 and b is -49.524411067206515\n",
      "Iteration 7052, the loss is 4.524676895341839, parameters k is 11.48994139130589 and b is -49.52437944665316\n",
      "Iteration 7053, the loss is 4.524676245760306, parameters k is 11.489924090910634 and b is -49.5243478260998\n",
      "Iteration 7054, the loss is 4.524675693189889, parameters k is 11.489906790515377 and b is -49.52431620554644\n",
      "Iteration 7055, the loss is 4.524675253235737, parameters k is 11.489939387353322 and b is -49.524276679854744\n",
      "Iteration 7056, the loss is 4.524674603654201, parameters k is 11.489922086958066 and b is -49.524245059301386\n",
      "Iteration 7057, the loss is 4.524673954072663, parameters k is 11.489904786562809 and b is -49.52421343874803\n",
      "Iteration 7058, the loss is 4.524673351943716, parameters k is 11.489887486167552 and b is -49.52418181819467\n",
      "Iteration 7059, the loss is 4.5246729615481, parameters k is 11.489920083005497 and b is -49.52414229250297\n",
      "Iteration 7060, the loss is 4.524672311966562, parameters k is 11.48990278261024 and b is -49.524110671949614\n",
      "Iteration 7061, the loss is 4.524671662385027, parameters k is 11.489885482214984 and b is -49.52407905139626\n",
      "Iteration 7062, the loss is 4.524671012803492, parameters k is 11.489868181819727 and b is -49.5240474308429\n",
      "Iteration 7063, the loss is 4.524670667754524, parameters k is 11.48985088142447 and b is -49.52401581028954\n",
      "Iteration 7064, the loss is 4.524670020278928, parameters k is 11.489883478262415 and b is -49.52397628459784\n",
      "Iteration 7065, the loss is 4.524669370697392, parameters k is 11.489866177867158 and b is -49.523944664044485\n",
      "Iteration 7066, the loss is 4.524668721115856, parameters k is 11.489848877471902 and b is -49.52391304349113\n",
      "Iteration 7067, the loss is 4.524668326508351, parameters k is 11.489831577076645 and b is -49.52388142293777\n",
      "Iteration 7068, the loss is 4.5246677285912895, parameters k is 11.48986417391459 and b is -49.52384189724607\n",
      "Iteration 7069, the loss is 4.524667079009755, parameters k is 11.489846873519333 and b is -49.523810276692714\n",
      "Iteration 7070, the loss is 4.524666429428226, parameters k is 11.489829573124076 and b is -49.523778656139356\n",
      "Iteration 7071, the loss is 4.524665985262189, parameters k is 11.48981227272882 and b is -49.523747035586\n",
      "Iteration 7072, the loss is 4.524665436903652, parameters k is 11.489844869566765 and b is -49.5237075098943\n",
      "Iteration 7073, the loss is 4.524664787322114, parameters k is 11.489827569171508 and b is -49.52367588934094\n",
      "Iteration 7074, the loss is 4.524664137740585, parameters k is 11.489810268776251 and b is -49.523644268787585\n",
      "Iteration 7075, the loss is 4.524663644016016, parameters k is 11.489792968380995 and b is -49.52361264823423\n",
      "Iteration 7076, the loss is 4.524663145216013, parameters k is 11.48982556521894 and b is -49.52357312254253\n",
      "Iteration 7077, the loss is 4.524662495634482, parameters k is 11.489808264823683 and b is -49.52354150198917\n",
      "Iteration 7078, the loss is 4.524661846052947, parameters k is 11.489790964428426 and b is -49.523509881435814\n",
      "Iteration 7079, the loss is 4.524661302769849, parameters k is 11.48977366403317 and b is -49.523478260882456\n",
      "Iteration 7080, the loss is 4.524660853528377, parameters k is 11.489806260871115 and b is -49.52343873519076\n",
      "Iteration 7081, the loss is 4.524660203946841, parameters k is 11.489788960475858 and b is -49.5234071146374\n",
      "Iteration 7082, the loss is 4.524659554365307, parameters k is 11.489771660080601 and b is -49.52337549408404\n",
      "Iteration 7083, the loss is 4.524658961523685, parameters k is 11.489754359685344 and b is -49.523343873530685\n",
      "Iteration 7084, the loss is 4.524658561840737, parameters k is 11.48978695652329 and b is -49.52330434783899\n",
      "Iteration 7085, the loss is 4.524657912259204, parameters k is 11.489769656128033 and b is -49.52327272728563\n",
      "Iteration 7086, the loss is 4.524657262677668, parameters k is 11.489752355732776 and b is -49.52324110673227\n",
      "Iteration 7087, the loss is 4.524656620277512, parameters k is 11.489735055337519 and b is -49.523209486178914\n",
      "Iteration 7088, the loss is 4.524656270153101, parameters k is 11.489767652175464 and b is -49.523169960487216\n",
      "Iteration 7089, the loss is 4.524655620571567, parameters k is 11.489750351780208 and b is -49.52313833993386\n",
      "Iteration 7090, the loss is 4.524654970990033, parameters k is 11.48973305138495 and b is -49.5231067193805\n",
      "Iteration 7091, the loss is 4.5246543214085, parameters k is 11.489715750989694 and b is -49.52307509882714\n",
      "Iteration 7092, the loss is 4.524653936088308, parameters k is 11.489698450594437 and b is -49.523043478273785\n",
      "Iteration 7093, the loss is 4.524653328883931, parameters k is 11.489731047432382 and b is -49.52300395258209\n",
      "Iteration 7094, the loss is 4.524652679302395, parameters k is 11.489713747037126 and b is -49.52297233202873\n",
      "Iteration 7095, the loss is 4.524652029720857, parameters k is 11.489696446641869 and b is -49.52294071147537\n",
      "Iteration 7096, the loss is 4.524651594842142, parameters k is 11.489679146246612 and b is -49.52290909092201\n",
      "Iteration 7097, the loss is 4.524651037196292, parameters k is 11.489711743084557 and b is -49.522869565230316\n",
      "Iteration 7098, the loss is 4.524650387614757, parameters k is 11.4896944426893 and b is -49.52283794467696\n",
      "Iteration 7099, the loss is 4.524649738033223, parameters k is 11.489677142294044 and b is -49.5228063241236\n",
      "Iteration 7100, the loss is 4.524649253595973, parameters k is 11.489659841898787 and b is -49.52277470357024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7101, the loss is 4.524648745508657, parameters k is 11.489692438736732 and b is -49.522735177878545\n",
      "Iteration 7102, the loss is 4.524648095927117, parameters k is 11.489675138341475 and b is -49.52270355732519\n",
      "Iteration 7103, the loss is 4.524647446345579, parameters k is 11.489657837946218 and b is -49.52267193677183\n",
      "Iteration 7104, the loss is 4.5246469123498025, parameters k is 11.489640537550962 and b is -49.52264031621847\n",
      "Iteration 7105, the loss is 4.524646453821014, parameters k is 11.489673134388907 and b is -49.52260079052677\n",
      "Iteration 7106, the loss is 4.524645804239481, parameters k is 11.48965583399365 and b is -49.522569169973416\n",
      "Iteration 7107, the loss is 4.524645154657943, parameters k is 11.489638533598393 and b is -49.52253754942006\n",
      "Iteration 7108, the loss is 4.524644571103636, parameters k is 11.489621233203136 and b is -49.5225059288667\n",
      "Iteration 7109, the loss is 4.524644162133379, parameters k is 11.489653830041082 and b is -49.522466403175\n",
      "Iteration 7110, the loss is 4.524643512551846, parameters k is 11.489636529645825 and b is -49.522434782621644\n",
      "Iteration 7111, the loss is 4.524642862970314, parameters k is 11.489619229250568 and b is -49.52240316206829\n",
      "Iteration 7112, the loss is 4.524642229857466, parameters k is 11.489601928855311 and b is -49.52237154151493\n",
      "Iteration 7113, the loss is 4.524641870445737, parameters k is 11.489634525693257 and b is -49.52233201582323\n",
      "Iteration 7114, the loss is 4.524641220864204, parameters k is 11.489617225298 and b is -49.52230039526987\n",
      "Iteration 7115, the loss is 4.524640571282667, parameters k is 11.489599924902743 and b is -49.522268774716515\n",
      "Iteration 7116, the loss is 4.524639921701134, parameters k is 11.489582624507486 and b is -49.52223715416316\n",
      "Iteration 7117, the loss is 4.524639545668263, parameters k is 11.48956532411223 and b is -49.5222055336098\n",
      "Iteration 7118, the loss is 4.524638929176571, parameters k is 11.489597920950175 and b is -49.5221660079181\n",
      "Iteration 7119, the loss is 4.524638279595037, parameters k is 11.489580620554918 and b is -49.522134387364744\n",
      "Iteration 7120, the loss is 4.524637630013496, parameters k is 11.489563320159661 and b is -49.522102766811386\n",
      "Iteration 7121, the loss is 4.524637204422101, parameters k is 11.489546019764404 and b is -49.52207114625803\n",
      "Iteration 7122, the loss is 4.52463663748893, parameters k is 11.48957861660235 and b is -49.52203162056633\n",
      "Iteration 7123, the loss is 4.524635987907397, parameters k is 11.489561316207093 and b is -49.52200000001297\n",
      "Iteration 7124, the loss is 4.524635338325861, parameters k is 11.489544015811836 and b is -49.521968379459615\n",
      "Iteration 7125, the loss is 4.5246348631759306, parameters k is 11.489526715416579 and b is -49.52193675890626\n",
      "Iteration 7126, the loss is 4.524634345801292, parameters k is 11.489559312254524 and b is -49.52189723321456\n",
      "Iteration 7127, the loss is 4.524633696219759, parameters k is 11.489542011859267 and b is -49.5218656126612\n",
      "Iteration 7128, the loss is 4.524633046638219, parameters k is 11.48952471146401 and b is -49.521833992107844\n",
      "Iteration 7129, the loss is 4.524632521929766, parameters k is 11.489507411068754 and b is -49.521802371554486\n",
      "Iteration 7130, the loss is 4.524632054113655, parameters k is 11.4895400079067 and b is -49.52176284586279\n",
      "Iteration 7131, the loss is 4.524631404532122, parameters k is 11.489522707511442 and b is -49.52173122530943\n",
      "Iteration 7132, the loss is 4.52463075495058, parameters k is 11.489505407116186 and b is -49.52169960475607\n",
      "Iteration 7133, the loss is 4.52463018068359, parameters k is 11.489488106720929 and b is -49.521667984202715\n",
      "Iteration 7134, the loss is 4.524629762426014, parameters k is 11.489520703558874 and b is -49.52162845851102\n",
      "Iteration 7135, the loss is 4.524629112844484, parameters k is 11.489503403163617 and b is -49.52159683795766\n",
      "Iteration 7136, the loss is 4.524628463262943, parameters k is 11.48948610276836 and b is -49.5215652174043\n",
      "Iteration 7137, the loss is 4.524627839437427, parameters k is 11.489468802373104 and b is -49.521533596850944\n",
      "Iteration 7138, the loss is 4.524627470738378, parameters k is 11.489501399211049 and b is -49.521494071159246\n",
      "Iteration 7139, the loss is 4.5246268211568434, parameters k is 11.489484098815792 and b is -49.52146245060589\n",
      "Iteration 7140, the loss is 4.524626171575306, parameters k is 11.489466798420535 and b is -49.52143083005253\n",
      "Iteration 7141, the loss is 4.52462552199377, parameters k is 11.489449498025278 and b is -49.52139920949917\n",
      "Iteration 7142, the loss is 4.524625155248228, parameters k is 11.489432197630022 and b is -49.521367588945814\n",
      "Iteration 7143, the loss is 4.52462452946921, parameters k is 11.489464794467967 and b is -49.52132806325412\n",
      "Iteration 7144, the loss is 4.52462387988767, parameters k is 11.48944749407271 and b is -49.52129644270076\n",
      "Iteration 7145, the loss is 4.524623230306137, parameters k is 11.489430193677453 and b is -49.5212648221474\n",
      "Iteration 7146, the loss is 4.52462281400206, parameters k is 11.489412893282196 and b is -49.52123320159404\n",
      "Iteration 7147, the loss is 4.524622237781571, parameters k is 11.489445490120142 and b is -49.521193675902346\n",
      "Iteration 7148, the loss is 4.524621588200032, parameters k is 11.489428189724885 and b is -49.52116205534899\n",
      "Iteration 7149, the loss is 4.5246209386185, parameters k is 11.489410889329628 and b is -49.52113043479563\n",
      "Iteration 7150, the loss is 4.524620472755892, parameters k is 11.489393588934371 and b is -49.52109881424227\n",
      "Iteration 7151, the loss is 4.524619946093935, parameters k is 11.489426185772317 and b is -49.521059288550575\n",
      "Iteration 7152, the loss is 4.524619296512397, parameters k is 11.48940888537706 and b is -49.52102766799722\n",
      "Iteration 7153, the loss is 4.524618646930864, parameters k is 11.489391584981803 and b is -49.52099604744386\n",
      "Iteration 7154, the loss is 4.524618131509723, parameters k is 11.489374284586546 and b is -49.5209644268905\n",
      "Iteration 7155, the loss is 4.524617654406296, parameters k is 11.489406881424491 and b is -49.5209249011988\n",
      "Iteration 7156, the loss is 4.52461700482476, parameters k is 11.489389581029235 and b is -49.520893280645446\n",
      "Iteration 7157, the loss is 4.524616355243226, parameters k is 11.489372280633978 and b is -49.52086166009209\n",
      "Iteration 7158, the loss is 4.524615790263551, parameters k is 11.489354980238721 and b is -49.52083003953873\n",
      "Iteration 7159, the loss is 4.5246153627186585, parameters k is 11.489387577076666 and b is -49.52079051384703\n",
      "Iteration 7160, the loss is 4.524614713137122, parameters k is 11.48937027668141 and b is -49.520758893293674\n",
      "Iteration 7161, the loss is 4.524614063555589, parameters k is 11.489352976286153 and b is -49.52072727274032\n",
      "Iteration 7162, the loss is 4.524613449017386, parameters k is 11.489335675890896 and b is -49.52069565218696\n",
      "Iteration 7163, the loss is 4.524613071031016, parameters k is 11.489368272728841 and b is -49.52065612649526\n",
      "Iteration 7164, the loss is 4.524612421449488, parameters k is 11.489350972333584 and b is -49.5206245059419\n",
      "Iteration 7165, the loss is 4.52461177186795, parameters k is 11.489333671938327 and b is -49.520592885388545\n",
      "Iteration 7166, the loss is 4.524611122286415, parameters k is 11.48931637154307 and b is -49.52056126483519\n",
      "Iteration 7167, the loss is 4.524610764828191, parameters k is 11.489299071147814 and b is -49.52052964428183\n",
      "Iteration 7168, the loss is 4.524610129761851, parameters k is 11.489331667985759 and b is -49.52049011859013\n",
      "Iteration 7169, the loss is 4.524609480180317, parameters k is 11.489314367590502 and b is -49.520458498036774\n",
      "Iteration 7170, the loss is 4.524608830598775, parameters k is 11.489297067195245 and b is -49.520426877483416\n",
      "Iteration 7171, the loss is 4.524608423582016, parameters k is 11.489279766799989 and b is -49.52039525693006\n",
      "Iteration 7172, the loss is 4.524607838074209, parameters k is 11.489312363637934 and b is -49.52035573123836\n",
      "Iteration 7173, the loss is 4.524607188492675, parameters k is 11.489295063242677 and b is -49.520324110685\n",
      "Iteration 7174, the loss is 4.524606538911137, parameters k is 11.48927776284742 and b is -49.520292490131645\n",
      "Iteration 7175, the loss is 4.52460608233585, parameters k is 11.489260462452163 and b is -49.52026086957829\n",
      "Iteration 7176, the loss is 4.52460554638657, parameters k is 11.489293059290109 and b is -49.52022134388659\n",
      "Iteration 7177, the loss is 4.524604896805038, parameters k is 11.489275758894852 and b is -49.52018972333323\n",
      "Iteration 7178, the loss is 4.524604247223498, parameters k is 11.489258458499595 and b is -49.520158102779874\n",
      "Iteration 7179, the loss is 4.52460374108968, parameters k is 11.489241158104338 and b is -49.520126482226516\n",
      "Iteration 7180, the loss is 4.524603254698934, parameters k is 11.489273754942284 and b is -49.52008695653482\n",
      "Iteration 7181, the loss is 4.524602605117403, parameters k is 11.489256454547027 and b is -49.52005533598146\n",
      "Iteration 7182, the loss is 4.524601955535863, parameters k is 11.48923915415177 and b is -49.5200237154281\n",
      "Iteration 7183, the loss is 4.524601399843515, parameters k is 11.489221853756513 and b is -49.519992094874745\n",
      "Iteration 7184, the loss is 4.524600963011297, parameters k is 11.489254450594458 and b is -49.51995256918305\n",
      "Iteration 7185, the loss is 4.524600313429757, parameters k is 11.489237150199202 and b is -49.51992094862969\n",
      "Iteration 7186, the loss is 4.5245996638482255, parameters k is 11.489219849803945 and b is -49.51988932807633\n",
      "Iteration 7187, the loss is 4.5245990585973415, parameters k is 11.489202549408688 and b is -49.519857707522974\n",
      "Iteration 7188, the loss is 4.52459867132366, parameters k is 11.489235146246633 and b is -49.519818181831276\n",
      "Iteration 7189, the loss is 4.524598021742121, parameters k is 11.489217845851377 and b is -49.51978656127792\n",
      "Iteration 7190, the loss is 4.524597372160587, parameters k is 11.48920054545612 and b is -49.51975494072456\n",
      "Iteration 7191, the loss is 4.524596722579051, parameters k is 11.489183245060863 and b is -49.5197233201712\n",
      "Iteration 7192, the loss is 4.5245963744081505, parameters k is 11.489165944665606 and b is -49.519691699617844\n",
      "Iteration 7193, the loss is 4.524595730054486, parameters k is 11.489198541503551 and b is -49.51965217392615\n",
      "Iteration 7194, the loss is 4.524595080472949, parameters k is 11.489181241108295 and b is -49.51962055337279\n",
      "Iteration 7195, the loss is 4.524594430891417, parameters k is 11.489163940713038 and b is -49.51958893281943\n",
      "Iteration 7196, the loss is 4.524594033161976, parameters k is 11.48914664031778 and b is -49.51955731226607\n",
      "Iteration 7197, the loss is 4.524593438366846, parameters k is 11.489179237155726 and b is -49.519517786574376\n",
      "Iteration 7198, the loss is 4.524592788785312, parameters k is 11.48916193676047 and b is -49.51948616602102\n",
      "Iteration 7199, the loss is 4.524592139203778, parameters k is 11.489144636365213 and b is -49.51945454546766\n",
      "Iteration 7200, the loss is 4.524591691915807, parameters k is 11.489127335969956 and b is -49.5194229249143\n",
      "Iteration 7201, the loss is 4.524591146679214, parameters k is 11.489159932807901 and b is -49.519383399222605\n",
      "Iteration 7202, the loss is 4.524590497097671, parameters k is 11.489142632412644 and b is -49.51935177866925\n",
      "Iteration 7203, the loss is 4.5245898475161415, parameters k is 11.489125332017387 and b is -49.51932015811589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7204, the loss is 4.52458935066964, parameters k is 11.48910803162213 and b is -49.51928853756253\n",
      "Iteration 7205, the loss is 4.524588854991577, parameters k is 11.489140628460076 and b is -49.51924901187083\n",
      "Iteration 7206, the loss is 4.524588205410039, parameters k is 11.489123328064819 and b is -49.519217391317476\n",
      "Iteration 7207, the loss is 4.5245875558285045, parameters k is 11.489106027669562 and b is -49.51918577076412\n",
      "Iteration 7208, the loss is 4.524587009423471, parameters k is 11.489088727274305 and b is -49.51915415021076\n",
      "Iteration 7209, the loss is 4.524586563303935, parameters k is 11.48912132411225 and b is -49.51911462451906\n",
      "Iteration 7210, the loss is 4.5245859137224, parameters k is 11.489104023716994 and b is -49.519083003965704\n",
      "Iteration 7211, the loss is 4.524585264140866, parameters k is 11.489086723321737 and b is -49.51905138341235\n",
      "Iteration 7212, the loss is 4.524584668177304, parameters k is 11.48906942292648 and b is -49.51901976285899\n",
      "Iteration 7213, the loss is 4.524584271616294, parameters k is 11.489102019764426 and b is -49.51898023716729\n",
      "Iteration 7214, the loss is 4.524583622034763, parameters k is 11.489084719369169 and b is -49.51894861661393\n",
      "Iteration 7215, the loss is 4.524582972453225, parameters k is 11.489067418973912 and b is -49.518916996060575\n",
      "Iteration 7216, the loss is 4.52458232693114, parameters k is 11.489050118578655 and b is -49.51888537550722\n",
      "Iteration 7217, the loss is 4.524581979928662, parameters k is 11.4890827154166 and b is -49.51884584981552\n",
      "Iteration 7218, the loss is 4.524581330347123, parameters k is 11.489065415021344 and b is -49.51881422926216\n",
      "Iteration 7219, the loss is 4.52458068076559, parameters k is 11.489048114626087 and b is -49.518782608708804\n",
      "Iteration 7220, the loss is 4.524580031184058, parameters k is 11.48903081423083 and b is -49.518750988155446\n",
      "Iteration 7221, the loss is 4.5245796427419345, parameters k is 11.489013513835573 and b is -49.51871936760209\n",
      "Iteration 7222, the loss is 4.524579038659485, parameters k is 11.489046110673518 and b is -49.51867984191039\n",
      "Iteration 7223, the loss is 4.524578389077952, parameters k is 11.489028810278262 and b is -49.51864822135703\n",
      "Iteration 7224, the loss is 4.524577739496417, parameters k is 11.489011509883005 and b is -49.518616600803675\n",
      "Iteration 7225, the loss is 4.524577301495765, parameters k is 11.488994209487748 and b is -49.51858498025032\n",
      "Iteration 7226, the loss is 4.524576746971843, parameters k is 11.489026806325693 and b is -49.51854545455862\n",
      "Iteration 7227, the loss is 4.524576097390315, parameters k is 11.489009505930436 and b is -49.51851383400526\n",
      "Iteration 7228, the loss is 4.524575447808777, parameters k is 11.48899220553518 and b is -49.518482213451904\n",
      "Iteration 7229, the loss is 4.524574960249596, parameters k is 11.488974905139923 and b is -49.518450592898546\n",
      "Iteration 7230, the loss is 4.524574455284211, parameters k is 11.489007501977868 and b is -49.51841106720685\n",
      "Iteration 7231, the loss is 4.524573805702682, parameters k is 11.488990201582611 and b is -49.51837944665349\n",
      "Iteration 7232, the loss is 4.524573156121141, parameters k is 11.488972901187354 and b is -49.51834782610013\n",
      "Iteration 7233, the loss is 4.524572619003429, parameters k is 11.488955600792098 and b is -49.518316205546775\n",
      "Iteration 7234, the loss is 4.524572163596578, parameters k is 11.488988197630043 and b is -49.51827667985508\n",
      "Iteration 7235, the loss is 4.524571514015038, parameters k is 11.488970897234786 and b is -49.51824505930172\n",
      "Iteration 7236, the loss is 4.524570864433508, parameters k is 11.48895359683953 and b is -49.51821343874836\n",
      "Iteration 7237, the loss is 4.524570277757265, parameters k is 11.488936296444273 and b is -49.518181818195\n",
      "Iteration 7238, the loss is 4.524569871908938, parameters k is 11.488968893282218 and b is -49.518142292503306\n",
      "Iteration 7239, the loss is 4.524569222327403, parameters k is 11.488951592886961 and b is -49.51811067194995\n",
      "Iteration 7240, the loss is 4.524568572745867, parameters k is 11.488934292491704 and b is -49.51807905139659\n",
      "Iteration 7241, the loss is 4.524567936511092, parameters k is 11.488916992096447 and b is -49.51804743084323\n",
      "Iteration 7242, the loss is 4.5245675802213015, parameters k is 11.488949588934393 and b is -49.518007905151535\n",
      "Iteration 7243, the loss is 4.524566930639764, parameters k is 11.488932288539136 and b is -49.51797628459818\n",
      "Iteration 7244, the loss is 4.52456628105823, parameters k is 11.488914988143879 and b is -49.51794466404482\n",
      "Iteration 7245, the loss is 4.524565631476691, parameters k is 11.488897687748622 and b is -49.51791304349146\n",
      "Iteration 7246, the loss is 4.524565252321892, parameters k is 11.488880387353365 and b is -49.5178814229381\n",
      "Iteration 7247, the loss is 4.524564638952132, parameters k is 11.48891298419131 and b is -49.517841897246406\n",
      "Iteration 7248, the loss is 4.524563989370592, parameters k is 11.488895683796054 and b is -49.51781027669305\n",
      "Iteration 7249, the loss is 4.524563339789056, parameters k is 11.488878383400797 and b is -49.51777865613969\n",
      "Iteration 7250, the loss is 4.524562911075722, parameters k is 11.48886108300554 and b is -49.51774703558633\n",
      "Iteration 7251, the loss is 4.524562347264493, parameters k is 11.488893679843486 and b is -49.517707509894635\n",
      "Iteration 7252, the loss is 4.524561697682957, parameters k is 11.488876379448229 and b is -49.51767588934128\n",
      "Iteration 7253, the loss is 4.5245610481014165, parameters k is 11.488859079052972 and b is -49.51764426878792\n",
      "Iteration 7254, the loss is 4.524560569829556, parameters k is 11.488841778657715 and b is -49.51761264823456\n",
      "Iteration 7255, the loss is 4.5245600555768535, parameters k is 11.48887437549566 and b is -49.51757312254286\n",
      "Iteration 7256, the loss is 4.524559405995317, parameters k is 11.488857075100404 and b is -49.517541501989506\n",
      "Iteration 7257, the loss is 4.524558756413781, parameters k is 11.488839774705147 and b is -49.51750988143615\n",
      "Iteration 7258, the loss is 4.52455822858339, parameters k is 11.48882247430989 and b is -49.51747826088279\n",
      "Iteration 7259, the loss is 4.524557763889212, parameters k is 11.488855071147835 and b is -49.51743873519109\n",
      "Iteration 7260, the loss is 4.524557114307682, parameters k is 11.488837770752578 and b is -49.517407114637734\n",
      "Iteration 7261, the loss is 4.524556464726145, parameters k is 11.488820470357322 and b is -49.517375494084376\n",
      "Iteration 7262, the loss is 4.524555887337218, parameters k is 11.488803169962065 and b is -49.51734387353102\n",
      "Iteration 7263, the loss is 4.524555472201581, parameters k is 11.48883576680001 and b is -49.51730434783932\n",
      "Iteration 7264, the loss is 4.52455482262004, parameters k is 11.488818466404753 and b is -49.51727272728596\n",
      "Iteration 7265, the loss is 4.524554173038503, parameters k is 11.488801166009496 and b is -49.517241106732605\n",
      "Iteration 7266, the loss is 4.524553546091049, parameters k is 11.48878386561424 and b is -49.51720948617925\n",
      "Iteration 7267, the loss is 4.5245531805139345, parameters k is 11.488816462452185 and b is -49.51716996048755\n",
      "Iteration 7268, the loss is 4.5245525309323975, parameters k is 11.488799162056928 and b is -49.51713833993419\n",
      "Iteration 7269, the loss is 4.52455188135087, parameters k is 11.488781861661671 and b is -49.517106719380834\n",
      "Iteration 7270, the loss is 4.524551231769333, parameters k is 11.488764561266414 and b is -49.517075098827476\n",
      "Iteration 7271, the loss is 4.524550861901851, parameters k is 11.488747260871158 and b is -49.51704347827412\n",
      "Iteration 7272, the loss is 4.524550239244763, parameters k is 11.488779857709103 and b is -49.51700395258242\n",
      "Iteration 7273, the loss is 4.5245495896632315, parameters k is 11.488762557313846 and b is -49.51697233202906\n",
      "Iteration 7274, the loss is 4.524548940081699, parameters k is 11.48874525691859 and b is -49.516940711475705\n",
      "Iteration 7275, the loss is 4.524548520655682, parameters k is 11.488727956523332 and b is -49.51690909092235\n",
      "Iteration 7276, the loss is 4.524547947557127, parameters k is 11.488760553361278 and b is -49.51686956523065\n",
      "Iteration 7277, the loss is 4.5245472979755945, parameters k is 11.488743252966021 and b is -49.51683794467729\n",
      "Iteration 7278, the loss is 4.524546648394059, parameters k is 11.488725952570764 and b is -49.516806324123934\n",
      "Iteration 7279, the loss is 4.524546179409515, parameters k is 11.488708652175507 and b is -49.516774703570576\n",
      "Iteration 7280, the loss is 4.524545655869491, parameters k is 11.488741249013453 and b is -49.51673517787888\n",
      "Iteration 7281, the loss is 4.524545006287952, parameters k is 11.488723948618196 and b is -49.51670355732552\n",
      "Iteration 7282, the loss is 4.5245443567064205, parameters k is 11.488706648222939 and b is -49.51667193677216\n",
      "Iteration 7283, the loss is 4.5245438381633445, parameters k is 11.488689347827682 and b is -49.516640316218805\n",
      "Iteration 7284, the loss is 4.524543364181853, parameters k is 11.488721944665627 and b is -49.51660079052711\n",
      "Iteration 7285, the loss is 4.524542714600318, parameters k is 11.48870464427037 and b is -49.51656916997375\n",
      "Iteration 7286, the loss is 4.524542065018784, parameters k is 11.488687343875114 and b is -49.51653754942039\n",
      "Iteration 7287, the loss is 4.524541496917179, parameters k is 11.488670043479857 and b is -49.51650592886703\n",
      "Iteration 7288, the loss is 4.52454107249422, parameters k is 11.488702640317802 and b is -49.516466403175336\n",
      "Iteration 7289, the loss is 4.524540422912681, parameters k is 11.488685339922545 and b is -49.51643478262198\n",
      "Iteration 7290, the loss is 4.524539773331146, parameters k is 11.488668039527289 and b is -49.51640316206862\n",
      "Iteration 7291, the loss is 4.524539155671012, parameters k is 11.488650739132032 and b is -49.51637154151526\n",
      "Iteration 7292, the loss is 4.5245387808065765, parameters k is 11.488683335969977 and b is -49.516332015823565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7293, the loss is 4.524538131225047, parameters k is 11.48866603557472 and b is -49.51630039527021\n",
      "Iteration 7294, the loss is 4.524537481643514, parameters k is 11.488648735179464 and b is -49.51626877471685\n",
      "Iteration 7295, the loss is 4.524536832061972, parameters k is 11.488631434784207 and b is -49.51623715416349\n",
      "Iteration 7296, the loss is 4.5245364714818095, parameters k is 11.48861413438895 and b is -49.51620553361013\n",
      "Iteration 7297, the loss is 4.52453583953741, parameters k is 11.488646731226895 and b is -49.516166007918436\n",
      "Iteration 7298, the loss is 4.5245351899558734, parameters k is 11.488629430831638 and b is -49.51613438736508\n",
      "Iteration 7299, the loss is 4.524534540374336, parameters k is 11.488612130436382 and b is -49.51610276681172\n",
      "Iteration 7300, the loss is 4.524534130235642, parameters k is 11.488594830041125 and b is -49.51607114625836\n",
      "Iteration 7301, the loss is 4.524533547849773, parameters k is 11.48862742687907 and b is -49.516031620566665\n",
      "Iteration 7302, the loss is 4.524532898268231, parameters k is 11.488610126483813 and b is -49.51600000001331\n",
      "Iteration 7303, the loss is 4.524532248686698, parameters k is 11.488592826088556 and b is -49.51596837945995\n",
      "Iteration 7304, the loss is 4.524531788989472, parameters k is 11.4885755256933 and b is -49.51593675890659\n",
      "Iteration 7305, the loss is 4.524531256162133, parameters k is 11.488608122531245 and b is -49.51589723321489\n",
      "Iteration 7306, the loss is 4.524530606580598, parameters k is 11.488590822135988 and b is -49.515865612661536\n",
      "Iteration 7307, the loss is 4.524529956999062, parameters k is 11.488573521740731 and b is -49.51583399210818\n",
      "Iteration 7308, the loss is 4.5245294477433085, parameters k is 11.488556221345474 and b is -49.51580237155482\n",
      "Iteration 7309, the loss is 4.524528964474492, parameters k is 11.48858881818342 and b is -49.51576284586312\n",
      "Iteration 7310, the loss is 4.524528314892957, parameters k is 11.488571517788163 and b is -49.515731225309764\n",
      "Iteration 7311, the loss is 4.5245276653114255, parameters k is 11.488554217392906 and b is -49.515699604756406\n",
      "Iteration 7312, the loss is 4.524527106497139, parameters k is 11.48853691699765 and b is -49.51566798420305\n",
      "Iteration 7313, the loss is 4.5245266727868545, parameters k is 11.488569513835595 and b is -49.51562845851135\n",
      "Iteration 7314, the loss is 4.52452602320532, parameters k is 11.488552213440338 and b is -49.51559683795799\n",
      "Iteration 7315, the loss is 4.5245253736237885, parameters k is 11.488534913045081 and b is -49.515565217404635\n",
      "Iteration 7316, the loss is 4.524524765250968, parameters k is 11.488517612649824 and b is -49.51553359685128\n",
      "Iteration 7317, the loss is 4.5245243810992175, parameters k is 11.48855020948777 and b is -49.51549407115958\n",
      "Iteration 7318, the loss is 4.5245237315176805, parameters k is 11.488532909092513 and b is -49.51546245060622\n",
      "Iteration 7319, the loss is 4.524523081936143, parameters k is 11.488515608697256 and b is -49.515430830052864\n",
      "Iteration 7320, the loss is 4.524522432354608, parameters k is 11.488498308301999 and b is -49.515399209499506\n",
      "Iteration 7321, the loss is 4.524522081061766, parameters k is 11.488481007906742 and b is -49.51536758894615\n",
      "Iteration 7322, the loss is 4.524521439830047, parameters k is 11.488513604744687 and b is -49.51532806325445\n",
      "Iteration 7323, the loss is 4.524520790248512, parameters k is 11.48849630434943 and b is -49.51529644270109\n",
      "Iteration 7324, the loss is 4.524520140666982, parameters k is 11.488479003954174 and b is -49.515264822147735\n",
      "Iteration 7325, the loss is 4.524519739815597, parameters k is 11.488461703558917 and b is -49.51523320159438\n",
      "Iteration 7326, the loss is 4.524519148142405, parameters k is 11.488494300396862 and b is -49.51519367590268\n",
      "Iteration 7327, the loss is 4.524518498560868, parameters k is 11.488477000001605 and b is -49.51516205534932\n",
      "Iteration 7328, the loss is 4.524517848979335, parameters k is 11.488459699606349 and b is -49.515130434795964\n",
      "Iteration 7329, the loss is 4.524517398569435, parameters k is 11.488442399211092 and b is -49.515098814242606\n",
      "Iteration 7330, the loss is 4.524516856454776, parameters k is 11.488474996049037 and b is -49.51505928855091\n",
      "Iteration 7331, the loss is 4.524516206873234, parameters k is 11.48845769565378 and b is -49.51502766799755\n",
      "Iteration 7332, the loss is 4.524515557291703, parameters k is 11.488440395258523 and b is -49.51499604744419\n",
      "Iteration 7333, the loss is 4.524515057323262, parameters k is 11.488423094863267 and b is -49.514964426890835\n",
      "Iteration 7334, the loss is 4.524514564767135, parameters k is 11.488455691701212 and b is -49.51492490119914\n",
      "Iteration 7335, the loss is 4.5245139151855955, parameters k is 11.488438391305955 and b is -49.51489328064578\n",
      "Iteration 7336, the loss is 4.524513265604056, parameters k is 11.488421090910698 and b is -49.51486166009242\n",
      "Iteration 7337, the loss is 4.524512716077094, parameters k is 11.488403790515441 and b is -49.51483003953906\n",
      "Iteration 7338, the loss is 4.524512273079493, parameters k is 11.488436387353387 and b is -49.514790513847366\n",
      "Iteration 7339, the loss is 4.524511623497959, parameters k is 11.48841908695813 and b is -49.51475889329401\n",
      "Iteration 7340, the loss is 4.524510973916427, parameters k is 11.488401786562873 and b is -49.51472727274065\n",
      "Iteration 7341, the loss is 4.524510374830928, parameters k is 11.488384486167616 and b is -49.51469565218729\n",
      "Iteration 7342, the loss is 4.524509981391858, parameters k is 11.488417083005562 and b is -49.514656126495595\n",
      "Iteration 7343, the loss is 4.52450933181032, parameters k is 11.488399782610305 and b is -49.51462450594224\n",
      "Iteration 7344, the loss is 4.524508682228787, parameters k is 11.488382482215048 and b is -49.51459288538888\n",
      "Iteration 7345, the loss is 4.524508033584759, parameters k is 11.488365181819791 and b is -49.51456126483552\n",
      "Iteration 7346, the loss is 4.524507689704218, parameters k is 11.488397778657736 and b is -49.514521739143824\n",
      "Iteration 7347, the loss is 4.524507040122684, parameters k is 11.48838047826248 and b is -49.514490118590466\n",
      "Iteration 7348, the loss is 4.524506390541151, parameters k is 11.488363177867223 and b is -49.51445849803711\n",
      "Iteration 7349, the loss is 4.524505740959613, parameters k is 11.488345877471966 and b is -49.51442687748375\n",
      "Iteration 7350, the loss is 4.52450534939556, parameters k is 11.48832857707671 and b is -49.51439525693039\n",
      "Iteration 7351, the loss is 4.524504748435042, parameters k is 11.488361173914655 and b is -49.514355731238695\n",
      "Iteration 7352, the loss is 4.52450409885351, parameters k is 11.488343873519398 and b is -49.51432411068534\n",
      "Iteration 7353, the loss is 4.524503449271979, parameters k is 11.48832657312414 and b is -49.51429249013198\n",
      "Iteration 7354, the loss is 4.52450300814939, parameters k is 11.488309272728884 and b is -49.51426086957862\n",
      "Iteration 7355, the loss is 4.524502456747411, parameters k is 11.48834186956683 and b is -49.51422134388692\n",
      "Iteration 7356, the loss is 4.524501807165873, parameters k is 11.488324569171573 and b is -49.514189723333565\n",
      "Iteration 7357, the loss is 4.524501157584337, parameters k is 11.488307268776316 and b is -49.51415810278021\n",
      "Iteration 7358, the loss is 4.524500666903216, parameters k is 11.488289968381059 and b is -49.51412648222685\n",
      "Iteration 7359, the loss is 4.524500165059768, parameters k is 11.488322565219004 and b is -49.51408695653515\n",
      "Iteration 7360, the loss is 4.524499515478236, parameters k is 11.488305264823747 and b is -49.514055335981794\n",
      "Iteration 7361, the loss is 4.524498865896706, parameters k is 11.48828796442849 and b is -49.514023715428436\n",
      "Iteration 7362, the loss is 4.524498325657053, parameters k is 11.488270664033234 and b is -49.51399209487508\n",
      "Iteration 7363, the loss is 4.524497873372131, parameters k is 11.488303260871179 and b is -49.51395256918338\n",
      "Iteration 7364, the loss is 4.524497223790601, parameters k is 11.488285960475922 and b is -49.51392094863002\n",
      "Iteration 7365, the loss is 4.524496574209061, parameters k is 11.488268660080665 and b is -49.513889328076665\n",
      "Iteration 7366, the loss is 4.5244959844108825, parameters k is 11.488251359685409 and b is -49.51385770752331\n",
      "Iteration 7367, the loss is 4.524495581684496, parameters k is 11.488283956523354 and b is -49.51381818183161\n",
      "Iteration 7368, the loss is 4.524494932102959, parameters k is 11.488266656128097 and b is -49.51378656127825\n",
      "Iteration 7369, the loss is 4.524494282521421, parameters k is 11.48824935573284 and b is -49.513754940724894\n",
      "Iteration 7370, the loss is 4.524493643164719, parameters k is 11.488232055337583 and b is -49.513723320171536\n",
      "Iteration 7371, the loss is 4.52449328999686, parameters k is 11.488264652175529 and b is -49.51368379447984\n",
      "Iteration 7372, the loss is 4.524492640415324, parameters k is 11.488247351780272 and b is -49.51365217392648\n",
      "Iteration 7373, the loss is 4.524491990833787, parameters k is 11.488230051385015 and b is -49.51362055337312\n",
      "Iteration 7374, the loss is 4.524491341252255, parameters k is 11.488212750989758 and b is -49.513588932819765\n",
      "Iteration 7375, the loss is 4.524490958975514, parameters k is 11.488195450594501 and b is -49.51355731226641\n",
      "Iteration 7376, the loss is 4.524490348727689, parameters k is 11.488228047432447 and b is -49.51351778657471\n",
      "Iteration 7377, the loss is 4.5244896991461525, parameters k is 11.48821074703719 and b is -49.51348616602135\n",
      "Iteration 7378, the loss is 4.524489049564617, parameters k is 11.488193446641933 and b is -49.513454545467994\n",
      "Iteration 7379, the loss is 4.524488617729347, parameters k is 11.488176146246676 and b is -49.513422924914636\n",
      "Iteration 7380, the loss is 4.524488057040049, parameters k is 11.488208743084622 and b is -49.51338339922294\n",
      "Iteration 7381, the loss is 4.524487407458514, parameters k is 11.488191442689365 and b is -49.51335177866958\n",
      "Iteration 7382, the loss is 4.524486757876974, parameters k is 11.488174142294108 and b is -49.51332015811622\n",
      "Iteration 7383, the loss is 4.5244862764831755, parameters k is 11.488156841898851 and b is -49.513288537562865\n",
      "Iteration 7384, the loss is 4.524485765352414, parameters k is 11.488189438736796 and b is -49.51324901187117\n",
      "Iteration 7385, the loss is 4.524485115770874, parameters k is 11.48817213834154 and b is -49.51321739131781\n",
      "Iteration 7386, the loss is 4.5244844661893415, parameters k is 11.488154837946283 and b is -49.51318577076445\n",
      "Iteration 7387, the loss is 4.524483935237016, parameters k is 11.488137537551026 and b is -49.51315415021109\n",
      "Iteration 7388, the loss is 4.524483473664773, parameters k is 11.488170134388971 and b is -49.513114624519396\n",
      "Iteration 7389, the loss is 4.524482824083237, parameters k is 11.488152833993714 and b is -49.51308300396604\n",
      "Iteration 7390, the loss is 4.524482174501701, parameters k is 11.488135533598458 and b is -49.51305138341268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7391, the loss is 4.524481593990842, parameters k is 11.4881182332032 and b is -49.51301976285932\n",
      "Iteration 7392, the loss is 4.524481181977137, parameters k is 11.488150830041146 and b is -49.512980237167625\n",
      "Iteration 7393, the loss is 4.524480532395602, parameters k is 11.48813352964589 and b is -49.51294861661427\n",
      "Iteration 7394, the loss is 4.524479882814065, parameters k is 11.488116229250632 and b is -49.51291699606091\n",
      "Iteration 7395, the loss is 4.524479252744675, parameters k is 11.488098928855376 and b is -49.51288537550755\n",
      "Iteration 7396, the loss is 4.524478890289501, parameters k is 11.488131525693321 and b is -49.512845849815854\n",
      "Iteration 7397, the loss is 4.524478240707963, parameters k is 11.488114225298064 and b is -49.512814229262496\n",
      "Iteration 7398, the loss is 4.524477591126428, parameters k is 11.488096924902807 and b is -49.51278260870914\n",
      "Iteration 7399, the loss is 4.5244769415448935, parameters k is 11.48807962450755 and b is -49.51275098815578\n",
      "Iteration 7400, the loss is 4.524476568555475, parameters k is 11.488062324112294 and b is -49.51271936760242\n",
      "Iteration 7401, the loss is 4.524475949020326, parameters k is 11.488094920950239 and b is -49.512679841910725\n",
      "Iteration 7402, the loss is 4.524475299438792, parameters k is 11.488077620554982 and b is -49.51264822135737\n",
      "Iteration 7403, the loss is 4.524474649857258, parameters k is 11.488060320159725 and b is -49.51261660080401\n",
      "Iteration 7404, the loss is 4.524474227309307, parameters k is 11.488043019764469 and b is -49.51258498025065\n",
      "Iteration 7405, the loss is 4.524473657332688, parameters k is 11.488075616602414 and b is -49.51254545455895\n",
      "Iteration 7406, the loss is 4.524473007751153, parameters k is 11.488058316207157 and b is -49.512513834005595\n",
      "Iteration 7407, the loss is 4.524472358169624, parameters k is 11.4880410158119 and b is -49.51248221345224\n",
      "Iteration 7408, the loss is 4.524471886063137, parameters k is 11.488023715416643 and b is -49.51245059289888\n",
      "Iteration 7409, the loss is 4.524471365645049, parameters k is 11.488056312254589 and b is -49.51241106720718\n",
      "Iteration 7410, the loss is 4.524470716063514, parameters k is 11.488039011859332 and b is -49.512379446653824\n",
      "Iteration 7411, the loss is 4.52447006648198, parameters k is 11.488021711464075 and b is -49.512347826100466\n",
      "Iteration 7412, the loss is 4.524469544816967, parameters k is 11.488004411068818 and b is -49.51231620554711\n",
      "Iteration 7413, the loss is 4.524469073957412, parameters k is 11.488037007906764 and b is -49.51227667985541\n",
      "Iteration 7414, the loss is 4.524468424375875, parameters k is 11.488019707511507 and b is -49.51224505930205\n",
      "Iteration 7415, the loss is 4.524467774794341, parameters k is 11.48800240711625 and b is -49.512213438748695\n",
      "Iteration 7416, the loss is 4.524467203570803, parameters k is 11.487985106720993 and b is -49.51218181819534\n",
      "Iteration 7417, the loss is 4.5244667822697755, parameters k is 11.488017703558938 and b is -49.51214229250364\n",
      "Iteration 7418, the loss is 4.5244661326882385, parameters k is 11.488000403163682 and b is -49.51211067195028\n",
      "Iteration 7419, the loss is 4.524465483106711, parameters k is 11.487983102768425 and b is -49.512079051396924\n",
      "Iteration 7420, the loss is 4.52446486232463, parameters k is 11.487965802373168 and b is -49.512047430843566\n",
      "Iteration 7421, the loss is 4.524464490582137, parameters k is 11.487998399211113 and b is -49.51200790515187\n",
      "Iteration 7422, the loss is 4.524463841000602, parameters k is 11.487981098815856 and b is -49.51197628459851\n",
      "Iteration 7423, the loss is 4.524463191419069, parameters k is 11.4879637984206 and b is -49.51194466404515\n",
      "Iteration 7424, the loss is 4.524462541837531, parameters k is 11.487946498025343 and b is -49.511913043491795\n",
      "Iteration 7425, the loss is 4.524462178135434, parameters k is 11.487929197630086 and b is -49.51188142293844\n",
      "Iteration 7426, the loss is 4.5244615493129645, parameters k is 11.487961794468031 and b is -49.51184189724674\n",
      "Iteration 7427, the loss is 4.5244608997314275, parameters k is 11.487944494072774 and b is -49.51181027669338\n",
      "Iteration 7428, the loss is 4.524460250149892, parameters k is 11.487927193677518 and b is -49.511778656140024\n",
      "Iteration 7429, the loss is 4.524459836889264, parameters k is 11.48790989328226 and b is -49.511747035586666\n",
      "Iteration 7430, the loss is 4.524459257625324, parameters k is 11.487942490120206 and b is -49.51170750989497\n",
      "Iteration 7431, the loss is 4.524458608043794, parameters k is 11.48792518972495 and b is -49.51167588934161\n",
      "Iteration 7432, the loss is 4.524457958462261, parameters k is 11.487907889329692 and b is -49.51164426878825\n",
      "Iteration 7433, the loss is 4.524457495643096, parameters k is 11.487890588934436 and b is -49.511612648234895\n",
      "Iteration 7434, the loss is 4.524456965937693, parameters k is 11.487923185772381 and b is -49.5115731225432\n",
      "Iteration 7435, the loss is 4.524456316356157, parameters k is 11.487905885377124 and b is -49.51154150198984\n",
      "Iteration 7436, the loss is 4.524455666774617, parameters k is 11.487888584981867 and b is -49.51150988143648\n",
      "Iteration 7437, the loss is 4.5244551543969305, parameters k is 11.48787128458661 and b is -49.51147826088312\n",
      "Iteration 7438, the loss is 4.524454674250052, parameters k is 11.487903881424556 and b is -49.511438735191426\n",
      "Iteration 7439, the loss is 4.524454024668516, parameters k is 11.487886581029299 and b is -49.51140711463807\n",
      "Iteration 7440, the loss is 4.5244533750869795, parameters k is 11.487869280634042 and b is -49.51137549408471\n",
      "Iteration 7441, the loss is 4.52445281315076, parameters k is 11.487851980238785 and b is -49.51134387353135\n",
      "Iteration 7442, the loss is 4.524452382562417, parameters k is 11.48788457707673 and b is -49.511304347839655\n",
      "Iteration 7443, the loss is 4.52445173298088, parameters k is 11.487867276681474 and b is -49.5112727272863\n",
      "Iteration 7444, the loss is 4.524451083399349, parameters k is 11.487849976286217 and b is -49.51124110673294\n",
      "Iteration 7445, the loss is 4.52445047190459, parameters k is 11.48783267589096 and b is -49.51120948617958\n",
      "Iteration 7446, the loss is 4.524450090874779, parameters k is 11.487865272728905 and b is -49.511169960487884\n",
      "Iteration 7447, the loss is 4.52444944129324, parameters k is 11.487847972333649 and b is -49.511138339934526\n",
      "Iteration 7448, the loss is 4.524448791711708, parameters k is 11.487830671938392 and b is -49.51110671938117\n",
      "Iteration 7449, the loss is 4.524448142130172, parameters k is 11.487813371543135 and b is -49.51107509882781\n",
      "Iteration 7450, the loss is 4.52444778771539, parameters k is 11.487796071147878 and b is -49.51104347827445\n",
      "Iteration 7451, the loss is 4.524447149605605, parameters k is 11.487828667985823 and b is -49.511003952582755\n",
      "Iteration 7452, the loss is 4.524446500024069, parameters k is 11.487811367590567 and b is -49.5109723320294\n",
      "Iteration 7453, the loss is 4.5244458504425324, parameters k is 11.48779406719531 and b is -49.51094071147604\n",
      "Iteration 7454, the loss is 4.524445446469219, parameters k is 11.487776766800053 and b is -49.51090909092268\n",
      "Iteration 7455, the loss is 4.52444485791797, parameters k is 11.487809363637998 and b is -49.51086956523098\n",
      "Iteration 7456, the loss is 4.52444420833643, parameters k is 11.487792063242741 and b is -49.510837944677625\n",
      "Iteration 7457, the loss is 4.5244435587548955, parameters k is 11.487774762847485 and b is -49.51080632412427\n",
      "Iteration 7458, the loss is 4.524443105223053, parameters k is 11.487757462452228 and b is -49.51077470357091\n",
      "Iteration 7459, the loss is 4.524442566230329, parameters k is 11.487790059290173 and b is -49.51073517787921\n",
      "Iteration 7460, the loss is 4.524441916648791, parameters k is 11.487772758894916 and b is -49.510703557325854\n",
      "Iteration 7461, the loss is 4.5244412670672585, parameters k is 11.48775545849966 and b is -49.510671936772496\n",
      "Iteration 7462, the loss is 4.5244407639768855, parameters k is 11.487738158104403 and b is -49.51064031621914\n",
      "Iteration 7463, the loss is 4.524440274542689, parameters k is 11.487770754942348 and b is -49.51060079052744\n",
      "Iteration 7464, the loss is 4.524439624961154, parameters k is 11.487753454547091 and b is -49.51056916997408\n",
      "Iteration 7465, the loss is 4.524438975379617, parameters k is 11.487736154151834 and b is -49.510537549420725\n",
      "Iteration 7466, the loss is 4.524438422730721, parameters k is 11.487718853756578 and b is -49.51050592886737\n",
      "Iteration 7467, the loss is 4.524437982855058, parameters k is 11.487751450594523 and b is -49.51046640317567\n",
      "Iteration 7468, the loss is 4.52443733327352, parameters k is 11.487734150199266 and b is -49.51043478262231\n",
      "Iteration 7469, the loss is 4.52443668369198, parameters k is 11.48771684980401 and b is -49.510403162068954\n",
      "Iteration 7470, the loss is 4.524436081484549, parameters k is 11.487699549408752 and b is -49.510371541515596\n",
      "Iteration 7471, the loss is 4.524435691167414, parameters k is 11.487732146246698 and b is -49.5103320158239\n",
      "Iteration 7472, the loss is 4.524435041585885, parameters k is 11.48771484585144 and b is -49.51030039527054\n",
      "Iteration 7473, the loss is 4.5244343920043475, parameters k is 11.487697545456184 and b is -49.51026877471718\n",
      "Iteration 7474, the loss is 4.524433742422814, parameters k is 11.487680245060927 and b is -49.510237154163825\n",
      "Iteration 7475, the loss is 4.524433397295348, parameters k is 11.48766294466567 and b is -49.51020553361047\n",
      "Iteration 7476, the loss is 4.524432749898242, parameters k is 11.487695541503616 and b is -49.51016600791877\n",
      "Iteration 7477, the loss is 4.5244321003167105, parameters k is 11.487678241108359 and b is -49.51013438736541\n",
      "Iteration 7478, the loss is 4.524431450735178, parameters k is 11.487660940713102 and b is -49.510102766812054\n",
      "Iteration 7479, the loss is 4.524431056049183, parameters k is 11.487643640317845 and b is -49.510071146258696\n",
      "Iteration 7480, the loss is 4.524430458210609, parameters k is 11.48767623715579 and b is -49.510031620567\n",
      "Iteration 7481, the loss is 4.524429808629067, parameters k is 11.487658936760534 and b is -49.51000000001364\n",
      "Iteration 7482, the loss is 4.5244291590475365, parameters k is 11.487641636365277 and b is -49.50996837946028\n",
      "Iteration 7483, the loss is 4.524428714803013, parameters k is 11.48762433597002 and b is -49.509936758906925\n",
      "Iteration 7484, the loss is 4.524428166522964, parameters k is 11.487656932807965 and b is -49.50989723321523\n",
      "Iteration 7485, the loss is 4.524427516941433, parameters k is 11.487639632412709 and b is -49.50986561266187\n",
      "Iteration 7486, the loss is 4.524426867359897, parameters k is 11.487622332017452 and b is -49.50983399210851\n",
      "Iteration 7487, the loss is 4.524426373556843, parameters k is 11.487605031622195 and b is -49.50980237155515\n",
      "Iteration 7488, the loss is 4.524425874835337, parameters k is 11.48763762846014 and b is -49.509762845863456\n",
      "Iteration 7489, the loss is 4.524425225253797, parameters k is 11.487620328064883 and b is -49.5097312253101\n",
      "Iteration 7490, the loss is 4.524424575672263, parameters k is 11.487603027669627 and b is -49.50969960475674\n",
      "Iteration 7491, the loss is 4.524424032310679, parameters k is 11.48758572727437 and b is -49.50966798420338\n",
      "Iteration 7492, the loss is 4.52442358314769, parameters k is 11.487618324112315 and b is -49.509628458511685\n",
      "Iteration 7493, the loss is 4.524422933566157, parameters k is 11.487601023717058 and b is -49.50959683795833\n",
      "Iteration 7494, the loss is 4.524422283984625, parameters k is 11.487583723321801 and b is -49.50956521740497\n",
      "Iteration 7495, the loss is 4.524421691064509, parameters k is 11.487566422926545 and b is -49.50953359685161\n",
      "Iteration 7496, the loss is 4.524421291460057, parameters k is 11.48759901976449 and b is -49.509494071159914\n",
      "Iteration 7497, the loss is 4.524420641878524, parameters k is 11.487581719369233 and b is -49.509462450606556\n",
      "Iteration 7498, the loss is 4.524419992296984, parameters k is 11.487564418973976 and b is -49.5094308300532\n",
      "Iteration 7499, the loss is 4.524419349818342, parameters k is 11.48754711857872 and b is -49.50939920949984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7500, the loss is 4.524418999772418, parameters k is 11.487579715416665 and b is -49.50935968380814\n",
      "Iteration 7501, the loss is 4.524418350190882, parameters k is 11.487562415021408 and b is -49.509328063254785\n",
      "Iteration 7502, the loss is 4.524417700609349, parameters k is 11.487545114626151 and b is -49.50929644270143\n",
      "Iteration 7503, the loss is 4.524417051027811, parameters k is 11.487527814230894 and b is -49.50926482214807\n",
      "Iteration 7504, the loss is 4.524416665629141, parameters k is 11.487510513835637 and b is -49.50923320159471\n",
      "Iteration 7505, the loss is 4.524416058503248, parameters k is 11.487543110673583 and b is -49.50919367590301\n",
      "Iteration 7506, the loss is 4.5244154089217075, parameters k is 11.487525810278326 and b is -49.509162055349655\n",
      "Iteration 7507, the loss is 4.524414759340178, parameters k is 11.48750850988307 and b is -49.5091304347963\n",
      "Iteration 7508, the loss is 4.5244143243829695, parameters k is 11.487491209487812 and b is -49.50909881424294\n",
      "Iteration 7509, the loss is 4.524413766815609, parameters k is 11.487523806325758 and b is -49.50905928855124\n",
      "Iteration 7510, the loss is 4.524413117234078, parameters k is 11.4875065059305 and b is -49.509027667997884\n",
      "Iteration 7511, the loss is 4.5244124676525335, parameters k is 11.487489205535244 and b is -49.508996047444526\n",
      "Iteration 7512, the loss is 4.5244119831368, parameters k is 11.487471905139987 and b is -49.50896442689117\n",
      "Iteration 7513, the loss is 4.524411475127972, parameters k is 11.487504501977932 and b is -49.50892490119947\n",
      "Iteration 7514, the loss is 4.52441082554644, parameters k is 11.487487201582676 and b is -49.50889328064611\n",
      "Iteration 7515, the loss is 4.524410175964899, parameters k is 11.487469901187419 and b is -49.508861660092755\n",
      "Iteration 7516, the loss is 4.524409641890637, parameters k is 11.487452600792162 and b is -49.5088300395394\n",
      "Iteration 7517, the loss is 4.524409183440331, parameters k is 11.487485197630107 and b is -49.5087905138477\n",
      "Iteration 7518, the loss is 4.524408533858799, parameters k is 11.48746789723485 and b is -49.50875889329434\n",
      "Iteration 7519, the loss is 4.524407884277264, parameters k is 11.487450596839594 and b is -49.508727272740984\n",
      "Iteration 7520, the loss is 4.524407300644464, parameters k is 11.487433296444337 and b is -49.508695652187626\n",
      "Iteration 7521, the loss is 4.524406891752697, parameters k is 11.487465893282282 and b is -49.50865612649593\n",
      "Iteration 7522, the loss is 4.5244062421711595, parameters k is 11.487448592887025 and b is -49.50862450594257\n",
      "Iteration 7523, the loss is 4.52440559258962, parameters k is 11.487431292491769 and b is -49.50859288538921\n",
      "Iteration 7524, the loss is 4.524404959398299, parameters k is 11.487413992096512 and b is -49.508561264835855\n",
      "Iteration 7525, the loss is 4.5244046000650595, parameters k is 11.487446588934457 and b is -49.50852173914416\n",
      "Iteration 7526, the loss is 4.5244039504835225, parameters k is 11.4874292885392 and b is -49.5084901185908\n",
      "Iteration 7527, the loss is 4.524403300901987, parameters k is 11.487411988143943 and b is -49.50845849803744\n",
      "Iteration 7528, the loss is 4.524402651320455, parameters k is 11.487394687748687 and b is -49.508426877484084\n",
      "Iteration 7529, the loss is 4.524402275209101, parameters k is 11.48737738735343 and b is -49.508395256930726\n",
      "Iteration 7530, the loss is 4.5244016587958855, parameters k is 11.487409984191375 and b is -49.50835573123903\n",
      "Iteration 7531, the loss is 4.524401009214347, parameters k is 11.487392683796118 and b is -49.50832411068567\n",
      "Iteration 7532, the loss is 4.524400359632812, parameters k is 11.487375383400861 and b is -49.50829249013231\n",
      "Iteration 7533, the loss is 4.524399933962931, parameters k is 11.487358083005605 and b is -49.508260869578955\n",
      "Iteration 7534, the loss is 4.524399367108244, parameters k is 11.48739067984355 and b is -49.50822134388726\n",
      "Iteration 7535, the loss is 4.52439871752671, parameters k is 11.487373379448293 and b is -49.5081897233339\n",
      "Iteration 7536, the loss is 4.524398067945177, parameters k is 11.487356079053036 and b is -49.50815810278054\n",
      "Iteration 7537, the loss is 4.524397592716764, parameters k is 11.48733877865778 and b is -49.50812648222718\n",
      "Iteration 7538, the loss is 4.524397075420611, parameters k is 11.487371375495725 and b is -49.508086956535486\n",
      "Iteration 7539, the loss is 4.524396425839073, parameters k is 11.487354075100468 and b is -49.50805533598213\n",
      "Iteration 7540, the loss is 4.524395776257534, parameters k is 11.487336774705211 and b is -49.50802371542877\n",
      "Iteration 7541, the loss is 4.524395251470594, parameters k is 11.487319474309954 and b is -49.50799209487541\n",
      "Iteration 7542, the loss is 4.524394783732974, parameters k is 11.4873520711479 and b is -49.507952569183715\n",
      "Iteration 7543, the loss is 4.524394134151437, parameters k is 11.487334770752643 and b is -49.50792094863036\n",
      "Iteration 7544, the loss is 4.524393484569898, parameters k is 11.487317470357386 and b is -49.507889328077\n",
      "Iteration 7545, the loss is 4.524392910224426, parameters k is 11.487300169962129 and b is -49.50785770752364\n",
      "Iteration 7546, the loss is 4.524392492045333, parameters k is 11.487332766800074 and b is -49.507818181831944\n",
      "Iteration 7547, the loss is 4.524391842463802, parameters k is 11.487315466404818 and b is -49.507786561278586\n",
      "Iteration 7548, the loss is 4.524391192882266, parameters k is 11.48729816600956 and b is -49.50775494072523\n",
      "Iteration 7549, the loss is 4.524390568978255, parameters k is 11.487280865614304 and b is -49.50772332017187\n",
      "Iteration 7550, the loss is 4.524390200357699, parameters k is 11.48731346245225 and b is -49.50768379448017\n",
      "Iteration 7551, the loss is 4.5243895507761644, parameters k is 11.487296162056992 and b is -49.507652173926814\n",
      "Iteration 7552, the loss is 4.524388901194626, parameters k is 11.487278861661736 and b is -49.50762055337346\n",
      "Iteration 7553, the loss is 4.524388251613092, parameters k is 11.487261561266479 and b is -49.5075889328201\n",
      "Iteration 7554, the loss is 4.524387884789056, parameters k is 11.487244260871222 and b is -49.50755731226674\n",
      "Iteration 7555, the loss is 4.524387259088523, parameters k is 11.487276857709167 and b is -49.50751778657504\n",
      "Iteration 7556, the loss is 4.524386609506989, parameters k is 11.48725955731391 and b is -49.507486166021685\n",
      "Iteration 7557, the loss is 4.5243859599254534, parameters k is 11.487242256918654 and b is -49.50745454546833\n",
      "Iteration 7558, the loss is 4.524385543542888, parameters k is 11.487224956523397 and b is -49.50742292491497\n",
      "Iteration 7559, the loss is 4.524384967400891, parameters k is 11.487257553361342 and b is -49.50738339922327\n",
      "Iteration 7560, the loss is 4.524384317819353, parameters k is 11.487240252966085 and b is -49.507351778669914\n",
      "Iteration 7561, the loss is 4.524383668237818, parameters k is 11.487222952570828 and b is -49.507320158116556\n",
      "Iteration 7562, the loss is 4.524383202296722, parameters k is 11.487205652175572 and b is -49.5072885375632\n",
      "Iteration 7563, the loss is 4.524382675713249, parameters k is 11.487238249013517 and b is -49.5072490118715\n",
      "Iteration 7564, the loss is 4.524382026131713, parameters k is 11.48722094861826 and b is -49.50721739131814\n",
      "Iteration 7565, the loss is 4.524381376550179, parameters k is 11.487203648223003 and b is -49.507185770764785\n",
      "Iteration 7566, the loss is 4.5243808610505525, parameters k is 11.487186347827747 and b is -49.50715415021143\n",
      "Iteration 7567, the loss is 4.52438038402561, parameters k is 11.487218944665692 and b is -49.50711462451973\n",
      "Iteration 7568, the loss is 4.524379734444077, parameters k is 11.487201644270435 and b is -49.50708300396637\n",
      "Iteration 7569, the loss is 4.524379084862539, parameters k is 11.487184343875178 and b is -49.507051383413014\n",
      "Iteration 7570, the loss is 4.524378519804382, parameters k is 11.487167043479921 and b is -49.507019762859656\n",
      "Iteration 7571, the loss is 4.524378092337972, parameters k is 11.487199640317867 and b is -49.50698023716796\n",
      "Iteration 7572, the loss is 4.524377442756439, parameters k is 11.48718233992261 and b is -49.5069486166146\n",
      "Iteration 7573, the loss is 4.524376793174907, parameters k is 11.487165039527353 and b is -49.50691699606124\n",
      "Iteration 7574, the loss is 4.524376178558215, parameters k is 11.487147739132096 and b is -49.506885375507885\n",
      "Iteration 7575, the loss is 4.524375800650338, parameters k is 11.487180335970042 and b is -49.50684584981619\n",
      "Iteration 7576, the loss is 4.5243751510688, parameters k is 11.487163035574785 and b is -49.50681422926283\n",
      "Iteration 7577, the loss is 4.524374501487268, parameters k is 11.487145735179528 and b is -49.50678260870947\n",
      "Iteration 7578, the loss is 4.52437385190573, parameters k is 11.487128434784271 and b is -49.506750988156114\n",
      "Iteration 7579, the loss is 4.524373494369014, parameters k is 11.487111134389014 and b is -49.506719367602756\n",
      "Iteration 7580, the loss is 4.524372859381162, parameters k is 11.48714373122696 and b is -49.50667984191106\n",
      "Iteration 7581, the loss is 4.524372209799629, parameters k is 11.487126430831703 and b is -49.5066482213577\n",
      "Iteration 7582, the loss is 4.524371560218093, parameters k is 11.487109130436446 and b is -49.50661660080434\n",
      "Iteration 7583, the loss is 4.524371153122845, parameters k is 11.487091830041189 and b is -49.506584980250985\n",
      "Iteration 7584, the loss is 4.524370567693525, parameters k is 11.487124426879134 and b is -49.50654545455929\n",
      "Iteration 7585, the loss is 4.524369918111991, parameters k is 11.487107126483878 and b is -49.50651383400593\n",
      "Iteration 7586, the loss is 4.524369268530459, parameters k is 11.48708982608862 and b is -49.50648221345257\n",
      "Iteration 7587, the loss is 4.524368811876681, parameters k is 11.487072525693364 and b is -49.50645059289921\n",
      "Iteration 7588, the loss is 4.5243682760058945, parameters k is 11.48710512253131 and b is -49.506411067207516\n",
      "Iteration 7589, the loss is 4.524367626424355, parameters k is 11.487087822136052 and b is -49.50637944665416\n",
      "Iteration 7590, the loss is 4.524366976842816, parameters k is 11.487070521740796 and b is -49.5063478261008\n",
      "Iteration 7591, the loss is 4.524366470630511, parameters k is 11.487053221345539 and b is -49.50631620554744\n",
      "Iteration 7592, the loss is 4.524365984318246, parameters k is 11.487085818183484 and b is -49.506276679855745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7593, the loss is 4.5243653347367125, parameters k is 11.487068517788227 and b is -49.50624505930239\n",
      "Iteration 7594, the loss is 4.524364685155181, parameters k is 11.48705121739297 and b is -49.50621343874903\n",
      "Iteration 7595, the loss is 4.52436412938434, parameters k is 11.487033916997714 and b is -49.50618181819567\n",
      "Iteration 7596, the loss is 4.5243636926306126, parameters k is 11.487066513835659 and b is -49.506142292503974\n",
      "Iteration 7597, the loss is 4.524363043049082, parameters k is 11.487049213440402 and b is -49.506110671950616\n",
      "Iteration 7598, the loss is 4.524362393467542, parameters k is 11.487031913045145 and b is -49.50607905139726\n",
      "Iteration 7599, the loss is 4.5243617881381715, parameters k is 11.487014612649888 and b is -49.5060474308439\n",
      "Iteration 7600, the loss is 4.5243614009429765, parameters k is 11.487047209487834 and b is -49.5060079051522\n",
      "Iteration 7601, the loss is 4.524360751361442, parameters k is 11.487029909092577 and b is -49.505976284598844\n",
      "Iteration 7602, the loss is 4.5243601017799016, parameters k is 11.48701260869732 and b is -49.50594466404549\n",
      "Iteration 7603, the loss is 4.524359452198367, parameters k is 11.486995308302063 and b is -49.50591304349213\n",
      "Iteration 7604, the loss is 4.5243591039489734, parameters k is 11.486978007906806 and b is -49.50588142293877\n",
      "Iteration 7605, the loss is 4.524358459673806, parameters k is 11.487010604744752 and b is -49.50584189724707\n",
      "Iteration 7606, the loss is 4.524357810092264, parameters k is 11.486993304349495 and b is -49.505810276693715\n",
      "Iteration 7607, the loss is 4.5243571605107284, parameters k is 11.486976003954238 and b is -49.50577865614036\n",
      "Iteration 7608, the loss is 4.524356762702808, parameters k is 11.486958703558981 and b is -49.505747035587\n",
      "Iteration 7609, the loss is 4.524356167986164, parameters k is 11.486991300396927 and b is -49.5057075098953\n",
      "Iteration 7610, the loss is 4.524355518404624, parameters k is 11.48697400000167 and b is -49.505675889341944\n",
      "Iteration 7611, the loss is 4.524354868823096, parameters k is 11.486956699606413 and b is -49.505644268788586\n",
      "Iteration 7612, the loss is 4.524354421456637, parameters k is 11.486939399211156 and b is -49.50561264823523\n",
      "Iteration 7613, the loss is 4.524353876298528, parameters k is 11.486971996049101 and b is -49.50557312254353\n",
      "Iteration 7614, the loss is 4.524353226716994, parameters k is 11.486954695653845 and b is -49.50554150199017\n",
      "Iteration 7615, the loss is 4.52435257713546, parameters k is 11.486937395258588 and b is -49.505509881436815\n",
      "Iteration 7616, the loss is 4.524352080210472, parameters k is 11.486920094863331 and b is -49.50547826088346\n",
      "Iteration 7617, the loss is 4.524351584610891, parameters k is 11.486952691701276 and b is -49.50543873519176\n",
      "Iteration 7618, the loss is 4.524350935029353, parameters k is 11.48693539130602 and b is -49.5054071146384\n",
      "Iteration 7619, the loss is 4.524350285447821, parameters k is 11.486918090910763 and b is -49.505375494085044\n",
      "Iteration 7620, the loss is 4.524349738964299, parameters k is 11.486900790515506 and b is -49.505343873531686\n",
      "Iteration 7621, the loss is 4.524349292923254, parameters k is 11.486933387353451 and b is -49.50530434783999\n",
      "Iteration 7622, the loss is 4.524348643341715, parameters k is 11.486916086958194 and b is -49.50527272728663\n",
      "Iteration 7623, the loss is 4.524347993760184, parameters k is 11.486898786562938 and b is -49.50524110673327\n",
      "Iteration 7624, the loss is 4.524347397718133, parameters k is 11.48688148616768 and b is -49.505209486179915\n",
      "Iteration 7625, the loss is 4.524347001235614, parameters k is 11.486914083005626 and b is -49.50516996048822\n",
      "Iteration 7626, the loss is 4.524346351654079, parameters k is 11.48689678261037 and b is -49.50513833993486\n",
      "Iteration 7627, the loss is 4.524345702072546, parameters k is 11.486879482215112 and b is -49.5051067193815\n",
      "Iteration 7628, the loss is 4.524345056471964, parameters k is 11.486862181819856 and b is -49.505075098828144\n",
      "Iteration 7629, the loss is 4.524344709547979, parameters k is 11.4868947786578 and b is -49.505035573136446\n",
      "Iteration 7630, the loss is 4.524344059966442, parameters k is 11.486877478262544 and b is -49.50500395258309\n",
      "Iteration 7631, the loss is 4.5243434103849, parameters k is 11.486860177867287 and b is -49.50497233202973\n",
      "Iteration 7632, the loss is 4.524342760803373, parameters k is 11.48684287747203 and b is -49.50494071147637\n",
      "Iteration 7633, the loss is 4.524342372282763, parameters k is 11.486825577076774 and b is -49.504909090923015\n",
      "Iteration 7634, the loss is 4.524341768278808, parameters k is 11.486858173914719 and b is -49.50486956523132\n",
      "Iteration 7635, the loss is 4.524341118697269, parameters k is 11.486840873519462 and b is -49.50483794467796\n",
      "Iteration 7636, the loss is 4.524340469115734, parameters k is 11.486823573124205 and b is -49.5048063241246\n",
      "Iteration 7637, the loss is 4.524340031036592, parameters k is 11.486806272728948 and b is -49.50477470357124\n",
      "Iteration 7638, the loss is 4.524339476591167, parameters k is 11.486838869566894 and b is -49.504735177879546\n",
      "Iteration 7639, the loss is 4.5243388270096325, parameters k is 11.486821569171637 and b is -49.50470355732619\n",
      "Iteration 7640, the loss is 4.5243381774280955, parameters k is 11.48680426877638 and b is -49.50467193677283\n",
      "Iteration 7641, the loss is 4.524337689790424, parameters k is 11.486786968381123 and b is -49.50464031621947\n",
      "Iteration 7642, the loss is 4.524337184903529, parameters k is 11.486819565219069 and b is -49.504600790527775\n",
      "Iteration 7643, the loss is 4.524336535321995, parameters k is 11.486802264823812 and b is -49.50456916997442\n",
      "Iteration 7644, the loss is 4.5243358857404585, parameters k is 11.486784964428555 and b is -49.50453754942106\n",
      "Iteration 7645, the loss is 4.524335348544257, parameters k is 11.486767664033298 and b is -49.5045059288677\n",
      "Iteration 7646, the loss is 4.524334893215895, parameters k is 11.486800260871243 and b is -49.504466403176004\n",
      "Iteration 7647, the loss is 4.524334243634361, parameters k is 11.486782960475987 and b is -49.504434782622646\n",
      "Iteration 7648, the loss is 4.524333594052824, parameters k is 11.48676566008073 and b is -49.50440316206929\n",
      "Iteration 7649, the loss is 4.524333007298083, parameters k is 11.486748359685473 and b is -49.50437154151593\n",
      "Iteration 7650, the loss is 4.524332601528253, parameters k is 11.486780956523418 and b is -49.50433201582423\n",
      "Iteration 7651, the loss is 4.524331951946716, parameters k is 11.486763656128161 and b is -49.504300395270874\n",
      "Iteration 7652, the loss is 4.524331302365184, parameters k is 11.486746355732905 and b is -49.50426877471752\n",
      "Iteration 7653, the loss is 4.524330666051919, parameters k is 11.486729055337648 and b is -49.50423715416416\n",
      "Iteration 7654, the loss is 4.524330309840623, parameters k is 11.486761652175593 and b is -49.50419762847246\n",
      "Iteration 7655, the loss is 4.524329660259082, parameters k is 11.486744351780336 and b is -49.5041660079191\n",
      "Iteration 7656, the loss is 4.524329010677546, parameters k is 11.48672705138508 and b is -49.504134387365745\n",
      "Iteration 7657, the loss is 4.524328361096014, parameters k is 11.486709750989823 and b is -49.50410276681239\n",
      "Iteration 7658, the loss is 4.524327981862721, parameters k is 11.486692450594566 and b is -49.50407114625903\n",
      "Iteration 7659, the loss is 4.524327368571443, parameters k is 11.486725047432511 and b is -49.50403162056733\n",
      "Iteration 7660, the loss is 4.524326718989909, parameters k is 11.486707747037254 and b is -49.504000000013974\n",
      "Iteration 7661, the loss is 4.5243260694083745, parameters k is 11.486690446641997 and b is -49.503968379460616\n",
      "Iteration 7662, the loss is 4.52432564061655, parameters k is 11.48667314624674 and b is -49.50393675890726\n",
      "Iteration 7663, the loss is 4.524325076883804, parameters k is 11.486705743084686 and b is -49.50389723321556\n",
      "Iteration 7664, the loss is 4.524324427302271, parameters k is 11.48668844268943 and b is -49.5038656126622\n",
      "Iteration 7665, the loss is 4.5243237777207375, parameters k is 11.486671142294172 and b is -49.503833992108845\n",
      "Iteration 7666, the loss is 4.524323299370389, parameters k is 11.486653841898915 and b is -49.50380237155549\n",
      "Iteration 7667, the loss is 4.524322785196168, parameters k is 11.48668643873686 and b is -49.50376284586379\n",
      "Iteration 7668, the loss is 4.5243221356146375, parameters k is 11.486669138341604 and b is -49.50373122531043\n",
      "Iteration 7669, the loss is 4.524321486033099, parameters k is 11.486651837946347 and b is -49.503699604757074\n",
      "Iteration 7670, the loss is 4.524320958124217, parameters k is 11.48663453755109 and b is -49.503667984203716\n",
      "Iteration 7671, the loss is 4.5243204935085295, parameters k is 11.486667134389036 and b is -49.50362845851202\n",
      "Iteration 7672, the loss is 4.524319843926993, parameters k is 11.486649833993779 and b is -49.50359683795866\n",
      "Iteration 7673, the loss is 4.524319194345461, parameters k is 11.486632533598522 and b is -49.5035652174053\n",
      "Iteration 7674, the loss is 4.5243186168780465, parameters k is 11.486615233203265 and b is -49.503533596851945\n",
      "Iteration 7675, the loss is 4.524318201820894, parameters k is 11.48664783004121 and b is -49.50349407116025\n",
      "Iteration 7676, the loss is 4.524317552239357, parameters k is 11.486630529645954 and b is -49.50346245060689\n",
      "Iteration 7677, the loss is 4.5243169026578265, parameters k is 11.486613229250697 and b is -49.50343083005353\n",
      "Iteration 7678, the loss is 4.524316275631885, parameters k is 11.48659592885544 and b is -49.503399209500174\n",
      "Iteration 7679, the loss is 4.524315910133255, parameters k is 11.486628525693385 and b is -49.503359683808476\n",
      "Iteration 7680, the loss is 4.524315260551722, parameters k is 11.486611225298129 and b is -49.50332806325512\n",
      "Iteration 7681, the loss is 4.524314610970184, parameters k is 11.486593924902872 and b is -49.50329644270176\n",
      "Iteration 7682, the loss is 4.524313961388649, parameters k is 11.486576624507615 and b is -49.5032648221484\n",
      "Iteration 7683, the loss is 4.524313591442677, parameters k is 11.486559324112358 and b is -49.503233201595044\n",
      "Iteration 7684, the loss is 4.5243129688640815, parameters k is 11.486591920950303 and b is -49.50319367590335\n",
      "Iteration 7685, the loss is 4.524312319282551, parameters k is 11.486574620555047 and b is -49.50316205534999\n",
      "Iteration 7686, the loss is 4.52431166970101, parameters k is 11.48655732015979 and b is -49.50313043479663\n",
      "Iteration 7687, the loss is 4.524311250196518, parameters k is 11.486540019764533 and b is -49.50309881424327\n",
      "Iteration 7688, the loss is 4.524310677176444, parameters k is 11.486572616602478 and b is -49.503059288551576\n",
      "Iteration 7689, the loss is 4.524310027594909, parameters k is 11.486555316207221 and b is -49.50302766799822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7690, the loss is 4.524309378013376, parameters k is 11.486538015811965 and b is -49.50299604744486\n",
      "Iteration 7691, the loss is 4.524308908950342, parameters k is 11.486520715416708 and b is -49.5029644268915\n",
      "Iteration 7692, the loss is 4.5243083854888075, parameters k is 11.486553312254653 and b is -49.502924901199805\n",
      "Iteration 7693, the loss is 4.524307735907272, parameters k is 11.486536011859396 and b is -49.50289328064645\n",
      "Iteration 7694, the loss is 4.52430708632574, parameters k is 11.48651871146414 and b is -49.50286166009309\n",
      "Iteration 7695, the loss is 4.5243065677041745, parameters k is 11.486501411068883 and b is -49.50283003953973\n",
      "Iteration 7696, the loss is 4.524306093801171, parameters k is 11.486534007906828 and b is -49.50279051384803\n",
      "Iteration 7697, the loss is 4.524305444219637, parameters k is 11.486516707511571 and b is -49.502758893294676\n",
      "Iteration 7698, the loss is 4.5243047946381, parameters k is 11.486499407116314 and b is -49.50272727274132\n",
      "Iteration 7699, the loss is 4.524304226458003, parameters k is 11.486482106721057 and b is -49.50269565218796\n",
      "Iteration 7700, the loss is 4.524303802113535, parameters k is 11.486514703559003 and b is -49.50265612649626\n",
      "Iteration 7701, the loss is 4.524303152532, parameters k is 11.486497403163746 and b is -49.502624505942904\n",
      "Iteration 7702, the loss is 4.5243025029504675, parameters k is 11.486480102768489 and b is -49.50259288538955\n",
      "Iteration 7703, the loss is 4.524301885211842, parameters k is 11.486462802373232 and b is -49.50256126483619\n",
      "Iteration 7704, the loss is 4.524301510425893, parameters k is 11.486495399211178 and b is -49.50252173914449\n",
      "Iteration 7705, the loss is 4.524300860844362, parameters k is 11.48647809881592 and b is -49.50249011859113\n",
      "Iteration 7706, the loss is 4.524300211262824, parameters k is 11.486460798420664 and b is -49.502458498037775\n",
      "Iteration 7707, the loss is 4.5242995616812856, parameters k is 11.486443498025407 and b is -49.50242687748442\n",
      "Iteration 7708, the loss is 4.524299201022636, parameters k is 11.48642619763015 and b is -49.50239525693106\n",
      "Iteration 7709, the loss is 4.524298569156722, parameters k is 11.486458794468096 and b is -49.50235573123936\n",
      "Iteration 7710, the loss is 4.524297919575194, parameters k is 11.486441494072839 and b is -49.502324110686004\n",
      "Iteration 7711, the loss is 4.5242972699936574, parameters k is 11.486424193677582 and b is -49.502292490132646\n",
      "Iteration 7712, the loss is 4.524296859776466, parameters k is 11.486406893282325 and b is -49.50226086957929\n",
      "Iteration 7713, the loss is 4.524296277469086, parameters k is 11.48643949012027 and b is -49.50222134388759\n",
      "Iteration 7714, the loss is 4.5242956278875495, parameters k is 11.486422189725014 and b is -49.50218972333423\n",
      "Iteration 7715, the loss is 4.524294978306015, parameters k is 11.486404889329757 and b is -49.502158102780875\n",
      "Iteration 7716, the loss is 4.524294518530301, parameters k is 11.4863875889345 and b is -49.50212648222752\n",
      "Iteration 7717, the loss is 4.524293985781447, parameters k is 11.486420185772445 and b is -49.50208695653582\n",
      "Iteration 7718, the loss is 4.524293336199915, parameters k is 11.486402885377188 and b is -49.50205533598246\n",
      "Iteration 7719, the loss is 4.5242926866183755, parameters k is 11.486385584981932 and b is -49.502023715429104\n",
      "Iteration 7720, the loss is 4.524292177284134, parameters k is 11.486368284586675 and b is -49.501992094875746\n",
      "Iteration 7721, the loss is 4.524291694093811, parameters k is 11.48640088142462 and b is -49.50195256918405\n",
      "Iteration 7722, the loss is 4.524291044512273, parameters k is 11.486383581029363 and b is -49.50192094863069\n",
      "Iteration 7723, the loss is 4.5242903949307385, parameters k is 11.486366280634106 and b is -49.50188932807733\n",
      "Iteration 7724, the loss is 4.524289836037961, parameters k is 11.48634898023885 and b is -49.501857707523975\n",
      "Iteration 7725, the loss is 4.524289402406176, parameters k is 11.486381577076795 and b is -49.50181818183228\n",
      "Iteration 7726, the loss is 4.524288752824634, parameters k is 11.486364276681538 and b is -49.50178656127892\n",
      "Iteration 7727, the loss is 4.5242881032431, parameters k is 11.486346976286281 and b is -49.50175494072556\n",
      "Iteration 7728, the loss is 4.524287494791798, parameters k is 11.486329675891024 and b is -49.501723320172204\n",
      "Iteration 7729, the loss is 4.524287110718537, parameters k is 11.48636227272897 and b is -49.501683794480506\n",
      "Iteration 7730, the loss is 4.524286461137001, parameters k is 11.486344972333713 and b is -49.50165217392715\n",
      "Iteration 7731, the loss is 4.524285811555461, parameters k is 11.486327671938456 and b is -49.50162055337379\n",
      "Iteration 7732, the loss is 4.5242851619739275, parameters k is 11.4863103715432 and b is -49.50158893282043\n",
      "Iteration 7733, the loss is 4.524284810602601, parameters k is 11.486293071147943 and b is -49.501557312267074\n",
      "Iteration 7734, the loss is 4.524284169449363, parameters k is 11.486325667985888 and b is -49.50151778657538\n",
      "Iteration 7735, the loss is 4.524283519867826, parameters k is 11.486308367590631 and b is -49.50148616602202\n",
      "Iteration 7736, the loss is 4.524282870286287, parameters k is 11.486291067195374 and b is -49.50145454546866\n",
      "Iteration 7737, the loss is 4.524282469356429, parameters k is 11.486273766800117 and b is -49.5014229249153\n",
      "Iteration 7738, the loss is 4.524281877761724, parameters k is 11.486306363638063 and b is -49.501383399223606\n",
      "Iteration 7739, the loss is 4.524281228180184, parameters k is 11.486289063242806 and b is -49.50135177867025\n",
      "Iteration 7740, the loss is 4.524280578598652, parameters k is 11.486271762847549 and b is -49.50132015811689\n",
      "Iteration 7741, the loss is 4.524280128110264, parameters k is 11.486254462452292 and b is -49.50128853756353\n",
      "Iteration 7742, the loss is 4.5242795860740905, parameters k is 11.486287059290238 and b is -49.501249011871835\n",
      "Iteration 7743, the loss is 4.5242789364925535, parameters k is 11.48626975889498 and b is -49.50121739131848\n",
      "Iteration 7744, the loss is 4.5242782869110165, parameters k is 11.486252458499724 and b is -49.50118577076512\n",
      "Iteration 7745, the loss is 4.524277786864091, parameters k is 11.486235158104467 and b is -49.50115415021176\n",
      "Iteration 7746, the loss is 4.52427729438645, parameters k is 11.486267754942412 and b is -49.50111462452006\n",
      "Iteration 7747, the loss is 4.524276644804913, parameters k is 11.486250454547156 and b is -49.501083003966706\n",
      "Iteration 7748, the loss is 4.524275995223383, parameters k is 11.486233154151899 and b is -49.50105138341335\n",
      "Iteration 7749, the loss is 4.524275445617922, parameters k is 11.486215853756642 and b is -49.50101976285999\n",
      "Iteration 7750, the loss is 4.524275002698811, parameters k is 11.486248450594587 and b is -49.50098023716829\n",
      "Iteration 7751, the loss is 4.524274353117277, parameters k is 11.48623115019933 and b is -49.500948616614934\n",
      "Iteration 7752, the loss is 4.5242737035357425, parameters k is 11.486213849804074 and b is -49.50091699606158\n",
      "Iteration 7753, the loss is 4.524273104371752, parameters k is 11.486196549408817 and b is -49.50088537550822\n",
      "Iteration 7754, the loss is 4.5242727110111725, parameters k is 11.486229146246762 and b is -49.50084584981652\n",
      "Iteration 7755, the loss is 4.524272061429636, parameters k is 11.486211845851505 and b is -49.50081422926316\n",
      "Iteration 7756, the loss is 4.524271411848106, parameters k is 11.486194545456248 and b is -49.500782608709805\n",
      "Iteration 7757, the loss is 4.524270763125588, parameters k is 11.486177245060992 and b is -49.50075098815645\n",
      "Iteration 7758, the loss is 4.52427041932354, parameters k is 11.486209841898937 and b is -49.50071146246475\n",
      "Iteration 7759, the loss is 4.524269769741999, parameters k is 11.48619254150368 and b is -49.50067984191139\n",
      "Iteration 7760, the loss is 4.524269120160465, parameters k is 11.486175241108423 and b is -49.500648221358034\n",
      "Iteration 7761, the loss is 4.524268470578931, parameters k is 11.486157940713166 and b is -49.500616600804676\n",
      "Iteration 7762, the loss is 4.524268078936383, parameters k is 11.48614064031791 and b is -49.50058498025132\n",
      "Iteration 7763, the loss is 4.5242674780543615, parameters k is 11.486173237155855 and b is -49.50054545455962\n",
      "Iteration 7764, the loss is 4.524266828472832, parameters k is 11.486155936760598 and b is -49.50051383400626\n",
      "Iteration 7765, the loss is 4.5242661788912875, parameters k is 11.486138636365341 and b is -49.500482213452905\n",
      "Iteration 7766, the loss is 4.5242657376902224, parameters k is 11.486121335970084 and b is -49.50045059289955\n",
      "Iteration 7767, the loss is 4.524265186366725, parameters k is 11.48615393280803 and b is -49.50041106720785\n",
      "Iteration 7768, the loss is 4.524264536785192, parameters k is 11.486136632412773 and b is -49.50037944665449\n",
      "Iteration 7769, the loss is 4.524263887203655, parameters k is 11.486119332017516 and b is -49.500347826101134\n",
      "Iteration 7770, the loss is 4.524263396444051, parameters k is 11.48610203162226 and b is -49.500316205547776\n",
      "Iteration 7771, the loss is 4.524262894679091, parameters k is 11.486134628460205 and b is -49.50027667985608\n",
      "Iteration 7772, the loss is 4.524262245097555, parameters k is 11.486117328064948 and b is -49.50024505930272\n",
      "Iteration 7773, the loss is 4.524261595516018, parameters k is 11.486100027669691 and b is -49.50021343874936\n",
      "Iteration 7774, the loss is 4.524261055197881, parameters k is 11.486082727274434 and b is -49.500181818196005\n",
      "Iteration 7775, the loss is 4.524260602991449, parameters k is 11.48611532411238 and b is -49.50014229250431\n",
      "Iteration 7776, the loss is 4.524259953409916, parameters k is 11.486098023717123 and b is -49.50011067195095\n",
      "Iteration 7777, the loss is 4.524259303828382, parameters k is 11.486080723321866 and b is -49.50007905139759\n",
      "Iteration 7778, the loss is 4.5242587139517125, parameters k is 11.486063422926609 and b is -49.50004743084423\n",
      "Iteration 7779, the loss is 4.524258311303812, parameters k is 11.486096019764554 and b is -49.500007905152536\n",
      "Iteration 7780, the loss is 4.524257661722278, parameters k is 11.486078719369297 and b is -49.49997628459918\n",
      "Iteration 7781, the loss is 4.52425701214074, parameters k is 11.48606141897404 and b is -49.49994466404582\n",
      "Iteration 7782, the loss is 4.524256372705546, parameters k is 11.486044118578784 and b is -49.49991304349246\n",
      "Iteration 7783, the loss is 4.524256019616179, parameters k is 11.48607671541673 and b is -49.499873517800765\n",
      "Iteration 7784, the loss is 4.52425537003464, parameters k is 11.486059415021472 and b is -49.49984189724741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7785, the loss is 4.524254720453109, parameters k is 11.486042114626215 and b is -49.49981027669405\n",
      "Iteration 7786, the loss is 4.524254070871567, parameters k is 11.486024814230959 and b is -49.49977865614069\n",
      "Iteration 7787, the loss is 4.524253688516347, parameters k is 11.486007513835702 and b is -49.49974703558733\n",
      "Iteration 7788, the loss is 4.524253078347003, parameters k is 11.486040110673647 and b is -49.499707509895636\n",
      "Iteration 7789, the loss is 4.524252428765466, parameters k is 11.48602281027839 and b is -49.49967588934228\n",
      "Iteration 7790, the loss is 4.524251779183933, parameters k is 11.486005509883134 and b is -49.49964426878892\n",
      "Iteration 7791, the loss is 4.524251347270173, parameters k is 11.485988209487877 and b is -49.49961264823556\n",
      "Iteration 7792, the loss is 4.5242507866593655, parameters k is 11.486020806325822 and b is -49.499573122543865\n",
      "Iteration 7793, the loss is 4.524250137077829, parameters k is 11.486003505930565 and b is -49.49954150199051\n",
      "Iteration 7794, the loss is 4.524249487496294, parameters k is 11.485986205535308 and b is -49.49950988143715\n",
      "Iteration 7795, the loss is 4.524249006024005, parameters k is 11.485968905140052 and b is -49.49947826088379\n",
      "Iteration 7796, the loss is 4.524248494971726, parameters k is 11.486001501977997 and b is -49.49943873519209\n",
      "Iteration 7797, the loss is 4.524247845390193, parameters k is 11.48598420158274 and b is -49.499407114638736\n",
      "Iteration 7798, the loss is 4.524247195808662, parameters k is 11.485966901187483 and b is -49.49937549408538\n",
      "Iteration 7799, the loss is 4.524246664777838, parameters k is 11.485949600792226 and b is -49.49934387353202\n",
      "Iteration 7800, the loss is 4.524246203284092, parameters k is 11.485982197630172 and b is -49.49930434784032\n",
      "Iteration 7801, the loss is 4.52424555370256, parameters k is 11.485964897234915 and b is -49.499272727286964\n",
      "Iteration 7802, the loss is 4.52424490412102, parameters k is 11.485947596839658 and b is -49.499241106733606\n",
      "Iteration 7803, the loss is 4.524244323531672, parameters k is 11.485930296444401 and b is -49.49920948618025\n",
      "Iteration 7804, the loss is 4.524243911596457, parameters k is 11.485962893282347 and b is -49.49916996048855\n",
      "Iteration 7805, the loss is 4.524243262014914, parameters k is 11.48594559288709 and b is -49.49913833993519\n",
      "Iteration 7806, the loss is 4.524242612433377, parameters k is 11.485928292491833 and b is -49.499106719381835\n",
      "Iteration 7807, the loss is 4.524241982285503, parameters k is 11.485910992096576 and b is -49.49907509882848\n",
      "Iteration 7808, the loss is 4.524241619908816, parameters k is 11.485943588934521 and b is -49.49903557313678\n",
      "Iteration 7809, the loss is 4.524240970327282, parameters k is 11.485926288539265 and b is -49.49900395258342\n",
      "Iteration 7810, the loss is 4.524240320745739, parameters k is 11.485908988144008 and b is -49.498972332030064\n",
      "Iteration 7811, the loss is 4.524239671164211, parameters k is 11.485891687748751 and b is -49.498940711476706\n",
      "Iteration 7812, the loss is 4.5242392980963055, parameters k is 11.485874387353494 and b is -49.49890909092335\n",
      "Iteration 7813, the loss is 4.52423867863964, parameters k is 11.48590698419144 and b is -49.49886956523165\n",
      "Iteration 7814, the loss is 4.524238029058107, parameters k is 11.485889683796183 and b is -49.49883794467829\n",
      "Iteration 7815, the loss is 4.524237379476575, parameters k is 11.485872383400926 and b is -49.498806324124935\n",
      "Iteration 7816, the loss is 4.524236956850138, parameters k is 11.485855083005669 and b is -49.49877470357158\n",
      "Iteration 7817, the loss is 4.524236386952, parameters k is 11.485887679843614 and b is -49.49873517787988\n",
      "Iteration 7818, the loss is 4.524235737370469, parameters k is 11.485870379448357 and b is -49.49870355732652\n",
      "Iteration 7819, the loss is 4.524235087788936, parameters k is 11.4858530790531 and b is -49.498671936773164\n",
      "Iteration 7820, the loss is 4.524234615603969, parameters k is 11.485835778657844 and b is -49.498640316219806\n",
      "Iteration 7821, the loss is 4.5242340952643625, parameters k is 11.485868375495789 and b is -49.49860079052811\n",
      "Iteration 7822, the loss is 4.524233445682827, parameters k is 11.485851075100532 and b is -49.49856916997475\n",
      "Iteration 7823, the loss is 4.524232796101302, parameters k is 11.485833774705275 and b is -49.49853754942139\n",
      "Iteration 7824, the loss is 4.5242322743577965, parameters k is 11.485816474310019 and b is -49.498505928868035\n",
      "Iteration 7825, the loss is 4.524231803576732, parameters k is 11.485849071147964 and b is -49.49846640317634\n",
      "Iteration 7826, the loss is 4.524231153995192, parameters k is 11.485831770752707 and b is -49.49843478262298\n",
      "Iteration 7827, the loss is 4.524230504413664, parameters k is 11.48581447035745 and b is -49.49840316206962\n",
      "Iteration 7828, the loss is 4.524229933111636, parameters k is 11.485797169962193 and b is -49.49837154151626\n",
      "Iteration 7829, the loss is 4.52422951188909, parameters k is 11.485829766800139 and b is -49.498332015824566\n",
      "Iteration 7830, the loss is 4.524228862307559, parameters k is 11.485812466404882 and b is -49.49830039527121\n",
      "Iteration 7831, the loss is 4.524228212726026, parameters k is 11.485795166009625 and b is -49.49826877471785\n",
      "Iteration 7832, the loss is 4.524227591865459, parameters k is 11.485777865614368 and b is -49.49823715416449\n",
      "Iteration 7833, the loss is 4.524227220201452, parameters k is 11.485810462452314 and b is -49.498197628472795\n",
      "Iteration 7834, the loss is 4.524226570619922, parameters k is 11.485793162057057 and b is -49.49816600791944\n",
      "Iteration 7835, the loss is 4.5242259210383855, parameters k is 11.4857758616618 and b is -49.49813438736608\n",
      "Iteration 7836, the loss is 4.524225271456853, parameters k is 11.485758561266543 and b is -49.49810276681272\n",
      "Iteration 7837, the loss is 4.524224907676261, parameters k is 11.485741260871286 and b is -49.49807114625936\n",
      "Iteration 7838, the loss is 4.524224278932282, parameters k is 11.485773857709232 and b is -49.498031620567666\n",
      "Iteration 7839, the loss is 4.524223629350749, parameters k is 11.485756557313975 and b is -49.49800000001431\n",
      "Iteration 7840, the loss is 4.524222979769218, parameters k is 11.485739256918718 and b is -49.49796837946095\n",
      "Iteration 7841, the loss is 4.524222566430096, parameters k is 11.485721956523461 and b is -49.49793675890759\n",
      "Iteration 7842, the loss is 4.5242219872446485, parameters k is 11.485754553361406 and b is -49.497897233215895\n",
      "Iteration 7843, the loss is 4.524221337663114, parameters k is 11.48573725296615 and b is -49.49786561266254\n",
      "Iteration 7844, the loss is 4.524220688081573, parameters k is 11.485719952570893 and b is -49.49783399210918\n",
      "Iteration 7845, the loss is 4.524220225183927, parameters k is 11.485702652175636 and b is -49.49780237155582\n",
      "Iteration 7846, the loss is 4.524219695557006, parameters k is 11.485735249013581 and b is -49.49776284586412\n",
      "Iteration 7847, the loss is 4.524219045975471, parameters k is 11.485717948618325 and b is -49.497731225310766\n",
      "Iteration 7848, the loss is 4.524218396393935, parameters k is 11.485700648223068 and b is -49.49769960475741\n",
      "Iteration 7849, the loss is 4.524217883937753, parameters k is 11.48568334782781 and b is -49.49766798420405\n",
      "Iteration 7850, the loss is 4.524217403869367, parameters k is 11.485715944665756 and b is -49.49762845851235\n",
      "Iteration 7851, the loss is 4.524216754287838, parameters k is 11.4856986442705 and b is -49.497596837958994\n",
      "Iteration 7852, the loss is 4.524216104706296, parameters k is 11.485681343875243 and b is -49.497565217405636\n",
      "Iteration 7853, the loss is 4.524215542691587, parameters k is 11.485664043479986 and b is -49.49753359685228\n",
      "Iteration 7854, the loss is 4.524215112181735, parameters k is 11.485696640317931 and b is -49.49749407116058\n",
      "Iteration 7855, the loss is 4.524214462600196, parameters k is 11.485679339922674 and b is -49.49746245060722\n",
      "Iteration 7856, the loss is 4.524213813018655, parameters k is 11.485662039527417 and b is -49.497430830053865\n",
      "Iteration 7857, the loss is 4.524213201445419, parameters k is 11.48564473913216 and b is -49.49739920950051\n",
      "Iteration 7858, the loss is 4.5242128204940935, parameters k is 11.485677335970106 and b is -49.49735968380881\n",
      "Iteration 7859, the loss is 4.524212170912557, parameters k is 11.485660035574849 and b is -49.49732806325545\n",
      "Iteration 7860, the loss is 4.524211521331024, parameters k is 11.485642735179592 and b is -49.497296442702094\n",
      "Iteration 7861, the loss is 4.524210871749492, parameters k is 11.485625434784335 and b is -49.497264822148736\n",
      "Iteration 7862, the loss is 4.524210517256219, parameters k is 11.485608134389079 and b is -49.49723320159538\n",
      "Iteration 7863, the loss is 4.524209879224923, parameters k is 11.485640731227024 and b is -49.49719367590368\n",
      "Iteration 7864, the loss is 4.524209229643383, parameters k is 11.485623430831767 and b is -49.49716205535032\n",
      "Iteration 7865, the loss is 4.524208580061853, parameters k is 11.48560613043651 and b is -49.497130434796965\n",
      "Iteration 7866, the loss is 4.524208176010048, parameters k is 11.485588830041253 and b is -49.49709881424361\n",
      "Iteration 7867, the loss is 4.524207587537286, parameters k is 11.485621426879199 and b is -49.49705928855191\n",
      "Iteration 7868, the loss is 4.52420693795575, parameters k is 11.485604126483942 and b is -49.49702766799855\n",
      "Iteration 7869, the loss is 4.524206288374212, parameters k is 11.485586826088685 and b is -49.496996047445194\n",
      "Iteration 7870, the loss is 4.524205834763881, parameters k is 11.485569525693428 and b is -49.496964426891836\n",
      "Iteration 7871, the loss is 4.524205295849646, parameters k is 11.485602122531374 and b is -49.49692490120014\n",
      "Iteration 7872, the loss is 4.524204646268111, parameters k is 11.485584822136117 and b is -49.49689328064678\n",
      "Iteration 7873, the loss is 4.524203996686572, parameters k is 11.48556752174086 and b is -49.49686166009342\n",
      "Iteration 7874, the loss is 4.524203493517712, parameters k is 11.485550221345603 and b is -49.496830039540065\n",
      "Iteration 7875, the loss is 4.524203004162013, parameters k is 11.485582818183548 and b is -49.49679051384837\n",
      "Iteration 7876, the loss is 4.524202354580473, parameters k is 11.485565517788292 and b is -49.49675889329501\n",
      "Iteration 7877, the loss is 4.524201704998934, parameters k is 11.485548217393035 and b is -49.49672727274165\n",
      "Iteration 7878, the loss is 4.5242011522715435, parameters k is 11.485530916997778 and b is -49.49669565218829\n",
      "Iteration 7879, the loss is 4.524200712474369, parameters k is 11.485563513835723 and b is -49.496656126496596\n",
      "Iteration 7880, the loss is 4.524200062892838, parameters k is 11.485546213440466 and b is -49.49662450594324\n",
      "Iteration 7881, the loss is 4.524199413311299, parameters k is 11.48552891304521 and b is -49.49659288538988\n",
      "Iteration 7882, the loss is 4.5241988110253795, parameters k is 11.485511612649953 and b is -49.49656126483652\n",
      "Iteration 7883, the loss is 4.524198420786736, parameters k is 11.485544209487898 and b is -49.496521739144825\n",
      "Iteration 7884, the loss is 4.524197771205193, parameters k is 11.485526909092641 and b is -49.49649011859147\n",
      "Iteration 7885, the loss is 4.524197121623661, parameters k is 11.485509608697384 and b is -49.49645849803811\n",
      "Iteration 7886, the loss is 4.524196472042128, parameters k is 11.485492308302128 and b is -49.49642687748475\n",
      "Iteration 7887, the loss is 4.524196126836175, parameters k is 11.48547500790687 and b is -49.49639525693139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7888, the loss is 4.524195479517561, parameters k is 11.485507604744816 and b is -49.496355731239696\n",
      "Iteration 7889, the loss is 4.524194829936023, parameters k is 11.48549030434956 and b is -49.49632411068634\n",
      "Iteration 7890, the loss is 4.524194180354492, parameters k is 11.485473003954302 and b is -49.49629249013298\n",
      "Iteration 7891, the loss is 4.524193785590011, parameters k is 11.485455703559046 and b is -49.49626086957962\n",
      "Iteration 7892, the loss is 4.524193187829927, parameters k is 11.485488300396991 and b is -49.496221343887925\n",
      "Iteration 7893, the loss is 4.524192538248386, parameters k is 11.485471000001734 and b is -49.49618972333457\n",
      "Iteration 7894, the loss is 4.524191888666854, parameters k is 11.485453699606477 and b is -49.49615810278121\n",
      "Iteration 7895, the loss is 4.524191444343838, parameters k is 11.48543639921122 and b is -49.49612648222785\n",
      "Iteration 7896, the loss is 4.524190896142288, parameters k is 11.485468996049166 and b is -49.49608695653615\n",
      "Iteration 7897, the loss is 4.524190246560752, parameters k is 11.485451695653909 and b is -49.496055335982795\n",
      "Iteration 7898, the loss is 4.524189596979215, parameters k is 11.485434395258652 and b is -49.49602371542944\n",
      "Iteration 7899, the loss is 4.524189103097671, parameters k is 11.485417094863395 and b is -49.49599209487608\n",
      "Iteration 7900, the loss is 4.524188604454646, parameters k is 11.48544969170134 and b is -49.49595256918438\n",
      "Iteration 7901, the loss is 4.5241879548731125, parameters k is 11.485432391306084 and b is -49.495920948631024\n",
      "Iteration 7902, the loss is 4.524187305291575, parameters k is 11.485415090910827 and b is -49.495889328077666\n",
      "Iteration 7903, the loss is 4.524186761851504, parameters k is 11.48539779051557 and b is -49.49585770752431\n",
      "Iteration 7904, the loss is 4.524186312767009, parameters k is 11.485430387353516 and b is -49.49581818183261\n",
      "Iteration 7905, the loss is 4.524185663185476, parameters k is 11.485413086958259 and b is -49.49578656127925\n",
      "Iteration 7906, the loss is 4.52418501360394, parameters k is 11.485395786563002 and b is -49.495754940725895\n",
      "Iteration 7907, the loss is 4.524184420605332, parameters k is 11.485378486167745 and b is -49.49572332017254\n",
      "Iteration 7908, the loss is 4.524184021079376, parameters k is 11.48541108300569 and b is -49.49568379448084\n",
      "Iteration 7909, the loss is 4.524183371497839, parameters k is 11.485393782610434 and b is -49.49565217392748\n",
      "Iteration 7910, the loss is 4.524182721916301, parameters k is 11.485376482215177 and b is -49.495620553374124\n",
      "Iteration 7911, the loss is 4.524182079359168, parameters k is 11.48535918181992 and b is -49.495588932820766\n",
      "Iteration 7912, the loss is 4.524181729391733, parameters k is 11.485391778657865 and b is -49.49554940712907\n",
      "Iteration 7913, the loss is 4.524181079810203, parameters k is 11.485374478262608 and b is -49.49551778657571\n",
      "Iteration 7914, the loss is 4.524180430228665, parameters k is 11.485357177867352 and b is -49.49548616602235\n",
      "Iteration 7915, the loss is 4.524179780647129, parameters k is 11.485339877472095 and b is -49.495454545468995\n",
      "Iteration 7916, the loss is 4.524179395169971, parameters k is 11.485322577076838 and b is -49.49542292491564\n",
      "Iteration 7917, the loss is 4.524178788122562, parameters k is 11.485355173914783 and b is -49.49538339922394\n",
      "Iteration 7918, the loss is 4.5241781385410285, parameters k is 11.485337873519526 and b is -49.49535177867058\n",
      "Iteration 7919, the loss is 4.524177488959487, parameters k is 11.48532057312427 and b is -49.495320158117224\n",
      "Iteration 7920, the loss is 4.524177053923796, parameters k is 11.485303272729013 and b is -49.495288537563866\n",
      "Iteration 7921, the loss is 4.524176496434926, parameters k is 11.485335869566958 and b is -49.49524901187217\n",
      "Iteration 7922, the loss is 4.524175846853385, parameters k is 11.485318569171701 and b is -49.49521739131881\n",
      "Iteration 7923, the loss is 4.524175197271852, parameters k is 11.485301268776444 and b is -49.49518577076545\n",
      "Iteration 7924, the loss is 4.5241747126776275, parameters k is 11.485283968381188 and b is -49.495154150212095\n",
      "Iteration 7925, the loss is 4.524174204747288, parameters k is 11.485316565219133 and b is -49.4951146245204\n",
      "Iteration 7926, the loss is 4.524173555165751, parameters k is 11.485299264823876 and b is -49.49508300396704\n",
      "Iteration 7927, the loss is 4.524172905584218, parameters k is 11.48528196442862 and b is -49.49505138341368\n",
      "Iteration 7928, the loss is 4.524172371431463, parameters k is 11.485264664033362 and b is -49.49501976286032\n",
      "Iteration 7929, the loss is 4.524171913059649, parameters k is 11.485297260871308 and b is -49.494980237168626\n",
      "Iteration 7930, the loss is 4.524171263478111, parameters k is 11.485279960476051 and b is -49.49494861661527\n",
      "Iteration 7931, the loss is 4.524170613896577, parameters k is 11.485262660080794 and b is -49.49491699606191\n",
      "Iteration 7932, the loss is 4.524170030185296, parameters k is 11.485245359685537 and b is -49.49488537550855\n",
      "Iteration 7933, the loss is 4.524169621372013, parameters k is 11.485277956523483 and b is -49.494845849816855\n",
      "Iteration 7934, the loss is 4.524168971790472, parameters k is 11.485260656128226 and b is -49.4948142292635\n",
      "Iteration 7935, the loss is 4.524168322208942, parameters k is 11.485243355732969 and b is -49.49478260871014\n",
      "Iteration 7936, the loss is 4.5241676889391265, parameters k is 11.485226055337712 and b is -49.49475098815678\n",
      "Iteration 7937, the loss is 4.524167329684379, parameters k is 11.485258652175657 and b is -49.494711462465084\n",
      "Iteration 7938, the loss is 4.524166680102837, parameters k is 11.4852413517804 and b is -49.494679841911726\n",
      "Iteration 7939, the loss is 4.524166030521301, parameters k is 11.485224051385144 and b is -49.49464822135837\n",
      "Iteration 7940, the loss is 4.524165380939766, parameters k is 11.485206750989887 and b is -49.49461660080501\n",
      "Iteration 7941, the loss is 4.524165004749928, parameters k is 11.48518945059463 and b is -49.49458498025165\n",
      "Iteration 7942, the loss is 4.524164388415198, parameters k is 11.485222047432575 and b is -49.494545454559955\n",
      "Iteration 7943, the loss is 4.524163738833662, parameters k is 11.485204747037319 and b is -49.4945138340066\n",
      "Iteration 7944, the loss is 4.524163089252133, parameters k is 11.485187446642062 and b is -49.49448221345324\n",
      "Iteration 7945, the loss is 4.524162663503756, parameters k is 11.485170146246805 and b is -49.49445059289988\n",
      "Iteration 7946, the loss is 4.524162096727564, parameters k is 11.48520274308475 and b is -49.49441106720818\n",
      "Iteration 7947, the loss is 4.524161447146026, parameters k is 11.485185442689493 and b is -49.494379446654825\n",
      "Iteration 7948, the loss is 4.524160797564499, parameters k is 11.485168142294237 and b is -49.49434782610147\n",
      "Iteration 7949, the loss is 4.524160322257591, parameters k is 11.48515084189898 and b is -49.49431620554811\n",
      "Iteration 7950, the loss is 4.524159805039926, parameters k is 11.485183438736925 and b is -49.49427667985641\n",
      "Iteration 7951, the loss is 4.52415915545839, parameters k is 11.485166138341668 and b is -49.494245059303054\n",
      "Iteration 7952, the loss is 4.524158505876859, parameters k is 11.485148837946412 and b is -49.494213438749696\n",
      "Iteration 7953, the loss is 4.524157981011421, parameters k is 11.485131537551155 and b is -49.49418181819634\n",
      "Iteration 7954, the loss is 4.5241575133522876, parameters k is 11.4851641343891 and b is -49.49414229250464\n",
      "Iteration 7955, the loss is 4.524156863770747, parameters k is 11.485146833993843 and b is -49.49411067195128\n",
      "Iteration 7956, the loss is 4.524156214189216, parameters k is 11.485129533598586 and b is -49.494079051397925\n",
      "Iteration 7957, the loss is 4.524155639765252, parameters k is 11.48511223320333 and b is -49.49404743084457\n",
      "Iteration 7958, the loss is 4.524155221664655, parameters k is 11.485144830041275 and b is -49.49400790515287\n",
      "Iteration 7959, the loss is 4.5241545720831144, parameters k is 11.485127529646018 and b is -49.49397628459951\n",
      "Iteration 7960, the loss is 4.524153922501579, parameters k is 11.485110229250761 and b is -49.493944664046154\n",
      "Iteration 7961, the loss is 4.524153298519082, parameters k is 11.485092928855504 and b is -49.493913043492796\n",
      "Iteration 7962, the loss is 4.524152929977014, parameters k is 11.48512552569345 and b is -49.4938735178011\n",
      "Iteration 7963, the loss is 4.524152280395475, parameters k is 11.485108225298193 and b is -49.49384189724774\n",
      "Iteration 7964, the loss is 4.524151630813943, parameters k is 11.485090924902936 and b is -49.49381027669438\n",
      "Iteration 7965, the loss is 4.524150981232407, parameters k is 11.48507362450768 and b is -49.493778656141025\n",
      "Iteration 7966, the loss is 4.524150614329888, parameters k is 11.485056324112422 and b is -49.49374703558767\n",
      "Iteration 7967, the loss is 4.524149988707843, parameters k is 11.485088920950368 and b is -49.49370750989597\n",
      "Iteration 7968, the loss is 4.524149339126306, parameters k is 11.48507162055511 and b is -49.49367588934261\n",
      "Iteration 7969, the loss is 4.524148689544769, parameters k is 11.485054320159854 and b is -49.493644268789254\n",
      "Iteration 7970, the loss is 4.524148273083721, parameters k is 11.485037019764597 and b is -49.493612648235896\n",
      "Iteration 7971, the loss is 4.5241476970202035, parameters k is 11.485069616602543 and b is -49.4935731225442\n",
      "Iteration 7972, the loss is 4.524147047438666, parameters k is 11.485052316207286 and b is -49.49354150199084\n",
      "Iteration 7973, the loss is 4.524146397857134, parameters k is 11.485035015812029 and b is -49.49350988143748\n",
      "Iteration 7974, the loss is 4.524145931837548, parameters k is 11.485017715416772 and b is -49.493478260884125\n",
      "Iteration 7975, the loss is 4.524145405332569, parameters k is 11.485050312254717 and b is -49.49343873519243\n",
      "Iteration 7976, the loss is 4.5241447557510295, parameters k is 11.48503301185946 and b is -49.49340711463907\n",
      "Iteration 7977, the loss is 4.5241441061694925, parameters k is 11.485015711464204 and b is -49.49337549408571\n",
      "Iteration 7978, the loss is 4.524143590591381, parameters k is 11.484998411068947 and b is -49.49334387353235\n",
      "Iteration 7979, the loss is 4.524143113644931, parameters k is 11.485031007906892 and b is -49.493304347840656\n",
      "Iteration 7980, the loss is 4.524142464063393, parameters k is 11.485013707511635 and b is -49.4932727272873\n",
      "Iteration 7981, the loss is 4.5241418144818555, parameters k is 11.484996407116379 and b is -49.49324110673394\n",
      "Iteration 7982, the loss is 4.52414124934521, parameters k is 11.484979106721122 and b is -49.49320948618058\n",
      "Iteration 7983, the loss is 4.524140821957294, parameters k is 11.485011703559067 and b is -49.493169960488885\n",
      "Iteration 7984, the loss is 4.524140172375757, parameters k is 11.48499440316381 and b is -49.49313833993553\n",
      "Iteration 7985, the loss is 4.524139522794225, parameters k is 11.484977102768553 and b is -49.49310671938217\n",
      "Iteration 7986, the loss is 4.5241389080990455, parameters k is 11.484959802373297 and b is -49.49307509882881\n",
      "Iteration 7987, the loss is 4.5241385302696555, parameters k is 11.484992399211242 and b is -49.493035573137114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7988, the loss is 4.524137880688116, parameters k is 11.484975098815985 and b is -49.493003952583756\n",
      "Iteration 7989, the loss is 4.524137231106582, parameters k is 11.484957798420728 and b is -49.4929723320304\n",
      "Iteration 7990, the loss is 4.524136581525047, parameters k is 11.484940498025471 and b is -49.49294071147704\n",
      "Iteration 7991, the loss is 4.524136223909842, parameters k is 11.484923197630215 and b is -49.49290909092368\n",
      "Iteration 7992, the loss is 4.524135589000474, parameters k is 11.48495579446816 and b is -49.492869565231985\n",
      "Iteration 7993, the loss is 4.524134939418944, parameters k is 11.484938494072903 and b is -49.49283794467863\n",
      "Iteration 7994, the loss is 4.524134289837408, parameters k is 11.484921193677646 and b is -49.49280632412527\n",
      "Iteration 7995, the loss is 4.524133882663669, parameters k is 11.48490389328239 and b is -49.49277470357191\n",
      "Iteration 7996, the loss is 4.524133297312845, parameters k is 11.484936490120335 and b is -49.49273517788021\n",
      "Iteration 7997, the loss is 4.52413264773131, parameters k is 11.484919189725078 and b is -49.492703557326855\n",
      "Iteration 7998, the loss is 4.524131998149773, parameters k is 11.484901889329821 and b is -49.4926719367735\n",
      "Iteration 7999, the loss is 4.5241315414175105, parameters k is 11.484884588934564 and b is -49.49264031622014\n",
      "Iteration 8000, the loss is 4.524131005625205, parameters k is 11.48491718577251 and b is -49.49260079052844\n",
      "Iteration 8001, the loss is 4.524130356043672, parameters k is 11.484899885377253 and b is -49.492569169975084\n",
      "Iteration 8002, the loss is 4.524129706462128, parameters k is 11.484882584981996 and b is -49.492537549421726\n",
      "Iteration 8003, the loss is 4.5241292001713385, parameters k is 11.48486528458674 and b is -49.49250592886837\n",
      "Iteration 8004, the loss is 4.524128713937567, parameters k is 11.484897881424684 and b is -49.49246640317667\n",
      "Iteration 8005, the loss is 4.524128064356033, parameters k is 11.484880581029428 and b is -49.49243478262331\n",
      "Iteration 8006, the loss is 4.524127414774495, parameters k is 11.48486328063417 and b is -49.492403162069955\n",
      "Iteration 8007, the loss is 4.524126858925169, parameters k is 11.484845980238914 and b is -49.4923715415166\n",
      "Iteration 8008, the loss is 4.524126422249931, parameters k is 11.48487857707686 and b is -49.4923320158249\n",
      "Iteration 8009, the loss is 4.524125772668394, parameters k is 11.484861276681603 and b is -49.49230039527154\n",
      "Iteration 8010, the loss is 4.524125123086857, parameters k is 11.484843976286346 and b is -49.492268774718184\n",
      "Iteration 8011, the loss is 4.524124517679001, parameters k is 11.484826675891089 and b is -49.492237154164826\n",
      "Iteration 8012, the loss is 4.5241241305622895, parameters k is 11.484859272729034 and b is -49.49219762847313\n",
      "Iteration 8013, the loss is 4.524123480980756, parameters k is 11.484841972333777 and b is -49.49216600791977\n",
      "Iteration 8014, the loss is 4.524122831399218, parameters k is 11.48482467193852 and b is -49.49213438736641\n",
      "Iteration 8015, the loss is 4.524122181817686, parameters k is 11.484807371543264 and b is -49.492102766813055\n",
      "Iteration 8016, the loss is 4.5241218334898, parameters k is 11.484790071148007 and b is -49.4920711462597\n",
      "Iteration 8017, the loss is 4.5241211892931155, parameters k is 11.484822667985952 and b is -49.492031620568\n",
      "Iteration 8018, the loss is 4.524120539711584, parameters k is 11.484805367590695 and b is -49.49200000001464\n",
      "Iteration 8019, the loss is 4.524119890130049, parameters k is 11.484788067195439 and b is -49.491968379461284\n",
      "Iteration 8020, the loss is 4.524119492243631, parameters k is 11.484770766800182 and b is -49.491936758907926\n",
      "Iteration 8021, the loss is 4.524118897605481, parameters k is 11.484803363638127 and b is -49.49189723321623\n",
      "Iteration 8022, the loss is 4.524118248023947, parameters k is 11.48478606324287 and b is -49.49186561266287\n",
      "Iteration 8023, the loss is 4.524117598442414, parameters k is 11.484768762847613 and b is -49.49183399210951\n",
      "Iteration 8024, the loss is 4.524117150997463, parameters k is 11.484751462452357 and b is -49.491802371556155\n",
      "Iteration 8025, the loss is 4.524116605917843, parameters k is 11.484784059290302 and b is -49.49176284586446\n",
      "Iteration 8026, the loss is 4.524115956336312, parameters k is 11.484766758895045 and b is -49.4917312253111\n",
      "Iteration 8027, the loss is 4.524115306754775, parameters k is 11.484749458499788 and b is -49.49169960475774\n",
      "Iteration 8028, the loss is 4.5241148097512935, parameters k is 11.484732158104531 and b is -49.49166798420438\n",
      "Iteration 8029, the loss is 4.524114314230207, parameters k is 11.484764754942477 and b is -49.491628458512686\n",
      "Iteration 8030, the loss is 4.524113664648669, parameters k is 11.48474745454722 and b is -49.49159683795933\n",
      "Iteration 8031, the loss is 4.524113015067135, parameters k is 11.484730154151963 and b is -49.49156521740597\n",
      "Iteration 8032, the loss is 4.524112468505122, parameters k is 11.484712853756706 and b is -49.49153359685261\n",
      "Iteration 8033, the loss is 4.524112022542562, parameters k is 11.484745450594652 and b is -49.491494071160915\n",
      "Iteration 8034, the loss is 4.524111372961029, parameters k is 11.484728150199395 and b is -49.49146245060756\n",
      "Iteration 8035, the loss is 4.524110723379499, parameters k is 11.484710849804138 and b is -49.4914308300542\n",
      "Iteration 8036, the loss is 4.524110127258957, parameters k is 11.484693549408881 and b is -49.49139920950084\n",
      "Iteration 8037, the loss is 4.524109730854932, parameters k is 11.484726146246826 and b is -49.491359683809144\n",
      "Iteration 8038, the loss is 4.524109081273401, parameters k is 11.48470884585157 and b is -49.491328063255786\n",
      "Iteration 8039, the loss is 4.524108431691861, parameters k is 11.484691545456313 and b is -49.49129644270243\n",
      "Iteration 8040, the loss is 4.524107786012795, parameters k is 11.484674245061056 and b is -49.49126482214907\n",
      "Iteration 8041, the loss is 4.5241074391672935, parameters k is 11.484706841899001 and b is -49.49122529645737\n",
      "Iteration 8042, the loss is 4.5241067895857565, parameters k is 11.484689541503744 and b is -49.491193675904015\n",
      "Iteration 8043, the loss is 4.524106140004228, parameters k is 11.484672241108488 and b is -49.49116205535066\n",
      "Iteration 8044, the loss is 4.524105490422688, parameters k is 11.48465494071323 and b is -49.4911304347973\n",
      "Iteration 8045, the loss is 4.524105101823592, parameters k is 11.484637640317974 and b is -49.49109881424394\n",
      "Iteration 8046, the loss is 4.524104497898121, parameters k is 11.48467023715592 and b is -49.49105928855224\n",
      "Iteration 8047, the loss is 4.524103848316587, parameters k is 11.484652936760662 and b is -49.491027667998885\n",
      "Iteration 8048, the loss is 4.524103198735052, parameters k is 11.484635636365406 and b is -49.49099604744553\n",
      "Iteration 8049, the loss is 4.5241027605774216, parameters k is 11.484618335970149 and b is -49.49096442689217\n",
      "Iteration 8050, the loss is 4.524102206210484, parameters k is 11.484650932808094 and b is -49.49092490120047\n",
      "Iteration 8051, the loss is 4.524101556628948, parameters k is 11.484633632412837 and b is -49.490893280647114\n",
      "Iteration 8052, the loss is 4.524100907047412, parameters k is 11.48461633201758 and b is -49.490861660093756\n",
      "Iteration 8053, the loss is 4.524100419331256, parameters k is 11.484599031622324 and b is -49.4908300395404\n",
      "Iteration 8054, the loss is 4.5240999145228455, parameters k is 11.484631628460269 and b is -49.4907905138487\n",
      "Iteration 8055, the loss is 4.524099264941309, parameters k is 11.484614328065012 and b is -49.49075889329534\n",
      "Iteration 8056, the loss is 4.524098615359772, parameters k is 11.484597027669755 and b is -49.490727272741985\n",
      "Iteration 8057, the loss is 4.524098078085086, parameters k is 11.484579727274498 and b is -49.49069565218863\n",
      "Iteration 8058, the loss is 4.524097622835211, parameters k is 11.484612324112444 and b is -49.49065612649693\n",
      "Iteration 8059, the loss is 4.524096973253673, parameters k is 11.484595023717187 and b is -49.49062450594357\n",
      "Iteration 8060, the loss is 4.524096323672137, parameters k is 11.48457772332193 and b is -49.490592885390214\n",
      "Iteration 8061, the loss is 4.524095736838915, parameters k is 11.484560422926673 and b is -49.490561264836856\n",
      "Iteration 8062, the loss is 4.52409533114757, parameters k is 11.484593019764619 and b is -49.49052173914516\n",
      "Iteration 8063, the loss is 4.524094681566034, parameters k is 11.484575719369362 and b is -49.4904901185918\n",
      "Iteration 8064, the loss is 4.524094031984498, parameters k is 11.484558418974105 and b is -49.49045849803844\n",
      "Iteration 8065, the loss is 4.5240933955927485, parameters k is 11.484541118578848 and b is -49.490426877485085\n",
      "Iteration 8066, the loss is 4.524093039459937, parameters k is 11.484573715416794 and b is -49.49038735179339\n",
      "Iteration 8067, the loss is 4.5240923898783985, parameters k is 11.484556415021537 and b is -49.49035573124003\n",
      "Iteration 8068, the loss is 4.5240917402968615, parameters k is 11.48453911462628 and b is -49.49032411068667\n",
      "Iteration 8069, the loss is 4.524091090715323, parameters k is 11.484521814231023 and b is -49.490292490133314\n",
      "Iteration 8070, the loss is 4.524090711403548, parameters k is 11.484504513835766 and b is -49.490260869579956\n",
      "Iteration 8071, the loss is 4.524090098190761, parameters k is 11.484537110673712 and b is -49.49022134388826\n",
      "Iteration 8072, the loss is 4.524089448609227, parameters k is 11.484519810278455 and b is -49.4901897233349\n",
      "Iteration 8073, the loss is 4.524088799027686, parameters k is 11.484502509883198 and b is -49.49015810278154\n",
      "Iteration 8074, the loss is 4.524088370157386, parameters k is 11.484485209487941 and b is -49.490126482228185\n",
      "Iteration 8075, the loss is 4.524087806503124, parameters k is 11.484517806325886 and b is -49.49008695653649\n",
      "Iteration 8076, the loss is 4.5240871569215875, parameters k is 11.48450050593063 and b is -49.49005533598313\n",
      "Iteration 8077, the loss is 4.524086507340054, parameters k is 11.484483205535373 and b is -49.49002371542977\n",
      "Iteration 8078, the loss is 4.5240860289112135, parameters k is 11.484465905140116 and b is -49.48999209487641\n",
      "Iteration 8079, the loss is 4.524085514815486, parameters k is 11.484498501978061 and b is -49.489952569184716\n",
      "Iteration 8080, the loss is 4.52408486523395, parameters k is 11.484481201582804 and b is -49.48992094863136\n",
      "Iteration 8081, the loss is 4.524084215652421, parameters k is 11.484463901187548 and b is -49.489889328078\n",
      "Iteration 8082, the loss is 4.524083687665047, parameters k is 11.48444660079229 and b is -49.48985770752464\n",
      "Iteration 8083, the loss is 4.524083223127847, parameters k is 11.484479197630236 and b is -49.489818181832945\n",
      "Iteration 8084, the loss is 4.524082573546314, parameters k is 11.48446189723498 and b is -49.48978656127959\n",
      "Iteration 8085, the loss is 4.524081923964776, parameters k is 11.484444596839722 and b is -49.48975494072623\n",
      "Iteration 8086, the loss is 4.52408134641888, parameters k is 11.484427296444466 and b is -49.48972332017287\n",
      "Iteration 8087, the loss is 4.52408093144021, parameters k is 11.484459893282411 and b is -49.489683794481174\n",
      "Iteration 8088, the loss is 4.52408028185867, parameters k is 11.484442592887154 and b is -49.489652173927816\n",
      "Iteration 8089, the loss is 4.524079632277138, parameters k is 11.484425292491897 and b is -49.48962055337446\n",
      "Iteration 8090, the loss is 4.524079005172708, parameters k is 11.48440799209664 and b is -49.4895889328211\n",
      "Iteration 8091, the loss is 4.524078639752573, parameters k is 11.484440588934586 and b is -49.4895494071294\n",
      "Iteration 8092, the loss is 4.524077990171039, parameters k is 11.484423288539329 and b is -49.489517786576045\n",
      "Iteration 8093, the loss is 4.524077340589502, parameters k is 11.484405988144072 and b is -49.48948616602269\n",
      "Iteration 8094, the loss is 4.524076691007969, parameters k is 11.484388687748815 and b is -49.48945454546933\n",
      "Iteration 8095, the loss is 4.52407632098351, parameters k is 11.484371387353558 and b is -49.48942292491597\n",
      "Iteration 8096, the loss is 4.524075698483399, parameters k is 11.484403984191504 and b is -49.48938339922427\n",
      "Iteration 8097, the loss is 4.524075048901867, parameters k is 11.484386683796247 and b is -49.489351778670915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8098, the loss is 4.52407439932033, parameters k is 11.48436938340099 and b is -49.48932015811756\n",
      "Iteration 8099, the loss is 4.524073979737335, parameters k is 11.484352083005733 and b is -49.4892885375642\n",
      "Iteration 8100, the loss is 4.524073406795759, parameters k is 11.484384679843679 and b is -49.4892490118725\n",
      "Iteration 8101, the loss is 4.524072757214228, parameters k is 11.484367379448422 and b is -49.489217391319144\n",
      "Iteration 8102, the loss is 4.524072107632688, parameters k is 11.484350079053165 and b is -49.489185770765786\n",
      "Iteration 8103, the loss is 4.52407163849117, parameters k is 11.484332778657908 and b is -49.48915415021243\n",
      "Iteration 8104, the loss is 4.524071115108123, parameters k is 11.484365375495853 and b is -49.48911462452073\n",
      "Iteration 8105, the loss is 4.524070465526588, parameters k is 11.484348075100597 and b is -49.48908300396737\n",
      "Iteration 8106, the loss is 4.524069815945048, parameters k is 11.48433077470534 and b is -49.489051383414015\n",
      "Iteration 8107, the loss is 4.524069297245002, parameters k is 11.484313474310083 and b is -49.48901976286066\n",
      "Iteration 8108, the loss is 4.52406882342049, parameters k is 11.484346071148028 and b is -49.48898023716896\n",
      "Iteration 8109, the loss is 4.524068173838955, parameters k is 11.484328770752771 and b is -49.4889486166156\n",
      "Iteration 8110, the loss is 4.524067524257416, parameters k is 11.484311470357515 and b is -49.488916996062244\n",
      "Iteration 8111, the loss is 4.52406695599883, parameters k is 11.484294169962258 and b is -49.488885375508886\n",
      "Iteration 8112, the loss is 4.524066531732847, parameters k is 11.484326766800203 and b is -49.48884584981719\n",
      "Iteration 8113, the loss is 4.524065882151316, parameters k is 11.484309466404946 and b is -49.48881422926383\n",
      "Iteration 8114, the loss is 4.5240652325697805, parameters k is 11.48429216600969 and b is -49.48878260871047\n",
      "Iteration 8115, the loss is 4.524064614752668, parameters k is 11.484274865614433 and b is -49.488750988157115\n",
      "Iteration 8116, the loss is 4.5240642400452105, parameters k is 11.484307462452378 and b is -49.48871146246542\n",
      "Iteration 8117, the loss is 4.524063590463674, parameters k is 11.484290162057121 and b is -49.48867984191206\n",
      "Iteration 8118, the loss is 4.5240629408821444, parameters k is 11.484272861661864 and b is -49.4886482213587\n",
      "Iteration 8119, the loss is 4.524062291300609, parameters k is 11.484255561266608 and b is -49.488616600805344\n",
      "Iteration 8120, the loss is 4.5240619305634615, parameters k is 11.48423826087135 and b is -49.488584980251986\n",
      "Iteration 8121, the loss is 4.524061298776043, parameters k is 11.484270857709296 and b is -49.48854545456029\n",
      "Iteration 8122, the loss is 4.524060649194506, parameters k is 11.48425355731404 and b is -49.48851383400693\n",
      "Iteration 8123, the loss is 4.524059999612969, parameters k is 11.484236256918782 and b is -49.48848221345357\n",
      "Iteration 8124, the loss is 4.524059589317301, parameters k is 11.484218956523526 and b is -49.488450592900215\n",
      "Iteration 8125, the loss is 4.524059007088405, parameters k is 11.48425155336147 and b is -49.48841106720852\n",
      "Iteration 8126, the loss is 4.5240583575068625, parameters k is 11.484234252966214 and b is -49.48837944665516\n",
      "Iteration 8127, the loss is 4.524057707925332, parameters k is 11.484216952570957 and b is -49.4883478261018\n",
      "Iteration 8128, the loss is 4.524057248071128, parameters k is 11.4841996521757 and b is -49.48831620554844\n",
      "Iteration 8129, the loss is 4.524056715400764, parameters k is 11.484232249013646 and b is -49.488276679856746\n",
      "Iteration 8130, the loss is 4.524056065819229, parameters k is 11.484214948618389 and b is -49.48824505930339\n",
      "Iteration 8131, the loss is 4.524055416237695, parameters k is 11.484197648223132 and b is -49.48821343875003\n",
      "Iteration 8132, the loss is 4.524054906824958, parameters k is 11.484180347827875 and b is -49.48818181819667\n",
      "Iteration 8133, the loss is 4.524054423713126, parameters k is 11.48421294466582 and b is -49.488142292504975\n",
      "Iteration 8134, the loss is 4.524053774131593, parameters k is 11.484195644270564 and b is -49.48811067195162\n",
      "Iteration 8135, the loss is 4.524053124550054, parameters k is 11.484178343875307 and b is -49.48807905139826\n",
      "Iteration 8136, the loss is 4.524052565578793, parameters k is 11.48416104348005 and b is -49.4880474308449\n",
      "Iteration 8137, the loss is 4.5240521320254885, parameters k is 11.484193640317995 and b is -49.488007905153204\n",
      "Iteration 8138, the loss is 4.5240514824439595, parameters k is 11.484176339922739 and b is -49.487976284599846\n",
      "Iteration 8139, the loss is 4.524050832862418, parameters k is 11.484159039527482 and b is -49.48794466404649\n",
      "Iteration 8140, the loss is 4.524050224332626, parameters k is 11.484141739132225 and b is -49.48791304349313\n",
      "Iteration 8141, the loss is 4.5240498403378515, parameters k is 11.48417433597017 and b is -49.48787351780143\n",
      "Iteration 8142, the loss is 4.5240491907563145, parameters k is 11.484157035574913 and b is -49.487841897248074\n",
      "Iteration 8143, the loss is 4.524048541174779, parameters k is 11.484139735179657 and b is -49.48781027669472\n",
      "Iteration 8144, the loss is 4.524047891593241, parameters k is 11.4841224347844 and b is -49.48777865614136\n",
      "Iteration 8145, the loss is 4.524047540143426, parameters k is 11.484105134389143 and b is -49.487747035588\n",
      "Iteration 8146, the loss is 4.5240468990686775, parameters k is 11.484137731227088 and b is -49.4877075098963\n",
      "Iteration 8147, the loss is 4.524046249487142, parameters k is 11.484120430831831 and b is -49.487675889342945\n",
      "Iteration 8148, the loss is 4.524045599905609, parameters k is 11.484103130436575 and b is -49.48764426878959\n",
      "Iteration 8149, the loss is 4.524045198897254, parameters k is 11.484085830041318 and b is -49.48761264823623\n",
      "Iteration 8150, the loss is 4.524044607381041, parameters k is 11.484118426879263 and b is -49.48757312254453\n",
      "Iteration 8151, the loss is 4.5240439577995035, parameters k is 11.484101126484006 and b is -49.487541501991174\n",
      "Iteration 8152, the loss is 4.524043308217968, parameters k is 11.48408382608875 and b is -49.487509881437816\n",
      "Iteration 8153, the loss is 4.5240428576510885, parameters k is 11.484066525693493 and b is -49.48747826088446\n",
      "Iteration 8154, the loss is 4.524042315693404, parameters k is 11.484099122531438 and b is -49.48743873519276\n",
      "Iteration 8155, the loss is 4.524041666111871, parameters k is 11.484081822136181 and b is -49.4874071146394\n",
      "Iteration 8156, the loss is 4.524041016530328, parameters k is 11.484064521740924 and b is -49.487375494086045\n",
      "Iteration 8157, the loss is 4.524040516404918, parameters k is 11.484047221345667 and b is -49.48734387353269\n",
      "Iteration 8158, the loss is 4.524040024005762, parameters k is 11.484079818183613 and b is -49.48730434784099\n",
      "Iteration 8159, the loss is 4.524039374424229, parameters k is 11.484062517788356 and b is -49.48727272728763\n",
      "Iteration 8160, the loss is 4.524038724842699, parameters k is 11.4840452173931 and b is -49.487241106734274\n",
      "Iteration 8161, the loss is 4.524038175158753, parameters k is 11.484027916997842 and b is -49.487209486180916\n",
      "Iteration 8162, the loss is 4.524037732318124, parameters k is 11.484060513835788 and b is -49.48716996048922\n",
      "Iteration 8163, the loss is 4.524037082736591, parameters k is 11.48404321344053 and b is -49.48713833993586\n",
      "Iteration 8164, the loss is 4.524036433155061, parameters k is 11.484025913045274 and b is -49.4871067193825\n",
      "Iteration 8165, the loss is 4.524035833912587, parameters k is 11.484008612650017 and b is -49.487075098829145\n",
      "Iteration 8166, the loss is 4.524035440630489, parameters k is 11.484041209487962 and b is -49.48703557313745\n",
      "Iteration 8167, the loss is 4.524034791048954, parameters k is 11.484023909092706 and b is -49.48700395258409\n",
      "Iteration 8168, the loss is 4.524034141467426, parameters k is 11.484006608697449 and b is -49.48697233203073\n",
      "Iteration 8169, the loss is 4.524033492666421, parameters k is 11.483989308302192 and b is -49.486940711477374\n",
      "Iteration 8170, the loss is 4.524033148942851, parameters k is 11.484021905140137 and b is -49.486901185785676\n",
      "Iteration 8171, the loss is 4.5240324993613195, parameters k is 11.48400460474488 and b is -49.48686956523232\n",
      "Iteration 8172, the loss is 4.524031849779782, parameters k is 11.483987304349624 and b is -49.48683794467896\n",
      "Iteration 8173, the loss is 4.524031200198247, parameters k is 11.483970003954367 and b is -49.4868063241256\n",
      "Iteration 8174, the loss is 4.524030808477211, parameters k is 11.48395270355911 and b is -49.486774703572245\n",
      "Iteration 8175, the loss is 4.524030207673679, parameters k is 11.483985300397055 and b is -49.48673517788055\n",
      "Iteration 8176, the loss is 4.524029558092146, parameters k is 11.483968000001799 and b is -49.48670355732719\n",
      "Iteration 8177, the loss is 4.524028908510609, parameters k is 11.483950699606542 and b is -49.48667193677383\n",
      "Iteration 8178, the loss is 4.524028467231044, parameters k is 11.483933399211285 and b is -49.48664031622047\n",
      "Iteration 8179, the loss is 4.524027915986046, parameters k is 11.48396599604923 and b is -49.486600790528776\n",
      "Iteration 8180, the loss is 4.524027266404508, parameters k is 11.483948695653973 and b is -49.48656916997542\n",
      "Iteration 8181, the loss is 4.524026616822979, parameters k is 11.483931395258717 and b is -49.48653754942206\n",
      "Iteration 8182, the loss is 4.524026125984876, parameters k is 11.48391409486346 and b is -49.4865059288687\n",
      "Iteration 8183, the loss is 4.524025624298404, parameters k is 11.483946691701405 and b is -49.486466403177005\n",
      "Iteration 8184, the loss is 4.524024974716869, parameters k is 11.483929391306148 and b is -49.48643478262365\n",
      "Iteration 8185, the loss is 4.524024325135333, parameters k is 11.483912090910891 and b is -49.48640316207029\n",
      "Iteration 8186, the loss is 4.524023784738705, parameters k is 11.483894790515635 and b is -49.48637154151693\n",
      "Iteration 8187, the loss is 4.524023332610765, parameters k is 11.48392738735358 and b is -49.486332015825234\n",
      "Iteration 8188, the loss is 4.52402268302923, parameters k is 11.483910086958323 and b is -49.486300395271876\n",
      "Iteration 8189, the loss is 4.5240220334476975, parameters k is 11.483892786563066 and b is -49.48626877471852\n",
      "Iteration 8190, the loss is 4.52402144349254, parameters k is 11.48387548616781 and b is -49.48623715416516\n",
      "Iteration 8191, the loss is 4.524021040923132, parameters k is 11.483908083005755 and b is -49.48619762847346\n",
      "Iteration 8192, the loss is 4.524020391341594, parameters k is 11.483890782610498 and b is -49.486166007920104\n",
      "Iteration 8193, the loss is 4.524019741760056, parameters k is 11.483873482215241 and b is -49.48613438736675\n",
      "Iteration 8194, the loss is 4.524019102246371, parameters k is 11.483856181819984 and b is -49.48610276681339\n",
      "Iteration 8195, the loss is 4.524018749235492, parameters k is 11.48388877865793 and b is -49.48606324112169\n",
      "Iteration 8196, the loss is 4.524018099653958, parameters k is 11.483871478262673 and b is -49.48603162056833\n",
      "Iteration 8197, the loss is 4.524017450072417, parameters k is 11.483854177867416 and b is -49.486000000014975\n",
      "Iteration 8198, the loss is 4.524016800490883, parameters k is 11.483836877472159 and b is -49.48596837946162\n",
      "Iteration 8199, the loss is 4.524016418057171, parameters k is 11.483819577076902 and b is -49.48593675890826\n",
      "Iteration 8200, the loss is 4.524015807966323, parameters k is 11.483852173914848 and b is -49.48589723321656\n",
      "Iteration 8201, the loss is 4.52401515838478, parameters k is 11.48383487351959 and b is -49.485865612663204\n",
      "Iteration 8202, the loss is 4.524014508803245, parameters k is 11.483817573124334 and b is -49.485833992109846\n",
      "Iteration 8203, the loss is 4.524014076811006, parameters k is 11.483800272729077 and b is -49.48580237155649\n",
      "Iteration 8204, the loss is 4.524013516278683, parameters k is 11.483832869567022 and b is -49.48576284586479\n",
      "Iteration 8205, the loss is 4.524012866697146, parameters k is 11.483815569171766 and b is -49.48573122531143\n",
      "Iteration 8206, the loss is 4.524012217115615, parameters k is 11.483798268776509 and b is -49.485699604758075\n",
      "Iteration 8207, the loss is 4.524011735564831, parameters k is 11.483780968381252 and b is -49.48566798420472\n",
      "Iteration 8208, the loss is 4.524011224591046, parameters k is 11.483813565219197 and b is -49.48562845851302\n",
      "Iteration 8209, the loss is 4.524010575009505, parameters k is 11.48379626482394 and b is -49.48559683795966\n",
      "Iteration 8210, the loss is 4.524009925427974, parameters k is 11.483778964428684 and b is -49.485565217406304\n",
      "Iteration 8211, the loss is 4.524009394318672, parameters k is 11.483761664033427 and b is -49.485533596852946\n",
      "Iteration 8212, the loss is 4.524008932903407, parameters k is 11.483794260871372 and b is -49.48549407116125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8213, the loss is 4.524008283321869, parameters k is 11.483776960476115 and b is -49.48546245060789\n",
      "Iteration 8214, the loss is 4.524007633740341, parameters k is 11.483759660080858 and b is -49.48543083005453\n",
      "Iteration 8215, the loss is 4.524007053072501, parameters k is 11.483742359685602 and b is -49.485399209501175\n",
      "Iteration 8216, the loss is 4.524006641215771, parameters k is 11.483774956523547 and b is -49.48535968380948\n",
      "Iteration 8217, the loss is 4.524005991634231, parameters k is 11.48375765612829 and b is -49.48532806325612\n",
      "Iteration 8218, the loss is 4.524005342052697, parameters k is 11.483740355733033 and b is -49.48529644270276\n",
      "Iteration 8219, the loss is 4.524004711826331, parameters k is 11.483723055337776 and b is -49.485264822149404\n",
      "Iteration 8220, the loss is 4.524004349528134, parameters k is 11.483755652175722 and b is -49.485225296457706\n",
      "Iteration 8221, the loss is 4.524003699946603, parameters k is 11.483738351780465 and b is -49.48519367590435\n",
      "Iteration 8222, the loss is 4.524003050365063, parameters k is 11.483721051385208 and b is -49.48516205535099\n",
      "Iteration 8223, the loss is 4.524002400783526, parameters k is 11.483703750989951 and b is -49.48513043479763\n",
      "Iteration 8224, the loss is 4.524002027637129, parameters k is 11.483686450594695 and b is -49.485098814244274\n",
      "Iteration 8225, the loss is 4.524001408258958, parameters k is 11.48371904743264 and b is -49.48505928855258\n",
      "Iteration 8226, the loss is 4.52400075867742, parameters k is 11.483701747037383 and b is -49.48502766799922\n",
      "Iteration 8227, the loss is 4.524000109095887, parameters k is 11.483684446642126 and b is -49.48499604744586\n",
      "Iteration 8228, the loss is 4.523999686390967, parameters k is 11.48366714624687 and b is -49.4849644268925\n",
      "Iteration 8229, the loss is 4.523999116571323, parameters k is 11.483699743084815 and b is -49.484924901200806\n",
      "Iteration 8230, the loss is 4.523998466989781, parameters k is 11.483682442689558 and b is -49.48489328064745\n",
      "Iteration 8231, the loss is 4.523997817408251, parameters k is 11.483665142294301 and b is -49.48486166009409\n",
      "Iteration 8232, the loss is 4.523997345144791, parameters k is 11.483647841899044 and b is -49.48483003954073\n",
      "Iteration 8233, the loss is 4.523996824883682, parameters k is 11.48368043873699 and b is -49.484790513849035\n",
      "Iteration 8234, the loss is 4.52399617530215, parameters k is 11.483663138341733 and b is -49.48475889329568\n",
      "Iteration 8235, the loss is 4.523995525720612, parameters k is 11.483645837946476 and b is -49.48472727274232\n",
      "Iteration 8236, the loss is 4.5239950038986265, parameters k is 11.483628537551219 and b is -49.48469565218896\n",
      "Iteration 8237, the loss is 4.523994533196045, parameters k is 11.483661134389164 and b is -49.48465612649726\n",
      "Iteration 8238, the loss is 4.523993883614512, parameters k is 11.483643833993908 and b is -49.484624505943906\n",
      "Iteration 8239, the loss is 4.523993234032974, parameters k is 11.48362653359865 and b is -49.48459288539055\n",
      "Iteration 8240, the loss is 4.523992662652455, parameters k is 11.483609233203394 and b is -49.48456126483719\n",
      "Iteration 8241, the loss is 4.523992241508407, parameters k is 11.48364183004134 and b is -49.48452173914549\n",
      "Iteration 8242, the loss is 4.523991591926876, parameters k is 11.483624529646082 and b is -49.484490118592134\n",
      "Iteration 8243, the loss is 4.523990942345336, parameters k is 11.483607229250826 and b is -49.48445849803878\n",
      "Iteration 8244, the loss is 4.523990321406289, parameters k is 11.483589928855569 and b is -49.48442687748542\n",
      "Iteration 8245, the loss is 4.5239899498207725, parameters k is 11.483622525693514 and b is -49.48438735179372\n",
      "Iteration 8246, the loss is 4.523989300239233, parameters k is 11.483605225298257 and b is -49.48435573124036\n",
      "Iteration 8247, the loss is 4.523988650657699, parameters k is 11.483587924903 and b is -49.484324110687005\n",
      "Iteration 8248, the loss is 4.523988001076169, parameters k is 11.483570624507744 and b is -49.48429249013365\n",
      "Iteration 8249, the loss is 4.523987637217089, parameters k is 11.483553324112487 and b is -49.48426086958029\n",
      "Iteration 8250, the loss is 4.5239870085515985, parameters k is 11.483585920950432 and b is -49.48422134388859\n",
      "Iteration 8251, the loss is 4.523986358970064, parameters k is 11.483568620555175 and b is -49.484189723335234\n",
      "Iteration 8252, the loss is 4.523985709388526, parameters k is 11.483551320159918 and b is -49.484158102781876\n",
      "Iteration 8253, the loss is 4.523985295970919, parameters k is 11.483534019764662 and b is -49.48412648222852\n",
      "Iteration 8254, the loss is 4.52398471686396, parameters k is 11.483566616602607 and b is -49.48408695653682\n",
      "Iteration 8255, the loss is 4.523984067282424, parameters k is 11.48354931620735 and b is -49.48405533598346\n",
      "Iteration 8256, the loss is 4.52398341770089, parameters k is 11.483532015812093 and b is -49.484023715430105\n",
      "Iteration 8257, the loss is 4.523982954724748, parameters k is 11.483514715416836 and b is -49.48399209487675\n",
      "Iteration 8258, the loss is 4.523982425176328, parameters k is 11.483547312254782 and b is -49.48395256918505\n",
      "Iteration 8259, the loss is 4.523981775594789, parameters k is 11.483530011859525 and b is -49.48392094863169\n",
      "Iteration 8260, the loss is 4.523981126013255, parameters k is 11.483512711464268 and b is -49.483889328078334\n",
      "Iteration 8261, the loss is 4.523980613478585, parameters k is 11.483495411069011 and b is -49.483857707524976\n",
      "Iteration 8262, the loss is 4.523980133488688, parameters k is 11.483528007906957 and b is -49.48381818183328\n",
      "Iteration 8263, the loss is 4.523979483907146, parameters k is 11.4835107075117 and b is -49.48378656127992\n",
      "Iteration 8264, the loss is 4.5239788343256135, parameters k is 11.483493407116443 and b is -49.48375494072656\n",
      "Iteration 8265, the loss is 4.523978272232414, parameters k is 11.483476106721186 and b is -49.483723320173205\n",
      "Iteration 8266, the loss is 4.52397784180105, parameters k is 11.483508703559131 and b is -49.48368379448151\n",
      "Iteration 8267, the loss is 4.523977192219512, parameters k is 11.483491403163875 and b is -49.48365217392815\n",
      "Iteration 8268, the loss is 4.523976542637977, parameters k is 11.483474102768618 and b is -49.48362055337479\n",
      "Iteration 8269, the loss is 4.5239759309862455, parameters k is 11.483456802373361 and b is -49.483588932821434\n",
      "Iteration 8270, the loss is 4.52397555011341, parameters k is 11.483489399211306 and b is -49.483549407129736\n",
      "Iteration 8271, the loss is 4.523974900531876, parameters k is 11.48347209881605 and b is -49.48351778657638\n",
      "Iteration 8272, the loss is 4.523974250950335, parameters k is 11.483454798420793 and b is -49.48348616602302\n",
      "Iteration 8273, the loss is 4.523973601368805, parameters k is 11.483437498025536 and b is -49.48345454546966\n",
      "Iteration 8274, the loss is 4.523973246797048, parameters k is 11.483420197630279 and b is -49.483422924916304\n",
      "Iteration 8275, the loss is 4.523972608844234, parameters k is 11.483452794468224 and b is -49.48338339922461\n",
      "Iteration 8276, the loss is 4.523971959262702, parameters k is 11.483435494072967 and b is -49.48335177867125\n",
      "Iteration 8277, the loss is 4.523971309681164, parameters k is 11.48341819367771 and b is -49.48332015811789\n",
      "Iteration 8278, the loss is 4.523970905550878, parameters k is 11.483400893282454 and b is -49.48328853756453\n",
      "Iteration 8279, the loss is 4.5239703171566, parameters k is 11.4834334901204 and b is -49.483249011872836\n",
      "Iteration 8280, the loss is 4.523969667575061, parameters k is 11.483416189725142 and b is -49.48321739131948\n",
      "Iteration 8281, the loss is 4.523969017993531, parameters k is 11.483398889329886 and b is -49.48318577076612\n",
      "Iteration 8282, the loss is 4.523968564304706, parameters k is 11.483381588934629 and b is -49.48315415021276\n",
      "Iteration 8283, the loss is 4.52396802546896, parameters k is 11.483414185772574 and b is -49.483114624521065\n",
      "Iteration 8284, the loss is 4.523967375887428, parameters k is 11.483396885377317 and b is -49.48308300396771\n",
      "Iteration 8285, the loss is 4.523966726305894, parameters k is 11.48337958498206 and b is -49.48305138341435\n",
      "Iteration 8286, the loss is 4.523966223058543, parameters k is 11.483362284586804 and b is -49.48301976286099\n",
      "Iteration 8287, the loss is 4.523965733781325, parameters k is 11.483394881424749 and b is -49.48298023716929\n",
      "Iteration 8288, the loss is 4.523965084199786, parameters k is 11.483377581029492 and b is -49.482948616615936\n",
      "Iteration 8289, the loss is 4.523964434618255, parameters k is 11.483360280634235 and b is -49.48291699606258\n",
      "Iteration 8290, the loss is 4.523963881812375, parameters k is 11.483342980238978 and b is -49.48288537550922\n",
      "Iteration 8291, the loss is 4.523963442093687, parameters k is 11.483375577076924 and b is -49.48284584981752\n",
      "Iteration 8292, the loss is 4.52396279251215, parameters k is 11.483358276681667 and b is -49.482814229264164\n",
      "Iteration 8293, the loss is 4.523962142930619, parameters k is 11.48334097628641 and b is -49.48278260871081\n",
      "Iteration 8294, the loss is 4.523961540566208, parameters k is 11.483323675891153 and b is -49.48275098815745\n",
      "Iteration 8295, the loss is 4.523961150406054, parameters k is 11.483356272729099 and b is -49.48271146246575\n",
      "Iteration 8296, the loss is 4.523960500824512, parameters k is 11.483338972333842 and b is -49.48267984191239\n",
      "Iteration 8297, the loss is 4.523959851242984, parameters k is 11.483321671938585 and b is -49.482648221359035\n",
      "Iteration 8298, the loss is 4.523959201661447, parameters k is 11.483304371543328 and b is -49.48261660080568\n",
      "Iteration 8299, the loss is 4.523958856377008, parameters k is 11.483287071148071 and b is -49.48258498025232\n",
      "Iteration 8300, the loss is 4.523958209136875, parameters k is 11.483319667986017 and b is -49.48254545456062\n",
      "Iteration 8301, the loss is 4.52395755955534, parameters k is 11.48330236759076 and b is -49.482513834007264\n",
      "Iteration 8302, the loss is 4.523956909973808, parameters k is 11.483285067195503 and b is -49.482482213453906\n",
      "Iteration 8303, the loss is 4.5239565151308385, parameters k is 11.483267766800246 and b is -49.48245059290055\n",
      "Iteration 8304, the loss is 4.52395591744924, parameters k is 11.483300363638191 and b is -49.48241106720885\n",
      "Iteration 8305, the loss is 4.523955267867711, parameters k is 11.483283063242935 and b is -49.48237944665549\n",
      "Iteration 8306, the loss is 4.523954618286166, parameters k is 11.483265762847678 and b is -49.482347826102135\n",
      "Iteration 8307, the loss is 4.523954173884673, parameters k is 11.483248462452421 and b is -49.48231620554878\n",
      "Iteration 8308, the loss is 4.5239536257616, parameters k is 11.483281059290366 and b is -49.48227667985708\n",
      "Iteration 8309, the loss is 4.523952976180069, parameters k is 11.48326375889511 and b is -49.48224505930372\n",
      "Iteration 8310, the loss is 4.523952326598529, parameters k is 11.483246458499853 and b is -49.482213438750364\n",
      "Iteration 8311, the loss is 4.523951832638499, parameters k is 11.483229158104596 and b is -49.482181818197006\n",
      "Iteration 8312, the loss is 4.523951334073963, parameters k is 11.483261754942541 and b is -49.48214229250531\n",
      "Iteration 8313, the loss is 4.523950684492428, parameters k is 11.483244454547284 and b is -49.48211067195195\n",
      "Iteration 8314, the loss is 4.523950034910896, parameters k is 11.483227154152027 and b is -49.48207905139859\n",
      "Iteration 8315, the loss is 4.523949491392329, parameters k is 11.48320985375677 and b is -49.482047430845235\n",
      "Iteration 8316, the loss is 4.523949042386329, parameters k is 11.483242450594716 and b is -49.48200790515354\n",
      "Iteration 8317, the loss is 4.523948392804794, parameters k is 11.483225150199459 and b is -49.48197628460018\n",
      "Iteration 8318, the loss is 4.523947743223254, parameters k is 11.483207849804202 and b is -49.48194466404682\n",
      "Iteration 8319, the loss is 4.523947150146166, parameters k is 11.483190549408945 and b is -49.48191304349346\n",
      "Iteration 8320, the loss is 4.52394675069869, parameters k is 11.48322314624689 and b is -49.481873517801766\n",
      "Iteration 8321, the loss is 4.523946101117154, parameters k is 11.483205845851634 and b is -49.48184189724841\n",
      "Iteration 8322, the loss is 4.52394545153562, parameters k is 11.483188545456377 and b is -49.48181027669505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8323, the loss is 4.523944808899996, parameters k is 11.48317124506112 and b is -49.48177865614169\n",
      "Iteration 8324, the loss is 4.52394445901105, parameters k is 11.483203841899066 and b is -49.481739130449995\n",
      "Iteration 8325, the loss is 4.523943809429516, parameters k is 11.483186541503809 and b is -49.48170750989664\n",
      "Iteration 8326, the loss is 4.52394315984798, parameters k is 11.483169241108552 and b is -49.48167588934328\n",
      "Iteration 8327, the loss is 4.523942510266451, parameters k is 11.483151940713295 and b is -49.48164426878992\n",
      "Iteration 8328, the loss is 4.523942124710797, parameters k is 11.483134640318038 and b is -49.48161264823656\n",
      "Iteration 8329, the loss is 4.5239415177418785, parameters k is 11.483167237155984 and b is -49.481573122544866\n",
      "Iteration 8330, the loss is 4.523940868160339, parameters k is 11.483149936760727 and b is -49.48154150199151\n",
      "Iteration 8331, the loss is 4.5239402185788045, parameters k is 11.48313263636547 and b is -49.48150988143815\n",
      "Iteration 8332, the loss is 4.523939783464627, parameters k is 11.483115335970213 and b is -49.48147826088479\n",
      "Iteration 8333, the loss is 4.523939226054241, parameters k is 11.483147932808158 and b is -49.481438735193095\n",
      "Iteration 8334, the loss is 4.523938576472707, parameters k is 11.483130632412902 and b is -49.48140711463974\n",
      "Iteration 8335, the loss is 4.523937926891171, parameters k is 11.483113332017645 and b is -49.48137549408638\n",
      "Iteration 8336, the loss is 4.523937442218462, parameters k is 11.483096031622388 and b is -49.48134387353302\n",
      "Iteration 8337, the loss is 4.5239369343666, parameters k is 11.483128628460333 and b is -49.48130434784132\n",
      "Iteration 8338, the loss is 4.5239362847850675, parameters k is 11.483111328065077 and b is -49.481272727287966\n",
      "Iteration 8339, the loss is 4.523935635203535, parameters k is 11.48309402766982 and b is -49.48124110673461\n",
      "Iteration 8340, the loss is 4.523935100972294, parameters k is 11.483076727274563 and b is -49.48120948618125\n",
      "Iteration 8341, the loss is 4.523934642678965, parameters k is 11.483109324112508 and b is -49.48116996048955\n",
      "Iteration 8342, the loss is 4.52393399309743, parameters k is 11.483092023717251 and b is -49.481138339936194\n",
      "Iteration 8343, the loss is 4.523933343515898, parameters k is 11.483074723321995 and b is -49.481106719382836\n",
      "Iteration 8344, the loss is 4.523932759726127, parameters k is 11.483057422926738 and b is -49.48107509882948\n",
      "Iteration 8345, the loss is 4.523932350991329, parameters k is 11.483090019764683 and b is -49.48103557313778\n",
      "Iteration 8346, the loss is 4.523931701409789, parameters k is 11.483072719369426 and b is -49.48100395258442\n",
      "Iteration 8347, the loss is 4.523931051828255, parameters k is 11.48305541897417 and b is -49.480972332031065\n",
      "Iteration 8348, the loss is 4.523930418479947, parameters k is 11.483038118578913 and b is -49.48094071147771\n",
      "Iteration 8349, the loss is 4.523930059303695, parameters k is 11.483070715416858 and b is -49.48090118578601\n",
      "Iteration 8350, the loss is 4.523929409722155, parameters k is 11.483053415021601 and b is -49.48086956523265\n",
      "Iteration 8351, the loss is 4.523928760140621, parameters k is 11.483036114626344 and b is -49.480837944679294\n",
      "Iteration 8352, the loss is 4.523928110559089, parameters k is 11.483018814231087 and b is -49.480806324125936\n",
      "Iteration 8353, the loss is 4.5239277342907585, parameters k is 11.48300151383583 and b is -49.48077470357258\n",
      "Iteration 8354, the loss is 4.523927118034522, parameters k is 11.483034110673776 and b is -49.48073517788088\n",
      "Iteration 8355, the loss is 4.523926468452986, parameters k is 11.483016810278519 and b is -49.48070355732752\n",
      "Iteration 8356, the loss is 4.523925818871441, parameters k is 11.482999509883262 and b is -49.480671936774165\n",
      "Iteration 8357, the loss is 4.523925393044585, parameters k is 11.482982209488005 and b is -49.48064031622081\n",
      "Iteration 8358, the loss is 4.523924826346883, parameters k is 11.48301480632595 and b is -49.48060079052911\n",
      "Iteration 8359, the loss is 4.523924176765348, parameters k is 11.482997505930694 and b is -49.48056916997575\n",
      "Iteration 8360, the loss is 4.523923527183807, parameters k is 11.482980205535437 and b is -49.480537549422394\n",
      "Iteration 8361, the loss is 4.5239230517984215, parameters k is 11.48296290514018 and b is -49.480505928869036\n",
      "Iteration 8362, the loss is 4.5239225346592375, parameters k is 11.482995501978126 and b is -49.48046640317734\n",
      "Iteration 8363, the loss is 4.523921885077704, parameters k is 11.482978201582869 and b is -49.48043478262398\n",
      "Iteration 8364, the loss is 4.523921235496171, parameters k is 11.482960901187612 and b is -49.48040316207062\n",
      "Iteration 8365, the loss is 4.5239207105522485, parameters k is 11.482943600792355 and b is -49.480371541517265\n",
      "Iteration 8366, the loss is 4.523920242971602, parameters k is 11.4829761976303 and b is -49.48033201582557\n",
      "Iteration 8367, the loss is 4.523919593390069, parameters k is 11.482958897235044 and b is -49.48030039527221\n",
      "Iteration 8368, the loss is 4.523918943808536, parameters k is 11.482941596839787 and b is -49.48026877471885\n",
      "Iteration 8369, the loss is 4.5239183693060845, parameters k is 11.48292429644453 and b is -49.48023715416549\n",
      "Iteration 8370, the loss is 4.523917951283967, parameters k is 11.482956893282475 and b is -49.480197628473796\n",
      "Iteration 8371, the loss is 4.523917301702433, parameters k is 11.482939592887218 and b is -49.48016600792044\n",
      "Iteration 8372, the loss is 4.523916652120897, parameters k is 11.482922292491962 and b is -49.48013438736708\n",
      "Iteration 8373, the loss is 4.5239160280599116, parameters k is 11.482904992096705 and b is -49.48010276681372\n",
      "Iteration 8374, the loss is 4.523915659596331, parameters k is 11.48293758893465 and b is -49.480063241122025\n",
      "Iteration 8375, the loss is 4.523915010014796, parameters k is 11.482920288539393 and b is -49.48003162056867\n",
      "Iteration 8376, the loss is 4.523914360433263, parameters k is 11.482902988144136 and b is -49.48000000001531\n",
      "Iteration 8377, the loss is 4.523913710851723, parameters k is 11.48288568774888 and b is -49.47996837946195\n",
      "Iteration 8378, the loss is 4.523913343870711, parameters k is 11.482868387353623 and b is -49.47993675890859\n",
      "Iteration 8379, the loss is 4.523912718327159, parameters k is 11.482900984191568 and b is -49.479897233216896\n",
      "Iteration 8380, the loss is 4.5239120687456245, parameters k is 11.482883683796311 and b is -49.47986561266354\n",
      "Iteration 8381, the loss is 4.523911419164087, parameters k is 11.482866383401054 and b is -49.47983399211018\n",
      "Iteration 8382, the loss is 4.523911002624543, parameters k is 11.482849083005798 and b is -49.47980237155682\n",
      "Iteration 8383, the loss is 4.523910426639519, parameters k is 11.482881679843743 and b is -49.479762845865125\n",
      "Iteration 8384, the loss is 4.523909777057982, parameters k is 11.482864379448486 and b is -49.47973122531177\n",
      "Iteration 8385, the loss is 4.523909127476447, parameters k is 11.48284707905323 and b is -49.47969960475841\n",
      "Iteration 8386, the loss is 4.5239086613783766, parameters k is 11.482829778657972 and b is -49.47966798420505\n",
      "Iteration 8387, the loss is 4.523908134951883, parameters k is 11.482862375495918 and b is -49.47962845851335\n",
      "Iteration 8388, the loss is 4.523907485370346, parameters k is 11.482845075100661 and b is -49.479596837959996\n",
      "Iteration 8389, the loss is 4.523906835788812, parameters k is 11.482827774705404 and b is -49.47956521740664\n",
      "Iteration 8390, the loss is 4.523906320132204, parameters k is 11.482810474310147 and b is -49.47953359685328\n",
      "Iteration 8391, the loss is 4.52390584326425, parameters k is 11.482843071148093 and b is -49.47949407116158\n",
      "Iteration 8392, the loss is 4.523905193682709, parameters k is 11.482825770752836 and b is -49.479462450608224\n",
      "Iteration 8393, the loss is 4.523904544101171, parameters k is 11.482808470357579 and b is -49.479430830054866\n",
      "Iteration 8394, the loss is 4.523903978886042, parameters k is 11.482791169962322 and b is -49.47939920950151\n",
      "Iteration 8395, the loss is 4.523903551576611, parameters k is 11.482823766800268 and b is -49.47935968380981\n",
      "Iteration 8396, the loss is 4.523902901995072, parameters k is 11.48280646640501 and b is -49.47932806325645\n",
      "Iteration 8397, the loss is 4.523902252413536, parameters k is 11.482789166009754 and b is -49.479296442703095\n",
      "Iteration 8398, the loss is 4.523901637639873, parameters k is 11.482771865614497 and b is -49.47926482214974\n",
      "Iteration 8399, the loss is 4.52390125988897, parameters k is 11.482804462452442 and b is -49.47922529645804\n",
      "Iteration 8400, the loss is 4.523900610307439, parameters k is 11.482787162057186 and b is -49.47919367590468\n",
      "Iteration 8401, the loss is 4.523899960725896, parameters k is 11.482769861661929 and b is -49.479162055351324\n",
      "Iteration 8402, the loss is 4.523899311144362, parameters k is 11.482752561266672 and b is -49.479130434797966\n",
      "Iteration 8403, the loss is 4.523898953450666, parameters k is 11.482735260871415 and b is -49.47909881424461\n",
      "Iteration 8404, the loss is 4.523898318619797, parameters k is 11.48276785770936 and b is -49.47905928855291\n",
      "Iteration 8405, the loss is 4.523897669038258, parameters k is 11.482750557314104 and b is -49.47902766799955\n",
      "Iteration 8406, the loss is 4.523897019456727, parameters k is 11.482733256918847 and b is -49.478996047446195\n",
      "Iteration 8407, the loss is 4.5238966122045055, parameters k is 11.48271595652359 and b is -49.47896442689284\n",
      "Iteration 8408, the loss is 4.52389602693216, parameters k is 11.482748553361535 and b is -49.47892490120114\n",
      "Iteration 8409, the loss is 4.523895377350621, parameters k is 11.482731252966278 and b is -49.47889328064778\n",
      "Iteration 8410, the loss is 4.5238947277690915, parameters k is 11.482713952571022 and b is -49.478861660094424\n",
      "Iteration 8411, the loss is 4.5238942709583325, parameters k is 11.482696652175765 and b is -49.478830039541066\n",
      "Iteration 8412, the loss is 4.523893735244517, parameters k is 11.48272924901371 and b is -49.47879051384937\n",
      "Iteration 8413, the loss is 4.523893085662984, parameters k is 11.482711948618453 and b is -49.47875889329601\n",
      "Iteration 8414, the loss is 4.523892436081453, parameters k is 11.482694648223196 and b is -49.47872727274265\n",
      "Iteration 8415, the loss is 4.523891929712169, parameters k is 11.48267734782794 and b is -49.478695652189295\n",
      "Iteration 8416, the loss is 4.523891443556881, parameters k is 11.482709944665885 and b is -49.4786561264976\n",
      "Iteration 8417, the loss is 4.52389079397535, parameters k is 11.482692644270628 and b is -49.47862450594424\n",
      "Iteration 8418, the loss is 4.523890144393819, parameters k is 11.482675343875371 and b is -49.47859288539088\n",
      "Iteration 8419, the loss is 4.523889588465992, parameters k is 11.482658043480114 and b is -49.47856126483752\n",
      "Iteration 8420, the loss is 4.523889151869248, parameters k is 11.48269064031806 and b is -49.478521739145826\n",
      "Iteration 8421, the loss is 4.523888502287708, parameters k is 11.482673339922803 and b is -49.47849011859247\n",
      "Iteration 8422, the loss is 4.523887852706178, parameters k is 11.482656039527546 and b is -49.47845849803911\n",
      "Iteration 8423, the loss is 4.523887247219832, parameters k is 11.48263873913229 and b is -49.47842687748575\n",
      "Iteration 8424, the loss is 4.523886860181607, parameters k is 11.482671335970235 and b is -49.478387351794055\n",
      "Iteration 8425, the loss is 4.5238862106000735, parameters k is 11.482654035574978 and b is -49.4783557312407\n",
      "Iteration 8426, the loss is 4.523885561018534, parameters k is 11.482636735179721 and b is -49.47832411068734\n",
      "Iteration 8427, the loss is 4.523884911437005, parameters k is 11.482619434784464 and b is -49.47829249013398\n",
      "Iteration 8428, the loss is 4.523884563030629, parameters k is 11.482602134389207 and b is -49.47826086958062\n",
      "Iteration 8429, the loss is 4.523883918912436, parameters k is 11.482634731227153 and b is -49.478221343888926\n",
      "Iteration 8430, the loss is 4.523883269330902, parameters k is 11.482617430831896 and b is -49.47818972333557\n",
      "Iteration 8431, the loss is 4.523882619749367, parameters k is 11.482600130436639 and b is -49.47815810278221\n",
      "Iteration 8432, the loss is 4.523882221784461, parameters k is 11.482582830041382 and b is -49.47812648222885\n",
      "Iteration 8433, the loss is 4.523881627224802, parameters k is 11.482615426879327 and b is -49.478086956537155\n",
      "Iteration 8434, the loss is 4.523880977643265, parameters k is 11.48259812648407 and b is -49.4780553359838\n",
      "Iteration 8435, the loss is 4.523880328061731, parameters k is 11.482580826088814 and b is -49.47802371543044\n",
      "Iteration 8436, the loss is 4.523879880538293, parameters k is 11.482563525693557 and b is -49.47799209487708\n",
      "Iteration 8437, the loss is 4.523879335537163, parameters k is 11.482596122531502 and b is -49.47795256918538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8438, the loss is 4.523878685955627, parameters k is 11.482578822136245 and b is -49.477920948632025\n",
      "Iteration 8439, the loss is 4.523878036374092, parameters k is 11.482561521740989 and b is -49.47788932807867\n",
      "Iteration 8440, the loss is 4.523877539292124, parameters k is 11.482544221345732 and b is -49.47785770752531\n",
      "Iteration 8441, the loss is 4.523877043849519, parameters k is 11.482576818183677 and b is -49.47781818183361\n",
      "Iteration 8442, the loss is 4.523876394267989, parameters k is 11.48255951778842 and b is -49.477786561280254\n",
      "Iteration 8443, the loss is 4.523875744686452, parameters k is 11.482542217393163 and b is -49.477754940726896\n",
      "Iteration 8444, the loss is 4.523875198045957, parameters k is 11.482524916997907 and b is -49.47772332017354\n",
      "Iteration 8445, the loss is 4.523874752161885, parameters k is 11.482557513835852 and b is -49.47768379448184\n",
      "Iteration 8446, the loss is 4.523874102580352, parameters k is 11.482540213440595 and b is -49.47765217392848\n",
      "Iteration 8447, the loss is 4.523873452998816, parameters k is 11.482522913045338 and b is -49.477620553375125\n",
      "Iteration 8448, the loss is 4.5238728567997875, parameters k is 11.482505612650082 and b is -49.47758893282177\n",
      "Iteration 8449, the loss is 4.523872460474248, parameters k is 11.482538209488027 and b is -49.47754940713007\n",
      "Iteration 8450, the loss is 4.523871810892712, parameters k is 11.48252090909277 and b is -49.47751778657671\n",
      "Iteration 8451, the loss is 4.523871161311176, parameters k is 11.482503608697513 and b is -49.477486166023354\n",
      "Iteration 8452, the loss is 4.523870515553622, parameters k is 11.482486308302256 and b is -49.477454545469996\n",
      "Iteration 8453, the loss is 4.523870168786607, parameters k is 11.482518905140202 and b is -49.4774150197783\n",
      "Iteration 8454, the loss is 4.523869519205079, parameters k is 11.482501604744945 and b is -49.47738339922494\n",
      "Iteration 8455, the loss is 4.523868869623542, parameters k is 11.482484304349688 and b is -49.47735177867158\n",
      "Iteration 8456, the loss is 4.523868220042003, parameters k is 11.482467003954431 and b is -49.477320158118225\n",
      "Iteration 8457, the loss is 4.523867831364416, parameters k is 11.482449703559174 and b is -49.47728853756487\n",
      "Iteration 8458, the loss is 4.5238672275174325, parameters k is 11.48248230039712 and b is -49.47724901187317\n",
      "Iteration 8459, the loss is 4.5238665779359, parameters k is 11.482465000001863 and b is -49.47721739131981\n",
      "Iteration 8460, the loss is 4.523865928354367, parameters k is 11.482447699606606 and b is -49.477185770766454\n",
      "Iteration 8461, the loss is 4.5238654901182525, parameters k is 11.48243039921135 and b is -49.477154150213096\n",
      "Iteration 8462, the loss is 4.5238649358298035, parameters k is 11.482462996049295 and b is -49.4771146245214\n",
      "Iteration 8463, the loss is 4.523864286248269, parameters k is 11.482445695654038 and b is -49.47708300396804\n",
      "Iteration 8464, the loss is 4.523863636666731, parameters k is 11.482428395258781 and b is -49.47705138341468\n",
      "Iteration 8465, the loss is 4.523863148872084, parameters k is 11.482411094863524 and b is -49.477019762861325\n",
      "Iteration 8466, the loss is 4.523862644142164, parameters k is 11.48244369170147 and b is -49.47698023716963\n",
      "Iteration 8467, the loss is 4.523861994560628, parameters k is 11.482426391306213 and b is -49.47694861661627\n",
      "Iteration 8468, the loss is 4.523861344979091, parameters k is 11.482409090910956 and b is -49.47691699606291\n",
      "Iteration 8469, the loss is 4.523860807625912, parameters k is 11.482391790515699 and b is -49.47688537550955\n",
      "Iteration 8470, the loss is 4.523860352454523, parameters k is 11.482424387353644 and b is -49.476845849817856\n",
      "Iteration 8471, the loss is 4.523859702872992, parameters k is 11.482407086958387 and b is -49.4768142292645\n",
      "Iteration 8472, the loss is 4.523859053291451, parameters k is 11.48238978656313 and b is -49.47678260871114\n",
      "Iteration 8473, the loss is 4.523858466379743, parameters k is 11.482372486167874 and b is -49.47675098815778\n",
      "Iteration 8474, the loss is 4.523858060766888, parameters k is 11.482405083005819 and b is -49.476711462466085\n",
      "Iteration 8475, the loss is 4.523857411185351, parameters k is 11.482387782610562 and b is -49.47667984191273\n",
      "Iteration 8476, the loss is 4.523856761603818, parameters k is 11.482370482215305 and b is -49.47664822135937\n",
      "Iteration 8477, the loss is 4.523856125133578, parameters k is 11.482353181820049 and b is -49.47661660080601\n",
      "Iteration 8478, the loss is 4.523855769079252, parameters k is 11.482385778657994 and b is -49.476577075114314\n",
      "Iteration 8479, the loss is 4.523855119497713, parameters k is 11.482368478262737 and b is -49.476545454560956\n",
      "Iteration 8480, the loss is 4.523854469916177, parameters k is 11.48235117786748 and b is -49.4765138340076\n",
      "Iteration 8481, the loss is 4.523853820334642, parameters k is 11.482333877472223 and b is -49.47648221345424\n",
      "Iteration 8482, the loss is 4.52385344094438, parameters k is 11.482316577076967 and b is -49.47645059290088\n",
      "Iteration 8483, the loss is 4.523852827810078, parameters k is 11.482349173914912 and b is -49.476411067209185\n",
      "Iteration 8484, the loss is 4.523852178228545, parameters k is 11.482331873519655 and b is -49.47637944665583\n",
      "Iteration 8485, the loss is 4.523851528647006, parameters k is 11.482314573124398 and b is -49.47634782610247\n",
      "Iteration 8486, the loss is 4.5238510996982075, parameters k is 11.482297272729141 and b is -49.47631620554911\n",
      "Iteration 8487, the loss is 4.523850536122442, parameters k is 11.482329869567087 and b is -49.47627667985741\n",
      "Iteration 8488, the loss is 4.523849886540907, parameters k is 11.48231256917183 and b is -49.476245059304055\n",
      "Iteration 8489, the loss is 4.523849236959367, parameters k is 11.482295268776573 and b is -49.4762134387507\n",
      "Iteration 8490, the loss is 4.523848758452037, parameters k is 11.482277968381316 and b is -49.47618181819734\n",
      "Iteration 8491, the loss is 4.523848244434804, parameters k is 11.482310565219262 and b is -49.47614229250564\n",
      "Iteration 8492, the loss is 4.523847594853268, parameters k is 11.482293264824005 and b is -49.476110671952284\n",
      "Iteration 8493, the loss is 4.523846945271729, parameters k is 11.482275964428748 and b is -49.476079051398926\n",
      "Iteration 8494, the loss is 4.523846417205876, parameters k is 11.482258664033491 and b is -49.47604743084557\n",
      "Iteration 8495, the loss is 4.523845952747165, parameters k is 11.482291260871436 and b is -49.47600790515387\n",
      "Iteration 8496, the loss is 4.523845303165626, parameters k is 11.48227396047618 and b is -49.47597628460051\n",
      "Iteration 8497, the loss is 4.523844653584097, parameters k is 11.482256660080923 and b is -49.475944664047155\n",
      "Iteration 8498, the loss is 4.523844075959702, parameters k is 11.482239359685666 and b is -49.4759130434938\n",
      "Iteration 8499, the loss is 4.5238436610595265, parameters k is 11.482271956523611 and b is -49.4758735178021\n",
      "Iteration 8500, the loss is 4.523843011477995, parameters k is 11.482254656128354 and b is -49.47584189724874\n",
      "Iteration 8501, the loss is 4.523842361896461, parameters k is 11.482237355733098 and b is -49.475810276695384\n",
      "Iteration 8502, the loss is 4.523841734713534, parameters k is 11.48222005533784 and b is -49.475778656142026\n",
      "Iteration 8503, the loss is 4.523841369371892, parameters k is 11.482252652175786 and b is -49.47573913045033\n",
      "Iteration 8504, the loss is 4.523840719790359, parameters k is 11.48223535178053 and b is -49.47570750989697\n",
      "Iteration 8505, the loss is 4.523840070208822, parameters k is 11.482218051385273 and b is -49.47567588934361\n",
      "Iteration 8506, the loss is 4.523839420627281, parameters k is 11.482200750990016 and b is -49.475644268790255\n",
      "Iteration 8507, the loss is 4.523839050524336, parameters k is 11.482183450594759 and b is -49.4756126482369\n",
      "Iteration 8508, the loss is 4.523838428102716, parameters k is 11.482216047432704 and b is -49.4755731225452\n",
      "Iteration 8509, the loss is 4.5238377785211865, parameters k is 11.482198747037447 and b is -49.47554150199184\n",
      "Iteration 8510, the loss is 4.523837128939648, parameters k is 11.48218144664219 and b is -49.475509881438484\n",
      "Iteration 8511, the loss is 4.52383670927817, parameters k is 11.482164146246934 and b is -49.475478260885126\n",
      "Iteration 8512, the loss is 4.523836136415077, parameters k is 11.482196743084879 and b is -49.47543873519343\n",
      "Iteration 8513, the loss is 4.523835486833542, parameters k is 11.482179442689622 and b is -49.47540711464007\n",
      "Iteration 8514, the loss is 4.52383483725201, parameters k is 11.482162142294365 and b is -49.47537549408671\n",
      "Iteration 8515, the loss is 4.523834368032, parameters k is 11.482144841899109 and b is -49.475343873533355\n",
      "Iteration 8516, the loss is 4.523833844727443, parameters k is 11.482177438737054 and b is -49.47530434784166\n",
      "Iteration 8517, the loss is 4.523833195145907, parameters k is 11.482160138341797 and b is -49.4752727272883\n",
      "Iteration 8518, the loss is 4.523832545564375, parameters k is 11.48214283794654 and b is -49.47524110673494\n",
      "Iteration 8519, the loss is 4.5238320267858265, parameters k is 11.482125537551283 and b is -49.47520948618158\n",
      "Iteration 8520, the loss is 4.523831553039807, parameters k is 11.482158134389229 and b is -49.475169960489886\n",
      "Iteration 8521, the loss is 4.523830903458272, parameters k is 11.482140833993972 and b is -49.47513833993653\n",
      "Iteration 8522, the loss is 4.523830253876735, parameters k is 11.482123533598715 and b is -49.47510671938317\n",
      "Iteration 8523, the loss is 4.5238296855396625, parameters k is 11.482106233203458 and b is -49.47507509882981\n",
      "Iteration 8524, the loss is 4.5238292613521685, parameters k is 11.482138830041404 and b is -49.475035573138115\n",
      "Iteration 8525, the loss is 4.523828611770627, parameters k is 11.482121529646147 and b is -49.47500395258476\n",
      "Iteration 8526, the loss is 4.523827962189091, parameters k is 11.48210422925089 and b is -49.4749723320314\n",
      "Iteration 8527, the loss is 4.523827344293492, parameters k is 11.482086928855633 and b is -49.47494071147804\n",
      "Iteration 8528, the loss is 4.523826969664527, parameters k is 11.482119525693578 and b is -49.474901185786344\n",
      "Iteration 8529, the loss is 4.523826320082988, parameters k is 11.482102225298322 and b is -49.474869565232986\n",
      "Iteration 8530, the loss is 4.52382567050146, parameters k is 11.482084924903065 and b is -49.47483794467963\n",
      "Iteration 8531, the loss is 4.523825020919922, parameters k is 11.482067624507808 and b is -49.47480632412627\n",
      "Iteration 8532, the loss is 4.523824660104292, parameters k is 11.482050324112551 and b is -49.47477470357291\n",
      "Iteration 8533, the loss is 4.5238240283953575, parameters k is 11.482082920950496 and b is -49.474735177881215\n",
      "Iteration 8534, the loss is 4.523823378813816, parameters k is 11.48206562055524 and b is -49.47470355732786\n",
      "Iteration 8535, the loss is 4.523822729232285, parameters k is 11.482048320159983 and b is -49.4746719367745\n",
      "Iteration 8536, the loss is 4.5238223188581275, parameters k is 11.482031019764726 and b is -49.47464031622114\n",
      "Iteration 8537, the loss is 4.523821736707717, parameters k is 11.482063616602671 and b is -49.47460079052944\n",
      "Iteration 8538, the loss is 4.523821087126182, parameters k is 11.482046316207414 and b is -49.474569169976085\n",
      "Iteration 8539, the loss is 4.523820437544647, parameters k is 11.482029015812158 and b is -49.47453754942273\n",
      "Iteration 8540, the loss is 4.523819977611956, parameters k is 11.4820117154169 and b is -49.47450592886937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8541, the loss is 4.523819445020084, parameters k is 11.482044312254846 and b is -49.47446640317767\n",
      "Iteration 8542, the loss is 4.523818795438543, parameters k is 11.48202701185959 and b is -49.474434782624314\n",
      "Iteration 8543, the loss is 4.523818145857004, parameters k is 11.482009711464332 and b is -49.474403162070956\n",
      "Iteration 8544, the loss is 4.5238176363657905, parameters k is 11.481992411069076 and b is -49.4743715415176\n",
      "Iteration 8545, the loss is 4.523817153332439, parameters k is 11.482025007907021 and b is -49.4743320158259\n",
      "Iteration 8546, the loss is 4.523816503750906, parameters k is 11.482007707511764 and b is -49.47430039527254\n",
      "Iteration 8547, the loss is 4.5238158541693725, parameters k is 11.481990407116507 and b is -49.474268774719185\n",
      "Iteration 8548, the loss is 4.523815295119616, parameters k is 11.48197310672125 and b is -49.47423715416583\n",
      "Iteration 8549, the loss is 4.523814861644805, parameters k is 11.482005703559196 and b is -49.47419762847413\n",
      "Iteration 8550, the loss is 4.523814212063273, parameters k is 11.481988403163939 and b is -49.47416600792077\n",
      "Iteration 8551, the loss is 4.523813562481733, parameters k is 11.481971102768682 and b is -49.474134387367414\n",
      "Iteration 8552, the loss is 4.523812953873453, parameters k is 11.481953802373425 and b is -49.474102766814056\n",
      "Iteration 8553, the loss is 4.523812569957165, parameters k is 11.48198639921137 and b is -49.47406324112236\n",
      "Iteration 8554, the loss is 4.523811920375634, parameters k is 11.481969098816114 and b is -49.474031620569\n",
      "Iteration 8555, the loss is 4.523811270794099, parameters k is 11.481951798420857 and b is -49.47400000001564\n",
      "Iteration 8556, the loss is 4.5238106212125615, parameters k is 11.4819344980256 and b is -49.473968379462285\n",
      "Iteration 8557, the loss is 4.5238102696842555, parameters k is 11.481917197630343 and b is -49.47393675890893\n",
      "Iteration 8558, the loss is 4.523809628687998, parameters k is 11.481949794468289 and b is -49.47389723321723\n",
      "Iteration 8559, the loss is 4.52380897910646, parameters k is 11.481932494073032 and b is -49.47386561266387\n",
      "Iteration 8560, the loss is 4.523808329524922, parameters k is 11.481915193677775 and b is -49.473833992110514\n",
      "Iteration 8561, the loss is 4.523807928438088, parameters k is 11.481897893282518 and b is -49.473802371557156\n",
      "Iteration 8562, the loss is 4.5238073370003535, parameters k is 11.481930490120464 and b is -49.47376284586546\n",
      "Iteration 8563, the loss is 4.523806687418826, parameters k is 11.481913189725207 and b is -49.4737312253121\n",
      "Iteration 8564, the loss is 4.5238060378372875, parameters k is 11.48189588932995 and b is -49.47369960475874\n",
      "Iteration 8565, the loss is 4.523805587191915, parameters k is 11.481878588934693 and b is -49.473667984205385\n",
      "Iteration 8566, the loss is 4.523805045312721, parameters k is 11.481911185772638 and b is -49.47362845851369\n",
      "Iteration 8567, the loss is 4.5238043957311795, parameters k is 11.481893885377382 and b is -49.47359683796033\n",
      "Iteration 8568, the loss is 4.5238037461496505, parameters k is 11.481876584982125 and b is -49.47356521740697\n",
      "Iteration 8569, the loss is 4.5238032459457465, parameters k is 11.481859284586868 and b is -49.47353359685361\n",
      "Iteration 8570, the loss is 4.52380275362508, parameters k is 11.481891881424813 and b is -49.473494071161916\n",
      "Iteration 8571, the loss is 4.523802104043544, parameters k is 11.481874581029556 and b is -49.47346245060856\n",
      "Iteration 8572, the loss is 4.52380145446201, parameters k is 11.4818572806343 and b is -49.4734308300552\n",
      "Iteration 8573, the loss is 4.523800904699584, parameters k is 11.481839980239043 and b is -49.47339920950184\n",
      "Iteration 8574, the loss is 4.523800461937444, parameters k is 11.481872577076988 and b is -49.473359683810145\n",
      "Iteration 8575, the loss is 4.523799812355912, parameters k is 11.481855276681731 and b is -49.47332806325679\n",
      "Iteration 8576, the loss is 4.523799162774375, parameters k is 11.481837976286474 and b is -49.47329644270343\n",
      "Iteration 8577, the loss is 4.523798563453413, parameters k is 11.481820675891218 and b is -49.47326482215007\n",
      "Iteration 8578, the loss is 4.523798170249808, parameters k is 11.481853272729163 and b is -49.473225296458374\n",
      "Iteration 8579, the loss is 4.523797520668272, parameters k is 11.481835972333906 and b is -49.473193675905016\n",
      "Iteration 8580, the loss is 4.523796871086739, parameters k is 11.48181867193865 and b is -49.47316205535166\n",
      "Iteration 8581, the loss is 4.523796222207242, parameters k is 11.481801371543392 and b is -49.4731304347983\n",
      "Iteration 8582, the loss is 4.52379587856217, parameters k is 11.481833968381338 and b is -49.4730909091066\n",
      "Iteration 8583, the loss is 4.52379522898063, parameters k is 11.481816667986081 and b is -49.473059288553245\n",
      "Iteration 8584, the loss is 4.523794579399098, parameters k is 11.481799367590824 and b is -49.47302766799989\n",
      "Iteration 8585, the loss is 4.523793929817564, parameters k is 11.481782067195567 and b is -49.47299604744653\n",
      "Iteration 8586, the loss is 4.523793538018043, parameters k is 11.48176476680031 and b is -49.47296442689317\n",
      "Iteration 8587, the loss is 4.5237929372929955, parameters k is 11.481797363638256 and b is -49.47292490120147\n",
      "Iteration 8588, the loss is 4.523792287711461, parameters k is 11.481780063242999 and b is -49.472893280648115\n",
      "Iteration 8589, the loss is 4.523791638129928, parameters k is 11.481762762847742 and b is -49.47286166009476\n",
      "Iteration 8590, the loss is 4.523791196771878, parameters k is 11.481745462452485 and b is -49.4728300395414\n",
      "Iteration 8591, the loss is 4.523790645605359, parameters k is 11.48177805929043 and b is -49.4727905138497\n",
      "Iteration 8592, the loss is 4.523789996023826, parameters k is 11.481760758895174 and b is -49.472758893296344\n",
      "Iteration 8593, the loss is 4.523789346442287, parameters k is 11.481743458499917 and b is -49.472727272742986\n",
      "Iteration 8594, the loss is 4.523788855525707, parameters k is 11.48172615810466 and b is -49.47269565218963\n",
      "Iteration 8595, the loss is 4.523788353917722, parameters k is 11.481758754942605 and b is -49.47265612649793\n",
      "Iteration 8596, the loss is 4.523787704336186, parameters k is 11.481741454547349 and b is -49.47262450594457\n",
      "Iteration 8597, the loss is 4.523787054754653, parameters k is 11.481724154152092 and b is -49.472592885391215\n",
      "Iteration 8598, the loss is 4.523786514279535, parameters k is 11.481706853756835 and b is -49.47256126483786\n",
      "Iteration 8599, the loss is 4.523786062230086, parameters k is 11.48173945059478 and b is -49.47252173914616\n",
      "Iteration 8600, the loss is 4.5237854126485475, parameters k is 11.481722150199523 and b is -49.4724901185928\n",
      "Iteration 8601, the loss is 4.523784763067015, parameters k is 11.481704849804267 and b is -49.472458498039444\n",
      "Iteration 8602, the loss is 4.523784173033371, parameters k is 11.48168754940901 and b is -49.472426877486086\n",
      "Iteration 8603, the loss is 4.523783770542449, parameters k is 11.481720146246955 and b is -49.47238735179439\n",
      "Iteration 8604, the loss is 4.5237831209609105, parameters k is 11.481702845851698 and b is -49.47235573124103\n",
      "Iteration 8605, the loss is 4.5237824713793735, parameters k is 11.481685545456441 and b is -49.47232411068767\n",
      "Iteration 8606, the loss is 4.5237818317872, parameters k is 11.481668245061185 and b is -49.472292490134315\n",
      "Iteration 8607, the loss is 4.523781478854804, parameters k is 11.48170084189913 and b is -49.47225296444262\n",
      "Iteration 8608, the loss is 4.523780829273273, parameters k is 11.481683541503873 and b is -49.47222134388926\n",
      "Iteration 8609, the loss is 4.523780179691743, parameters k is 11.481666241108616 and b is -49.4721897233359\n",
      "Iteration 8610, the loss is 4.523779530110206, parameters k is 11.48164894071336 and b is -49.472158102782544\n",
      "Iteration 8611, the loss is 4.523779147598005, parameters k is 11.481631640318103 and b is -49.472126482229186\n",
      "Iteration 8612, the loss is 4.523778537585633, parameters k is 11.481664237156048 and b is -49.47208695653749\n",
      "Iteration 8613, the loss is 4.5237778880041, parameters k is 11.481646936760791 and b is -49.47205533598413\n",
      "Iteration 8614, the loss is 4.523777238422565, parameters k is 11.481629636365534 and b is -49.47202371543077\n",
      "Iteration 8615, the loss is 4.523776806351828, parameters k is 11.481612335970278 and b is -49.471992094877415\n",
      "Iteration 8616, the loss is 4.523776245897998, parameters k is 11.481644932808223 and b is -49.47195256918572\n",
      "Iteration 8617, the loss is 4.523775596316464, parameters k is 11.481627632412966 and b is -49.47192094863236\n",
      "Iteration 8618, the loss is 4.523774946734927, parameters k is 11.48161033201771 and b is -49.471889328079\n",
      "Iteration 8619, the loss is 4.523774465105663, parameters k is 11.481593031622452 and b is -49.47185770752564\n",
      "Iteration 8620, the loss is 4.523773954210364, parameters k is 11.481625628460398 and b is -49.471818181833946\n",
      "Iteration 8621, the loss is 4.523773304628825, parameters k is 11.48160832806514 and b is -49.47178656128059\n",
      "Iteration 8622, the loss is 4.5237726550472965, parameters k is 11.481591027669884 and b is -49.47175494072723\n",
      "Iteration 8623, the loss is 4.523772123859494, parameters k is 11.481573727274627 and b is -49.47172332017387\n",
      "Iteration 8624, the loss is 4.523771662522721, parameters k is 11.481606324112573 and b is -49.471683794482175\n",
      "Iteration 8625, the loss is 4.523771012941192, parameters k is 11.481589023717316 and b is -49.47165217392882\n",
      "Iteration 8626, the loss is 4.523770363359653, parameters k is 11.481571723322059 and b is -49.47162055337546\n",
      "Iteration 8627, the loss is 4.523769782613329, parameters k is 11.481554422926802 and b is -49.4715889328221\n",
      "Iteration 8628, the loss is 4.523769370835087, parameters k is 11.481587019764747 and b is -49.471549407130404\n",
      "Iteration 8629, the loss is 4.523768721253551, parameters k is 11.48156971936949 and b is -49.471517786577046\n",
      "Iteration 8630, the loss is 4.523768071672011, parameters k is 11.481552418974234 and b is -49.47148616602369\n",
      "Iteration 8631, the loss is 4.523767441367163, parameters k is 11.481535118578977 and b is -49.47145454547033\n",
      "Iteration 8632, the loss is 4.523767079147457, parameters k is 11.481567715416922 and b is -49.47141501977863\n",
      "Iteration 8633, the loss is 4.523766429565912, parameters k is 11.481550415021665 and b is -49.471383399225275\n",
      "Iteration 8634, the loss is 4.52376577998438, parameters k is 11.481533114626409 and b is -49.47135177867192\n",
      "Iteration 8635, the loss is 4.5237651304028415, parameters k is 11.481515814231152 and b is -49.47132015811856\n",
      "Iteration 8636, the loss is 4.523764757177958, parameters k is 11.481498513835895 and b is -49.4712885375652\n",
      "Iteration 8637, the loss is 4.523764137878276, parameters k is 11.48153111067384 and b is -49.4712490118735\n",
      "Iteration 8638, the loss is 4.523763488296736, parameters k is 11.481513810278583 and b is -49.471217391320145\n",
      "Iteration 8639, the loss is 4.523762838715205, parameters k is 11.481496509883327 and b is -49.47118577076679\n",
      "Iteration 8640, the loss is 4.52376241593179, parameters k is 11.48147920948807 and b is -49.47115415021343\n",
      "Iteration 8641, the loss is 4.523761846190634, parameters k is 11.481511806326015 and b is -49.47111462452173\n",
      "Iteration 8642, the loss is 4.523761196609103, parameters k is 11.481494505930758 and b is -49.471083003968374\n",
      "Iteration 8643, the loss is 4.523760547027567, parameters k is 11.481477205535501 and b is -49.471051383415016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8644, the loss is 4.523760074685623, parameters k is 11.481459905140245 and b is -49.47101976286166\n",
      "Iteration 8645, the loss is 4.523759554503, parameters k is 11.48149250197819 and b is -49.47098023716996\n",
      "Iteration 8646, the loss is 4.5237589049214675, parameters k is 11.481475201582933 and b is -49.4709486166166\n",
      "Iteration 8647, the loss is 4.52375825533993, parameters k is 11.481457901187676 and b is -49.470916996063245\n",
      "Iteration 8648, the loss is 4.523757733439453, parameters k is 11.48144060079242 and b is -49.47088537550989\n",
      "Iteration 8649, the loss is 4.523757262815365, parameters k is 11.481473197630365 and b is -49.47084584981819\n",
      "Iteration 8650, the loss is 4.523756613233827, parameters k is 11.481455897235108 and b is -49.47081422926483\n",
      "Iteration 8651, the loss is 4.523755963652291, parameters k is 11.481438596839851 and b is -49.470782608711474\n",
      "Iteration 8652, the loss is 4.523755392193286, parameters k is 11.481421296444594 and b is -49.470750988158116\n",
      "Iteration 8653, the loss is 4.523754971127725, parameters k is 11.48145389328254 and b is -49.47071146246642\n",
      "Iteration 8654, the loss is 4.52375432154619, parameters k is 11.481436592887283 and b is -49.47067984191306\n",
      "Iteration 8655, the loss is 4.523753671964652, parameters k is 11.481419292492026 and b is -49.4706482213597\n",
      "Iteration 8656, the loss is 4.523753050947115, parameters k is 11.48140199209677 and b is -49.470616600806345\n",
      "Iteration 8657, the loss is 4.523752679440086, parameters k is 11.481434588934714 and b is -49.47057707511465\n",
      "Iteration 8658, the loss is 4.523752029858556, parameters k is 11.481417288539458 and b is -49.47054545456129\n",
      "Iteration 8659, the loss is 4.523751380277015, parameters k is 11.4813999881442 and b is -49.47051383400793\n",
      "Iteration 8660, the loss is 4.523750730695482, parameters k is 11.481382687748944 and b is -49.470482213454574\n",
      "Iteration 8661, the loss is 4.523750366757914, parameters k is 11.481365387353687 and b is -49.470450592901216\n",
      "Iteration 8662, the loss is 4.523749738170919, parameters k is 11.481397984191632 and b is -49.47041106720952\n",
      "Iteration 8663, the loss is 4.523749088589379, parameters k is 11.481380683796376 and b is -49.47037944665616\n",
      "Iteration 8664, the loss is 4.5237484390078455, parameters k is 11.481363383401119 and b is -49.4703478261028\n",
      "Iteration 8665, the loss is 4.523748025511751, parameters k is 11.481346083005862 and b is -49.470316205549445\n",
      "Iteration 8666, the loss is 4.5237474464832745, parameters k is 11.481378679843807 and b is -49.47027667985775\n",
      "Iteration 8667, the loss is 4.523746796901744, parameters k is 11.48136137944855 and b is -49.47024505930439\n",
      "Iteration 8668, the loss is 4.523746147320205, parameters k is 11.481344079053294 and b is -49.47021343875103\n",
      "Iteration 8669, the loss is 4.52374568426558, parameters k is 11.481326778658037 and b is -49.47018181819767\n",
      "Iteration 8670, the loss is 4.523745154795641, parameters k is 11.481359375495982 and b is -49.470142292505976\n",
      "Iteration 8671, the loss is 4.523744505214103, parameters k is 11.481342075100725 and b is -49.47011067195262\n",
      "Iteration 8672, the loss is 4.523743855632566, parameters k is 11.481324774705469 and b is -49.47007905139926\n",
      "Iteration 8673, the loss is 4.5237433430194125, parameters k is 11.481307474310212 and b is -49.4700474308459\n",
      "Iteration 8674, the loss is 4.523742863108003, parameters k is 11.481340071148157 and b is -49.470007905154205\n",
      "Iteration 8675, the loss is 4.52374221352647, parameters k is 11.4813227707529 and b is -49.46997628460085\n",
      "Iteration 8676, the loss is 4.523741563944933, parameters k is 11.481305470357643 and b is -49.46994466404749\n",
      "Iteration 8677, the loss is 4.523741001773247, parameters k is 11.481288169962387 and b is -49.46991304349413\n",
      "Iteration 8678, the loss is 4.523740571420365, parameters k is 11.481320766800332 and b is -49.469873517802434\n",
      "Iteration 8679, the loss is 4.523739921838829, parameters k is 11.481303466405075 and b is -49.469841897249076\n",
      "Iteration 8680, the loss is 4.523739272257292, parameters k is 11.481286166009818 and b is -49.46981027669572\n",
      "Iteration 8681, the loss is 4.523738660527075, parameters k is 11.481268865614561 and b is -49.46977865614236\n",
      "Iteration 8682, the loss is 4.523738279732728, parameters k is 11.481301462452507 and b is -49.46973913045066\n",
      "Iteration 8683, the loss is 4.5237376301511905, parameters k is 11.48128416205725 and b is -49.469707509897304\n",
      "Iteration 8684, the loss is 4.523736980569657, parameters k is 11.481266861661993 and b is -49.46967588934395\n",
      "Iteration 8685, the loss is 4.5237363309881236, parameters k is 11.481249561266736 and b is -49.46964426879059\n",
      "Iteration 8686, the loss is 4.523735976337877, parameters k is 11.48123226087148 and b is -49.46961264823723\n",
      "Iteration 8687, the loss is 4.523735338463548, parameters k is 11.481264857709425 and b is -49.46957312254553\n",
      "Iteration 8688, the loss is 4.52373468888202, parameters k is 11.481247557314168 and b is -49.469541501992175\n",
      "Iteration 8689, the loss is 4.523734039300485, parameters k is 11.481230256918911 and b is -49.46950988143882\n",
      "Iteration 8690, the loss is 4.523733635091703, parameters k is 11.481212956523654 and b is -49.46947826088546\n",
      "Iteration 8691, the loss is 4.523733046775916, parameters k is 11.4812455533616 and b is -49.46943873519376\n",
      "Iteration 8692, the loss is 4.52373239719438, parameters k is 11.481228252966343 and b is -49.469407114640404\n",
      "Iteration 8693, the loss is 4.523731747612843, parameters k is 11.481210952571086 and b is -49.469375494087046\n",
      "Iteration 8694, the loss is 4.523731293845542, parameters k is 11.481193652175829 and b is -49.46934387353369\n",
      "Iteration 8695, the loss is 4.5237307550882795, parameters k is 11.481226249013774 and b is -49.46930434784199\n",
      "Iteration 8696, the loss is 4.523730105506743, parameters k is 11.481208948618518 and b is -49.46927272728863\n",
      "Iteration 8697, the loss is 4.523729455925209, parameters k is 11.48119164822326 and b is -49.469241106735275\n",
      "Iteration 8698, the loss is 4.523728952599374, parameters k is 11.481174347828004 and b is -49.46920948618192\n",
      "Iteration 8699, the loss is 4.523728463400643, parameters k is 11.48120694466595 and b is -49.46916996049022\n",
      "Iteration 8700, the loss is 4.523727813819103, parameters k is 11.481189644270692 and b is -49.46913833993686\n",
      "Iteration 8701, the loss is 4.523727164237574, parameters k is 11.481172343875436 and b is -49.469106719383504\n",
      "Iteration 8702, the loss is 4.523726611353202, parameters k is 11.481155043480179 and b is -49.469075098830146\n",
      "Iteration 8703, the loss is 4.523726171713007, parameters k is 11.481187640318124 and b is -49.46903557313845\n",
      "Iteration 8704, the loss is 4.523725522131466, parameters k is 11.481170339922867 and b is -49.46900395258509\n",
      "Iteration 8705, the loss is 4.523724872549933, parameters k is 11.48115303952761 and b is -49.46897233203173\n",
      "Iteration 8706, the loss is 4.5237242701070315, parameters k is 11.481135739132354 and b is -49.468940711478375\n",
      "Iteration 8707, the loss is 4.523723880025366, parameters k is 11.481168335970299 and b is -49.46890118578668\n",
      "Iteration 8708, the loss is 4.523723230443831, parameters k is 11.481151035575042 and b is -49.46886956523332\n",
      "Iteration 8709, the loss is 4.523722580862297, parameters k is 11.481133735179785 and b is -49.46883794467996\n",
      "Iteration 8710, the loss is 4.523721931280761, parameters k is 11.481116434784528 and b is -49.468806324126604\n",
      "Iteration 8711, the loss is 4.523721585917834, parameters k is 11.481099134389272 and b is -49.468774703573246\n",
      "Iteration 8712, the loss is 4.5237209387561945, parameters k is 11.481131731227217 and b is -49.46873517788155\n",
      "Iteration 8713, the loss is 4.523720289174662, parameters k is 11.48111443083196 and b is -49.46870355732819\n",
      "Iteration 8714, the loss is 4.523719639593121, parameters k is 11.481097130436703 and b is -49.46867193677483\n",
      "Iteration 8715, the loss is 4.52371924467167, parameters k is 11.481079830041446 and b is -49.468640316221475\n",
      "Iteration 8716, the loss is 4.523718647068557, parameters k is 11.481112426879392 and b is -49.46860079052978\n",
      "Iteration 8717, the loss is 4.523717997487022, parameters k is 11.481095126484135 and b is -49.46856916997642\n",
      "Iteration 8718, the loss is 4.52371734790549, parameters k is 11.481077826088878 and b is -49.46853754942306\n",
      "Iteration 8719, the loss is 4.523716903425495, parameters k is 11.481060525693621 and b is -49.4685059288697\n",
      "Iteration 8720, the loss is 4.523716355380913, parameters k is 11.481093122531567 and b is -49.468466403178006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8721, the loss is 4.523715705799383, parameters k is 11.48107582213631 and b is -49.46843478262465\n",
      "Iteration 8722, the loss is 4.523715056217849, parameters k is 11.481058521741053 and b is -49.46840316207129\n",
      "Iteration 8723, the loss is 4.52371456217933, parameters k is 11.481041221345796 and b is -49.46837154151793\n",
      "Iteration 8724, the loss is 4.523714063693281, parameters k is 11.481073818183742 and b is -49.468332015826235\n",
      "Iteration 8725, the loss is 4.523713414111747, parameters k is 11.481056517788485 and b is -49.46830039527288\n",
      "Iteration 8726, the loss is 4.523712764530208, parameters k is 11.481039217393228 and b is -49.46826877471952\n",
      "Iteration 8727, the loss is 4.52371222093316, parameters k is 11.481021916997971 and b is -49.46823715416616\n",
      "Iteration 8728, the loss is 4.523711772005641, parameters k is 11.481054513835916 and b is -49.468197628474464\n",
      "Iteration 8729, the loss is 4.523711122424107, parameters k is 11.48103721344066 and b is -49.468166007921106\n",
      "Iteration 8730, the loss is 4.52371047284257, parameters k is 11.481019913045403 and b is -49.46813438736775\n",
      "Iteration 8731, the loss is 4.523709879686992, parameters k is 11.481002612650146 and b is -49.46810276681439\n",
      "Iteration 8732, the loss is 4.523709480318006, parameters k is 11.481035209488091 and b is -49.46806324112269\n",
      "Iteration 8733, the loss is 4.52370883073647, parameters k is 11.481017909092834 and b is -49.468031620569334\n",
      "Iteration 8734, the loss is 4.523708181154934, parameters k is 11.481000608697578 and b is -49.46800000001598\n",
      "Iteration 8735, the loss is 4.523707538440823, parameters k is 11.48098330830232 and b is -49.46796837946262\n",
      "Iteration 8736, the loss is 4.523707188630368, parameters k is 11.481015905140266 and b is -49.46792885377092\n",
      "Iteration 8737, the loss is 4.523706539048834, parameters k is 11.48099860474501 and b is -49.46789723321756\n",
      "Iteration 8738, the loss is 4.523705889467294, parameters k is 11.480981304349752 and b is -49.467865612664205\n",
      "Iteration 8739, the loss is 4.523705239885766, parameters k is 11.480964003954496 and b is -49.46783399211085\n",
      "Iteration 8740, the loss is 4.523704854251621, parameters k is 11.480946703559239 and b is -49.46780237155749\n",
      "Iteration 8741, the loss is 4.523704247361198, parameters k is 11.480979300397184 and b is -49.46776284586579\n",
      "Iteration 8742, the loss is 4.523703597779659, parameters k is 11.480962000001927 and b is -49.467731225312434\n",
      "Iteration 8743, the loss is 4.523702948198125, parameters k is 11.48094469960667 and b is -49.467699604759076\n",
      "Iteration 8744, the loss is 4.523702513005457, parameters k is 11.480927399211414 and b is -49.46766798420572\n",
      "Iteration 8745, the loss is 4.5237019556735625, parameters k is 11.480959996049359 and b is -49.46762845851402\n",
      "Iteration 8746, the loss is 4.523701306092023, parameters k is 11.480942695654102 and b is -49.46759683796066\n",
      "Iteration 8747, the loss is 4.523700656510492, parameters k is 11.480925395258845 and b is -49.467565217407305\n",
      "Iteration 8748, the loss is 4.523700171759289, parameters k is 11.480908094863588 and b is -49.46753359685395\n",
      "Iteration 8749, the loss is 4.523699663985918, parameters k is 11.480940691701534 and b is -49.46749407116225\n",
      "Iteration 8750, the loss is 4.523699014404382, parameters k is 11.480923391306277 and b is -49.46746245060889\n",
      "Iteration 8751, the loss is 4.52369836482285, parameters k is 11.48090609091102 and b is -49.467430830055534\n",
      "Iteration 8752, the loss is 4.52369783051312, parameters k is 11.480888790515763 and b is -49.467399209502176\n",
      "Iteration 8753, the loss is 4.5236973722982885, parameters k is 11.480921387353709 and b is -49.46735968381048\n",
      "Iteration 8754, the loss is 4.523696722716747, parameters k is 11.480904086958452 and b is -49.46732806325712\n",
      "Iteration 8755, the loss is 4.523696073135215, parameters k is 11.480886786563195 and b is -49.46729644270376\n",
      "Iteration 8756, the loss is 4.523695489266952, parameters k is 11.480869486167938 and b is -49.467264822150405\n",
      "Iteration 8757, the loss is 4.523695080610645, parameters k is 11.480902083005883 and b is -49.46722529645871\n",
      "Iteration 8758, the loss is 4.523694431029108, parameters k is 11.480884782610627 and b is -49.46719367590535\n",
      "Iteration 8759, the loss is 4.523693781447572, parameters k is 11.48086748221537 and b is -49.46716205535199\n",
      "Iteration 8760, the loss is 4.52369314802078, parameters k is 11.480850181820113 and b is -49.467130434798634\n",
      "Iteration 8761, the loss is 4.523692788923008, parameters k is 11.480882778658058 and b is -49.467090909106936\n",
      "Iteration 8762, the loss is 4.523692139341468, parameters k is 11.480865478262801 and b is -49.46705928855358\n",
      "Iteration 8763, the loss is 4.523691489759936, parameters k is 11.480848177867545 and b is -49.46702766800022\n",
      "Iteration 8764, the loss is 4.523690840178405, parameters k is 11.480830877472288 and b is -49.46699604744686\n",
      "Iteration 8765, the loss is 4.523690463831588, parameters k is 11.480813577077031 and b is -49.466964426893504\n",
      "Iteration 8766, the loss is 4.523689847653836, parameters k is 11.480846173914976 and b is -49.46692490120181\n",
      "Iteration 8767, the loss is 4.523689198072298, parameters k is 11.48082887351972 and b is -49.46689328064845\n",
      "Iteration 8768, the loss is 4.523688548490765, parameters k is 11.480811573124463 and b is -49.46686166009509\n",
      "Iteration 8769, the loss is 4.523688122585412, parameters k is 11.480794272729206 and b is -49.46683003954173\n",
      "Iteration 8770, the loss is 4.523687555966199, parameters k is 11.480826869567151 and b is -49.466790513850036\n",
      "Iteration 8771, the loss is 4.523686906384662, parameters k is 11.480809569171894 and b is -49.46675889329668\n",
      "Iteration 8772, the loss is 4.5236862568031295, parameters k is 11.480792268776637 and b is -49.46672727274332\n",
      "Iteration 8773, the loss is 4.52368578133924, parameters k is 11.48077496838138 and b is -49.46669565218996\n",
      "Iteration 8774, the loss is 4.5236852642785585, parameters k is 11.480807565219326 and b is -49.466656126498265\n",
      "Iteration 8775, the loss is 4.523684614697024, parameters k is 11.48079026482407 and b is -49.46662450594491\n",
      "Iteration 8776, the loss is 4.523683965115491, parameters k is 11.480772964428812 and b is -49.46659288539155\n",
      "Iteration 8777, the loss is 4.523683440093082, parameters k is 11.480755664033556 and b is -49.46656126483819\n",
      "Iteration 8778, the loss is 4.523682972590921, parameters k is 11.4807882608715 and b is -49.46652173914649\n",
      "Iteration 8779, the loss is 4.523682323009387, parameters k is 11.480770960476244 and b is -49.466490118593136\n",
      "Iteration 8780, the loss is 4.523681673427849, parameters k is 11.480753660080987 and b is -49.46645849803978\n",
      "Iteration 8781, the loss is 4.523681098846907, parameters k is 11.48073635968573 and b is -49.46642687748642\n",
      "Iteration 8782, the loss is 4.523680680903281, parameters k is 11.480768956523676 and b is -49.46638735179472\n",
      "Iteration 8783, the loss is 4.5236800313217485, parameters k is 11.480751656128419 and b is -49.466355731241364\n",
      "Iteration 8784, the loss is 4.5236793817402114, parameters k is 11.480734355733162 and b is -49.46632411068801\n",
      "Iteration 8785, the loss is 4.523678757600741, parameters k is 11.480717055337905 and b is -49.46629249013465\n",
      "Iteration 8786, the loss is 4.523678389215647, parameters k is 11.48074965217585 and b is -49.46625296444295\n",
      "Iteration 8787, the loss is 4.523677739634114, parameters k is 11.480732351780594 and b is -49.46622134388959\n",
      "Iteration 8788, the loss is 4.523677090052576, parameters k is 11.480715051385337 and b is -49.466189723336235\n",
      "Iteration 8789, the loss is 4.523676440471041, parameters k is 11.48069775099008 and b is -49.46615810278288\n",
      "Iteration 8790, the loss is 4.523676073411539, parameters k is 11.480680450594823 and b is -49.46612648222952\n",
      "Iteration 8791, the loss is 4.523675447946475, parameters k is 11.480713047432769 and b is -49.46608695653782\n",
      "Iteration 8792, the loss is 4.523674798364938, parameters k is 11.480695747037512 and b is -49.466055335984464\n",
      "Iteration 8793, the loss is 4.523674148783405, parameters k is 11.480678446642255 and b is -49.466023715431106\n",
      "Iteration 8794, the loss is 4.523673732165377, parameters k is 11.480661146246998 and b is -49.46599209487775\n",
      "Iteration 8795, the loss is 4.523673156258838, parameters k is 11.480693743084943 and b is -49.46595256918605\n",
      "Iteration 8796, the loss is 4.5236725066773, parameters k is 11.480676442689687 and b is -49.46592094863269\n",
      "Iteration 8797, the loss is 4.523671857095766, parameters k is 11.48065914229443 and b is -49.465889328079335\n",
      "Iteration 8798, the loss is 4.523671390919202, parameters k is 11.480641841899173 and b is -49.46585770752598\n",
      "Iteration 8799, the loss is 4.523670864571199, parameters k is 11.480674438737118 and b is -49.46581818183428\n",
      "Iteration 8800, the loss is 4.52367021498966, parameters k is 11.480657138341861 and b is -49.46578656128092\n",
      "Iteration 8801, the loss is 4.523669565408126, parameters k is 11.480639837946605 and b is -49.465754940727564\n",
      "Iteration 8802, the loss is 4.523669049673034, parameters k is 11.480622537551348 and b is -49.465723320174206\n",
      "Iteration 8803, the loss is 4.523668572883562, parameters k is 11.480655134389293 and b is -49.46568379448251\n",
      "Iteration 8804, the loss is 4.523667923302023, parameters k is 11.480637833994036 and b is -49.46565217392915\n",
      "Iteration 8805, the loss is 4.523667273720489, parameters k is 11.48062053359878 and b is -49.46562055337579\n",
      "Iteration 8806, the loss is 4.523666708426867, parameters k is 11.480603233203523 and b is -49.465588932822435\n",
      "Iteration 8807, the loss is 4.523666281195924, parameters k is 11.480635830041468 and b is -49.46554940713074\n",
      "Iteration 8808, the loss is 4.52366563161439, parameters k is 11.480618529646211 and b is -49.46551778657738\n",
      "Iteration 8809, the loss is 4.523664982032854, parameters k is 11.480601229250954 and b is -49.46548616602402\n",
      "Iteration 8810, the loss is 4.523664367180701, parameters k is 11.480583928855697 and b is -49.465454545470664\n",
      "Iteration 8811, the loss is 4.523663989508282, parameters k is 11.480616525693643 and b is -49.465415019778966\n",
      "Iteration 8812, the loss is 4.523663339926748, parameters k is 11.480599225298386 and b is -49.46538339922561\n",
      "Iteration 8813, the loss is 4.523662690345211, parameters k is 11.48058192490313 and b is -49.46535177867225\n",
      "Iteration 8814, the loss is 4.523662040763679, parameters k is 11.480564624507872 and b is -49.46532015811889\n",
      "Iteration 8815, the loss is 4.523661682991502, parameters k is 11.480547324112615 and b is -49.465288537565534\n",
      "Iteration 8816, the loss is 4.523661048239113, parameters k is 11.48057992095056 and b is -49.46524901187384\n",
      "Iteration 8817, the loss is 4.523660398657581, parameters k is 11.480562620555304 and b is -49.46521739132048\n",
      "Iteration 8818, the loss is 4.52365974907604, parameters k is 11.480545320160047 and b is -49.46518577076712\n",
      "Iteration 8819, the loss is 4.523659341745327, parameters k is 11.48052801976479 and b is -49.46515415021376\n",
      "Iteration 8820, the loss is 4.523658756551476, parameters k is 11.480560616602736 and b is -49.465114624522066\n",
      "Iteration 8821, the loss is 4.523658106969938, parameters k is 11.480543316207479 and b is -49.46508300396871\n",
      "Iteration 8822, the loss is 4.5236574573884045, parameters k is 11.480526015812222 and b is -49.46505138341535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8823, the loss is 4.523657000499162, parameters k is 11.480508715416965 and b is -49.46501976286199\n",
      "Iteration 8824, the loss is 4.523656464863836, parameters k is 11.48054131225491 and b is -49.464980237170295\n",
      "Iteration 8825, the loss is 4.523655815282302, parameters k is 11.480524011859654 and b is -49.46494861661694\n",
      "Iteration 8826, the loss is 4.523655165700768, parameters k is 11.480506711464397 and b is -49.46491699606358\n",
      "Iteration 8827, the loss is 4.523654659252997, parameters k is 11.48048941106914 and b is -49.46488537551022\n",
      "Iteration 8828, the loss is 4.523654173176199, parameters k is 11.480522007907085 and b is -49.46484584981852\n",
      "Iteration 8829, the loss is 4.523653523594663, parameters k is 11.480504707511828 and b is -49.464814229265166\n",
      "Iteration 8830, the loss is 4.523652874013125, parameters k is 11.480487407116572 and b is -49.46478260871181\n",
      "Iteration 8831, the loss is 4.523652318006828, parameters k is 11.480470106721315 and b is -49.46475098815845\n",
      "Iteration 8832, the loss is 4.523651881488564, parameters k is 11.48050270355926 and b is -49.46471146246675\n",
      "Iteration 8833, the loss is 4.523651231907028, parameters k is 11.480485403164003 and b is -49.464679841913394\n",
      "Iteration 8834, the loss is 4.52365058232549, parameters k is 11.480468102768747 and b is -49.46464822136004\n",
      "Iteration 8835, the loss is 4.523649976760656, parameters k is 11.48045080237349 and b is -49.46461660080668\n",
      "Iteration 8836, the loss is 4.523649589800929, parameters k is 11.480483399211435 and b is -49.46457707511498\n",
      "Iteration 8837, the loss is 4.52364894021939, parameters k is 11.480466098816178 and b is -49.46454545456162\n",
      "Iteration 8838, the loss is 4.523648290637858, parameters k is 11.480448798420921 and b is -49.464513834008265\n",
      "Iteration 8839, the loss is 4.52364764105632, parameters k is 11.480431498025665 and b is -49.46448221345491\n",
      "Iteration 8840, the loss is 4.523647292571458, parameters k is 11.480414197630408 and b is -49.46445059290155\n",
      "Iteration 8841, the loss is 4.523646648531752, parameters k is 11.480446794468353 and b is -49.46441106720985\n",
      "Iteration 8842, the loss is 4.523645998950216, parameters k is 11.480429494073096 and b is -49.464379446656494\n",
      "Iteration 8843, the loss is 4.523645349368682, parameters k is 11.48041219367784 and b is -49.464347826103136\n",
      "Iteration 8844, the loss is 4.52364495132529, parameters k is 11.480394893282583 and b is -49.46431620554978\n",
      "Iteration 8845, the loss is 4.523644356844118, parameters k is 11.480427490120528 and b is -49.46427667985808\n",
      "Iteration 8846, the loss is 4.523643707262585, parameters k is 11.480410189725271 and b is -49.46424505930472\n",
      "Iteration 8847, the loss is 4.523643057681049, parameters k is 11.480392889330014 and b is -49.464213438751365\n",
      "Iteration 8848, the loss is 4.523642610079122, parameters k is 11.480375588934757 and b is -49.46418181819801\n",
      "Iteration 8849, the loss is 4.523642065156474, parameters k is 11.480408185772703 and b is -49.46414229250631\n",
      "Iteration 8850, the loss is 4.523641415574939, parameters k is 11.480390885377446 and b is -49.46411067195295\n",
      "Iteration 8851, the loss is 4.523640765993404, parameters k is 11.480373584982189 and b is -49.464079051399594\n",
      "Iteration 8852, the loss is 4.523640268832953, parameters k is 11.480356284586932 and b is -49.464047430846236\n",
      "Iteration 8853, the loss is 4.523639773468843, parameters k is 11.480388881424878 and b is -49.46400790515454\n",
      "Iteration 8854, the loss is 4.523639123887305, parameters k is 11.48037158102962 and b is -49.46397628460118\n",
      "Iteration 8855, the loss is 4.523638474305771, parameters k is 11.480354280634364 and b is -49.46394466404782\n",
      "Iteration 8856, the loss is 4.5236379275867815, parameters k is 11.480336980239107 and b is -49.463913043494465\n",
      "Iteration 8857, the loss is 4.5236374817812015, parameters k is 11.480369577077052 and b is -49.46387351780277\n",
      "Iteration 8858, the loss is 4.523636832199666, parameters k is 11.480352276681796 and b is -49.46384189724941\n",
      "Iteration 8859, the loss is 4.523636182618127, parameters k is 11.480334976286539 and b is -49.46381027669605\n",
      "Iteration 8860, the loss is 4.523635586340613, parameters k is 11.480317675891282 and b is -49.46377865614269\n",
      "Iteration 8861, the loss is 4.523635190093563, parameters k is 11.480350272729227 and b is -49.463739130450996\n",
      "Iteration 8862, the loss is 4.523634540512032, parameters k is 11.48033297233397 and b is -49.46370750989764\n",
      "Iteration 8863, the loss is 4.523633890930492, parameters k is 11.480315671938714 and b is -49.46367588934428\n",
      "Iteration 8864, the loss is 4.5236332450944445, parameters k is 11.480298371543457 and b is -49.46364426879092\n",
      "Iteration 8865, the loss is 4.523632898405928, parameters k is 11.480330968381402 and b is -49.463604743099225\n",
      "Iteration 8866, the loss is 4.5236322488243905, parameters k is 11.480313667986145 and b is -49.46357312254587\n",
      "Iteration 8867, the loss is 4.523631599242854, parameters k is 11.480296367590888 and b is -49.46354150199251\n",
      "Iteration 8868, the loss is 4.523630949661321, parameters k is 11.480279067195632 and b is -49.46350988143915\n",
      "Iteration 8869, the loss is 4.523630560905247, parameters k is 11.480261766800375 and b is -49.46347826088579\n",
      "Iteration 8870, the loss is 4.523629957136751, parameters k is 11.48029436363832 and b is -49.463438735194096\n",
      "Iteration 8871, the loss is 4.523629307555217, parameters k is 11.480277063243063 and b is -49.46340711464074\n",
      "Iteration 8872, the loss is 4.523628657973682, parameters k is 11.480259762847806 and b is -49.46337549408738\n",
      "Iteration 8873, the loss is 4.523628219659079, parameters k is 11.48024246245255 and b is -49.46334387353402\n",
      "Iteration 8874, the loss is 4.52362766544912, parameters k is 11.480275059290495 and b is -49.463304347842325\n",
      "Iteration 8875, the loss is 4.523627015867581, parameters k is 11.480257758895238 and b is -49.46327272728897\n",
      "Iteration 8876, the loss is 4.523626366286047, parameters k is 11.480240458499981 and b is -49.46324110673561\n",
      "Iteration 8877, the loss is 4.523625878412915, parameters k is 11.480223158104724 and b is -49.46320948618225\n",
      "Iteration 8878, the loss is 4.52362537376148, parameters k is 11.48025575494267 and b is -49.46316996049055\n",
      "Iteration 8879, the loss is 4.523624724179946, parameters k is 11.480238454547413 and b is -49.463138339937196\n",
      "Iteration 8880, the loss is 4.523624074598409, parameters k is 11.480221154152156 and b is -49.46310671938384\n",
      "Iteration 8881, the loss is 4.523623537166738, parameters k is 11.4802038537569 and b is -49.46307509883048\n",
      "Iteration 8882, the loss is 4.523623082073842, parameters k is 11.480236450594845 and b is -49.46303557313878\n",
      "Iteration 8883, the loss is 4.523622432492305, parameters k is 11.480219150199588 and b is -49.463003952585424\n",
      "Iteration 8884, the loss is 4.52362178291077, parameters k is 11.480201849804331 and b is -49.462972332032066\n",
      "Iteration 8885, the loss is 4.523621195920579, parameters k is 11.480184549409074 and b is -49.46294071147871\n",
      "Iteration 8886, the loss is 4.523620790386206, parameters k is 11.48021714624702 and b is -49.46290118578701\n",
      "Iteration 8887, the loss is 4.5236201408046695, parameters k is 11.480199845851763 and b is -49.46286956523365\n",
      "Iteration 8888, the loss is 4.523619491223138, parameters k is 11.480182545456506 and b is -49.462837944680295\n",
      "Iteration 8889, the loss is 4.523618854674407, parameters k is 11.480165245061249 and b is -49.46280632412694\n",
      "Iteration 8890, the loss is 4.523618498698563, parameters k is 11.480197841899194 and b is -49.46276679843524\n",
      "Iteration 8891, the loss is 4.52361784911703, parameters k is 11.480180541503938 and b is -49.46273517788188\n",
      "Iteration 8892, the loss is 4.523617199535492, parameters k is 11.48016324110868 and b is -49.462703557328524\n",
      "Iteration 8893, the loss is 4.52361654995396, parameters k is 11.480145940713424 and b is -49.462671936775166\n",
      "Iteration 8894, the loss is 4.523616170485202, parameters k is 11.480128640318167 and b is -49.46264031622181\n",
      "Iteration 8895, the loss is 4.523615557429393, parameters k is 11.480161237156112 and b is -49.46260079053011\n",
      "Iteration 8896, the loss is 4.52361490784786, parameters k is 11.480143936760856 and b is -49.46256916997675\n",
      "Iteration 8897, the loss is 4.5236142582663215, parameters k is 11.480126636365599 and b is -49.462537549423395\n",
      "Iteration 8898, the loss is 4.523613829239037, parameters k is 11.480109335970342 and b is -49.46250592887004\n",
      "Iteration 8899, the loss is 4.523613265741757, parameters k is 11.480141932808287 and b is -49.46246640317834\n",
      "Iteration 8900, the loss is 4.523612616160222, parameters k is 11.48012463241303 and b is -49.46243478262498\n",
      "Iteration 8901, the loss is 4.523611966578688, parameters k is 11.480107332017774 and b is -49.462403162071624\n",
      "Iteration 8902, the loss is 4.523611487992868, parameters k is 11.480090031622517 and b is -49.462371541518266\n",
      "Iteration 8903, the loss is 4.523610974054116, parameters k is 11.480122628460462 and b is -49.46233201582657\n",
      "Iteration 8904, the loss is 4.5236103244725845, parameters k is 11.480105328065205 and b is -49.46230039527321\n",
      "Iteration 8905, the loss is 4.523609674891042, parameters k is 11.480088027669948 and b is -49.46226877471985\n",
      "Iteration 8906, the loss is 4.5236091467467, parameters k is 11.480070727274692 and b is -49.462237154166495\n",
      "Iteration 8907, the loss is 4.523608682366482, parameters k is 11.480103324112637 and b is -49.4621976284748\n",
      "Iteration 8908, the loss is 4.523608032784946, parameters k is 11.48008602371738 and b is -49.46216600792144\n",
      "Iteration 8909, the loss is 4.523607383203407, parameters k is 11.480068723322123 and b is -49.46213438736808\n",
      "Iteration 8910, the loss is 4.523606805500532, parameters k is 11.480051422926866 and b is -49.46210276681472\n",
      "Iteration 8911, the loss is 4.523606390678838, parameters k is 11.480084019764812 and b is -49.462063241123026\n",
      "Iteration 8912, the loss is 4.523605741097304, parameters k is 11.480066719369555 and b is -49.46203162056967\n",
      "Iteration 8913, the loss is 4.52360509151577, parameters k is 11.480049418974298 and b is -49.46200000001631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8914, the loss is 4.523604464254364, parameters k is 11.480032118579041 and b is -49.46196837946295\n",
      "Iteration 8915, the loss is 4.5236040989912025, parameters k is 11.480064715416987 and b is -49.461928853771255\n",
      "Iteration 8916, the loss is 4.523603449409669, parameters k is 11.48004741502173 and b is -49.4618972332179\n",
      "Iteration 8917, the loss is 4.523602799828135, parameters k is 11.480030114626473 and b is -49.46186561266454\n",
      "Iteration 8918, the loss is 4.5236021502466, parameters k is 11.480012814231216 and b is -49.46183399211118\n",
      "Iteration 8919, the loss is 4.523601780065164, parameters k is 11.47999551383596 and b is -49.46180237155782\n",
      "Iteration 8920, the loss is 4.523601157722035, parameters k is 11.480028110673905 and b is -49.461762845866126\n",
      "Iteration 8921, the loss is 4.523600508140497, parameters k is 11.480010810278648 and b is -49.46173122531277\n",
      "Iteration 8922, the loss is 4.523599858558958, parameters k is 11.479993509883391 and b is -49.46169960475941\n",
      "Iteration 8923, the loss is 4.523599438818998, parameters k is 11.479976209488134 and b is -49.46166798420605\n",
      "Iteration 8924, the loss is 4.5235988660343915, parameters k is 11.48000880632608 and b is -49.461628458514355\n",
      "Iteration 8925, the loss is 4.523598216452862, parameters k is 11.479991505930823 and b is -49.461596837961\n",
      "Iteration 8926, the loss is 4.523597566871329, parameters k is 11.479974205535566 and b is -49.46156521740764\n",
      "Iteration 8927, the loss is 4.523597097572828, parameters k is 11.479956905140309 and b is -49.46153359685428\n",
      "Iteration 8928, the loss is 4.523596574346761, parameters k is 11.479989501978254 and b is -49.46149407116258\n",
      "Iteration 8929, the loss is 4.523595924765222, parameters k is 11.479972201582997 and b is -49.461462450609226\n",
      "Iteration 8930, the loss is 4.5235952751836885, parameters k is 11.47995490118774 and b is -49.46143083005587\n",
      "Iteration 8931, the loss is 4.52359475632666, parameters k is 11.479937600792484 and b is -49.46139920950251\n",
      "Iteration 8932, the loss is 4.52359428265912, parameters k is 11.47997019763043 and b is -49.46135968381081\n",
      "Iteration 8933, the loss is 4.523593633077587, parameters k is 11.479952897235172 and b is -49.461328063257454\n",
      "Iteration 8934, the loss is 4.523592983496047, parameters k is 11.479935596839915 and b is -49.461296442704096\n",
      "Iteration 8935, the loss is 4.523592415080489, parameters k is 11.479918296444659 and b is -49.46126482215074\n",
      "Iteration 8936, the loss is 4.523591990971482, parameters k is 11.479950893282604 and b is -49.46122529645904\n",
      "Iteration 8937, the loss is 4.5235913413899445, parameters k is 11.479933592887347 and b is -49.46119367590568\n",
      "Iteration 8938, the loss is 4.5235906918084146, parameters k is 11.47991629249209 and b is -49.461162055352325\n",
      "Iteration 8939, the loss is 4.523590073834325, parameters k is 11.479898992096834 and b is -49.46113043479897\n",
      "Iteration 8940, the loss is 4.523589699283846, parameters k is 11.479931588934779 and b is -49.46109090910727\n",
      "Iteration 8941, the loss is 4.523589049702311, parameters k is 11.479914288539522 and b is -49.46105928855391\n",
      "Iteration 8942, the loss is 4.523588400120776, parameters k is 11.479896988144265 and b is -49.461027668000554\n",
      "Iteration 8943, the loss is 4.5235877505392414, parameters k is 11.479879687749008 and b is -49.460996047447196\n",
      "Iteration 8944, the loss is 4.523587389645125, parameters k is 11.479862387353752 and b is -49.46096442689384\n",
      "Iteration 8945, the loss is 4.523586758014672, parameters k is 11.479894984191697 and b is -49.46092490120214\n",
      "Iteration 8946, the loss is 4.523586108433138, parameters k is 11.47987768379644 and b is -49.46089328064878\n",
      "Iteration 8947, the loss is 4.523585458851603, parameters k is 11.479860383401183 and b is -49.460861660095425\n",
      "Iteration 8948, the loss is 4.523585048398952, parameters k is 11.479843083005926 and b is -49.46083003954207\n",
      "Iteration 8949, the loss is 4.523584466327034, parameters k is 11.479875679843872 and b is -49.46079051385037\n",
      "Iteration 8950, the loss is 4.523583816745502, parameters k is 11.479858379448615 and b is -49.46075889329701\n",
      "Iteration 8951, the loss is 4.523583167163963, parameters k is 11.479841079053358 and b is -49.460727272743654\n",
      "Iteration 8952, the loss is 4.5235827071527845, parameters k is 11.479823778658101 and b is -49.460695652190296\n",
      "Iteration 8953, the loss is 4.5235821746393965, parameters k is 11.479856375496047 and b is -49.4606561264986\n",
      "Iteration 8954, the loss is 4.523581525057858, parameters k is 11.47983907510079 and b is -49.46062450594524\n",
      "Iteration 8955, the loss is 4.5235808754763225, parameters k is 11.479821774705533 and b is -49.46059288539188\n",
      "Iteration 8956, the loss is 4.523580365906615, parameters k is 11.479804474310276 and b is -49.460561264838525\n",
      "Iteration 8957, the loss is 4.523579882951765, parameters k is 11.479837071148221 and b is -49.46052173914683\n",
      "Iteration 8958, the loss is 4.523579233370226, parameters k is 11.479819770752965 and b is -49.46049011859347\n",
      "Iteration 8959, the loss is 4.523578583788693, parameters k is 11.479802470357708 and b is -49.46045849804011\n",
      "Iteration 8960, the loss is 4.523578024660454, parameters k is 11.479785169962451 and b is -49.46042687748675\n",
      "Iteration 8961, the loss is 4.52357759126412, parameters k is 11.479817766800396 and b is -49.460387351795056\n",
      "Iteration 8962, the loss is 4.5235769416825855, parameters k is 11.47980046640514 and b is -49.4603557312417\n",
      "Iteration 8963, the loss is 4.523576292101048, parameters k is 11.479783166009883 and b is -49.46032411068834\n",
      "Iteration 8964, the loss is 4.523575683414279, parameters k is 11.479765865614626 and b is -49.46029249013498\n",
      "Iteration 8965, the loss is 4.5235752995764855, parameters k is 11.479798462452571 and b is -49.460252964443285\n",
      "Iteration 8966, the loss is 4.523574649994948, parameters k is 11.479781162057314 and b is -49.46022134388993\n",
      "Iteration 8967, the loss is 4.523574000413412, parameters k is 11.479763861662057 and b is -49.46018972333657\n",
      "Iteration 8968, the loss is 4.523573350831875, parameters k is 11.4797465612668 and b is -49.46015810278321\n",
      "Iteration 8969, the loss is 4.52357299922508, parameters k is 11.479729260871544 and b is -49.46012648222985\n",
      "Iteration 8970, the loss is 4.523572358307308, parameters k is 11.479761857709489 and b is -49.460086956538156\n",
      "Iteration 8971, the loss is 4.5235717087257745, parameters k is 11.479744557314232 and b is -49.4600553359848\n",
      "Iteration 8972, the loss is 4.523571059144242, parameters k is 11.479727256918975 and b is -49.46002371543144\n",
      "Iteration 8973, the loss is 4.523570657978912, parameters k is 11.479709956523719 and b is -49.45999209487808\n",
      "Iteration 8974, the loss is 4.523570066619677, parameters k is 11.479742553361664 and b is -49.459952569186385\n",
      "Iteration 8975, the loss is 4.523569417038141, parameters k is 11.479725252966407 and b is -49.45992094863303\n",
      "Iteration 8976, the loss is 4.5235687674566005, parameters k is 11.47970795257115 and b is -49.45988932807967\n",
      "Iteration 8977, the loss is 4.523568316732746, parameters k is 11.479690652175893 and b is -49.45985770752631\n",
      "Iteration 8978, the loss is 4.523567774932039, parameters k is 11.479723249013839 and b is -49.45981818183461\n",
      "Iteration 8979, the loss is 4.523567125350497, parameters k is 11.479705948618582 and b is -49.459786561281256\n",
      "Iteration 8980, the loss is 4.523566475768966, parameters k is 11.479688648223325 and b is -49.4597549407279\n",
      "Iteration 8981, the loss is 4.523565975486575, parameters k is 11.479671347828068 and b is -49.45972332017454\n",
      "Iteration 8982, the loss is 4.523565483244401, parameters k is 11.479703944666014 and b is -49.45968379448284\n",
      "Iteration 8983, the loss is 4.5235648336628635, parameters k is 11.479686644270757 and b is -49.459652173929484\n",
      "Iteration 8984, the loss is 4.523564184081325, parameters k is 11.4796693438755 and b is -49.459620553376126\n",
      "Iteration 8985, the loss is 4.52356363424041, parameters k is 11.479652043480243 and b is -49.45958893282277\n",
      "Iteration 8986, the loss is 4.523563191556761, parameters k is 11.479684640318188 and b is -49.45954940713107\n",
      "Iteration 8987, the loss is 4.523562541975226, parameters k is 11.479667339922932 and b is -49.45951778657771\n",
      "Iteration 8988, the loss is 4.523561892393691, parameters k is 11.479650039527675 and b is -49.459486166024355\n",
      "Iteration 8989, the loss is 4.5235612929942395, parameters k is 11.479632739132418 and b is -49.459454545471\n",
      "Iteration 8990, the loss is 4.523560899869122, parameters k is 11.479665335970363 and b is -49.4594150197793\n",
      "Iteration 8991, the loss is 4.52356025028759, parameters k is 11.479648035575106 and b is -49.45938339922594\n",
      "Iteration 8992, the loss is 4.523559600706054, parameters k is 11.47963073517985 and b is -49.459351778672584\n",
      "Iteration 8993, the loss is 4.523558951748068, parameters k is 11.479613434784593 and b is -49.459320158119226\n",
      "Iteration 8994, the loss is 4.523558608181486, parameters k is 11.479646031622538 and b is -49.45928063242753\n",
      "Iteration 8995, the loss is 4.523557958599952, parameters k is 11.479628731227281 and b is -49.45924901187417\n",
      "Iteration 8996, the loss is 4.5235573090184165, parameters k is 11.479611430832025 and b is -49.45921739132081\n",
      "Iteration 8997, the loss is 4.523556659436881, parameters k is 11.479594130436768 and b is -49.459185770767455\n",
      "Iteration 8998, the loss is 4.523556267558876, parameters k is 11.47957683004151 and b is -49.4591541502141\n",
      "Iteration 8999, the loss is 4.52355566691231, parameters k is 11.479609426879456 and b is -49.4591146245224\n",
      "Iteration 9000, the loss is 4.523555017330778, parameters k is 11.4795921264842 and b is -49.45908300396904\n",
      "Iteration 9001, the loss is 4.523554367749244, parameters k is 11.479574826088943 and b is -49.459051383415684\n",
      "Iteration 9002, the loss is 4.523553926312704, parameters k is 11.479557525693686 and b is -49.459019762862326\n",
      "Iteration 9003, the loss is 4.523553375224673, parameters k is 11.479590122531631 and b is -49.45898023717063\n",
      "Iteration 9004, the loss is 4.5235527256431425, parameters k is 11.479572822136374 and b is -49.45894861661727\n",
      "Iteration 9005, the loss is 4.523552076061604, parameters k is 11.479555521741117 and b is -49.45891699606391\n",
      "Iteration 9006, the loss is 4.523551585066531, parameters k is 11.47953822134586 and b is -49.458885375510555\n",
      "Iteration 9007, the loss is 4.52355108353704, parameters k is 11.479570818183806 and b is -49.45884584981886\n",
      "Iteration 9008, the loss is 4.523550433955498, parameters k is 11.479553517788549 and b is -49.4588142292655\n",
      "Iteration 9009, the loss is 4.523549784373968, parameters k is 11.479536217393292 and b is -49.45878260871214\n",
      "Iteration 9010, the loss is 4.523549243820363, parameters k is 11.479518916998035 and b is -49.45875098815878\n",
      "Iteration 9011, the loss is 4.523548791849401, parameters k is 11.47955151383598 and b is -49.458711462467086\n",
      "Iteration 9012, the loss is 4.523548142267869, parameters k is 11.479534213440724 and b is -49.45867984191373\n",
      "Iteration 9013, the loss is 4.523547492686335, parameters k is 11.479516913045467 and b is -49.45864822136037\n",
      "Iteration 9014, the loss is 4.523546902574197, parameters k is 11.47949961265021 and b is -49.45861660080701\n",
      "Iteration 9015, the loss is 4.523546500161763, parameters k is 11.479532209488156 and b is -49.458577075115315\n",
      "Iteration 9016, the loss is 4.523545850580226, parameters k is 11.479514909092899 and b is -49.45854545456196\n",
      "Iteration 9017, the loss is 4.523545200998694, parameters k is 11.479497608697642 and b is -49.4585138340086\n",
      "Iteration 9018, the loss is 4.5235445613280305, parameters k is 11.479480308302385 and b is -49.45848221345524\n",
      "Iteration 9019, the loss is 4.523544208474126, parameters k is 11.47951290514033 and b is -49.458442687763544\n",
      "Iteration 9020, the loss is 4.523543558892587, parameters k is 11.479495604745074 and b is -49.458411067210186\n",
      "Iteration 9021, the loss is 4.523542909311054, parameters k is 11.479478304349817 and b is -49.45837944665683\n",
      "Iteration 9022, the loss is 4.523542259729518, parameters k is 11.47946100395456 and b is -49.45834782610347\n",
      "Iteration 9023, the loss is 4.523541877138827, parameters k is 11.479443703559303 and b is -49.45831620555011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9024, the loss is 4.5235412672049495, parameters k is 11.479476300397248 and b is -49.458276679858415\n",
      "Iteration 9025, the loss is 4.523540617623417, parameters k is 11.479459000001992 and b is -49.45824505930506\n",
      "Iteration 9026, the loss is 4.52353996804188, parameters k is 11.479441699606735 and b is -49.4582134387517\n",
      "Iteration 9027, the loss is 4.52353953589267, parameters k is 11.479424399211478 and b is -49.45818181819834\n",
      "Iteration 9028, the loss is 4.523538975517322, parameters k is 11.479456996049423 and b is -49.45814229250664\n",
      "Iteration 9029, the loss is 4.52353832593578, parameters k is 11.479439695654166 and b is -49.458110671953285\n",
      "Iteration 9030, the loss is 4.523537676354242, parameters k is 11.47942239525891 and b is -49.45807905139993\n",
      "Iteration 9031, the loss is 4.523537194646494, parameters k is 11.479405094863653 and b is -49.45804743084657\n",
      "Iteration 9032, the loss is 4.523536683829673, parameters k is 11.479437691701598 and b is -49.45800790515487\n",
      "Iteration 9033, the loss is 4.5235360342481465, parameters k is 11.479420391306341 and b is -49.457976284601514\n",
      "Iteration 9034, the loss is 4.523535384666606, parameters k is 11.479403090911084 and b is -49.457944664048156\n",
      "Iteration 9035, the loss is 4.523534853400324, parameters k is 11.479385790515828 and b is -49.4579130434948\n",
      "Iteration 9036, the loss is 4.523534392142039, parameters k is 11.479418387353773 and b is -49.4578735178031\n",
      "Iteration 9037, the loss is 4.523533742560503, parameters k is 11.479401086958516 and b is -49.45784189724974\n",
      "Iteration 9038, the loss is 4.52353309297897, parameters k is 11.47938378656326 and b is -49.457810276696385\n",
      "Iteration 9039, the loss is 4.523532512154157, parameters k is 11.479366486168002 and b is -49.45777865614303\n",
      "Iteration 9040, the loss is 4.523532100454402, parameters k is 11.479399083005948 and b is -49.45773913045133\n",
      "Iteration 9041, the loss is 4.523531450872868, parameters k is 11.479381782610691 and b is -49.45770750989797\n",
      "Iteration 9042, the loss is 4.523530801291331, parameters k is 11.479364482215434 and b is -49.457675889344614\n",
      "Iteration 9043, the loss is 4.523530170907987, parameters k is 11.479347181820177 and b is -49.457644268791256\n",
      "Iteration 9044, the loss is 4.523529808766764, parameters k is 11.479379778658123 and b is -49.45760474309956\n",
      "Iteration 9045, the loss is 4.523529159185225, parameters k is 11.479362478262866 and b is -49.4575731225462\n",
      "Iteration 9046, the loss is 4.523528509603696, parameters k is 11.479345177867609 and b is -49.45754150199284\n",
      "Iteration 9047, the loss is 4.523527860022159, parameters k is 11.479327877472352 and b is -49.457509881439485\n",
      "Iteration 9048, the loss is 4.523527486718784, parameters k is 11.479310577077095 and b is -49.45747826088613\n",
      "Iteration 9049, the loss is 4.523526867497593, parameters k is 11.47934317391504 and b is -49.45743873519443\n",
      "Iteration 9050, the loss is 4.523526217916061, parameters k is 11.479325873519784 and b is -49.45740711464107\n",
      "Iteration 9051, the loss is 4.523525568334525, parameters k is 11.479308573124527 and b is -49.457375494087714\n",
      "Iteration 9052, the loss is 4.523525145472619, parameters k is 11.47929127272927 and b is -49.457343873534356\n",
      "Iteration 9053, the loss is 4.523524575809953, parameters k is 11.479323869567216 and b is -49.45730434784266\n",
      "Iteration 9054, the loss is 4.523523926228417, parameters k is 11.479306569171959 and b is -49.4572727272893\n",
      "Iteration 9055, the loss is 4.523523276646884, parameters k is 11.479289268776702 and b is -49.45724110673594\n",
      "Iteration 9056, the loss is 4.52352280422645, parameters k is 11.479271968381445 and b is -49.457209486182585\n",
      "Iteration 9057, the loss is 4.523522284122318, parameters k is 11.47930456521939 and b is -49.45716996049089\n",
      "Iteration 9058, the loss is 4.523521634540783, parameters k is 11.479287264824134 and b is -49.45713833993753\n",
      "Iteration 9059, the loss is 4.523520984959249, parameters k is 11.479269964428877 and b is -49.45710671938417\n",
      "Iteration 9060, the loss is 4.523520462980282, parameters k is 11.47925266403362 and b is -49.45707509883081\n",
      "Iteration 9061, the loss is 4.523519992434676, parameters k is 11.479285260871565 and b is -49.457035573139116\n",
      "Iteration 9062, the loss is 4.523519342853141, parameters k is 11.479267960476308 and b is -49.45700395258576\n",
      "Iteration 9063, the loss is 4.523518693271605, parameters k is 11.479250660081052 and b is -49.4569723320324\n",
      "Iteration 9064, the loss is 4.523518121734117, parameters k is 11.479233359685795 and b is -49.45694071147904\n",
      "Iteration 9065, the loss is 4.523517700747043, parameters k is 11.47926595652374 and b is -49.456901185787345\n",
      "Iteration 9066, the loss is 4.52351705116551, parameters k is 11.479248656128483 and b is -49.45686956523399\n",
      "Iteration 9067, the loss is 4.52351640158397, parameters k is 11.479231355733226 and b is -49.45683794468063\n",
      "Iteration 9068, the loss is 4.523515780487946, parameters k is 11.47921405533797 and b is -49.45680632412727\n",
      "Iteration 9069, the loss is 4.523515409059403, parameters k is 11.479246652175915 and b is -49.456766798435574\n",
      "Iteration 9070, the loss is 4.5235147594778695, parameters k is 11.479229351780658 and b is -49.456735177882216\n",
      "Iteration 9071, the loss is 4.5235141098963325, parameters k is 11.479212051385401 and b is -49.45670355732886\n",
      "Iteration 9072, the loss is 4.523513460314795, parameters k is 11.479194750990144 and b is -49.4566719367755\n",
      "Iteration 9073, the loss is 4.523513096298744, parameters k is 11.479177450594888 and b is -49.45664031622214\n",
      "Iteration 9074, the loss is 4.523512467790229, parameters k is 11.479210047432833 and b is -49.456600790530445\n",
      "Iteration 9075, the loss is 4.5235118182086955, parameters k is 11.479192747037576 and b is -49.45656916997709\n",
      "Iteration 9076, the loss is 4.523511168627163, parameters k is 11.47917544664232 and b is -49.45653754942373\n",
      "Iteration 9077, the loss is 4.523510755052574, parameters k is 11.479158146247062 and b is -49.45650592887037\n",
      "Iteration 9078, the loss is 4.523510176102592, parameters k is 11.479190743085008 and b is -49.45646640317867\n",
      "Iteration 9079, the loss is 4.523509526521058, parameters k is 11.479173442689751 and b is -49.456434782625315\n",
      "Iteration 9080, the loss is 4.523508876939525, parameters k is 11.479156142294494 and b is -49.45640316207196\n",
      "Iteration 9081, the loss is 4.523508413806408, parameters k is 11.479138841899237 and b is -49.4563715415186\n",
      "Iteration 9082, the loss is 4.5235078844149585, parameters k is 11.479171438737183 and b is -49.4563320158269\n",
      "Iteration 9083, the loss is 4.523507234833422, parameters k is 11.479154138341926 and b is -49.456300395273544\n",
      "Iteration 9084, the loss is 4.5235065852518845, parameters k is 11.479136837946669 and b is -49.456268774720186\n",
      "Iteration 9085, the loss is 4.523506072560239, parameters k is 11.479119537551412 and b is -49.45623715416683\n",
      "Iteration 9086, the loss is 4.523505592727322, parameters k is 11.479152134389357 and b is -49.45619762847513\n",
      "Iteration 9087, the loss is 4.523504943145783, parameters k is 11.4791348339941 and b is -49.45616600792177\n",
      "Iteration 9088, the loss is 4.52350429356425, parameters k is 11.479117533598844 and b is -49.456134387368415\n",
      "Iteration 9089, the loss is 4.5235037313140705, parameters k is 11.479100233203587 and b is -49.45610276681506\n",
      "Iteration 9090, the loss is 4.523503301039682, parameters k is 11.479132830041532 and b is -49.45606324112336\n",
      "Iteration 9091, the loss is 4.523502651458147, parameters k is 11.479115529646275 and b is -49.45603162057\n",
      "Iteration 9092, the loss is 4.523502001876611, parameters k is 11.479098229251019 and b is -49.456000000016644\n",
      "Iteration 9093, the loss is 4.523501390067902, parameters k is 11.479080928855762 and b is -49.455968379463286\n",
      "Iteration 9094, the loss is 4.523501009352042, parameters k is 11.479113525693707 and b is -49.45592885377159\n",
      "Iteration 9095, the loss is 4.523500359770507, parameters k is 11.47909622529845 and b is -49.45589723321823\n",
      "Iteration 9096, the loss is 4.523499710188974, parameters k is 11.479078924903193 and b is -49.45586561266487\n",
      "Iteration 9097, the loss is 4.523499060607437, parameters k is 11.479061624507937 and b is -49.455833992111515\n",
      "Iteration 9098, the loss is 4.523498705878702, parameters k is 11.47904432411268 and b is -49.45580237155816\n",
      "Iteration 9099, the loss is 4.523498068082871, parameters k is 11.479076920950625 and b is -49.45576284586646\n",
      "Iteration 9100, the loss is 4.523497418501335, parameters k is 11.479059620555368 and b is -49.4557312253131\n",
      "Iteration 9101, the loss is 4.523496768919802, parameters k is 11.479042320160112 and b is -49.455699604759744\n",
      "Iteration 9102, the loss is 4.523496364632532, parameters k is 11.479025019764855 and b is -49.455667984206386\n",
      "Iteration 9103, the loss is 4.523495776395231, parameters k is 11.4790576166028 and b is -49.45562845851469\n",
      "Iteration 9104, the loss is 4.523495126813698, parameters k is 11.479040316207543 and b is -49.45559683796133\n",
      "Iteration 9105, the loss is 4.523494477232162, parameters k is 11.479023015812286 and b is -49.45556521740797\n",
      "Iteration 9106, the loss is 4.523494023386366, parameters k is 11.47900571541703 and b is -49.455533596854615\n",
      "Iteration 9107, the loss is 4.5234934847076005, parameters k is 11.479038312254975 and b is -49.45549407116292\n",
      "Iteration 9108, the loss is 4.523492835126063, parameters k is 11.479021011859718 and b is -49.45546245060956\n",
      "Iteration 9109, the loss is 4.523492185544523, parameters k is 11.479003711464461 and b is -49.4554308300562\n",
      "Iteration 9110, the loss is 4.523491682140197, parameters k is 11.478986411069204 and b is -49.45539920950284\n",
      "Iteration 9111, the loss is 4.523491193019957, parameters k is 11.47901900790715 and b is -49.455359683811146\n",
      "Iteration 9112, the loss is 4.523490543438421, parameters k is 11.479001707511893 and b is -49.45532806325779\n",
      "Iteration 9113, the loss is 4.523489893856887, parameters k is 11.478984407116636 and b is -49.45529644270443\n",
      "Iteration 9114, the loss is 4.523489340894026, parameters k is 11.47896710672138 and b is -49.45526482215107\n",
      "Iteration 9115, the loss is 4.523488901332322, parameters k is 11.478999703559325 and b is -49.455225296459375\n",
      "Iteration 9116, the loss is 4.523488251750784, parameters k is 11.478982403164068 and b is -49.45519367590602\n",
      "Iteration 9117, the loss is 4.523487602169246, parameters k is 11.47896510276881 and b is -49.45516205535266\n",
      "Iteration 9118, the loss is 4.5234869996478615, parameters k is 11.478947802373554 and b is -49.4551304347993\n",
      "Iteration 9119, the loss is 4.523486609644682, parameters k is 11.4789803992115 and b is -49.455090909107604\n",
      "Iteration 9120, the loss is 4.523485960063148, parameters k is 11.478963098816243 and b is -49.455059288554246\n",
      "Iteration 9121, the loss is 4.523485310481619, parameters k is 11.478945798420986 and b is -49.45502766800089\n",
      "Iteration 9122, the loss is 4.523484660900074, parameters k is 11.478928498025729 and b is -49.45499604744753\n",
      "Iteration 9123, the loss is 4.523484315458663, parameters k is 11.478911197630472 and b is -49.45496442689417\n",
      "Iteration 9124, the loss is 4.523483668375513, parameters k is 11.478943794468417 and b is -49.454924901202475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9125, the loss is 4.523483018793974, parameters k is 11.47892649407316 and b is -49.45489328064912\n",
      "Iteration 9126, the loss is 4.52348236921244, parameters k is 11.478909193677904 and b is -49.45486166009576\n",
      "Iteration 9127, the loss is 4.523481974212492, parameters k is 11.478891893282647 and b is -49.4548300395424\n",
      "Iteration 9128, the loss is 4.523481376687874, parameters k is 11.478924490120592 and b is -49.4547905138507\n",
      "Iteration 9129, the loss is 4.523480727106334, parameters k is 11.478907189725335 and b is -49.454758893297345\n",
      "Iteration 9130, the loss is 4.523480077524798, parameters k is 11.478889889330079 and b is -49.45472727274399\n",
      "Iteration 9131, the loss is 4.523479632966327, parameters k is 11.478872588934822 and b is -49.45469565219063\n",
      "Iteration 9132, the loss is 4.523479085000234, parameters k is 11.478905185772767 and b is -49.45465612649893\n",
      "Iteration 9133, the loss is 4.523478435418695, parameters k is 11.47888788537751 and b is -49.454624505945574\n",
      "Iteration 9134, the loss is 4.523477785837163, parameters k is 11.478870584982253 and b is -49.454592885392216\n",
      "Iteration 9135, the loss is 4.523477291720159, parameters k is 11.478853284586997 and b is -49.45456126483886\n",
      "Iteration 9136, the loss is 4.523476793312601, parameters k is 11.478885881424942 and b is -49.45452173914716\n",
      "Iteration 9137, the loss is 4.523476143731066, parameters k is 11.478868581029685 and b is -49.4544901185938\n",
      "Iteration 9138, the loss is 4.523475494149523, parameters k is 11.478851280634428 and b is -49.454458498040445\n",
      "Iteration 9139, the loss is 4.523474950473985, parameters k is 11.478833980239171 and b is -49.45442687748709\n",
      "Iteration 9140, the loss is 4.523474501624958, parameters k is 11.478866577077117 and b is -49.45438735179539\n",
      "Iteration 9141, the loss is 4.523473852043425, parameters k is 11.47884927668186 and b is -49.45435573124203\n",
      "Iteration 9142, the loss is 4.523473202461892, parameters k is 11.478831976286603 and b is -49.454324110688674\n",
      "Iteration 9143, the loss is 4.523472609227819, parameters k is 11.478814675891346 and b is -49.454292490135316\n",
      "Iteration 9144, the loss is 4.523472209937325, parameters k is 11.478847272729292 and b is -49.45425296444362\n",
      "Iteration 9145, the loss is 4.523471560355785, parameters k is 11.478829972334035 and b is -49.45422134389026\n",
      "Iteration 9146, the loss is 4.523470910774253, parameters k is 11.478812671938778 and b is -49.4541897233369\n",
      "Iteration 9147, the loss is 4.523470267981655, parameters k is 11.478795371543521 and b is -49.454158102783545\n",
      "Iteration 9148, the loss is 4.523469918249685, parameters k is 11.478827968381466 and b is -49.45411857709185\n",
      "Iteration 9149, the loss is 4.523469268668148, parameters k is 11.47881066798621 and b is -49.45408695653849\n",
      "Iteration 9150, the loss is 4.523468619086609, parameters k is 11.478793367590953 and b is -49.45405533598513\n",
      "Iteration 9151, the loss is 4.523467969505079, parameters k is 11.478776067195696 and b is -49.454023715431774\n",
      "Iteration 9152, the loss is 4.523467583792453, parameters k is 11.47875876680044 and b is -49.453992094878416\n",
      "Iteration 9153, the loss is 4.523466976980511, parameters k is 11.478791363638384 and b is -49.45395256918672\n",
      "Iteration 9154, the loss is 4.523466327398971, parameters k is 11.478774063243128 and b is -49.45392094863336\n",
      "Iteration 9155, the loss is 4.523465677817436, parameters k is 11.47875676284787 and b is -49.45388932808\n",
      "Iteration 9156, the loss is 4.523465242546288, parameters k is 11.478739462452614 and b is -49.453857707526645\n",
      "Iteration 9157, the loss is 4.523464685292875, parameters k is 11.47877205929056 and b is -49.45381818183495\n",
      "Iteration 9158, the loss is 4.5234640357113385, parameters k is 11.478754758895303 and b is -49.45378656128159\n",
      "Iteration 9159, the loss is 4.523463386129801, parameters k is 11.478737458500046 and b is -49.45375494072823\n",
      "Iteration 9160, the loss is 4.523462901300117, parameters k is 11.478720158104789 and b is -49.45372332017487\n",
      "Iteration 9161, the loss is 4.5234623936052385, parameters k is 11.478752754942734 and b is -49.453683794483176\n",
      "Iteration 9162, the loss is 4.5234617440237015, parameters k is 11.478735454547477 and b is -49.45365217392982\n",
      "Iteration 9163, the loss is 4.523461094442168, parameters k is 11.47871815415222 and b is -49.45362055337646\n",
      "Iteration 9164, the loss is 4.523460560053952, parameters k is 11.478700853756964 and b is -49.4535889328231\n",
      "Iteration 9165, the loss is 4.523460101917598, parameters k is 11.478733450594909 and b is -49.453549407131405\n",
      "Iteration 9166, the loss is 4.523459452336062, parameters k is 11.478716150199652 and b is -49.45351778657805\n",
      "Iteration 9167, the loss is 4.52345880275453, parameters k is 11.478698849804395 and b is -49.45348616602469\n",
      "Iteration 9168, the loss is 4.523458218807778, parameters k is 11.478681549409139 and b is -49.45345454547133\n",
      "Iteration 9169, the loss is 4.523457810229959, parameters k is 11.478714146247084 and b is -49.453415019779634\n",
      "Iteration 9170, the loss is 4.5234571606484275, parameters k is 11.478696845851827 and b is -49.453383399226276\n",
      "Iteration 9171, the loss is 4.523456511066892, parameters k is 11.47867954545657 and b is -49.45335177867292\n",
      "Iteration 9172, the loss is 4.523455877561611, parameters k is 11.478662245061313 and b is -49.45332015811956\n",
      "Iteration 9173, the loss is 4.523455518542325, parameters k is 11.478694841899259 and b is -49.45328063242786\n",
      "Iteration 9174, the loss is 4.523454868960785, parameters k is 11.478677541504002 and b is -49.453249011874505\n",
      "Iteration 9175, the loss is 4.523454219379256, parameters k is 11.478660241108745 and b is -49.45321739132115\n",
      "Iteration 9176, the loss is 4.523453569797719, parameters k is 11.478642940713488 and b is -49.45318577076779\n",
      "Iteration 9177, the loss is 4.523453193372411, parameters k is 11.478625640318231 and b is -49.45315415021443\n",
      "Iteration 9178, the loss is 4.5234525772731535, parameters k is 11.478658237156177 and b is -49.45311462452273\n",
      "Iteration 9179, the loss is 4.523451927691614, parameters k is 11.47864093676092 and b is -49.453083003969375\n",
      "Iteration 9180, the loss is 4.523451278110077, parameters k is 11.478623636365663 and b is -49.45305138341602\n",
      "Iteration 9181, the loss is 4.523450852126242, parameters k is 11.478606335970406 and b is -49.45301976286266\n",
      "Iteration 9182, the loss is 4.523450285585512, parameters k is 11.478638932808352 and b is -49.45298023717096\n",
      "Iteration 9183, the loss is 4.52344963600398, parameters k is 11.478621632413095 and b is -49.452948616617604\n",
      "Iteration 9184, the loss is 4.523448986422444, parameters k is 11.478604332017838 and b is -49.452916996064246\n",
      "Iteration 9185, the loss is 4.5234485108800735, parameters k is 11.478587031622581 and b is -49.45288537551089\n",
      "Iteration 9186, the loss is 4.523447993897874, parameters k is 11.478619628460526 and b is -49.45284584981919\n",
      "Iteration 9187, the loss is 4.523447344316335, parameters k is 11.47860232806527 and b is -49.45281422926583\n",
      "Iteration 9188, the loss is 4.523446694734807, parameters k is 11.478585027670013 and b is -49.452782608712475\n",
      "Iteration 9189, the loss is 4.523446169633907, parameters k is 11.478567727274756 and b is -49.45275098815912\n",
      "Iteration 9190, the loss is 4.523445702210236, parameters k is 11.478600324112701 and b is -49.45271146246742\n",
      "Iteration 9191, the loss is 4.523445052628702, parameters k is 11.478583023717444 and b is -49.45267984191406\n",
      "Iteration 9192, the loss is 4.523444403047166, parameters k is 11.478565723322188 and b is -49.452648221360704\n",
      "Iteration 9193, the loss is 4.523443828387738, parameters k is 11.47854842292693 and b is -49.452616600807346\n",
      "Iteration 9194, the loss is 4.523443410522602, parameters k is 11.478581019764876 and b is -49.45257707511565\n",
      "Iteration 9195, the loss is 4.523442760941062, parameters k is 11.47856371936962 and b is -49.45254545456229\n",
      "Iteration 9196, the loss is 4.523442111359528, parameters k is 11.478546418974362 and b is -49.45251383400893\n",
      "Iteration 9197, the loss is 4.523441487141568, parameters k is 11.478529118579106 and b is -49.452482213455575\n",
      "Iteration 9198, the loss is 4.523441118834962, parameters k is 11.478561715417051 and b is -49.45244268776388\n",
      "Iteration 9199, the loss is 4.52344046925343, parameters k is 11.478544415021794 and b is -49.45241106721052\n",
      "Iteration 9200, the loss is 4.523439819671894, parameters k is 11.478527114626537 and b is -49.45237944665716\n",
      "Iteration 9201, the loss is 4.5234391700903585, parameters k is 11.47850981423128 and b is -49.452347826103804\n",
      "Iteration 9202, the loss is 4.523438802952373, parameters k is 11.478492513836024 and b is -49.452316205550446\n",
      "Iteration 9203, the loss is 4.523438177565791, parameters k is 11.478525110673969 and b is -49.45227667985875\n",
      "Iteration 9204, the loss is 4.523437527984251, parameters k is 11.478507810278712 and b is -49.45224505930539\n",
      "Iteration 9205, the loss is 4.523436878402721, parameters k is 11.478490509883455 and b is -49.45221343875203\n",
      "Iteration 9206, the loss is 4.5234364617062, parameters k is 11.478473209488198 and b is -49.452181818198675\n",
      "Iteration 9207, the loss is 4.523435885878155, parameters k is 11.478505806326144 and b is -49.45214229250698\n",
      "Iteration 9208, the loss is 4.523435236296614, parameters k is 11.478488505930887 and b is -49.45211067195362\n",
      "Iteration 9209, the loss is 4.523434586715078, parameters k is 11.47847120553563 and b is -49.45207905140026\n",
      "Iteration 9210, the loss is 4.523434120460032, parameters k is 11.478453905140373 and b is -49.4520474308469\n",
      "Iteration 9211, the loss is 4.523433594190512, parameters k is 11.478486501978319 and b is -49.452007905155206\n",
      "Iteration 9212, the loss is 4.523432944608978, parameters k is 11.478469201583062 and b is -49.45197628460185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9213, the loss is 4.523432295027448, parameters k is 11.478451901187805 and b is -49.45194466404849\n",
      "Iteration 9214, the loss is 4.5234317792138645, parameters k is 11.478434600792548 and b is -49.45191304349513\n",
      "Iteration 9215, the loss is 4.52343130250288, parameters k is 11.478467197630494 and b is -49.451873517803435\n",
      "Iteration 9216, the loss is 4.523430652921344, parameters k is 11.478449897235237 and b is -49.45184189725008\n",
      "Iteration 9217, the loss is 4.523430003339804, parameters k is 11.47843259683998 and b is -49.45181027669672\n",
      "Iteration 9218, the loss is 4.5234294379676925, parameters k is 11.478415296444723 and b is -49.45177865614336\n",
      "Iteration 9219, the loss is 4.52342901081524, parameters k is 11.478447893282668 and b is -49.451739130451664\n",
      "Iteration 9220, the loss is 4.523428361233703, parameters k is 11.478430592887412 and b is -49.451707509898306\n",
      "Iteration 9221, the loss is 4.5234277116521655, parameters k is 11.478413292492155 and b is -49.45167588934495\n",
      "Iteration 9222, the loss is 4.523427096721525, parameters k is 11.478395992096898 and b is -49.45164426879159\n",
      "Iteration 9223, the loss is 4.5234267191276025, parameters k is 11.478428588934843 and b is -49.45160474309989\n",
      "Iteration 9224, the loss is 4.523426069546066, parameters k is 11.478411288539586 and b is -49.451573122546534\n",
      "Iteration 9225, the loss is 4.523425419964532, parameters k is 11.47839398814433 and b is -49.45154150199318\n",
      "Iteration 9226, the loss is 4.523424770382996, parameters k is 11.478376687749073 and b is -49.45150988143982\n",
      "Iteration 9227, the loss is 4.523424412532325, parameters k is 11.478359387353816 and b is -49.45147826088646\n",
      "Iteration 9228, the loss is 4.523423777858432, parameters k is 11.478391984191761 and b is -49.45143873519476\n",
      "Iteration 9229, the loss is 4.5234231282768915, parameters k is 11.478374683796504 and b is -49.451407114641405\n",
      "Iteration 9230, the loss is 4.523422478695357, parameters k is 11.478357383401248 and b is -49.45137549408805\n",
      "Iteration 9231, the loss is 4.523422071286159, parameters k is 11.47834008300599 and b is -49.45134387353469\n",
      "Iteration 9232, the loss is 4.5234214861707915, parameters k is 11.478372679843936 and b is -49.45130434784299\n",
      "Iteration 9233, the loss is 4.523420836589258, parameters k is 11.47835537944868 and b is -49.451272727289634\n",
      "Iteration 9234, the loss is 4.523420187007724, parameters k is 11.478338079053422 and b is -49.451241106736276\n",
      "Iteration 9235, the loss is 4.523419730039991, parameters k is 11.478320778658166 and b is -49.45120948618292\n",
      "Iteration 9236, the loss is 4.523419194483153, parameters k is 11.478353375496111 and b is -49.45116996049122\n",
      "Iteration 9237, the loss is 4.523418544901616, parameters k is 11.478336075100854 and b is -49.45113833993786\n",
      "Iteration 9238, the loss is 4.523417895320083, parameters k is 11.478318774705597 and b is -49.451106719384505\n",
      "Iteration 9239, the loss is 4.523417388793823, parameters k is 11.47830147431034 and b is -49.45107509883115\n",
      "Iteration 9240, the loss is 4.523416902795518, parameters k is 11.478334071148286 and b is -49.45103557313945\n",
      "Iteration 9241, the loss is 4.5234162532139806, parameters k is 11.478316770753029 and b is -49.45100395258609\n",
      "Iteration 9242, the loss is 4.523415603632445, parameters k is 11.478299470357772 and b is -49.450972332032734\n",
      "Iteration 9243, the loss is 4.523415047547652, parameters k is 11.478282169962515 and b is -49.450940711479376\n",
      "Iteration 9244, the loss is 4.52341461110788, parameters k is 11.47831476680046 and b is -49.45090118578768\n",
      "Iteration 9245, the loss is 4.523413961526345, parameters k is 11.478297466405204 and b is -49.45086956523432\n",
      "Iteration 9246, the loss is 4.523413311944809, parameters k is 11.478280166009947 and b is -49.45083794468096\n",
      "Iteration 9247, the loss is 4.523412706301483, parameters k is 11.47826286561469 and b is -49.450806324127605\n",
      "Iteration 9248, the loss is 4.523412319420238, parameters k is 11.478295462452635 and b is -49.45076679843591\n",
      "Iteration 9249, the loss is 4.523411669838706, parameters k is 11.478278162057379 and b is -49.45073517788255\n",
      "Iteration 9250, the loss is 4.523411020257172, parameters k is 11.478260861662122 and b is -49.45070355732919\n",
      "Iteration 9251, the loss is 4.523410370675633, parameters k is 11.478243561266865 and b is -49.450671936775834\n",
      "Iteration 9252, the loss is 4.523410022112283, parameters k is 11.478226260871608 and b is -49.450640316222476\n",
      "Iteration 9253, the loss is 4.523409378151065, parameters k is 11.478258857709553 and b is -49.45060079053078\n",
      "Iteration 9254, the loss is 4.523408728569536, parameters k is 11.478241557314297 and b is -49.45056916997742\n",
      "Iteration 9255, the loss is 4.5234080789879965, parameters k is 11.47822425691904 and b is -49.45053754942406\n",
      "Iteration 9256, the loss is 4.52340768086612, parameters k is 11.478206956523783 and b is -49.450505928870705\n",
      "Iteration 9257, the loss is 4.5234070864634335, parameters k is 11.478239553361728 and b is -49.45046640317901\n",
      "Iteration 9258, the loss is 4.523406436881895, parameters k is 11.478222252966471 and b is -49.45043478262565\n",
      "Iteration 9259, the loss is 4.5234057873003595, parameters k is 11.478204952571215 and b is -49.45040316207229\n",
      "Iteration 9260, the loss is 4.523405339619946, parameters k is 11.478187652175958 and b is -49.45037154151893\n",
      "Iteration 9261, the loss is 4.523404794775794, parameters k is 11.478220249013903 and b is -49.450332015827236\n",
      "Iteration 9262, the loss is 4.5234041451942595, parameters k is 11.478202948618646 and b is -49.45030039527388\n",
      "Iteration 9263, the loss is 4.52340349561272, parameters k is 11.47818564822339 and b is -49.45026877472052\n",
      "Iteration 9264, the loss is 4.523402998373783, parameters k is 11.478168347828133 and b is -49.45023715416716\n",
      "Iteration 9265, the loss is 4.523402503088158, parameters k is 11.478200944666078 and b is -49.450197628475465\n",
      "Iteration 9266, the loss is 4.523401853506624, parameters k is 11.478183644270821 and b is -49.45016600792211\n",
      "Iteration 9267, the loss is 4.523401203925087, parameters k is 11.478166343875564 and b is -49.45013438736875\n",
      "Iteration 9268, the loss is 4.523400657127617, parameters k is 11.478149043480308 and b is -49.45010276681539\n",
      "Iteration 9269, the loss is 4.523400211400521, parameters k is 11.478181640318253 and b is -49.450063241123694\n",
      "Iteration 9270, the loss is 4.5233995618189855, parameters k is 11.478164339922996 and b is -49.450031620570336\n",
      "Iteration 9271, the loss is 4.5233989122374485, parameters k is 11.47814703952774 and b is -49.45000000001698\n",
      "Iteration 9272, the loss is 4.523398315881446, parameters k is 11.478129739132482 and b is -49.44996837946362\n",
      "Iteration 9273, the loss is 4.523397919712879, parameters k is 11.478162335970428 and b is -49.44992885377192\n",
      "Iteration 9274, the loss is 4.523397270131346, parameters k is 11.47814503557517 and b is -49.449897233218564\n",
      "Iteration 9275, the loss is 4.523396620549814, parameters k is 11.478127735179914 and b is -49.44986561266521\n",
      "Iteration 9276, the loss is 4.523395974635276, parameters k is 11.478110434784657 and b is -49.44983399211185\n",
      "Iteration 9277, the loss is 4.523395628025246, parameters k is 11.478143031622603 and b is -49.44979446642015\n",
      "Iteration 9278, the loss is 4.52339497844371, parameters k is 11.478125731227346 and b is -49.44976284586679\n",
      "Iteration 9279, the loss is 4.523394328862175, parameters k is 11.478108430832089 and b is -49.449731225313435\n",
      "Iteration 9280, the loss is 4.523393679280641, parameters k is 11.478091130436832 and b is -49.44969960476008\n",
      "Iteration 9281, the loss is 4.523393290446075, parameters k is 11.478073830041575 and b is -49.44966798420672\n",
      "Iteration 9282, the loss is 4.523392686756073, parameters k is 11.47810642687952 and b is -49.44962845851502\n",
      "Iteration 9283, the loss is 4.523392037174533, parameters k is 11.478089126484264 and b is -49.449596837961664\n",
      "Iteration 9284, the loss is 4.523391387592996, parameters k is 11.478071826089007 and b is -49.449565217408306\n",
      "Iteration 9285, the loss is 4.5233909491999045, parameters k is 11.47805452569375 and b is -49.44953359685495\n",
      "Iteration 9286, the loss is 4.523390395068434, parameters k is 11.478087122531695 and b is -49.44949407116325\n",
      "Iteration 9287, the loss is 4.523389745486898, parameters k is 11.478069822136439 and b is -49.44946245060989\n",
      "Iteration 9288, the loss is 4.523389095905361, parameters k is 11.478052521741182 and b is -49.449430830056535\n",
      "Iteration 9289, the loss is 4.5233886079537395, parameters k is 11.478035221345925 and b is -49.44939920950318\n",
      "Iteration 9290, the loss is 4.523388103380797, parameters k is 11.47806781818387 and b is -49.44935968381148\n",
      "Iteration 9291, the loss is 4.523387453799259, parameters k is 11.478050517788613 and b is -49.44932806325812\n",
      "Iteration 9292, the loss is 4.523386804217723, parameters k is 11.478033217393357 and b is -49.449296442704764\n",
      "Iteration 9293, the loss is 4.523386266707566, parameters k is 11.4780159169981 and b is -49.449264822151406\n",
      "Iteration 9294, the loss is 4.523385811693156, parameters k is 11.478048513836045 and b is -49.44922529645971\n",
      "Iteration 9295, the loss is 4.523385162111626, parameters k is 11.478031213440788 and b is -49.44919367590635\n",
      "Iteration 9296, the loss is 4.523384512530091, parameters k is 11.478013913045531 and b is -49.44916205535299\n",
      "Iteration 9297, the loss is 4.523383925461398, parameters k is 11.477996612650275 and b is -49.449130434799635\n",
      "Iteration 9298, the loss is 4.523383520005519, parameters k is 11.47802920948822 and b is -49.44909090910794\n",
      "Iteration 9299, the loss is 4.523382870423986, parameters k is 11.478011909092963 and b is -49.44905928855458\n",
      "Iteration 9300, the loss is 4.523382220842448, parameters k is 11.477994608697706 and b is -49.44902766800122\n",
      "Iteration 9301, the loss is 4.523381584215236, parameters k is 11.47797730830245 and b is -49.448996047447864\n",
      "Iteration 9302, the loss is 4.523381228317882, parameters k is 11.478009905140395 and b is -49.448956521756166\n",
      "Iteration 9303, the loss is 4.523380578736348, parameters k is 11.477992604745138 and b is -49.44892490120281\n",
      "Iteration 9304, the loss is 4.523379929154815, parameters k is 11.477975304349881 and b is -49.44889328064945\n",
      "Iteration 9305, the loss is 4.523379279573279, parameters k is 11.477958003954624 and b is -49.44886166009609\n",
      "Iteration 9306, the loss is 4.523378900026037, parameters k is 11.477940703559367 and b is -49.448830039542734\n",
      "Iteration 9307, the loss is 4.523378287048713, parameters k is 11.477973300397313 and b is -49.44879051385104\n",
      "Iteration 9308, the loss is 4.523377637467172, parameters k is 11.477956000002056 and b is -49.44875889329768\n",
      "Iteration 9309, the loss is 4.523376987885639, parameters k is 11.4779386996068 and b is -49.44872727274432\n",
      "Iteration 9310, the loss is 4.523376558779867, parameters k is 11.477921399211542 and b is -49.44869565219096\n",
      "Iteration 9311, the loss is 4.5233759953610715, parameters k is 11.477953996049488 and b is -49.448656126499266\n",
      "Iteration 9312, the loss is 4.52337534577954, parameters k is 11.47793669565423 and b is -49.44862450594591\n",
      "Iteration 9313, the loss is 4.523374696198004, parameters k is 11.477919395258974 and b is -49.44859288539255\n",
      "Iteration 9314, the loss is 4.5233742175336955, parameters k is 11.477902094863717 and b is -49.44856126483919\n",
      "Iteration 9315, the loss is 4.5233737036734345, parameters k is 11.477934691701662 and b is -49.448521739147495\n",
      "Iteration 9316, the loss is 4.523373054091899, parameters k is 11.477917391306406 and b is -49.44849011859414\n",
      "Iteration 9317, the loss is 4.523372404510362, parameters k is 11.477900090911149 and b is -49.44845849804078\n",
      "Iteration 9318, the loss is 4.5233718762875315, parameters k is 11.477882790515892 and b is -49.44842687748742\n",
      "Iteration 9319, the loss is 4.523371411985794, parameters k is 11.477915387353837 and b is -49.44838735179572\n",
      "Iteration 9320, the loss is 4.5233707624042605, parameters k is 11.47789808695858 and b is -49.448355731242366\n",
      "Iteration 9321, the loss is 4.523370112822728, parameters k is 11.477880786563324 and b is -49.44832411068901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9322, the loss is 4.5233695350413585, parameters k is 11.477863486168067 and b is -49.44829249013565\n",
      "Iteration 9323, the loss is 4.5233691202981605, parameters k is 11.477896083006012 and b is -49.44825296444395\n",
      "Iteration 9324, the loss is 4.523368470716622, parameters k is 11.477878782610755 and b is -49.448221343890594\n",
      "Iteration 9325, the loss is 4.523367821135087, parameters k is 11.477861482215499 and b is -49.44818972333724\n",
      "Iteration 9326, the loss is 4.523367193795189, parameters k is 11.477844181820242 and b is -49.44815810278388\n",
      "Iteration 9327, the loss is 4.523366828610525, parameters k is 11.477876778658187 and b is -49.44811857709218\n",
      "Iteration 9328, the loss is 4.523366179028989, parameters k is 11.47785947826293 and b is -49.44808695653882\n",
      "Iteration 9329, the loss is 4.523365529447445, parameters k is 11.477842177867673 and b is -49.448055335985465\n",
      "Iteration 9330, the loss is 4.523364879865915, parameters k is 11.477824877472417 and b is -49.44802371543211\n",
      "Iteration 9331, the loss is 4.523364509605993, parameters k is 11.47780757707716 and b is -49.44799209487875\n",
      "Iteration 9332, the loss is 4.523363887341349, parameters k is 11.477840173915105 and b is -49.44795256918705\n",
      "Iteration 9333, the loss is 4.5233632377598125, parameters k is 11.477822873519848 and b is -49.447920948633694\n",
      "Iteration 9334, the loss is 4.52336258817828, parameters k is 11.477805573124591 and b is -49.447889328080336\n",
      "Iteration 9335, the loss is 4.523362168359825, parameters k is 11.477788272729335 and b is -49.44785770752698\n",
      "Iteration 9336, the loss is 4.52336159565371, parameters k is 11.47782086956728 and b is -49.44781818183528\n",
      "Iteration 9337, the loss is 4.5233609460721755, parameters k is 11.477803569172023 and b is -49.44778656128192\n",
      "Iteration 9338, the loss is 4.52336029649064, parameters k is 11.477786268776766 and b is -49.447754940728565\n",
      "Iteration 9339, the loss is 4.523359827113659, parameters k is 11.47776896838151 and b is -49.44772332017521\n",
      "Iteration 9340, the loss is 4.523359303966075, parameters k is 11.477801565219455 and b is -49.44768379448351\n",
      "Iteration 9341, the loss is 4.523358654384542, parameters k is 11.477784264824198 and b is -49.44765217393015\n",
      "Iteration 9342, the loss is 4.523358004803003, parameters k is 11.477766964428941 and b is -49.447620553376794\n",
      "Iteration 9343, the loss is 4.523357485867488, parameters k is 11.477749664033684 and b is -49.447588932823436\n",
      "Iteration 9344, the loss is 4.523357012278435, parameters k is 11.47778226087163 and b is -49.44754940713174\n",
      "Iteration 9345, the loss is 4.523356362696901, parameters k is 11.477764960476373 and b is -49.44751778657838\n",
      "Iteration 9346, the loss is 4.523355713115366, parameters k is 11.477747660081116 and b is -49.44748616602502\n",
      "Iteration 9347, the loss is 4.5233551446213145, parameters k is 11.477730359685859 and b is -49.447454545471665\n",
      "Iteration 9348, the loss is 4.523354720590802, parameters k is 11.477762956523804 and b is -49.44741501977997\n",
      "Iteration 9349, the loss is 4.5233540710092655, parameters k is 11.477745656128548 and b is -49.44738339922661\n",
      "Iteration 9350, the loss is 4.5233534214277284, parameters k is 11.47772835573329 and b is -49.44735177867325\n",
      "Iteration 9351, the loss is 4.523352803375152, parameters k is 11.477711055338034 and b is -49.447320158119894\n",
      "Iteration 9352, the loss is 4.5233524289031575, parameters k is 11.47774365217598 and b is -49.447280632428196\n",
      "Iteration 9353, the loss is 4.523351779321621, parameters k is 11.477726351780722 and b is -49.44724901187484\n",
      "Iteration 9354, the loss is 4.52335112974009, parameters k is 11.477709051385466 and b is -49.44721739132148\n",
      "Iteration 9355, the loss is 4.5233504801585545, parameters k is 11.477691750990209 and b is -49.44718577076812\n",
      "Iteration 9356, the loss is 4.5233501191859515, parameters k is 11.477674450594952 and b is -49.447154150214764\n",
      "Iteration 9357, the loss is 4.523349487633992, parameters k is 11.477707047432897 and b is -49.44711462452307\n",
      "Iteration 9358, the loss is 4.523348838052457, parameters k is 11.47768974703764 and b is -49.44708300396971\n",
      "Iteration 9359, the loss is 4.523348188470919, parameters k is 11.477672446642384 and b is -49.44705138341635\n",
      "Iteration 9360, the loss is 4.52334777793978, parameters k is 11.477655146247127 and b is -49.44701976286299\n",
      "Iteration 9361, the loss is 4.523347195946348, parameters k is 11.477687743085072 and b is -49.446980237171296\n",
      "Iteration 9362, the loss is 4.523346546364818, parameters k is 11.477670442689815 and b is -49.44694861661794\n",
      "Iteration 9363, the loss is 4.523345896783284, parameters k is 11.477653142294558 and b is -49.44691699606458\n",
      "Iteration 9364, the loss is 4.523345436693614, parameters k is 11.477635841899302 and b is -49.44688537551122\n",
      "Iteration 9365, the loss is 4.523344904258718, parameters k is 11.477668438737247 and b is -49.446845849819525\n",
      "Iteration 9366, the loss is 4.5233442546771725, parameters k is 11.47765113834199 and b is -49.44681422926617\n",
      "Iteration 9367, the loss is 4.523343605095639, parameters k is 11.477633837946733 and b is -49.44678260871281\n",
      "Iteration 9368, the loss is 4.523343095447444, parameters k is 11.477616537551476 and b is -49.44675098815945\n",
      "Iteration 9369, the loss is 4.523342612571075, parameters k is 11.477649134389422 and b is -49.44671146246775\n",
      "Iteration 9370, the loss is 4.523341962989542, parameters k is 11.477631833994165 and b is -49.446679841914396\n",
      "Iteration 9371, the loss is 4.523341313408005, parameters k is 11.477614533598908 and b is -49.44664822136104\n",
      "Iteration 9372, the loss is 4.523340754201274, parameters k is 11.477597233203651 and b is -49.44661660080768\n",
      "Iteration 9373, the loss is 4.523340320883439, parameters k is 11.477629830041597 and b is -49.44657707511598\n",
      "Iteration 9374, the loss is 4.523339671301901, parameters k is 11.47761252964634 and b is -49.446545454562624\n",
      "Iteration 9375, the loss is 4.5233390217203615, parameters k is 11.477595229251083 and b is -49.44651383400927\n",
      "Iteration 9376, the loss is 4.523338412955107, parameters k is 11.477577928855826 and b is -49.44648221345591\n",
      "Iteration 9377, the loss is 4.523338029195804, parameters k is 11.477610525693771 and b is -49.44644268776421\n",
      "Iteration 9378, the loss is 4.523337379614265, parameters k is 11.477593225298515 and b is -49.44641106721085\n",
      "Iteration 9379, the loss is 4.523336730032728, parameters k is 11.477575924903258 and b is -49.446379446657495\n",
      "Iteration 9380, the loss is 4.523336080451196, parameters k is 11.477558624508001 and b is -49.44634782610414\n",
      "Iteration 9381, the loss is 4.523335728765912, parameters k is 11.477541324112744 and b is -49.44631620555078\n",
      "Iteration 9382, the loss is 4.523335087926625, parameters k is 11.47757392095069 and b is -49.44627667985908\n",
      "Iteration 9383, the loss is 4.523334438345091, parameters k is 11.477556620555433 and b is -49.446245059305724\n",
      "Iteration 9384, the loss is 4.523333788763558, parameters k is 11.477539320160176 and b is -49.446213438752366\n",
      "Iteration 9385, the loss is 4.523333387519737, parameters k is 11.477522019764919 and b is -49.44618181819901\n",
      "Iteration 9386, the loss is 4.523332796238992, parameters k is 11.477554616602864 and b is -49.44614229250731\n",
      "Iteration 9387, the loss is 4.523332146657456, parameters k is 11.477537316207608 and b is -49.44611067195395\n",
      "Iteration 9388, the loss is 4.523331497075925, parameters k is 11.47752001581235 and b is -49.446079051400595\n",
      "Iteration 9389, the loss is 4.523331046273571, parameters k is 11.477502715417094 and b is -49.44604743084724\n",
      "Iteration 9390, the loss is 4.523330504551351, parameters k is 11.47753531225504 and b is -49.44600790515554\n",
      "Iteration 9391, the loss is 4.523329854969815, parameters k is 11.477518011859782 and b is -49.44597628460218\n",
      "Iteration 9392, the loss is 4.523329205388279, parameters k is 11.477500711464526 and b is -49.445944664048824\n",
      "Iteration 9393, the loss is 4.5233287050274065, parameters k is 11.477483411069269 and b is -49.445913043495466\n",
      "Iteration 9394, the loss is 4.523328212863717, parameters k is 11.477516007907214 and b is -49.44587351780377\n",
      "Iteration 9395, the loss is 4.523327563282178, parameters k is 11.477498707511957 and b is -49.44584189725041\n",
      "Iteration 9396, the loss is 4.523326913700648, parameters k is 11.4774814071167 and b is -49.44581027669705\n",
      "Iteration 9397, the loss is 4.523326363781236, parameters k is 11.477464106721444 and b is -49.445778656143695\n",
      "Iteration 9398, the loss is 4.5233259211760775, parameters k is 11.477496703559389 and b is -49.445739130452\n",
      "Iteration 9399, the loss is 4.523325271594544, parameters k is 11.477479403164132 and b is -49.44570750989864\n",
      "Iteration 9400, the loss is 4.523324622013006, parameters k is 11.477462102768875 and b is -49.44567588934528\n",
      "Iteration 9401, the loss is 4.523324022535065, parameters k is 11.477444802373618 and b is -49.44564426879192\n",
      "Iteration 9402, the loss is 4.5233236294884405, parameters k is 11.477477399211564 and b is -49.445604743100226\n",
      "Iteration 9403, the loss is 4.52332297990691, parameters k is 11.477460098816307 and b is -49.44557312254687\n",
      "Iteration 9404, the loss is 4.52332233032537, parameters k is 11.47744279842105 and b is -49.44554150199351\n",
      "Iteration 9405, the loss is 4.523321681288898, parameters k is 11.477425498025793 and b is -49.44550988144015\n",
      "Iteration 9406, the loss is 4.523321337800799, parameters k is 11.477458094863739 and b is -49.445470355748455\n",
      "Iteration 9407, the loss is 4.523320688219266, parameters k is 11.477440794468482 and b is -49.4454387351951\n",
      "Iteration 9408, the loss is 4.523320038637734, parameters k is 11.477423494073225 and b is -49.44540711464174\n",
      "Iteration 9409, the loss is 4.523319389056194, parameters k is 11.477406193677968 and b is -49.44537549408838\n",
      "Iteration 9410, the loss is 4.523318997099695, parameters k is 11.477388893282711 and b is -49.44534387353502\n",
      "Iteration 9411, the loss is 4.523318396531628, parameters k is 11.477421490120657 and b is -49.445304347843326\n",
      "Iteration 9412, the loss is 4.523317746950096, parameters k is 11.4774041897254 and b is -49.44527272728997\n",
      "Iteration 9413, the loss is 4.5233170973685555, parameters k is 11.477386889330143 and b is -49.44524110673661\n",
      "Iteration 9414, the loss is 4.52331665585353, parameters k is 11.477369588934886 and b is -49.44520948618325\n",
      "Iteration 9415, the loss is 4.52331610484399, parameters k is 11.477402185772831 and b is -49.445169960491555\n",
      "Iteration 9416, the loss is 4.523315455262456, parameters k is 11.477384885377575 and b is -49.4451383399382\n",
      "Iteration 9417, the loss is 4.523314805680922, parameters k is 11.477367584982318 and b is -49.44510671938484\n",
      "Iteration 9418, the loss is 4.523314314607363, parameters k is 11.477350284587061 and b is -49.44507509883148\n",
      "Iteration 9419, the loss is 4.523313813156356, parameters k is 11.477382881425006 and b is -49.44503557313978\n",
      "Iteration 9420, the loss is 4.523313163574819, parameters k is 11.47736558102975 and b is -49.445003952586426\n",
      "Iteration 9421, the loss is 4.523312513993286, parameters k is 11.477348280634493 and b is -49.44497233203307\n",
      "Iteration 9422, the loss is 4.523311973361193, parameters k is 11.477330980239236 and b is -49.44494071147971\n",
      "Iteration 9423, the loss is 4.523311521468715, parameters k is 11.477363577077181 and b is -49.44490118578801\n",
      "Iteration 9424, the loss is 4.523310871887182, parameters k is 11.477346276681924 and b is -49.444869565234654\n",
      "Iteration 9425, the loss is 4.523310222305645, parameters k is 11.477328976286667 and b is -49.4448379446813\n",
      "Iteration 9426, the loss is 4.523309632115026, parameters k is 11.47731167589141 and b is -49.44480632412794\n",
      "Iteration 9427, the loss is 4.523309229781079, parameters k is 11.477344272729356 and b is -49.44476679843624\n",
      "Iteration 9428, the loss is 4.523308580199547, parameters k is 11.4773269723341 and b is -49.44473517788288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9429, the loss is 4.523307930618014, parameters k is 11.477309671938842 and b is -49.444703557329525\n",
      "Iteration 9430, the loss is 4.523307290868858, parameters k is 11.477292371543586 and b is -49.44467193677617\n",
      "Iteration 9431, the loss is 4.523306938093445, parameters k is 11.47732496838153 and b is -49.44463241108447\n",
      "Iteration 9432, the loss is 4.523306288511907, parameters k is 11.477307667986274 and b is -49.44460079053111\n",
      "Iteration 9433, the loss is 4.523305638930369, parameters k is 11.477290367591017 and b is -49.444569169977754\n",
      "Iteration 9434, the loss is 4.523304989348837, parameters k is 11.47727306719576 and b is -49.444537549424396\n",
      "Iteration 9435, the loss is 4.523304606679654, parameters k is 11.477255766800504 and b is -49.44450592887104\n",
      "Iteration 9436, the loss is 4.523303996824271, parameters k is 11.477288363638449 and b is -49.44446640317934\n",
      "Iteration 9437, the loss is 4.5233033472427335, parameters k is 11.477271063243192 and b is -49.44443478262598\n",
      "Iteration 9438, the loss is 4.523302697661197, parameters k is 11.477253762847935 and b is -49.444403162072625\n",
      "Iteration 9439, the loss is 4.5233022654334905, parameters k is 11.477236462452678 and b is -49.44437154151927\n",
      "Iteration 9440, the loss is 4.523301705136632, parameters k is 11.477269059290624 and b is -49.44433201582757\n",
      "Iteration 9441, the loss is 4.523301055555097, parameters k is 11.477251758895367 and b is -49.44430039527421\n",
      "Iteration 9442, the loss is 4.5233004059735595, parameters k is 11.47723445850011 and b is -49.444268774720854\n",
      "Iteration 9443, the loss is 4.523299924187318, parameters k is 11.477217158104853 and b is -49.444237154167496\n",
      "Iteration 9444, the loss is 4.523299413448995, parameters k is 11.477249754942799 and b is -49.4441976284758\n",
      "Iteration 9445, the loss is 4.5232987638674595, parameters k is 11.477232454547542 and b is -49.44416600792244\n",
      "Iteration 9446, the loss is 4.523298114285925, parameters k is 11.477215154152285 and b is -49.44413438736908\n",
      "Iteration 9447, the loss is 4.523297582941149, parameters k is 11.477197853757028 and b is -49.444102766815725\n",
      "Iteration 9448, the loss is 4.523297121761354, parameters k is 11.477230450594973 and b is -49.44406324112403\n",
      "Iteration 9449, the loss is 4.5232964721798234, parameters k is 11.477213150199717 and b is -49.44403162057067\n",
      "Iteration 9450, the loss is 4.52329582259829, parameters k is 11.47719584980446 and b is -49.44400000001731\n",
      "Iteration 9451, the loss is 4.5232952416949805, parameters k is 11.477178549409203 and b is -49.44396837946395\n",
      "Iteration 9452, the loss is 4.523294830073719, parameters k is 11.477211146247148 and b is -49.443928853772256\n",
      "Iteration 9453, the loss is 4.523294180492183, parameters k is 11.477193845851891 and b is -49.4438972332189\n",
      "Iteration 9454, the loss is 4.523293530910651, parameters k is 11.477176545456635 and b is -49.44386561266554\n",
      "Iteration 9455, the loss is 4.523292900448812, parameters k is 11.477159245061378 and b is -49.44383399211218\n",
      "Iteration 9456, the loss is 4.523292538386082, parameters k is 11.477191841899323 and b is -49.443794466420485\n",
      "Iteration 9457, the loss is 4.523291888804545, parameters k is 11.477174541504066 and b is -49.44376284586713\n",
      "Iteration 9458, the loss is 4.523291239223006, parameters k is 11.47715724110881 and b is -49.44373122531377\n",
      "Iteration 9459, the loss is 4.523290589641474, parameters k is 11.477139940713553 and b is -49.44369960476041\n",
      "Iteration 9460, the loss is 4.523290216259614, parameters k is 11.477122640318296 and b is -49.44366798420705\n",
      "Iteration 9461, the loss is 4.523289597116912, parameters k is 11.477155237156241 and b is -49.443628458515356\n",
      "Iteration 9462, the loss is 4.523288947535375, parameters k is 11.477137936760984 and b is -49.443596837962\n",
      "Iteration 9463, the loss is 4.523288297953837, parameters k is 11.477120636365727 and b is -49.44356521740864\n",
      "Iteration 9464, the loss is 4.523287875013449, parameters k is 11.47710333597047 and b is -49.44353359685528\n",
      "Iteration 9465, the loss is 4.523287305429275, parameters k is 11.477135932808416 and b is -49.443494071163585\n",
      "Iteration 9466, the loss is 4.523286655847734, parameters k is 11.477118632413159 and b is -49.44346245061023\n",
      "Iteration 9467, the loss is 4.523286006266203, parameters k is 11.477101332017902 and b is -49.44343083005687\n",
      "Iteration 9468, the loss is 4.523285533767277, parameters k is 11.477084031622645 and b is -49.44339920950351\n",
      "Iteration 9469, the loss is 4.523285013741639, parameters k is 11.47711662846059 and b is -49.44335968381181\n",
      "Iteration 9470, the loss is 4.523284364160096, parameters k is 11.477099328065334 and b is -49.443328063258456\n",
      "Iteration 9471, the loss is 4.523283714578562, parameters k is 11.477082027670077 and b is -49.4432964427051\n",
      "Iteration 9472, the loss is 4.523283192521108, parameters k is 11.47706472727482 and b is -49.44326482215174\n",
      "Iteration 9473, the loss is 4.523282722053996, parameters k is 11.477097324112766 and b is -49.44322529646004\n",
      "Iteration 9474, the loss is 4.523282072472455, parameters k is 11.477080023717509 and b is -49.443193675906684\n",
      "Iteration 9475, the loss is 4.52328142289093, parameters k is 11.477062723322252 and b is -49.443162055353326\n",
      "Iteration 9476, the loss is 4.523280851274942, parameters k is 11.477045422926995 and b is -49.44313043479997\n",
      "Iteration 9477, the loss is 4.523280430366362, parameters k is 11.47707801976494 and b is -49.44309090910827\n",
      "Iteration 9478, the loss is 4.523279780784822, parameters k is 11.477060719369684 and b is -49.44305928855491\n",
      "Iteration 9479, the loss is 4.523279131203284, parameters k is 11.477043418974427 and b is -49.443027668001555\n",
      "Iteration 9480, the loss is 4.52327851002877, parameters k is 11.47702611857917 and b is -49.4429960474482\n",
      "Iteration 9481, the loss is 4.523278138678722, parameters k is 11.477058715417115 and b is -49.4429565217565\n",
      "Iteration 9482, the loss is 4.523277489097183, parameters k is 11.477041415021858 and b is -49.44292490120314\n",
      "Iteration 9483, the loss is 4.523276839515655, parameters k is 11.477024114626602 and b is -49.442893280649784\n",
      "Iteration 9484, the loss is 4.5232761899341165, parameters k is 11.477006814231345 and b is -49.442861660096426\n",
      "Iteration 9485, the loss is 4.523275825839574, parameters k is 11.476989513836088 and b is -49.44283003954307\n",
      "Iteration 9486, the loss is 4.523275197409545, parameters k is 11.477022110674033 and b is -49.44279051385137\n",
      "Iteration 9487, the loss is 4.523274547828014, parameters k is 11.477004810278777 and b is -49.44275889329801\n",
      "Iteration 9488, the loss is 4.523273898246473, parameters k is 11.47698750988352 and b is -49.442727272744655\n",
      "Iteration 9489, the loss is 4.523273484593405, parameters k is 11.476970209488263 and b is -49.4426956521913\n",
      "Iteration 9490, the loss is 4.523272905721909, parameters k is 11.477002806326208 and b is -49.4426561264996\n",
      "Iteration 9491, the loss is 4.523272256140375, parameters k is 11.476985505930951 and b is -49.44262450594624\n",
      "Iteration 9492, the loss is 4.52327160655884, parameters k is 11.476968205535695 and b is -49.442592885392884\n",
      "Iteration 9493, the loss is 4.523271143347239, parameters k is 11.476950905140438 and b is -49.442561264839526\n",
      "Iteration 9494, the loss is 4.523270614034271, parameters k is 11.476983501978383 and b is -49.44252173914783\n",
      "Iteration 9495, the loss is 4.523269964452736, parameters k is 11.476966201583126 and b is -49.44249011859447\n",
      "Iteration 9496, the loss is 4.523269314871202, parameters k is 11.47694890118787 and b is -49.44245849804111\n",
      "Iteration 9497, the loss is 4.5232688021010645, parameters k is 11.476931600792613 and b is -49.442426877487755\n",
      "Iteration 9498, the loss is 4.52326832234664, parameters k is 11.476964197630558 and b is -49.44238735179606\n",
      "Iteration 9499, the loss is 4.523267672765102, parameters k is 11.476946897235301 and b is -49.4423557312427\n",
      "Iteration 9500, the loss is 4.523267023183561, parameters k is 11.476929596840044 and b is -49.44232411068934\n",
      "Iteration 9501, the loss is 4.523266460854899, parameters k is 11.476912296444787 and b is -49.44229249013598\n",
      "Iteration 9502, the loss is 4.5232660306589985, parameters k is 11.476944893282733 and b is -49.442252964444286\n",
      "Iteration 9503, the loss is 4.523265381077462, parameters k is 11.476927592887476 and b is -49.44222134389093\n",
      "Iteration 9504, the loss is 4.523264731495928, parameters k is 11.476910292492219 and b is -49.44218972333757\n",
      "Iteration 9505, the loss is 4.523264119608728, parameters k is 11.476892992096962 and b is -49.44215810278421\n",
      "Iteration 9506, the loss is 4.523263738971366, parameters k is 11.476925588934908 and b is -49.442118577092515\n",
      "Iteration 9507, the loss is 4.523263089389826, parameters k is 11.47690828853965 and b is -49.44208695653916\n",
      "Iteration 9508, the loss is 4.5232624398082875, parameters k is 11.476890988144394 and b is -49.4420553359858\n",
      "Iteration 9509, the loss is 4.523261790226749, parameters k is 11.476873687749137 and b is -49.44202371543244\n",
      "Iteration 9510, the loss is 4.523261435419531, parameters k is 11.47685638735388 and b is -49.44199209487908\n",
      "Iteration 9511, the loss is 4.52326079770219, parameters k is 11.476888984191826 and b is -49.441952569187386\n",
      "Iteration 9512, the loss is 4.523260148120651, parameters k is 11.476871683796569 and b is -49.44192094863403\n",
      "Iteration 9513, the loss is 4.523259498539116, parameters k is 11.476854383401312 and b is -49.44188932808067\n",
      "Iteration 9514, the loss is 4.523259094173365, parameters k is 11.476837083006055 and b is -49.44185770752731\n",
      "Iteration 9515, the loss is 4.523258506014548, parameters k is 11.476869679844 and b is -49.441818181835615\n",
      "Iteration 9516, the loss is 4.523257856433016, parameters k is 11.476852379448744 and b is -49.44178656128226\n",
      "Iteration 9517, the loss is 4.523257206851482, parameters k is 11.476835079053487 and b is -49.4417549407289\n",
      "Iteration 9518, the loss is 4.523256752927196, parameters k is 11.47681777865823 and b is -49.44172332017554\n",
      "Iteration 9519, the loss is 4.523256214326914, parameters k is 11.476850375496175 and b is -49.44168379448384\n",
      "Iteration 9520, the loss is 4.523255564745378, parameters k is 11.476833075100918 and b is -49.441652173930486\n",
      "Iteration 9521, the loss is 4.523254915163842, parameters k is 11.476815774705662 and b is -49.44162055337713\n",
      "Iteration 9522, the loss is 4.523254411681028, parameters k is 11.476798474310405 and b is -49.44158893282377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9523, the loss is 4.523253922639276, parameters k is 11.47683107114835 and b is -49.44154940713207\n",
      "Iteration 9524, the loss is 4.5232532730577395, parameters k is 11.476813770753093 and b is -49.441517786578714\n",
      "Iteration 9525, the loss is 4.523252623476205, parameters k is 11.476796470357836 and b is -49.441486166025356\n",
      "Iteration 9526, the loss is 4.523252070434861, parameters k is 11.47677916996258 and b is -49.441454545472\n",
      "Iteration 9527, the loss is 4.523251630951635, parameters k is 11.476811766800525 and b is -49.4414150197803\n",
      "Iteration 9528, the loss is 4.523250981370105, parameters k is 11.476794466405268 and b is -49.44138339922694\n",
      "Iteration 9529, the loss is 4.523250331788568, parameters k is 11.476777166010011 and b is -49.441351778673585\n",
      "Iteration 9530, the loss is 4.5232497291886915, parameters k is 11.476759865614754 and b is -49.44132015812023\n",
      "Iteration 9531, the loss is 4.523249339264001, parameters k is 11.4767924624527 and b is -49.44128063242853\n",
      "Iteration 9532, the loss is 4.5232486896824655, parameters k is 11.476775162057443 and b is -49.44124901187517\n",
      "Iteration 9533, the loss is 4.523248040100924, parameters k is 11.476757861662186 and b is -49.441217391321814\n",
      "Iteration 9534, the loss is 4.523247390519393, parameters k is 11.47674056126693 and b is -49.441185770768456\n",
      "Iteration 9535, the loss is 4.523247044999492, parameters k is 11.476723260871672 and b is -49.4411541502151\n",
      "Iteration 9536, the loss is 4.523246397994828, parameters k is 11.476755857709618 and b is -49.4411146245234\n",
      "Iteration 9537, the loss is 4.523245748413295, parameters k is 11.476738557314361 and b is -49.44108300397004\n",
      "Iteration 9538, the loss is 4.5232450988317545, parameters k is 11.476721256919104 and b is -49.441051383416685\n",
      "Iteration 9539, the loss is 4.523244703753322, parameters k is 11.476703956523847 and b is -49.44101976286333\n",
      "Iteration 9540, the loss is 4.523244106307189, parameters k is 11.476736553361793 and b is -49.44098023717163\n",
      "Iteration 9541, the loss is 4.52324345672565, parameters k is 11.476719252966536 and b is -49.44094861661827\n",
      "Iteration 9542, the loss is 4.523242807144119, parameters k is 11.476701952571279 and b is -49.440916996064914\n",
      "Iteration 9543, the loss is 4.523242362507158, parameters k is 11.476684652176022 and b is -49.440885375511556\n",
      "Iteration 9544, the loss is 4.5232418146195545, parameters k is 11.476717249013968 and b is -49.44084584981986\n",
      "Iteration 9545, the loss is 4.523241165038014, parameters k is 11.47669994861871 and b is -49.4408142292665\n",
      "Iteration 9546, the loss is 4.523240515456485, parameters k is 11.476682648223454 and b is -49.44078260871314\n",
      "Iteration 9547, the loss is 4.5232400212609845, parameters k is 11.476665347828197 and b is -49.440750988159785\n",
      "Iteration 9548, the loss is 4.523239522931913, parameters k is 11.476697944666142 and b is -49.44071146246809\n",
      "Iteration 9549, the loss is 4.5232388733503806, parameters k is 11.476680644270886 and b is -49.44067984191473\n",
      "Iteration 9550, the loss is 4.523238223768843, parameters k is 11.476663343875629 and b is -49.44064822136137\n",
      "Iteration 9551, the loss is 4.523237680014819, parameters k is 11.476646043480372 and b is -49.44061660080801\n",
      "Iteration 9552, the loss is 4.52323723124428, parameters k is 11.476678640318317 and b is -49.440577075116316\n",
      "Iteration 9553, the loss is 4.523236581662743, parameters k is 11.47666133992306 and b is -49.44054545456296\n",
      "Iteration 9554, the loss is 4.523235932081211, parameters k is 11.476644039527804 and b is -49.4405138340096\n",
      "Iteration 9555, the loss is 4.523235338768651, parameters k is 11.476626739132547 and b is -49.44048221345624\n",
      "Iteration 9556, the loss is 4.5232349395566365, parameters k is 11.476659335970492 and b is -49.440442687764545\n",
      "Iteration 9557, the loss is 4.523234289975101, parameters k is 11.476642035575235 and b is -49.44041106721119\n",
      "Iteration 9558, the loss is 4.523233640393567, parameters k is 11.476624735179978 and b is -49.44037944665783\n",
      "Iteration 9559, the loss is 4.523232997522482, parameters k is 11.476607434784722 and b is -49.44034782610447\n",
      "Iteration 9560, the loss is 4.5232326478689995, parameters k is 11.476640031622667 and b is -49.440308300412774\n",
      "Iteration 9561, the loss is 4.523231998287464, parameters k is 11.47662273122741 and b is -49.440276679859416\n",
      "Iteration 9562, the loss is 4.523231348705931, parameters k is 11.476605430832153 and b is -49.44024505930606\n",
      "Iteration 9563, the loss is 4.523230699124393, parameters k is 11.476588130436896 and b is -49.4402134387527\n",
      "Iteration 9564, the loss is 4.523230313333281, parameters k is 11.47657083004164 and b is -49.44018181819934\n",
      "Iteration 9565, the loss is 4.523229706599829, parameters k is 11.476603426879585 and b is -49.440142292507645\n",
      "Iteration 9566, the loss is 4.523229057018293, parameters k is 11.476586126484328 and b is -49.44011067195429\n",
      "Iteration 9567, the loss is 4.523228407436756, parameters k is 11.476568826089071 and b is -49.44007905140093\n",
      "Iteration 9568, the loss is 4.5232279720871125, parameters k is 11.476551525693814 and b is -49.44004743084757\n",
      "Iteration 9569, the loss is 4.52322741491219, parameters k is 11.47658412253176 and b is -49.44000790515587\n",
      "Iteration 9570, the loss is 4.523226765330655, parameters k is 11.476566822136503 and b is -49.439976284602515\n",
      "Iteration 9571, the loss is 4.523226115749117, parameters k is 11.476549521741246 and b is -49.43994466404916\n",
      "Iteration 9572, the loss is 4.523225630840945, parameters k is 11.47653222134599 and b is -49.4399130434958\n",
      "Iteration 9573, the loss is 4.523225123224553, parameters k is 11.476564818183935 and b is -49.4398735178041\n",
      "Iteration 9574, the loss is 4.523224473643021, parameters k is 11.476547517788678 and b is -49.439841897250744\n",
      "Iteration 9575, the loss is 4.523223824061483, parameters k is 11.476530217393421 and b is -49.439810276697386\n",
      "Iteration 9576, the loss is 4.523223289594779, parameters k is 11.476512916998164 and b is -49.43977865614403\n",
      "Iteration 9577, the loss is 4.523222831536918, parameters k is 11.47654551383611 and b is -49.43973913045233\n",
      "Iteration 9578, the loss is 4.52322218195538, parameters k is 11.476528213440853 and b is -49.43970750989897\n",
      "Iteration 9579, the loss is 4.523221532373841, parameters k is 11.476510913045596 and b is -49.439675889345615\n",
      "Iteration 9580, the loss is 4.523220948348606, parameters k is 11.476493612650339 and b is -49.43964426879226\n",
      "Iteration 9581, the loss is 4.5232205398492775, parameters k is 11.476526209488284 and b is -49.43960474310056\n",
      "Iteration 9582, the loss is 4.523219890267743, parameters k is 11.476508909093027 and b is -49.4395731225472\n",
      "Iteration 9583, the loss is 4.5232192406862115, parameters k is 11.47649160869777 and b is -49.439541501993844\n",
      "Iteration 9584, the loss is 4.523218607102443, parameters k is 11.476474308302514 and b is -49.439509881440486\n",
      "Iteration 9585, the loss is 4.523218248161644, parameters k is 11.47650690514046 and b is -49.43947035574879\n",
      "Iteration 9586, the loss is 4.523217598580104, parameters k is 11.476489604745202 and b is -49.43943873519543\n",
      "Iteration 9587, the loss is 4.5232169489985665, parameters k is 11.476472304349945 and b is -49.43940711464207\n",
      "Iteration 9588, the loss is 4.52321629941703, parameters k is 11.476455003954689 and b is -49.439375494088715\n",
      "Iteration 9589, the loss is 4.523215922913238, parameters k is 11.476437703559432 and b is -49.43934387353536\n",
      "Iteration 9590, the loss is 4.523215306892468, parameters k is 11.476470300397377 and b is -49.43930434784366\n",
      "Iteration 9591, the loss is 4.523214657310932, parameters k is 11.47645300000212 and b is -49.4392727272903\n",
      "Iteration 9592, the loss is 4.523214007729399, parameters k is 11.476435699606863 and b is -49.439241106736944\n",
      "Iteration 9593, the loss is 4.52321358166707, parameters k is 11.476418399211607 and b is -49.439209486183586\n",
      "Iteration 9594, the loss is 4.523213015204827, parameters k is 11.476450996049552 and b is -49.43916996049189\n",
      "Iteration 9595, the loss is 4.523212365623294, parameters k is 11.476433695654295 and b is -49.43913833993853\n",
      "Iteration 9596, the loss is 4.523211716041757, parameters k is 11.476416395259038 and b is -49.43910671938517\n",
      "Iteration 9597, the loss is 4.523211240420899, parameters k is 11.476399094863782 and b is -49.439075098831815\n",
      "Iteration 9598, the loss is 4.523210723517193, parameters k is 11.476431691701727 and b is -49.43903557314012\n",
      "Iteration 9599, the loss is 4.523210073935661, parameters k is 11.47641439130647 and b is -49.43900395258676\n",
      "Iteration 9600, the loss is 4.523209424354122, parameters k is 11.476397090911213 and b is -49.4389723320334\n",
      "Iteration 9601, the loss is 4.523208899174735, parameters k is 11.476379790515956 and b is -49.43894071148004\n",
      "Iteration 9602, the loss is 4.523208431829554, parameters k is 11.476412387353902 and b is -49.438901185788346\n",
      "Iteration 9603, the loss is 4.523207782248022, parameters k is 11.476395086958645 and b is -49.43886956523499\n",
      "Iteration 9604, the loss is 4.523207132666484, parameters k is 11.476377786563388 and b is -49.43883794468163\n",
      "Iteration 9605, the loss is 4.523206557928567, parameters k is 11.476360486168131 and b is -49.43880632412827\n",
      "Iteration 9606, the loss is 4.523206140141915, parameters k is 11.476393083006077 and b is -49.438766798436575\n",
      "Iteration 9607, the loss is 4.523205490560385, parameters k is 11.47637578261082 and b is -49.43873517788322\n",
      "Iteration 9608, the loss is 4.523204840978841, parameters k is 11.476358482215563 and b is -49.43870355732986\n",
      "Iteration 9609, the loss is 4.523204216682398, parameters k is 11.476341181820306 and b is -49.4386719367765\n",
      "Iteration 9610, the loss is 4.523203848454282, parameters k is 11.476373778658251 and b is -49.438632411084804\n",
      "Iteration 9611, the loss is 4.523203198872745, parameters k is 11.476356478262995 and b is -49.438600790531446\n",
      "Iteration 9612, the loss is 4.523202549291213, parameters k is 11.476339177867738 and b is -49.43856916997809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9613, the loss is 4.523201899709673, parameters k is 11.476321877472481 and b is -49.43853754942473\n",
      "Iteration 9614, the loss is 4.5232015324931965, parameters k is 11.476304577077224 and b is -49.43850592887137\n",
      "Iteration 9615, the loss is 4.523200907185111, parameters k is 11.47633717391517 and b is -49.438466403179675\n",
      "Iteration 9616, the loss is 4.523200257603572, parameters k is 11.476319873519913 and b is -49.43843478262632\n",
      "Iteration 9617, the loss is 4.52319960802204, parameters k is 11.476302573124656 and b is -49.43840316207296\n",
      "Iteration 9618, the loss is 4.523199191247027, parameters k is 11.476285272729399 and b is -49.4383715415196\n",
      "Iteration 9619, the loss is 4.523198615497473, parameters k is 11.476317869567344 and b is -49.4383320158279\n",
      "Iteration 9620, the loss is 4.523197965915934, parameters k is 11.476300569172087 and b is -49.438300395274545\n",
      "Iteration 9621, the loss is 4.523197316334402, parameters k is 11.47628326877683 and b is -49.43826877472119\n",
      "Iteration 9622, the loss is 4.523196850000861, parameters k is 11.476265968381574 and b is -49.43823715416783\n",
      "Iteration 9623, the loss is 4.523196323809834, parameters k is 11.476298565219519 and b is -49.43819762847613\n",
      "Iteration 9624, the loss is 4.523195674228297, parameters k is 11.476281264824262 and b is -49.438166007922774\n",
      "Iteration 9625, the loss is 4.523195024646763, parameters k is 11.476263964429005 and b is -49.438134387369416\n",
      "Iteration 9626, the loss is 4.523194508754693, parameters k is 11.476246664033749 and b is -49.43810276681606\n",
      "Iteration 9627, the loss is 4.523194032122196, parameters k is 11.476279260871694 and b is -49.43806324112436\n",
      "Iteration 9628, the loss is 4.523193382540656, parameters k is 11.476261960476437 and b is -49.438031620571\n",
      "Iteration 9629, the loss is 4.523192732959121, parameters k is 11.47624466008118 and b is -49.438000000017645\n",
      "Iteration 9630, the loss is 4.523192167508524, parameters k is 11.476227359685923 and b is -49.43796837946429\n",
      "Iteration 9631, the loss is 4.523191740434559, parameters k is 11.476259956523869 and b is -49.43792885377259\n",
      "Iteration 9632, the loss is 4.5231910908530235, parameters k is 11.476242656128612 and b is -49.43789723321923\n",
      "Iteration 9633, the loss is 4.523190441271489, parameters k is 11.476225355733355 and b is -49.437865612665874\n",
      "Iteration 9634, the loss is 4.523189826262356, parameters k is 11.476208055338098 and b is -49.437833992112516\n",
      "Iteration 9635, the loss is 4.52318944874692, parameters k is 11.476240652176044 and b is -49.43779446642082\n",
      "Iteration 9636, the loss is 4.523188799165381, parameters k is 11.476223351780787 and b is -49.43776284586746\n",
      "Iteration 9637, the loss is 4.523188149583849, parameters k is 11.47620605138553 and b is -49.4377312253141\n",
      "Iteration 9638, the loss is 4.52318750000231, parameters k is 11.476188750990273 and b is -49.437699604760745\n",
      "Iteration 9639, the loss is 4.523187142073156, parameters k is 11.476171450595016 and b is -49.43766798420739\n",
      "Iteration 9640, the loss is 4.523186507477747, parameters k is 11.476204047432962 and b is -49.43762845851569\n",
      "Iteration 9641, the loss is 4.523185857896207, parameters k is 11.476186747037705 and b is -49.43759683796233\n",
      "Iteration 9642, the loss is 4.523185208314676, parameters k is 11.476169446642448 and b is -49.437565217408974\n",
      "Iteration 9643, the loss is 4.523184800826988, parameters k is 11.476152146247191 and b is -49.437533596855616\n",
      "Iteration 9644, the loss is 4.52318421579011, parameters k is 11.476184743085136 and b is -49.43749407116392\n",
      "Iteration 9645, the loss is 4.523183566208574, parameters k is 11.47616744268988 and b is -49.43746245061056\n",
      "Iteration 9646, the loss is 4.523182916627035, parameters k is 11.476150142294623 and b is -49.4374308300572\n",
      "Iteration 9647, the loss is 4.523182459580819, parameters k is 11.476132841899366 and b is -49.437399209503845\n",
      "Iteration 9648, the loss is 4.523181924102471, parameters k is 11.476165438737311 and b is -49.43735968381215\n",
      "Iteration 9649, the loss is 4.523181274520933, parameters k is 11.476148138342054 and b is -49.43732806325879\n",
      "Iteration 9650, the loss is 4.523180624939401, parameters k is 11.476130837946798 and b is -49.43729644270543\n",
      "Iteration 9651, the loss is 4.523180118334651, parameters k is 11.47611353755154 and b is -49.43726482215207\n",
      "Iteration 9652, the loss is 4.523179632414832, parameters k is 11.476146134389486 and b is -49.437225296460376\n",
      "Iteration 9653, the loss is 4.5231789828333016, parameters k is 11.47612883399423 and b is -49.43719367590702\n",
      "Iteration 9654, the loss is 4.523178333251757, parameters k is 11.476111533598973 and b is -49.43716205535366\n",
      "Iteration 9655, the loss is 4.523177777088484, parameters k is 11.476094233203716 and b is -49.4371304348003\n",
      "Iteration 9656, the loss is 4.523177340727194, parameters k is 11.476126830041661 and b is -49.437090909108605\n",
      "Iteration 9657, the loss is 4.523176691145662, parameters k is 11.476109529646404 and b is -49.43705928855525\n",
      "Iteration 9658, the loss is 4.523176041564126, parameters k is 11.476092229251147 and b is -49.43702766800189\n",
      "Iteration 9659, the loss is 4.523175435842313, parameters k is 11.47607492885589 and b is -49.43699604744853\n",
      "Iteration 9660, the loss is 4.523175049039553, parameters k is 11.476107525693836 and b is -49.436956521756834\n",
      "Iteration 9661, the loss is 4.523174399458024, parameters k is 11.476090225298579 and b is -49.436924901203476\n",
      "Iteration 9662, the loss is 4.523173749876487, parameters k is 11.476072924903322 and b is -49.43689328065012\n",
      "Iteration 9663, the loss is 4.523173100294954, parameters k is 11.476055624508065 and b is -49.43686166009676\n",
      "Iteration 9664, the loss is 4.523172751653114, parameters k is 11.476038324112809 and b is -49.4368300395434\n",
      "Iteration 9665, the loss is 4.523172107770384, parameters k is 11.476070920950754 and b is -49.436790513851705\n",
      "Iteration 9666, the loss is 4.523171458188847, parameters k is 11.476053620555497 and b is -49.43675889329835\n",
      "Iteration 9667, the loss is 4.523170808607317, parameters k is 11.47603632016024 and b is -49.43672727274499\n",
      "Iteration 9668, the loss is 4.523170410406947, parameters k is 11.476019019764983 and b is -49.43669565219163\n",
      "Iteration 9669, the loss is 4.523169816082745, parameters k is 11.476051616602929 and b is -49.43665612649993\n",
      "Iteration 9670, the loss is 4.523169166501212, parameters k is 11.476034316207672 and b is -49.436624505946575\n",
      "Iteration 9671, the loss is 4.523168516919678, parameters k is 11.476017015812415 and b is -49.43659288539322\n",
      "Iteration 9672, the loss is 4.523168069160777, parameters k is 11.475999715417158 and b is -49.43656126483986\n",
      "Iteration 9673, the loss is 4.523167524395111, parameters k is 11.476032312255104 and b is -49.43652173914816\n",
      "Iteration 9674, the loss is 4.523166874813578, parameters k is 11.476015011859847 and b is -49.436490118594804\n",
      "Iteration 9675, the loss is 4.523166225232043, parameters k is 11.47599771146459 and b is -49.436458498041446\n",
      "Iteration 9676, the loss is 4.523165727914611, parameters k is 11.475980411069333 and b is -49.43642687748809\n",
      "Iteration 9677, the loss is 4.523165232707473, parameters k is 11.476013007907278 and b is -49.43638735179639\n",
      "Iteration 9678, the loss is 4.523164583125941, parameters k is 11.475995707512022 and b is -49.43635573124303\n",
      "Iteration 9679, the loss is 4.523163933544401, parameters k is 11.475978407116765 and b is -49.436324110689675\n",
      "Iteration 9680, the loss is 4.523163386668436, parameters k is 11.475961106721508 and b is -49.43629249013632\n",
      "Iteration 9681, the loss is 4.523162941019839, parameters k is 11.475993703559453 and b is -49.43625296444462\n",
      "Iteration 9682, the loss is 4.523162291438295, parameters k is 11.475976403164196 and b is -49.43622134389126\n",
      "Iteration 9683, the loss is 4.523161641856763, parameters k is 11.47595910276894 and b is -49.436189723337904\n",
      "Iteration 9684, the loss is 4.5231610454222695, parameters k is 11.475941802373683 and b is -49.436158102784546\n",
      "Iteration 9685, the loss is 4.523160649332195, parameters k is 11.475974399211628 and b is -49.43611857709285\n",
      "Iteration 9686, the loss is 4.523159999750668, parameters k is 11.475957098816371 and b is -49.43608695653949\n",
      "Iteration 9687, the loss is 4.523159350169126, parameters k is 11.475939798421114 and b is -49.43605533598613\n",
      "Iteration 9688, the loss is 4.523158704176103, parameters k is 11.475922498025858 and b is -49.436023715432775\n",
      "Iteration 9689, the loss is 4.52315835764456, parameters k is 11.475955094863803 and b is -49.43598418974108\n",
      "Iteration 9690, the loss is 4.523157708063022, parameters k is 11.475937794468546 and b is -49.43595256918772\n",
      "Iteration 9691, the loss is 4.523157058481492, parameters k is 11.47592049407329 and b is -49.43592094863436\n",
      "Iteration 9692, the loss is 4.523156408899957, parameters k is 11.475903193678032 and b is -49.435889328081004\n",
      "Iteration 9693, the loss is 4.523156019986902, parameters k is 11.475885893282776 and b is -49.435857707527646\n",
      "Iteration 9694, the loss is 4.523155416375394, parameters k is 11.475918490120721 and b is -49.43581818183595\n",
      "Iteration 9695, the loss is 4.52315476679385, parameters k is 11.475901189725464 and b is -49.43578656128259\n",
      "Iteration 9696, the loss is 4.52315411721232, parameters k is 11.475883889330207 and b is -49.43575494072923\n",
      "Iteration 9697, the loss is 4.523153678740738, parameters k is 11.47586658893495 and b is -49.435723320175875\n",
      "Iteration 9698, the loss is 4.523153124687754, parameters k is 11.475899185772896 and b is -49.43568379448418\n",
      "Iteration 9699, the loss is 4.523152475106214, parameters k is 11.475881885377639 and b is -49.43565217393082\n",
      "Iteration 9700, the loss is 4.523151825524679, parameters k is 11.475864584982382 and b is -49.43562055337746\n",
      "Iteration 9701, the loss is 4.523151337494562, parameters k is 11.475847284587125 and b is -49.4355889328241\n",
      "Iteration 9702, the loss is 4.523150833000113, parameters k is 11.47587988142507 and b is -49.435549407132406\n",
      "Iteration 9703, the loss is 4.523150183418578, parameters k is 11.475862581029814 and b is -49.43551778657905\n",
      "Iteration 9704, the loss is 4.52314953383704, parameters k is 11.475845280634557 and b is -49.43548616602569\n",
      "Iteration 9705, the loss is 4.523148996248397, parameters k is 11.4758279802393 and b is -49.43545454547233\n",
      "Iteration 9706, the loss is 4.523148541312474, parameters k is 11.475860577077245 and b is -49.435415019780635\n",
      "Iteration 9707, the loss is 4.523147891730943, parameters k is 11.475843276681989 and b is -49.43538339922728\n",
      "Iteration 9708, the loss is 4.523147242149404, parameters k is 11.475825976286732 and b is -49.43535177867392\n",
      "Iteration 9709, the loss is 4.523146655002231, parameters k is 11.475808675891475 and b is -49.43532015812056\n",
      "Iteration 9710, the loss is 4.523146249624839, parameters k is 11.47584127272942 and b is -49.435280632428864\n",
      "Iteration 9711, the loss is 4.5231456000433035, parameters k is 11.475823972334164 and b is -49.435249011875506\n",
      "Iteration 9712, the loss is 4.523144950461769, parameters k is 11.475806671938907 and b is -49.43521739132215\n",
      "Iteration 9713, the loss is 4.523144313756067, parameters k is 11.47578937154365 and b is -49.43518577076879\n",
      "Iteration 9714, the loss is 4.5231439579372, parameters k is 11.475821968381595 and b is -49.43514624507709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9715, the loss is 4.5231433083556665, parameters k is 11.475804667986338 and b is -49.435114624523735\n",
      "Iteration 9716, the loss is 4.523142658774126, parameters k is 11.475787367591082 and b is -49.43508300397038\n",
      "Iteration 9717, the loss is 4.523142009192595, parameters k is 11.475770067195825 and b is -49.43505138341702\n",
      "Iteration 9718, the loss is 4.52314162956686, parameters k is 11.475752766800568 and b is -49.43501976286366\n",
      "Iteration 9719, the loss is 4.523141016668026, parameters k is 11.475785363638513 and b is -49.43498023717196\n",
      "Iteration 9720, the loss is 4.523140367086489, parameters k is 11.475768063243256 and b is -49.434948616618605\n",
      "Iteration 9721, the loss is 4.523139717504955, parameters k is 11.475750762848 and b is -49.43491699606525\n",
      "Iteration 9722, the loss is 4.523139288320691, parameters k is 11.475733462452743 and b is -49.43488537551189\n",
      "Iteration 9723, the loss is 4.523138724980387, parameters k is 11.475766059290688 and b is -49.43484584982019\n",
      "Iteration 9724, the loss is 4.523138075398855, parameters k is 11.475748758895431 and b is -49.434814229266834\n",
      "Iteration 9725, the loss is 4.523137425817317, parameters k is 11.475731458500174 and b is -49.434782608713476\n",
      "Iteration 9726, the loss is 4.5231369470745255, parameters k is 11.475714158104918 and b is -49.43475098816012\n",
      "Iteration 9727, the loss is 4.523136433292752, parameters k is 11.475746754942863 and b is -49.43471146246842\n",
      "Iteration 9728, the loss is 4.523135783711214, parameters k is 11.475729454547606 and b is -49.43467984191506\n",
      "Iteration 9729, the loss is 4.523135134129685, parameters k is 11.47571215415235 and b is -49.434648221361705\n",
      "Iteration 9730, the loss is 4.523134605828355, parameters k is 11.475694853757092 and b is -49.43461660080835\n",
      "Iteration 9731, the loss is 4.523134141605109, parameters k is 11.475727450595038 and b is -49.43457707511665\n",
      "Iteration 9732, the loss is 4.523133492023581, parameters k is 11.475710150199781 and b is -49.43454545456329\n",
      "Iteration 9733, the loss is 4.523132842442038, parameters k is 11.475692849804524 and b is -49.434513834009934\n",
      "Iteration 9734, the loss is 4.5231322645821885, parameters k is 11.475675549409267 and b is -49.434482213456576\n",
      "Iteration 9735, the loss is 4.523131849917473, parameters k is 11.475708146247213 and b is -49.43444268776488\n",
      "Iteration 9736, the loss is 4.523131200335939, parameters k is 11.475690845851956 and b is -49.43441106721152\n",
      "Iteration 9737, the loss is 4.5231305507544, parameters k is 11.475673545456699 and b is -49.43437944665816\n",
      "Iteration 9738, the loss is 4.523129923336021, parameters k is 11.475656245061442 and b is -49.434347826104805\n",
      "Iteration 9739, the loss is 4.5231295582298365, parameters k is 11.475688841899387 and b is -49.43430830041311\n",
      "Iteration 9740, the loss is 4.523128908648307, parameters k is 11.47567154150413 and b is -49.43427667985975\n",
      "Iteration 9741, the loss is 4.523128259066769, parameters k is 11.475654241108874 and b is -49.43424505930639\n",
      "Iteration 9742, the loss is 4.52312760948523, parameters k is 11.475636940713617 and b is -49.434213438753034\n",
      "Iteration 9743, the loss is 4.523127239146823, parameters k is 11.47561964031836 and b is -49.434181818199676\n",
      "Iteration 9744, the loss is 4.523126616960665, parameters k is 11.475652237156305 and b is -49.43414229250798\n",
      "Iteration 9745, the loss is 4.523125967379128, parameters k is 11.475634936761049 and b is -49.43411067195462\n",
      "Iteration 9746, the loss is 4.523125317797597, parameters k is 11.475617636365792 and b is -49.43407905140126\n",
      "Iteration 9747, the loss is 4.523124897900649, parameters k is 11.475600335970535 and b is -49.434047430847905\n",
      "Iteration 9748, the loss is 4.523124325273032, parameters k is 11.47563293280848 and b is -49.43400790515621\n",
      "Iteration 9749, the loss is 4.52312367569149, parameters k is 11.475615632413223 and b is -49.43397628460285\n",
      "Iteration 9750, the loss is 4.523123026109959, parameters k is 11.475598332017967 and b is -49.43394466404949\n",
      "Iteration 9751, the loss is 4.5231225566544815, parameters k is 11.47558103162271 and b is -49.43391304349613\n",
      "Iteration 9752, the loss is 4.523122033585392, parameters k is 11.475613628460655 and b is -49.433873517804436\n",
      "Iteration 9753, the loss is 4.523121384003858, parameters k is 11.475596328065398 and b is -49.43384189725108\n",
      "Iteration 9754, the loss is 4.52312073442232, parameters k is 11.475579027670141 and b is -49.43381027669772\n",
      "Iteration 9755, the loss is 4.523120215408314, parameters k is 11.475561727274885 and b is -49.43377865614436\n",
      "Iteration 9756, the loss is 4.5231197418977525, parameters k is 11.47559432411283 and b is -49.433739130452665\n",
      "Iteration 9757, the loss is 4.523119092316222, parameters k is 11.475577023717573 and b is -49.43370750989931\n",
      "Iteration 9758, the loss is 4.523118442734681, parameters k is 11.475559723322316 and b is -49.43367588934595\n",
      "Iteration 9759, the loss is 4.523117874162145, parameters k is 11.47554242292706 and b is -49.43364426879259\n",
      "Iteration 9760, the loss is 4.523117450210116, parameters k is 11.475575019765005 and b is -49.433604743100894\n",
      "Iteration 9761, the loss is 4.523116800628581, parameters k is 11.475557719369748 and b is -49.433573122547536\n",
      "Iteration 9762, the loss is 4.523116151047044, parameters k is 11.475540418974491 and b is -49.43354150199418\n",
      "Iteration 9763, the loss is 4.523115532915977, parameters k is 11.475523118579234 and b is -49.43350988144082\n",
      "Iteration 9764, the loss is 4.523115158522478, parameters k is 11.47555571541718 and b is -49.43347035574912\n",
      "Iteration 9765, the loss is 4.523114508940943, parameters k is 11.475538415021923 and b is -49.433438735195764\n",
      "Iteration 9766, the loss is 4.523113859359409, parameters k is 11.475521114626666 and b is -49.43340711464241\n",
      "Iteration 9767, the loss is 4.523113209777872, parameters k is 11.47550381423141 and b is -49.43337549408905\n",
      "Iteration 9768, the loss is 4.523112848726777, parameters k is 11.475486513836152 and b is -49.43334387353569\n",
      "Iteration 9769, the loss is 4.523112217253308, parameters k is 11.475519110674098 and b is -49.43330434784399\n",
      "Iteration 9770, the loss is 4.523111567671772, parameters k is 11.47550181027884 and b is -49.433272727290635\n",
      "Iteration 9771, the loss is 4.523110918090231, parameters k is 11.475484509883584 and b is -49.43324110673728\n",
      "Iteration 9772, the loss is 4.5231105074806095, parameters k is 11.475467209488327 and b is -49.43320948618392\n",
      "Iteration 9773, the loss is 4.523109925565666, parameters k is 11.475499806326273 and b is -49.43316996049222\n",
      "Iteration 9774, the loss is 4.523109275984131, parameters k is 11.475482505931016 and b is -49.433138339938864\n",
      "Iteration 9775, the loss is 4.5231086264025935, parameters k is 11.475465205535759 and b is -49.433106719385506\n",
      "Iteration 9776, the loss is 4.523108166234446, parameters k is 11.475447905140502 and b is -49.43307509883215\n",
      "Iteration 9777, the loss is 4.523107633878028, parameters k is 11.475480501978447 and b is -49.43303557314045\n",
      "Iteration 9778, the loss is 4.523106984296489, parameters k is 11.47546320158319 and b is -49.43300395258709\n",
      "Iteration 9779, the loss is 4.523106334714958, parameters k is 11.475445901187934 and b is -49.432972332033735\n",
      "Iteration 9780, the loss is 4.523105824988273, parameters k is 11.475428600792677 and b is -49.43294071148038\n",
      "Iteration 9781, the loss is 4.5231053421903935, parameters k is 11.475461197630622 and b is -49.43290118578868\n",
      "Iteration 9782, the loss is 4.52310469260886, parameters k is 11.475443897235365 and b is -49.43286956523532\n",
      "Iteration 9783, the loss is 4.52310404302732, parameters k is 11.475426596840109 and b is -49.432837944681964\n",
      "Iteration 9784, the loss is 4.523103483742106, parameters k is 11.475409296444852 and b is -49.432806324128606\n",
      "Iteration 9785, the loss is 4.523103050502756, parameters k is 11.475441893282797 and b is -49.43276679843691\n",
      "Iteration 9786, the loss is 4.523102400921216, parameters k is 11.47542459288754 and b is -49.43273517788355\n",
      "Iteration 9787, the loss is 4.52310175133969, parameters k is 11.475407292492283 and b is -49.43270355733019\n",
      "Iteration 9788, the loss is 4.523101142495937, parameters k is 11.475389992097027 and b is -49.432671936776835\n",
      "Iteration 9789, the loss is 4.523100758815115, parameters k is 11.475422588934972 and b is -49.43263241108514\n",
      "Iteration 9790, the loss is 4.523100109233584, parameters k is 11.475405288539715 and b is -49.43260079053178\n",
      "Iteration 9791, the loss is 4.523099459652045, parameters k is 11.475387988144458 and b is -49.43256916997842\n",
      "Iteration 9792, the loss is 4.523098810070509, parameters k is 11.475370687749201 and b is -49.432537549425064\n",
      "Iteration 9793, the loss is 4.523098458306739, parameters k is 11.475353387353945 and b is -49.432505928871706\n",
      "Iteration 9794, the loss is 4.523097817545943, parameters k is 11.47538598419189 and b is -49.43246640318001\n",
      "Iteration 9795, the loss is 4.523097167964411, parameters k is 11.475368683796633 and b is -49.43243478262665\n",
      "Iteration 9796, the loss is 4.523096518382874, parameters k is 11.475351383401376 and b is -49.43240316207329\n",
      "Iteration 9797, the loss is 4.523096117060576, parameters k is 11.47533408300612 and b is -49.432371541519935\n",
      "Iteration 9798, the loss is 4.5230955258583085, parameters k is 11.475366679844065 and b is -49.43233201582824\n",
      "Iteration 9799, the loss is 4.523094876276777, parameters k is 11.475349379448808 and b is -49.43230039527488\n",
      "Iteration 9800, the loss is 4.523094226695237, parameters k is 11.475332079053551 and b is -49.43226877472152\n",
      "Iteration 9801, the loss is 4.523093775814399, parameters k is 11.475314778658294 and b is -49.43223715416816\n",
      "Iteration 9802, the loss is 4.5230932341706644, parameters k is 11.47534737549624 and b is -49.432197628476466\n",
      "Iteration 9803, the loss is 4.523092584589136, parameters k is 11.475330075100983 and b is -49.43216600792311\n",
      "Iteration 9804, the loss is 4.523091935007593, parameters k is 11.475312774705726 and b is -49.43213438736975\n",
      "Iteration 9805, the loss is 4.523091434568237, parameters k is 11.47529547431047 and b is -49.43210276681639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9806, the loss is 4.523090942483027, parameters k is 11.475328071148414 and b is -49.432063241124695\n",
      "Iteration 9807, the loss is 4.5230902929015, parameters k is 11.475310770753158 and b is -49.43203162057134\n",
      "Iteration 9808, the loss is 4.5230896433199606, parameters k is 11.4752934703579 and b is -49.43200000001798\n",
      "Iteration 9809, the loss is 4.523089093322066, parameters k is 11.475276169962644 and b is -49.43196837946462\n",
      "Iteration 9810, the loss is 4.523088650795391, parameters k is 11.47530876680059 and b is -49.431928853772924\n",
      "Iteration 9811, the loss is 4.523088001213859, parameters k is 11.475291466405332 and b is -49.431897233219566\n",
      "Iteration 9812, the loss is 4.523087351632324, parameters k is 11.475274166010076 and b is -49.43186561266621\n",
      "Iteration 9813, the loss is 4.523086752075897, parameters k is 11.475256865614819 and b is -49.43183399211285\n",
      "Iteration 9814, the loss is 4.523086359107758, parameters k is 11.475289462452764 and b is -49.43179446642115\n",
      "Iteration 9815, the loss is 4.523085709526217, parameters k is 11.475272162057507 and b is -49.431762845867794\n",
      "Iteration 9816, the loss is 4.523085059944686, parameters k is 11.47525486166225 and b is -49.43173122531444\n",
      "Iteration 9817, the loss is 4.523084410829729, parameters k is 11.475237561266994 and b is -49.43169960476108\n",
      "Iteration 9818, the loss is 4.523084067420118, parameters k is 11.475270158104939 and b is -49.43166007906938\n",
      "Iteration 9819, the loss is 4.523083417838584, parameters k is 11.475252857709682 and b is -49.43162845851602\n",
      "Iteration 9820, the loss is 4.523082768257048, parameters k is 11.475235557314425 and b is -49.431596837962665\n",
      "Iteration 9821, the loss is 4.523082118675517, parameters k is 11.475218256919169 and b is -49.43156521740931\n",
      "Iteration 9822, the loss is 4.523081726640527, parameters k is 11.475200956523912 and b is -49.43153359685595\n",
      "Iteration 9823, the loss is 4.523081126150944, parameters k is 11.475233553361857 and b is -49.43149407116425\n",
      "Iteration 9824, the loss is 4.523080476569409, parameters k is 11.4752162529666 and b is -49.431462450610894\n",
      "Iteration 9825, the loss is 4.523079826987877, parameters k is 11.475198952571343 and b is -49.431430830057536\n",
      "Iteration 9826, the loss is 4.523079385394358, parameters k is 11.475181652176087 and b is -49.43139920950418\n",
      "Iteration 9827, the loss is 4.523078834463305, parameters k is 11.475214249014032 and b is -49.43135968381248\n",
      "Iteration 9828, the loss is 4.523078184881772, parameters k is 11.475196948618775 and b is -49.43132806325912\n",
      "Iteration 9829, the loss is 4.523077535300236, parameters k is 11.475179648223518 and b is -49.431296442705765\n",
      "Iteration 9830, the loss is 4.5230770441481924, parameters k is 11.475162347828261 and b is -49.43126482215241\n",
      "Iteration 9831, the loss is 4.523076542775673, parameters k is 11.475194944666207 and b is -49.43122529646071\n",
      "Iteration 9832, the loss is 4.523075893194135, parameters k is 11.47517764427095 and b is -49.43119367590735\n",
      "Iteration 9833, the loss is 4.523075243612599, parameters k is 11.475160343875693 and b is -49.431162055353994\n",
      "Iteration 9834, the loss is 4.523074702902021, parameters k is 11.475143043480436 and b is -49.431130434800636\n",
      "Iteration 9835, the loss is 4.523074251088036, parameters k is 11.475175640318382 and b is -49.43109090910894\n",
      "Iteration 9836, the loss is 4.5230736015065025, parameters k is 11.475158339923125 and b is -49.43105928855558\n",
      "Iteration 9837, the loss is 4.523072951924963, parameters k is 11.475141039527868 and b is -49.43102766800222\n",
      "Iteration 9838, the loss is 4.523072361655855, parameters k is 11.475123739132611 and b is -49.430996047448865\n",
      "Iteration 9839, the loss is 4.523071959400398, parameters k is 11.475156335970556 and b is -49.43095652175717\n",
      "Iteration 9840, the loss is 4.52307130981886, parameters k is 11.4751390355753 and b is -49.43092490120381\n",
      "Iteration 9841, the loss is 4.523070660237328, parameters k is 11.475121735180043 and b is -49.43089328065045\n",
      "Iteration 9842, the loss is 4.523070020409685, parameters k is 11.475104434784786 and b is -49.430861660097094\n",
      "Iteration 9843, the loss is 4.523069667712756, parameters k is 11.475137031622731 and b is -49.430822134405396\n",
      "Iteration 9844, the loss is 4.523069018131223, parameters k is 11.475119731227474 and b is -49.43079051385204\n",
      "Iteration 9845, the loss is 4.523068368549688, parameters k is 11.475102430832218 and b is -49.43075889329868\n",
      "Iteration 9846, the loss is 4.5230677189681545, parameters k is 11.47508513043696 and b is -49.43072727274532\n",
      "Iteration 9847, the loss is 4.523067336220485, parameters k is 11.475067830041704 and b is -49.430695652191964\n",
      "Iteration 9848, the loss is 4.523066726443585, parameters k is 11.47510042687965 and b is -49.43065612650027\n",
      "Iteration 9849, the loss is 4.523066076862047, parameters k is 11.475083126484392 and b is -49.43062450594691\n",
      "Iteration 9850, the loss is 4.523065427280513, parameters k is 11.475065826089136 and b is -49.43059288539355\n",
      "Iteration 9851, the loss is 4.523064994974315, parameters k is 11.475048525693879 and b is -49.43056126484019\n",
      "Iteration 9852, the loss is 4.523064434755949, parameters k is 11.475081122531824 and b is -49.430521739148496\n",
      "Iteration 9853, the loss is 4.5230637851744175, parameters k is 11.475063822136567 and b is -49.43049011859514\n",
      "Iteration 9854, the loss is 4.523063135592878, parameters k is 11.47504652174131 and b is -49.43045849804178\n",
      "Iteration 9855, the loss is 4.5230626537281475, parameters k is 11.475029221346054 and b is -49.43042687748842\n",
      "Iteration 9856, the loss is 4.523062143068313, parameters k is 11.475061818183999 and b is -49.430387351796725\n",
      "Iteration 9857, the loss is 4.523061493486775, parameters k is 11.475044517788742 and b is -49.43035573124337\n",
      "Iteration 9858, the loss is 4.523060843905243, parameters k is 11.475027217393485 and b is -49.43032411069001\n",
      "Iteration 9859, the loss is 4.52306031248198, parameters k is 11.475009916998228 and b is -49.43029249013665\n",
      "Iteration 9860, the loss is 4.52305985138067, parameters k is 11.475042513836174 and b is -49.43025296444495\n",
      "Iteration 9861, the loss is 4.52305920179914, parameters k is 11.475025213440917 and b is -49.430221343891596\n",
      "Iteration 9862, the loss is 4.5230585522175994, parameters k is 11.47500791304566 and b is -49.43018972333824\n",
      "Iteration 9863, the loss is 4.523057971235811, parameters k is 11.474990612650403 and b is -49.43015810278488\n",
      "Iteration 9864, the loss is 4.523057559693033, parameters k is 11.475023209488349 and b is -49.43011857709318\n",
      "Iteration 9865, the loss is 4.5230569101114995, parameters k is 11.475005909093092 and b is -49.430086956539824\n",
      "Iteration 9866, the loss is 4.523056260529964, parameters k is 11.474988608697835 and b is -49.43005533598647\n",
      "Iteration 9867, the loss is 4.523055629989638, parameters k is 11.474971308302578 and b is -49.43002371543311\n",
      "Iteration 9868, the loss is 4.523055268005396, parameters k is 11.475003905140523 and b is -49.42998418974141\n",
      "Iteration 9869, the loss is 4.523054618423858, parameters k is 11.474986604745267 and b is -49.42995256918805\n",
      "Iteration 9870, the loss is 4.523053968842326, parameters k is 11.47496930435001 and b is -49.429920948634695\n",
      "Iteration 9871, the loss is 4.523053319260792, parameters k is 11.474952003954753 and b is -49.42988932808134\n",
      "Iteration 9872, the loss is 4.523052945800441, parameters k is 11.474934703559496 and b is -49.42985770752798\n",
      "Iteration 9873, the loss is 4.523052326736227, parameters k is 11.474967300397442 and b is -49.42981818183628\n",
      "Iteration 9874, the loss is 4.523051677154689, parameters k is 11.474950000002185 and b is -49.429786561282924\n",
      "Iteration 9875, the loss is 4.523051027573152, parameters k is 11.474932699606928 and b is -49.429754940729566\n",
      "Iteration 9876, the loss is 4.523050604554278, parameters k is 11.474915399211671 and b is -49.42972332017621\n",
      "Iteration 9877, the loss is 4.523050035048584, parameters k is 11.474947996049616 and b is -49.42968379448451\n",
      "Iteration 9878, the loss is 4.52304938546705, parameters k is 11.47493069565436 and b is -49.42965217393115\n",
      "Iteration 9879, the loss is 4.52304873588551, parameters k is 11.474913395259103 and b is -49.429620553377795\n",
      "Iteration 9880, the loss is 4.523048263308105, parameters k is 11.474896094863846 and b is -49.42958893282444\n",
      "Iteration 9881, the loss is 4.523047743360949, parameters k is 11.474928691701791 and b is -49.42954940713274\n",
      "Iteration 9882, the loss is 4.523047093779413, parameters k is 11.474911391306534 and b is -49.42951778657938\n",
      "Iteration 9883, the loss is 4.5230464441978775, parameters k is 11.474894090911278 and b is -49.429486166026024\n",
      "Iteration 9884, the loss is 4.523045922061939, parameters k is 11.47487679051602 and b is -49.429454545472666\n",
      "Iteration 9885, the loss is 4.523045451673308, parameters k is 11.474909387353966 and b is -49.42941501978097\n",
      "Iteration 9886, the loss is 4.5230448020917775, parameters k is 11.47489208695871 and b is -49.42938339922761\n",
      "Iteration 9887, the loss is 4.523044152510245, parameters k is 11.474874786563452 and b is -49.42935177867425\n",
      "Iteration 9888, the loss is 4.523043580815768, parameters k is 11.474857486168196 and b is -49.429320158120895\n",
      "Iteration 9889, the loss is 4.523043159985674, parameters k is 11.47489008300614 and b is -49.4292806324292\n",
      "Iteration 9890, the loss is 4.523042510404143, parameters k is 11.474872782610884 and b is -49.42924901187584\n",
      "Iteration 9891, the loss is 4.5230418608226035, parameters k is 11.474855482215627 and b is -49.42921739132248\n",
      "Iteration 9892, the loss is 4.523041239569606, parameters k is 11.47483818182037 and b is -49.429185770769124\n",
      "Iteration 9893, the loss is 4.523040868298039, parameters k is 11.474870778658316 and b is -49.429146245077426\n",
      "Iteration 9894, the loss is 4.523040218716507, parameters k is 11.474853478263059 and b is -49.42911462452407\n",
      "Iteration 9895, the loss is 4.5230395691349665, parameters k is 11.474836177867802 and b is -49.42908300397071\n",
      "Iteration 9896, the loss is 4.523038919553429, parameters k is 11.474818877472545 and b is -49.42905138341735\n",
      "Iteration 9897, the loss is 4.523038555380398, parameters k is 11.474801577077288 and b is -49.429019762863994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9898, the loss is 4.523037927028866, parameters k is 11.474834173915234 and b is -49.4289802371723\n",
      "Iteration 9899, the loss is 4.523037277447332, parameters k is 11.474816873519977 and b is -49.42894861661894\n",
      "Iteration 9900, the loss is 4.523036627865792, parameters k is 11.47479957312472 and b is -49.42891699606558\n",
      "Iteration 9901, the loss is 4.523036214134235, parameters k is 11.474782272729463 and b is -49.42888537551222\n",
      "Iteration 9902, the loss is 4.523035635341227, parameters k is 11.474814869567409 and b is -49.428845849820526\n",
      "Iteration 9903, the loss is 4.523034985759693, parameters k is 11.474797569172152 and b is -49.42881422926717\n",
      "Iteration 9904, the loss is 4.523034336178154, parameters k is 11.474780268776895 and b is -49.42878260871381\n",
      "Iteration 9905, the loss is 4.523033872888067, parameters k is 11.474762968381638 and b is -49.42875098816045\n",
      "Iteration 9906, the loss is 4.523033343653584, parameters k is 11.474795565219583 and b is -49.428711462468755\n",
      "Iteration 9907, the loss is 4.523032694072057, parameters k is 11.474778264824327 and b is -49.4286798419154\n",
      "Iteration 9908, the loss is 4.523032044490519, parameters k is 11.47476096442907 and b is -49.42864822136204\n",
      "Iteration 9909, the loss is 4.523031531641902, parameters k is 11.474743664033813 and b is -49.42861660080868\n",
      "Iteration 9910, the loss is 4.523031051965946, parameters k is 11.474776260871758 and b is -49.42857707511698\n",
      "Iteration 9911, the loss is 4.523030402384414, parameters k is 11.474758960476501 and b is -49.428545454563626\n",
      "Iteration 9912, the loss is 4.5230297528028816, parameters k is 11.474741660081245 and b is -49.42851383401027\n",
      "Iteration 9913, the loss is 4.523029190395727, parameters k is 11.474724359685988 and b is -49.42848221345691\n",
      "Iteration 9914, the loss is 4.523028760278313, parameters k is 11.474756956523933 and b is -49.42844268776521\n",
      "Iteration 9915, the loss is 4.523028110696778, parameters k is 11.474739656128676 and b is -49.428411067211854\n",
      "Iteration 9916, the loss is 4.523027461115241, parameters k is 11.47472235573342 and b is -49.4283794466585\n",
      "Iteration 9917, the loss is 4.5230268491495575, parameters k is 11.474705055338163 and b is -49.42834782610514\n",
      "Iteration 9918, the loss is 4.523026468590675, parameters k is 11.474737652176108 and b is -49.42830830041344\n",
      "Iteration 9919, the loss is 4.523025819009137, parameters k is 11.474720351780851 and b is -49.42827667986008\n",
      "Iteration 9920, the loss is 4.523025169427602, parameters k is 11.474703051385594 and b is -49.428245059306725\n",
      "Iteration 9921, the loss is 4.523024519846072, parameters k is 11.474685750990337 and b is -49.42821343875337\n",
      "Iteration 9922, the loss is 4.523024164960364, parameters k is 11.47466845059508 and b is -49.42818181820001\n",
      "Iteration 9923, the loss is 4.523023527321501, parameters k is 11.474701047433026 and b is -49.42814229250831\n",
      "Iteration 9924, the loss is 4.523022877739964, parameters k is 11.47468374703777 and b is -49.428110671954954\n",
      "Iteration 9925, the loss is 4.523022228158433, parameters k is 11.474666446642512 and b is -49.428079051401596\n",
      "Iteration 9926, the loss is 4.523021823714188, parameters k is 11.474649146247256 and b is -49.42804743084824\n",
      "Iteration 9927, the loss is 4.523021235633869, parameters k is 11.4746817430852 and b is -49.42800790515654\n",
      "Iteration 9928, the loss is 4.523020586052332, parameters k is 11.474664442689944 and b is -49.42797628460318\n",
      "Iteration 9929, the loss is 4.523019936470792, parameters k is 11.474647142294687 and b is -49.427944664049825\n",
      "Iteration 9930, the loss is 4.523019482468025, parameters k is 11.47462984189943 and b is -49.42791304349647\n",
      "Iteration 9931, the loss is 4.523018943946228, parameters k is 11.474662438737376 and b is -49.42787351780477\n",
      "Iteration 9932, the loss is 4.523018294364695, parameters k is 11.474645138342119 and b is -49.42784189725141\n",
      "Iteration 9933, the loss is 4.52301764478316, parameters k is 11.474627837946862 and b is -49.427810276698054\n",
      "Iteration 9934, the loss is 4.52301714122185, parameters k is 11.474610537551605 and b is -49.427778656144696\n",
      "Iteration 9935, the loss is 4.523016652258591, parameters k is 11.47464313438955 and b is -49.427739130453\n",
      "Iteration 9936, the loss is 4.523016002677055, parameters k is 11.474625833994294 and b is -49.42770750989964\n",
      "Iteration 9937, the loss is 4.523015353095523, parameters k is 11.474608533599037 and b is -49.42767588934628\n",
      "Iteration 9938, the loss is 4.523014799975692, parameters k is 11.47459123320378 and b is -49.427644268792925\n",
      "Iteration 9939, the loss is 4.523014360570953, parameters k is 11.474623830041725 and b is -49.42760474310123\n",
      "Iteration 9940, the loss is 4.52301371098942, parameters k is 11.474606529646469 and b is -49.42757312254787\n",
      "Iteration 9941, the loss is 4.523013061407883, parameters k is 11.474589229251212 and b is -49.42754150199451\n",
      "Iteration 9942, the loss is 4.523012458729525, parameters k is 11.474571928855955 and b is -49.42750988144115\n",
      "Iteration 9943, the loss is 4.5230120688833155, parameters k is 11.4746045256939 and b is -49.427470355749456\n",
      "Iteration 9944, the loss is 4.523011419301782, parameters k is 11.474587225298643 and b is -49.4274387351961\n",
      "Iteration 9945, the loss is 4.523010769720246, parameters k is 11.474569924903387 and b is -49.42740711464274\n",
      "Iteration 9946, the loss is 4.5230101201387125, parameters k is 11.47455262450813 and b is -49.42737549408938\n",
      "Iteration 9947, the loss is 4.523009774540315, parameters k is 11.474535324112873 and b is -49.427343873536024\n",
      "Iteration 9948, the loss is 4.523009127614142, parameters k is 11.474567920950818 and b is -49.42730434784433\n",
      "Iteration 9949, the loss is 4.523008478032602, parameters k is 11.474550620555561 and b is -49.42727272729097\n",
      "Iteration 9950, the loss is 4.523007828451072, parameters k is 11.474533320160305 and b is -49.42724110673761\n",
      "Iteration 9951, the loss is 4.523007433294145, parameters k is 11.474516019765048 and b is -49.42720948618425\n",
      "Iteration 9952, the loss is 4.523006835926505, parameters k is 11.474548616602993 and b is -49.427169960492556\n",
      "Iteration 9953, the loss is 4.523006186344966, parameters k is 11.474531316207736 and b is -49.4271383399392\n",
      "Iteration 9954, the loss is 4.523005536763445, parameters k is 11.47451401581248 and b is -49.42710671938584\n",
      "Iteration 9955, the loss is 4.523005092047985, parameters k is 11.474496715417223 and b is -49.42707509883248\n",
      "Iteration 9956, the loss is 4.52300454423887, parameters k is 11.474529312255168 and b is -49.427035573140785\n",
      "Iteration 9957, the loss is 4.523003894657331, parameters k is 11.474512011859911 and b is -49.42700395258743\n",
      "Iteration 9958, the loss is 4.523003245075794, parameters k is 11.474494711464654 and b is -49.42697233203407\n",
      "Iteration 9959, the loss is 4.52300275080181, parameters k is 11.474477411069397 and b is -49.42694071148071\n",
      "Iteration 9960, the loss is 4.523002252551224, parameters k is 11.474510007907343 and b is -49.42690118578901\n",
      "Iteration 9961, the loss is 4.523001602969692, parameters k is 11.474492707512086 and b is -49.426869565235656\n",
      "Iteration 9962, the loss is 4.523000953388157, parameters k is 11.47447540711683 and b is -49.4268379446823\n",
      "Iteration 9963, the loss is 4.523000409555644, parameters k is 11.474458106721572 and b is -49.42680632412894\n",
      "Iteration 9964, the loss is 4.522999960863597, parameters k is 11.474490703559518 and b is -49.42676679843724\n",
      "Iteration 9965, the loss is 4.522999311282057, parameters k is 11.47447340316426 and b is -49.426735177883884\n",
      "Iteration 9966, the loss is 4.52299866170052, parameters k is 11.474456102769004 and b is -49.42670355733053\n",
      "Iteration 9967, the loss is 4.5229980683094775, parameters k is 11.474438802373747 and b is -49.42667193677717\n",
      "Iteration 9968, the loss is 4.522997669175957, parameters k is 11.474471399211692 and b is -49.42663241108547\n",
      "Iteration 9969, the loss is 4.522997019594423, parameters k is 11.474454098816436 and b is -49.42660079053211\n",
      "Iteration 9970, the loss is 4.522996370012885, parameters k is 11.474436798421179 and b is -49.426569169978755\n",
      "Iteration 9971, the loss is 4.52299572706331, parameters k is 11.474419498025922 and b is -49.4265375494254\n",
      "Iteration 9972, the loss is 4.522995377488315, parameters k is 11.474452094863867 and b is -49.4264980237337\n",
      "Iteration 9973, the loss is 4.522994727906784, parameters k is 11.47443479446861 and b is -49.42646640318034\n",
      "Iteration 9974, the loss is 4.52299407832525, parameters k is 11.474417494073354 and b is -49.426434782626984\n",
      "Iteration 9975, the loss is 4.522993428743712, parameters k is 11.474400193678097 and b is -49.426403162073626\n",
      "Iteration 9976, the loss is 4.522993042874114, parameters k is 11.47438289328284 and b is -49.42637154152027\n",
      "Iteration 9977, the loss is 4.522992436219148, parameters k is 11.474415490120785 and b is -49.42633201582857\n",
      "Iteration 9978, the loss is 4.522991786637609, parameters k is 11.474398189725528 and b is -49.42630039527521\n",
      "Iteration 9979, the loss is 4.522991137056074, parameters k is 11.474380889330272 and b is -49.426268774721855\n",
      "Iteration 9980, the loss is 4.52299070162794, parameters k is 11.474363588935015 and b is -49.4262371541685\n",
      "Iteration 9981, the loss is 4.5229901445315095, parameters k is 11.47439618577296 and b is -49.4261976284768\n",
      "Iteration 9982, the loss is 4.522989494949968, parameters k is 11.474378885377703 and b is -49.42616600792344\n",
      "Iteration 9983, the loss is 4.5229888453684355, parameters k is 11.474361584982447 and b is -49.426134387370084\n",
      "Iteration 9984, the loss is 4.522988360381773, parameters k is 11.47434428458719 and b is -49.426102766816726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9985, the loss is 4.522987852843871, parameters k is 11.474376881425135 and b is -49.42606324112503\n",
      "Iteration 9986, the loss is 4.522987203262335, parameters k is 11.474359581029878 and b is -49.42603162057167\n",
      "Iteration 9987, the loss is 4.522986553680799, parameters k is 11.474342280634621 and b is -49.42600000001831\n",
      "Iteration 9988, the loss is 4.522986019135603, parameters k is 11.474324980239365 and b is -49.425968379464955\n",
      "Iteration 9989, the loss is 4.522985561156229, parameters k is 11.47435757707731 and b is -49.42592885377326\n",
      "Iteration 9990, the loss is 4.522984911574694, parameters k is 11.474340276682053 and b is -49.4258972332199\n",
      "Iteration 9991, the loss is 4.522984261993159, parameters k is 11.474322976286796 and b is -49.42586561266654\n",
      "Iteration 9992, the loss is 4.52298367788944, parameters k is 11.47430567589154 and b is -49.42583399211318\n",
      "Iteration 9993, the loss is 4.522983269468595, parameters k is 11.474338272729485 and b is -49.425794466421486\n",
      "Iteration 9994, the loss is 4.52298261988706, parameters k is 11.474320972334228 and b is -49.42576284586813\n",
      "Iteration 9995, the loss is 4.522981970305526, parameters k is 11.474303671938971 and b is -49.42573122531477\n",
      "Iteration 9996, the loss is 4.522981336643267, parameters k is 11.474286371543714 and b is -49.42569960476141\n",
      "Iteration 9997, the loss is 4.522980977780954, parameters k is 11.47431896838166 and b is -49.425660079069715\n",
      "Iteration 9998, the loss is 4.52298032819942, parameters k is 11.474301667986403 and b is -49.42562845851636\n",
      "Iteration 9999, the loss is 4.522979678617883, parameters k is 11.474284367591146 and b is -49.425596837963\n"
     ]
    }
   ],
   "source": [
    "#initialized parameters\n",
    "\n",
    "k = random.random() * 200 - 100  # -100 100\n",
    "b = random.random() * 200 - 100  # -100 100\n",
    "k = 10\n",
    "b = -50\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "iteration_num = 10000\n",
    "losses = []\n",
    "for i in range(iteration_num):\n",
    "    \n",
    "    price_use_current_parameters = [price(r, k, b) for r in X_rm]  # \\hat{y}\n",
    "    \n",
    "    current_loss = loss(y, price_use_current_parameters)\n",
    "    losses.append(current_loss)\n",
    "    print(\"Iteration {}, the loss is {}, parameters k is {} and b is {}\".format(i,current_loss,k,b))\n",
    "    \n",
    "    k_gradient = partial_derivative_k(X_rm, y, price_use_current_parameters)\n",
    "    b_gradient = partial_derivative_b(y, price_use_current_parameters)\n",
    "    \n",
    "    k = k + (-1 * k_gradient) * learning_rate\n",
    "    b = b + (-1 * b_gradient) * learning_rate\n",
    "best_k = k\n",
    "best_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b7e3b5b1d0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(losses))),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b7e3b28470>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_use_best_parameters = [price(r, best_k, best_b) for r in X_rm]\n",
    "\n",
    "plt.scatter(X_rm,y)\n",
    "plt.scatter(X_rm,price_use_current_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.474267067195889"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.42556521740964"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "+ 是否将Loss改成了“绝对值”(3')\n",
    "+ 是否完成了偏导的重新定义(5')\n",
    "+ 新的模型Loss是否能够收敛 (11’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
